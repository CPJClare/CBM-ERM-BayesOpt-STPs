{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9wHutsqZUcn"
      },
      "source": [
        "XGBoost Regression - 'real-world' example: Californian Housing Dataset\n",
        "\n",
        "https://scikit-learn.org/stable/datasets/real_world.html#california-housing-dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-0Pe1i4Z2R_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "295dd488-3781-4578-b94b-60bd466c5279"
      },
      "source": [
        "!pip install pyGPGO"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyGPGO\n",
            "  Downloading pyGPGO-0.5.1.tar.gz (14 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pyGPGO) (1.21.6)\n",
            "Requirement already satisfied: mkl in /usr/local/lib/python3.7/dist-packages (from pyGPGO) (2019.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from pyGPGO) (1.7.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from pyGPGO) (1.1.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from pyGPGO) (1.0.2)\n",
            "Collecting Theano-PyMC\n",
            "  Downloading Theano-PyMC-1.1.2.tar.gz (1.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8 MB 5.1 MB/s \n",
            "\u001b[?25hCollecting pyMC3\n",
            "  Downloading pymc3-3.11.5-py3-none-any.whl (872 kB)\n",
            "\u001b[K     |████████████████████████████████| 872 kB 40.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: intel-openmp in /usr/local/lib/python3.7/dist-packages (from mkl->pyGPGO) (2022.1.0)\n",
            "Requirement already satisfied: arviz>=0.11.0 in /usr/local/lib/python3.7/dist-packages (from pyMC3->pyGPGO) (0.12.1)\n",
            "Requirement already satisfied: cachetools>=4.2.1 in /usr/local/lib/python3.7/dist-packages (from pyMC3->pyGPGO) (4.2.4)\n",
            "Requirement already satisfied: fastprogress>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from pyMC3->pyGPGO) (1.0.3)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from pyMC3->pyGPGO) (1.3.5)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from pyMC3->pyGPGO) (4.1.1)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.7/dist-packages (from pyMC3->pyGPGO) (0.5.2)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from pyMC3->pyGPGO) (0.3.5.1)\n",
            "Collecting deprecat\n",
            "  Downloading deprecat-2.1.1-py2.py3-none-any.whl (9.8 kB)\n",
            "Collecting semver>=2.13.0\n",
            "  Downloading semver-2.13.0-py2.py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from Theano-PyMC->pyGPGO) (3.8.0)\n",
            "Requirement already satisfied: matplotlib>=3.0 in /usr/local/lib/python3.7/dist-packages (from arviz>=0.11.0->pyMC3->pyGPGO) (3.2.2)\n",
            "Requirement already satisfied: setuptools>=38.4 in /usr/local/lib/python3.7/dist-packages (from arviz>=0.11.0->pyMC3->pyGPGO) (57.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from arviz>=0.11.0->pyMC3->pyGPGO) (21.3)\n",
            "Requirement already satisfied: netcdf4 in /usr/local/lib/python3.7/dist-packages (from arviz>=0.11.0->pyMC3->pyGPGO) (1.6.0)\n",
            "Requirement already satisfied: xarray-einstats>=0.2 in /usr/local/lib/python3.7/dist-packages (from arviz>=0.11.0->pyMC3->pyGPGO) (0.2.2)\n",
            "Requirement already satisfied: xarray>=0.16.1 in /usr/local/lib/python3.7/dist-packages (from arviz>=0.11.0->pyMC3->pyGPGO) (0.20.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0->arviz>=0.11.0->pyMC3->pyGPGO) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0->arviz>=0.11.0->pyMC3->pyGPGO) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0->arviz>=0.11.0->pyMC3->pyGPGO) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0->arviz>=0.11.0->pyMC3->pyGPGO) (1.4.4)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->pyMC3->pyGPGO) (2022.2.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from patsy>=0.5.1->pyMC3->pyGPGO) (1.15.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from xarray>=0.16.1->arviz>=0.11.0->pyMC3->pyGPGO) (4.12.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from deprecat->pyMC3->pyGPGO) (1.14.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->xarray>=0.16.1->arviz>=0.11.0->pyMC3->pyGPGO) (3.8.1)\n",
            "Requirement already satisfied: cftime in /usr/local/lib/python3.7/dist-packages (from netcdf4->arviz>=0.11.0->pyMC3->pyGPGO) (1.6.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pyGPGO) (3.1.0)\n",
            "Building wheels for collected packages: pyGPGO, Theano-PyMC\n",
            "  Building wheel for pyGPGO (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyGPGO: filename=pyGPGO-0.5.1-py3-none-any.whl size=19879 sha256=c812f5830032bfc9a2bf654ef8d54ecfc17340c9024d67736dd9e9bdd4e46059\n",
            "  Stored in directory: /root/.cache/pip/wheels/c8/5d/0b/2160114e2f1b87791c51b66cf07f89831dbb6f49167950316f\n",
            "  Building wheel for Theano-PyMC (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for Theano-PyMC: filename=Theano_PyMC-1.1.2-py3-none-any.whl size=1529963 sha256=21b1105b9cfc9eca636f868ebc51865b2c9255f6f1ff4fae12a36458a487c376\n",
            "  Stored in directory: /root/.cache/pip/wheels/f3/af/8c/5dd7553522d74c52a7813806fc7ee1a9caa20a3f7c8fd850d5\n",
            "Successfully built pyGPGO Theano-PyMC\n",
            "Installing collected packages: Theano-PyMC, semver, deprecat, pyMC3, pyGPGO\n",
            "Successfully installed Theano-PyMC-1.1.2 deprecat-2.1.1 pyGPGO-0.5.1 pyMC3-3.11.5 semver-2.13.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7zDTf1naBsH"
      },
      "source": [
        "# Load some default Python modules:\n",
        "\n",
        "import numpy as np\n",
        "import scipy as sp\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import xgboost as xgb\n",
        "import time\n",
        "\n",
        "from matplotlib.pyplot import rc\n",
        "rc('font',**{'family':'sans-serif','sans-serif':['Helvetica']})\n",
        "rc('text', usetex=False)\n",
        "import seaborn as sns\n",
        "plt.style.use('seaborn-whitegrid')\n",
        "\n",
        "from collections import OrderedDict\n",
        "from joblib import Parallel, delayed\n",
        "from numpy.linalg import slogdet, inv, cholesky, solve\n",
        "from scipy.optimize import minimize\n",
        "from scipy.spatial.distance import cdist\n",
        "from scipy.special import gamma\n",
        "from scipy.stats import norm, t\n",
        "from joblib import Parallel, delayed\n",
        "import itertools\n",
        "\n",
        "from pyGPGO.logger import EventLogger\n",
        "from pyGPGO.GPGO import GPGO\n",
        "from pyGPGO.surrogates.GaussianProcess import GaussianProcess\n",
        "from pyGPGO.surrogates.tStudentProcess import tStudentProcess\n",
        "from pyGPGO.acquisition import Acquisition\n",
        "from pyGPGO.covfunc import squaredExponential\n",
        "from sklearn.model_selection import cross_val_score, train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from xgboost import XGBRegressor\n",
        "from pandas_datareader import data\n",
        "\n",
        "import warnings\n",
        "import random\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXicekJhaE0P"
      },
      "source": [
        "# Read data in pandas dataframe:\n",
        "df_train =  pd.read_csv('/content/sample_data/california_housing_train.csv')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQ0mDzt_cBmw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "outputId": "c29d6700-2478-4234-f223-8d06642a1930"
      },
      "source": [
        "# List first rows:\n",
        "\n",
        "df_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
              "0    -114.31     34.19                15.0       5612.0          1283.0   \n",
              "1    -114.47     34.40                19.0       7650.0          1901.0   \n",
              "2    -114.56     33.69                17.0        720.0           174.0   \n",
              "3    -114.57     33.64                14.0       1501.0           337.0   \n",
              "4    -114.57     33.57                20.0       1454.0           326.0   \n",
              "\n",
              "   population  households  median_income  median_house_value  \n",
              "0      1015.0       472.0         1.4936             66900.0  \n",
              "1      1129.0       463.0         1.8200             80100.0  \n",
              "2       333.0       117.0         1.6509             85700.0  \n",
              "3       515.0       226.0         3.1917             73400.0  \n",
              "4       624.0       262.0         1.9250             65500.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bec68a38-1912-4c89-8c4f-dbdbb0b3e678\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>longitude</th>\n",
              "      <th>latitude</th>\n",
              "      <th>housing_median_age</th>\n",
              "      <th>total_rooms</th>\n",
              "      <th>total_bedrooms</th>\n",
              "      <th>population</th>\n",
              "      <th>households</th>\n",
              "      <th>median_income</th>\n",
              "      <th>median_house_value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-114.31</td>\n",
              "      <td>34.19</td>\n",
              "      <td>15.0</td>\n",
              "      <td>5612.0</td>\n",
              "      <td>1283.0</td>\n",
              "      <td>1015.0</td>\n",
              "      <td>472.0</td>\n",
              "      <td>1.4936</td>\n",
              "      <td>66900.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-114.47</td>\n",
              "      <td>34.40</td>\n",
              "      <td>19.0</td>\n",
              "      <td>7650.0</td>\n",
              "      <td>1901.0</td>\n",
              "      <td>1129.0</td>\n",
              "      <td>463.0</td>\n",
              "      <td>1.8200</td>\n",
              "      <td>80100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-114.56</td>\n",
              "      <td>33.69</td>\n",
              "      <td>17.0</td>\n",
              "      <td>720.0</td>\n",
              "      <td>174.0</td>\n",
              "      <td>333.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>1.6509</td>\n",
              "      <td>85700.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-114.57</td>\n",
              "      <td>33.64</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1501.0</td>\n",
              "      <td>337.0</td>\n",
              "      <td>515.0</td>\n",
              "      <td>226.0</td>\n",
              "      <td>3.1917</td>\n",
              "      <td>73400.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-114.57</td>\n",
              "      <td>33.57</td>\n",
              "      <td>20.0</td>\n",
              "      <td>1454.0</td>\n",
              "      <td>326.0</td>\n",
              "      <td>624.0</td>\n",
              "      <td>262.0</td>\n",
              "      <td>1.9250</td>\n",
              "      <td>65500.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bec68a38-1912-4c89-8c4f-dbdbb0b3e678')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bec68a38-1912-4c89-8c4f-dbdbb0b3e678 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bec68a38-1912-4c89-8c4f-dbdbb0b3e678');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTVDAD2KchTv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b28f0c5-8acb-4ad5-8348-a7c266bf4fe3"
      },
      "source": [
        "# Remove missing data:\n",
        "\n",
        "df_train = df_train.dropna(how = 'any', axis = 'rows')\n",
        "print('New size: %d' % len(df_train))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New size: 17000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXgSHPyYcnuv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "outputId": "a39deca7-328d-4316-cf59-c98e88445e23"
      },
      "source": [
        "# Histogram fare plot:\n",
        "\n",
        "df_train.median_house_value.hist(bins=100, figsize=(16,5), color = \"red\")\n",
        "plt.xlabel('$ US Dollars', weight = 'bold', family = 'Arial')\n",
        "plt.title('Median Californian House Price', weight = 'bold', family = 'Arial')\n",
        "plt.grid(b=None)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.font_manager:findfont: Font family ['Arial'] not found. Falling back to DejaVu Sans.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family ['Arial'] not found. Falling back to DejaVu Sans.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1152x360 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA58AAAFJCAYAAAAc6ZlnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de1xU5b7H8e8ozCYML0OMpqlpKroVSNC2onhJrSgrMiEjNNtW3tOT5gU5Hrvf3ZXZzfRolkmiGZUJu45auxATirRSwy7eCAZBSS6iuM4f+zAnUhhSFs7g5/16+Xo5z7o9a/kU8+X3rLUshmEYAgAAAADARI3OdwcAAAAAAA0f4RMAAAAAYDrCJwAAAADAdIRPAAAAAIDpCJ8AAAAAANMRPgEAAAAApiN8AgCqtWjRIgUGBmrSpEmSpPT0dAUGBurqq68+zz2r2R/7eeDAAQUGBiowMNC5Tk5OjkaPHq3g4GAFBgZq06ZNpvbp6quvVmBgoNLT0009zoWG6woAnsPrfHcAAHD2rr76ah08eFCS9NZbb6lXr16SpO3bt+uOO+6QJLVp00b/8z//UyfHa9WqlcaMGaNmzZrVyf5q8u6772r16tXas2ePJKldu3aKjo5WXFzcn97XxRdfrDFjxlRpe/XVV7Vt2zZ16dJFffr0Udu2beuk39UZMWKEjh49qlatWpl2jNGjR2vbtm2aO3euxo4dK+nfwXvIkCGSpC+//FJNmzY17fhna86cOXr33Xedn319fdWhQweNGzdON9xwQ43b1sd1BQDUDcInADQQq1evdobPt99+25RjtG/fXvPmzTNl37/34IMPatWqVZKkfv36qVWrVtq1a5eSkpLOKnw2b978tH7//PPPkqQ777xTI0eOPOu+njhxQt7e3i7XmzJlylkf40LRrVs39e7dWz/++KP+9a9/6f7771fz5s3Vr1+/09atvO5cVwDwHEy7BYAGoFmzZkpJSVFBQYEKCgqUkpJyxurkoUOH9B//8R+KiIhQr1699Pe//91ZWZSk7OxsxcTEKCQkRBMmTNCRI0eqbP/H6awnTpzQXXfdpX79+qlHjx7q1auXJkyYoJycHOc2ldNd33zzTV177bXq2bOnZs6cqfLy8jOey9dff+0Mng899JCWLVumxx57TOvWrdOzzz4rSdq1a5diYmLUu3dvde/eXf3799dDDz1U7T7/OO129OjRSktLkyTNmzdPgYGBOnDggEpKSvTkk09q6NCh6tmzp26++WatX7/euZ/Kacj33Xefpk2bpuDgYL3//vtV2mfNmqWePXtq2LBh+uKLL5zb/nF66NKlS3XNNdfoyiuvVI8ePXTTTTdp48aNzvXnzJmjwMBAzZ8/XxMmTFBISIhuvPFGff/992c8xz+joKBA8+bN06BBgxQaGqqYmBh9+umnzuWjR49WYGCg1q1bJ+n0f/fy8nIlJCQ4/90HDhyoCRMmOLd3Nc6q07t3b82bN09Lly5Vly5dJElbtmyR9P/X7+WXX9YNN9yg4ODgKu2V17W0tFQvvPCCrrvuOgUHB2vAgAF65513JEknT57UkiVLFBkZqSuvvFLXX3+9EhMTz/VyAgBqifAJAA1AVFSUysvLtXbtWiUlJenEiRO65ZZbqqxTWlqqO++8Ux999JEzSGzbtk133nmnCgoKdPLkSU2cOFFZWVnq1KmT/vKXv7isoBqGIYfDof79+ys6Olpt27bVpk2blJCQcNq6ixYtUs+ePXXq1Cm9//77eu+99864z8p7LwMCAhQTE1Nl2RVXXCFJKiwslLe3t6655hrdeuutatSokd566y0tX768Vtfr2muvVcuWLSX9u7I6ZswYXXzxxZo7d66WLVumxo0b67rrrtMvv/yi2bNn64MPPqiyfUpKivbv36+bb75Zl1xySZX2vLw8de7cWfv27VN8fHy1fThw4IC6dOmiW265RUOGDFF2drYeeOABHThwoMp6iYmJaty4sS677DLt2bNHDz/8sMvz+/jjj/Xoo4/q0Ucf1eLFi6ssO3XqlCZOnKikpCS1aNFCQ4YM0bfffqvx48crMzPT5b4l6b333tOaNWvUokULjRw5Ut27d9dXX30lyfU4q429e/cqLy9PktSiRYsqyxYtWqQuXbpo2LBhZ9w2ISFBixcvVkFBgW644Qb99a9/1U8//SRJev755/XMM8/IMAwNHz5cx48f1/z586tM+QUAmIdptwDQAFx11VX6/PPPnVWcTp06qXfv3lXC2ObNm7Vv3z61bNlSHTp0kCRdeuml2rdvn1JSUpyBqUmTJnrzzTd10UUXaerUqUpNTa32uFarVS+++KI2bdokh8OhLl266LvvvtOXX34pwzBksVic6y5YsECRkZEyDEPr16+vtoJ3+PBhSVLr1q2rbP97ffv2lZeXlzIzM1VQUKAOHTooNzdXW7du1b333uvyesXFxSklJUW5ubkaPny4RowYocOHDzsrj8uWLVObNm3UtWtXPfbYY3rzzTc1fPhw5/Zt27bVO++8Iy+vf/8YzcrKkiR17txZ//3f/60DBw5o6NChysnJUUFBgWw222l9eOCBB5Samqqff/5Z3t7estlscjgc+uqrr3TZZZc51xs4cKAWL16srVu36s4776xV5fPLL7/Ul19+ecZlO3fu1Ndffy1fX1+99dZb8vX1VYsWLbRixQq99dZbCg0Ndbn/EydOSJK6dOmiG2+8UZ06ddLFF18syfU4u/3226vd7xtvvKE33njD+blNmza67bbbqqwzfvx4TZs27YzbFxQUOH9RsHz5cv31r3919tcwDL355puSpJ49e+qiiy5S586ddeDAAb399tun/bIGAFD3CJ8A0ECMGjVKjzzyiCTpP//zP09bXvlgotzc3Cpf8CVp3759zmm6rVq10kUXXSRJuvzyy2s85vbt2zVmzBhVVFRUaT9+/LiOHTsmPz8/Z1tlEKhsKykpOeM+/f39Jf176uYfA2ylV199VQsXLjytvbaVtTOpvD4+Pj5q06aNJKljx45VllUKDg52Bs/f69q1qywWS5WH+pSUlJwWPsvLy3XbbbedcSrqH8+hW7dukuTcZ3XX7feqe+BQ5Wfp34HQ19e3xvOsdOrUqSqfo6KitG3bNn3yySf68MMPZbFYFB4erhdffNHlOKtJ5T2fTZo00eWXX67rrrtOPj4+VdapKRxXnpvVanWON0ny9vZWQUGB89pVTieu9Msvv9TYLwBA3WDaLQA0EFFRUbrooovk6+urqKio05ZXBqru3btr165d2r17t3bv3q0vv/xSEyZMkN1ulyT9+uuvKi0tlfT/D+WpTkpKiioqKjRo0CB9/fXXWrNmjXOZYRhV1m3cuLEkVVvNrDRo0CBJksPhcN6rV6myPxs2bJAkTZ8+Xd99951mzpx5xmP+GZXXp6ysTIcOHZIk53TNymWVrFbrGfdRGUhdnePevXu1Z88eeXl56eOPP9auXbvUqVOnM55DbfdZW5VV1ZycHOe/8x/Ps/KXD8eOHZOk00Kyl5eXnnvuOWVkZGjDhg0KDw/X559/rtTUVJfjrCaV93xOnz5dUVFRpwVPqfpr//tzKy8vr1IhPnnypFq0aOEM2++9956zX7t27dLatWtr7BcAoG5Q+QSABsLPz885rbByCuTvDRw4UJdddpm+/fZb3X777erSpYtycnK0bds2vfbaawoLC1Pbtm21f/9+xcXF6bLLLtM///nPGo9Zeb/j119/rYcffrjaqZ5/Rs+ePXXbbbcpMTFR8+fPV0pKilq3bq3s7GyVlZVp/fr1zuO+//772rdvnz7++ONzPq6/v7+uvfZapaSk6K677lJoaKhzGm7la2vqSosWLdSoUSOdPHlSTzzxhIqLi+ut+tajRw+FhIQoKytLd9xxhzp16uSsXlZOie3WrZu2bNmi5cuXKycnp8ovFSTpgw8+0JIlS9SjRw/5+vo6w2nTpk3Vp0+fGsfZ3/72N9POzWazafjw4frggw80duxYDRkyREVFRWrXrp1mzZql2NhYvf766xo3bpwGDx6skpISff3117rqqqv0xBNPmNYvAMC/UfkEgAakR48e6tGjxxmX+fr6asWKFRo+fLgOHTqk9evX66efftJNN92kDh06yMvLSy+99JKCg4P1ww8/6NixY6fdb/dHcXFxGjp0qI4fP67t27e7rGzV1kMPPaRHH31UISEh+uqrr/Thhx+qpKTE+UqUuXPnqnv37tq/f7/27dvnnGJ6rh577DGNHTtWJ06c0EcffaTLLrtMjz/+uG688cY62X+lVq1aKSEhQZdccom2bt2q7t27q2fPnnV6jOo0atRIL7/8svM+13/+85/q1q2bXn75Zeereu666y5FRESosLBQ6enpp13fDh06qEWLFvr000+1du1aeXt7a+LEiRo8eLDLcWa2Rx55RJMmTVLz5s31/vvv65tvvnFOH58+fbpmzpypZs2aKTk5WVu3blWHDh0UGRlper8AAJLFOJc5SgAAAAAA1AKVTwAAAACA6QifAAAAAADTET4BAAAAAKYjfAIAAAAATEf4BAAAAACYrt7f85mRkVHfhwQAAAAA1JOwsLAzttd7+JSq7wwAAAAAwHPVVGxk2i0AAAAAwHSETwAAAACA6QifAAAAAADTET4BAAAAAKYjfAIAAAAATEf4BAAAAACYjvAJAAAAADAd4RMAAAAAYDrCJwAAAADAdIRPAAAAAIDpvM53BwAAAAAA/8diqXm5YdRPP0xA5RMAAAAAYDrCJwAAAADAdIRPAAAAAIDpCJ8AAAAAANMRPgEAAAAApiN8AgAAAABMR/gEAAAAAJiO8AkAAAAAMB3hEwAAAABgOsInAAAAAMB0hE8AAAAAgOkInwAAAAAA03m5WqG4uFizZ8/W0aNHdeLECU2ePFkBAQFasGCBJCkwMFAPPvigJOn111/Xxo0bZbFYNGXKFA0cONDUzgMAAAAAPIPL8Pnuu++qQ4cOmjFjhnJzc3XnnXcqICBA8fHxCg4O1owZM7RlyxZ17NhRGzZs0OrVq3Xs2DHFxsaqf//+aty4cX2cBwAAAADAjbmcdtuiRQsdOXJEklRUVKTmzZvr4MGDCg4OliQNHjxYaWlpSk9PV0REhKxWq2w2m9q0aaPs7Gxzew8AAAAA8Aguw+cNN9ygQ4cOadiwYYqLi9OsWbPUtGlT53J/f385HA7l5+fLZrM52202mxwOhzm9BgAAAAB4FJfTbt977z21bt1aS5cu1a5duzR58mT5+fk5lxuGccbtqmsHAAAAAFx4XFY+MzMz1b9/f0lS165ddfz4cRUWFjqX5+bmym63y263Kz8//7R2AAAAAABchs/27dsrKytLknTw4EE1adJEV1xxhbZv3y5JSk1NVUREhPr06aPNmzervLxcubm5ysvLU6dOncztPQAAAADAI7icdnvbbbcpPj5ecXFxOnnypBYsWKCAgADNnz9fp06dUkhIiMLDwyVJMTExiouLk8Vi0YIFC9SoEa8RBQAAAABIFqOeb87MyMhQWFhYfR4SAAAAADyDxVLzcjd/tk5NeY/SJAAAAADAdIRPAAAAAIDpCJ8AAAAAANMRPgEAAAAApiN8AgAAAABMR/gEAAAAAJiO8AkAAAAAMB3hEwAAAABgOsInAAAAAMB0hE8AAAAAgOkInwAAAAAA0xE+AQAAAACmI3wCAAAAAExH+AQAAAAAmI7wCQAAAAAwHeETAAAAAGA6wicAAAAAwHSETwAAAACA6QifAAAAAADTET4BAAAAAKYjfAIAAAAATOflaoU1a9YoOTnZ+Xnnzp16++23tWDBAklSYGCgHnzwQUnS66+/ro0bN8pisWjKlCkaOHCgOb0GAAAAAHgUl+EzOjpa0dHRkqRt27bpo48+0qOPPqr4+HgFBwdrxowZ2rJlizp27KgNGzZo9erVOnbsmGJjY9W/f381btzY9JMAAAAAALi3PzXtdvHixbrnnnt08OBBBQcHS5IGDx6stLQ0paenKyIiQlarVTabTW3atFF2drYpnQYAAAAAeJZah89vvvlGl156qRo3bqymTZs62/39/eVwOJSfny+bzeZst9lscjgcddtbAAAAAIBHqnX4TEpK0i233HJau2EYZ1y/unYAAAAAwIWn1uEzPT1dPXv2lM1m05EjR5ztubm5stvtstvtys/PP60dAAAAAIBahc/c3Fw1adJEVqtV3t7e6tixo7Zv3y5JSk1NVUREhPr06aPNmzervLxcubm5ysvLU6dOnUztPAAAAADAM7h82q0kORyOKvdzxsfHa/78+Tp16pRCQkIUHh4uSYqJiVFcXJwsFosWLFigRo14jSgAAAAAQLIY9XxzZkZGhsLCwurzkAAAAADgGSyWmpe7+bN1asp7lCYBAAAAAKYjfAIAAAAATEf4BAAAAACYjvAJAAAAADAd4RMAAAAAYDrCJwAAAADAdIRPAAAAAIDpCJ8AAAAAANMRPgEAAAAApiN8AgAAAABMR/gEAAAAAJiO8AkAAAAAMB3hEwAAAABgOsInAAAAAMB0hE8AAAAAgOkInwAAAAAA0xE+AQAAAACmI3wCAAAAAExH+AQAAAAAmI7wCQAAAAAwHeETAAAAAGA6wicAAAAAwHRetVkpOTlZr7/+ury8vHTfffcpMDBQs2bNUkVFhQICAvT000/LarUqOTlZK1asUKNGjRQTE6Po6Giz+w8AAAAA8AAuw2dhYaEWL16stWvXqqSkRIsWLVJKSopiY2MVGRmphQsXKikpSVFRUVq8eLGSkpLk7e2tkSNHatiwYWrevHl9nAcAAAAAwI25nHablpamvn376uKLL5bdbtfDDz+s9PR0DRkyRJI0ePBgpaWlKSsrS0FBQfLz85OPj49CQ0OVmZlp+gkAAAAAANyfy8rngQMHVFZWpgkTJqioqEhTp05VaWmprFarJMnf318Oh0P5+fmy2WzO7Ww2mxwOh3k9BwAAAAB4jFrd83nkyBG9+OKLOnTokMaMGSPDMJzLfv/336uuHQAAAABw4XE57dbf3189e/aUl5eX2rVrpyZNmqhJkyYqKyuTJOXm5sput8tutys/P9+5XV5enux2u3k9BwAAAAB4DJfhs3///tq6datOnTqlwsJClZSUKDw8XCkpKZKk1NRURUREKCQkRDt27FBRUZGKi4uVmZmpXr16mX4CAAAAAAD353LabcuWLXXttdcqJiZGkpSQkKCgoCDNnj1biYmJat26taKiouTt7a0ZM2Zo3Lhxslgsmjx5svz8/Ew/AQAAAACA+7MY9XxzZkZGhsLCwurzkAAAAADgGSyWmpe7+bN1asp7LqfdAgAAAABwrgifAAAAAADTET4BAAAAAKYjfAIAAAAATEf4BAAAAACYjvAJAAAAADAd4RMAAAAAYDrCJwAAAADAdIRPAAAAAIDpCJ8AAAAAANMRPgEAAAAApiN8AgAAAABMR/gEAAAAAJiO8AkAAAAAMB3hEwAAAABgOsInAAAAAMB0hE8AAAAAgOkInwAAAAAA0xE+AQAAAACmI3wCAAAAAExH+AQAAAAAmM7L1Qrp6emaNm2aOnfuLEnq0qWL7r77bs2aNUsVFRUKCAjQ008/LavVquTkZK1YsUKNGjVSTEyMoqOjTT8BAAAAAID7cxk+Jemqq67SCy+84Pw8d+5cxcbGKjIyUgsXLlRSUpKioqK0ePFiJSUlydvbWyNHjtSwYcPUvHlz0zoPAAAAAPAMZzXtNj09XUOGDJEkDR48WGlpacrKylJQUJD8/Pzk4+Oj0NBQZWZm1mlnAQAAAACeqVaVz+zsbE2YMEFHjx7VlClTVFpaKqvVKkny9/eXw+FQfn6+bDabcxubzSaHw2FOrwEAAAAAHsVl+Lz88ss1ZcoURUZGav/+/RozZowqKiqcyw3DOON21bUDAAAAAC48LqfdtmzZUtdff70sFovatWunSy65REePHlVZWZkkKTc3V3a7XXa7Xfn5+c7t8vLyZLfbzes5AAAAAMBjuAyfycnJWrp0qSTJ4XDo8OHDGjFihFJSUiRJqampioiIUEhIiHbs2KGioiIVFxcrMzNTvXr1Mrf3AAAAAACP4HLa7dVXX62ZM2fqk08+0YkTJ7RgwQJ169ZNs2fPVmJiolq3bq2oqCh5e3trxowZGjdunCwWiyZPniw/P7/6OAcAAAAAgJuzGPV8c2ZGRobCwsLq85AAAAAA4BkslpqXu/mzdWrKe2f1qhUAAAAAAP4MwicAAAAAwHSETwAAAACA6QifAAAAAADTET4BAAAAAKYjfAIAAAAATEf4BAAAAACYjvAJAAAAADCd1/nuAACYxsNf0gwAANCQUPkEAAAAAJiO8AkAAAAAMB3hEwAAAABgOsInAAAAAMB0hE8AAAAAgOkInwAAAAAA0xE+AQAAAACmI3wCAAAAAExH+AQAAAAAmI7wCQAAAAAwHeETAAAAAGA6wicAAAAAwHS1Cp9lZWUaOnSo1q1bp5ycHI0ePVqxsbGaNm2aysvLJUnJycm69dZbFR0drTVr1pjaaQAAAACAZ6lV+Hz55ZfVrFkzSdILL7yg2NhYrVq1Su3bt1dSUpJKSkq0ePFiLV++XCtXrtSKFSt05MgRUzsOAAAAAPAcLsPn3r17lZ2drUGDBkmS0tPTNWTIEEnS4MGDlZaWpqysLAUFBcnPz08+Pj4KDQ1VZmamqR0HAAAAAHgOl+HzySef1Jw5c5yfS0tLZbVaJUn+/v5yOBzKz8+XzWZzrmOz2eRwOEzoLgAAAADAE9UYPtevX68rr7xSbdu2PeNywzD+VDsAAAAA4MLkVdPCzZs3a//+/dq8ebN+/fVXWa1W+fr6qqysTD4+PsrNzZXdbpfdbld+fr5zu7y8PF155ZWmdx4AAAAA4BlqDJ/PPfec8++LFi1SmzZt9NVXXyklJUU333yzUlNTFRERoZCQECUkJKioqEiNGzdWZmam4uPjTe88gPPIYql5OTMgAAAA8Ds1hs8zmTp1qmbPnq3ExES1bt1aUVFR8vb21owZMzRu3DhZLBZNnjxZfn5+ZvQXqB8EK8/g6t8JAAAAbsNi1PMNmhkZGQoLC6vPQwJ/HuHTNXe4RucaPvl3BAAA7sYdvmOdg5ryXq3e8wkAAAAAwLn409NuAdSD2lT03Py3XgAAAMDvUfkEAAAAAJiO8AkAAAAAMB3hEwAAAABgOsInAAAAAMB0hE8AAAAAgOkInwAAAAAA0xE+AQAAAACm4z2fANxTbd51CgAAAI9B5RMAAAAAYDoqnwBQHVfVV8Nw7/0DAAC4EcInAHN4QrBiai8AAEC9IXwCgFkItwAAAE6ETzRMnlB1A1xhHAMAgAaEBw4BAAAAAExH+AQAAAAAmI5ptwDOD+6HBAAAuKBQ+QQAAAAAmI7KJy5MVN0AAACAekX4BM4GTyEFAAAA/hSm3QIAAAAATOey8llaWqo5c+bo8OHDOn78uCZNmqSuXbtq1qxZqqioUEBAgJ5++mlZrVYlJydrxYoVatSokWJiYhQdHV0f5wAAAAAAcHMuw+emTZvUo0cP3XPPPTp48KD+/ve/KzQ0VLGxsYqMjNTChQuVlJSkqKgoLV68WElJSfL29tbIkSM1bNgwNW/evD7OA7jwMPUXAAAAHsTltNvrr79e99xzjyQpJydHLVu2VHp6uoYMGSJJGjx4sNLS0pSVlaWgoCD5+fnJx8dHoaGhyszMNLf3gKeyWGr+AwAAADQwtX7g0KhRo/Trr7/qlVde0V133SWr1SpJ8vf3l8PhUH5+vmw2m3N9m80mh8NR9z0GAAAAAHicWofP1atX6/vvv9cDDzwg43fT+YxqpvZV1w7ATTBtFwAAAPXI5bTbnTt3KicnR5LUrVs3VVRUqEmTJiorK5Mk5ebmym63y263Kz8/37ldXl6e7Ha7Sd0GAAAAAHgSl+Fz+/btWrZsmSQpPz9fJSUlCg8PV0pKiiQpNTVVERERCgkJ0Y4dO1RUVKTi4mJlZmaqV69e5vYeQPW4rxSegHEKAMAFw+W021GjRmnevHmKjY1VWVmZ5s+frx49emj27NlKTExU69atFRUVJW9vb82YMUPjxo2TxWLR5MmT5efnVx/nAAAAAABwcxajnm/OzMjIUFhYWH0eEu6mNtWMcx2W57ti4qr/57t/tdEQzsFs5/saNYT7crn3GACAqjz8Z2NNea/WDxwCcIEhXLrGNQIAAKg1wifqHl/IAQAAAPyBywcOAQAAAABwrgifAAAAAADTMe0WMANTjwEAAIAqCJ8AgLPn4U/kAwAA9YdptwAAAAAA01H5BAC4LyqrAAA0GIRPAIB5uP8ZAAD8H6bdAgAAAABMR+UTADxVbaqKTEsFAABugvAJz8RUPgAAAMCjMO0WAAAAAGA6wicAAAAAwHRMu8XpeLUBgEpMcQcAAHWEyicAAAAAwHSETwAAAACA6Zh2CwDwXLxuBgAAj0HlEwAAAABgOiqfcE885ASoH/y3BgAA6gnhEwAaMsIlAABwE7UKn0899ZQyMjJ08uRJjR8/XkFBQZo1a5YqKioUEBCgp59+WlarVcnJyVqxYoUaNWqkmJgYRUdHm91/nA98mQXgSXh9FAAAbsFl+Ny6dat++OEHJSYmqrCwULfccov69u2r2NhYRUZGauHChUpKSlJUVJQWL16spKQkeXt7a+TIkRo2bJiaN29eH+cBAAAAAHBjLh841Lt3bz3//POSpKZNm6q0tFTp6ekaMmSIJGnw4MFKS0tTVlaWgoKC5OfnJx8fH4WGhiozM9Pc3gMA4Okslpr/AADQQLgMn40bN5avr68kKSkpSQMGDFBpaamsVqskyd/fXw6HQ/n5+bLZbM7tbDabHA6HSd0GAAAAAHiSWr9q5eOPP1ZSUpLmz59fpd2o5l6Z6toBAAAAABeeWoXPzz77TK+88oqWLFkiPz8/+fr6qqysTJKUm5sru90uu92u/Px85zZ5eXmy2+3m9BoAgLrCtFcAAOqFy/D522+/6amnntKrr77qfHhQeHi4UlJSJEmpqamKiIhQSEiIduzYoaKiIhUXFyszM1O9evUyt/cAAAAAAI/g8mm3GzZsUGFhoaZPn+5se+KJJ5SQkKDExBd2fg0AAA/0SURBVES1bt1aUVFR8vb21owZMzRu3DhZLBZNnjxZfn5+pnYeAAAAAOAZLEY935yZkZGhsLCw+jwk/iymmQHA/zP7x+S5voeU95gCQMPi4f9frynvuax8AgBwQfPwLwEAALgLwicAAO6M2SgAgAaC8AkAwLmgMgoAQK3U+j2fAAAAAACcLcInAAAAAMB0TLsFAMBM3LMJAIAkKp8AAAAAgHpA+AQAAAAAmI7wCQAAAAAwHeETAAAAAGA6HjgEAADg6XjfLAAPQOUTAAAAAGA6Kp8AADRktXnVC1UxAEA9IHxeiHjnHAAAAIB6xrRbAAAAAIDpCJ8AAAAAANMx7RYAANSMJ6kCAOoA4RMAgAvduT4LgHAKAKgFpt0CAAAAAExH5RMAAOB8o3oM4AJA5RMAAAAAYDoqnwAAAOeKyiUAuFSryueePXs0dOhQvfnmm5KknJwcjR49WrGxsZo2bZrKy8slScnJybr11lsVHR2tNWvWmNdrAACAumKxuP4DADhnLsNnSUmJHn74YfXt29fZ9sILLyg2NlarVq1S+/btlZSUpJKSEi1evFjLly/XypUrtWLFCh05csTUzgMAAAAAPIPL8Gm1WrVkyRLZ7XZnW3p6uoYMGSJJGjx4sNLS0pSVlaWgoCD5+fnJx8dHoaGhyszMNK/nAAAAElVLAPAQLu/59PLykpdX1dVKS0tltVolSf7+/nI4HMrPz5fNZnOuY7PZ5HA46ri7AAAAAABPdM4PHDKquYG+unYAAHCB4WE8VGABQGf5qhVfX1+VlZVJknJzc2W322W325Wfn+9cJy8vr8pUXQAAAADAheuswmd4eLhSUlIkSampqYqIiFBISIh27NihoqIiFRcXKzMzU7169arTzgIAAFyQuK8VQAPgctrtzp079eSTT+rgwYPy8vJSSkqKnnnmGc2ZM0eJiYlq3bq1oqKi5O3trRkzZmjcuHGyWCyaPHmy/Pz86uMcAAAAqlcX4YyABwDnzGLU882ZGRkZCgsLq89D4o/4AQoAcCfn+lWEn2uuubrGtbmGF8K9uYA78PD75GvKe+f8wCEAAABTES7dg4d/IQZw/hE+GyJ+SAMAgN/juwEAN3BWDxwCAAAAAODPoPIJAADOL6pyAHBBIHwCAADAfNwzClzwmHYLAAAAADAd4RMAAAAAYDqm3QIAAOD8O9d7f8/1XaZM+wVMR/gEAADAufP0B0cRTgHTET4BAAAA1A1CPGpA+AQAAADqAsELqBEPHAIAAAAAmI7Kpyfy9HsqAAAA6prZ34/q4/uXu1dO+Q6Kc0T4BAAAAOrDuYa3cw2n7h5u0eARPgEAAICGgMok3BzhEwAAAADhFaYjfAIAAABwD+4+Ndjd++fmCJ8AAAAA6oe7PxiK8GgqwicAAAAASEw9NhnhEwAAAIBnIBx6NMInAAAAANQFwnGN6jx8PvbYY8rKypLFYlF8fLyCg4Pr+hANH4MWAAAAQANTp+Fz27Zt+uWXX5SYmKi9e/cqPj5eiYmJdXmIhoFwCQAAAOACU6fhMy0tTUOHDpUkXXHFFTp69KiOHTumiy++uC4PYy6CIQAAAADUuToNn/n5+erevbvzs81mk8PhOC18ZmRk1OVh69b27ee7BwAAAABwZu6cpVww9YFDxhnekxMWFmbmIQEAAAAAbqhRXe7MbrcrPz/f+TkvL08BAQF1eQgAAAAAgAeq0/DZr18/paSkSJK+/fZb2e12z7rfEwAAAABgijqddhsaGqru3btr1KhRslgs+q//+q862zevcIHZ9uzZo0mTJmns2LGKi4tTTk6OZs2apYqKCgUEBOjpp5+W1WpVcnKyVqxYoUaNGikmJkbR0dE6ceKE5syZo0OHDqlx48Z6/PHH1bZtW+3atUsLFiyQJAUGBurBBx+UJL3++uvauHGjLBaLpkyZooEDB57HM4e7e+qpp5SRkaGTJ09q/PjxCgoKYmzCLZSWlmrOnDk6fPiwjh8/rkmTJqlr166MT7iNsrIyDR8+XJMmTVLfvn0Zmzjv0tPTNW3aNHXu3FmS1KVLF919990Xztg0PEB6erpx7733GoZhGNnZ2UZMTMx57hEamuLiYiMuLs5ISEgwVq5caRiGYcyZM8fYsGGDYRiG8eyzzxpvvfWWUVxcbFxzzTVGUVGRUVpaatxwww1GYWGhsW7dOmPBggWGYRjGZ599ZkybNs0wDMOIi4szsrKyDMMwjPvvv9/YvHmzsW/fPuOWW24xjh8/bhw+fNi49tprjZMnT56Hs4YnSEtLM+6++27DMAyjoKDAGDhwIGMTbuPDDz80XnvtNcMwDOPAgQPGNddcw/iEW1m4cKExYsQIY+3atYxNuIWtW7caU6dOrdJ2IY3NOp12a5bqXuEC1BWr1aolS5bIbrc729LT0zVkyBBJ0uDBg5WWlqasrCwFBQXJz89PPj4+Cg0NVWZmptLS0jRs2DBJUnh4uDIzM1VeXq6DBw86q/SV+0hPT1dERISsVqtsNpvatGmj7Ozs+j9peITevXvr+eeflyQ1bdpUpaWljE24jeuvv1733HOPJCknJ0ctW7ZkfMJt7N27V9nZ2Ro0aJAkfq7DfV1IY9Mjwmd+fr5atGjh/Fz5Chegrnh5ecnHx6dKW2lpqaxWqyTJ399fDodD+fn5stlsznUqx+Lv2xs1aiSLxaL8/Hw1bdrUua6rfQBn0rhxY/n6+kqSkpKSNGDAAMYm3M6oUaM0c+ZMxcfHMz7hNp588knNmTPH+ZmxCXeRnZ2tCRMm6Pbbb9fnn39+QY1NU1+1YhbjDK9wAcxU3Zj7M+1/dh/A73388cdKSkrSsmXLdM011zjbGZtwB6tXr9b333+vBx54oMq4YXzifFm/fr2uvPJKtW3b9ozLGZs4Xy6//HJNmTJFkZGR2r9/v8aMGaOKigrn8oY+Nj2i8skrXHA++Pr6qqysTJKUm5sru91+xrFY2V75m6QTJ07IMAwFBAToyJEjznWr20dlO1Cdzz77TK+88oqWLFkiPz8/xibcxs6dO5WTkyNJ6tatmyoqKtSkSRPGJ867zZs365NPPlFMTIzWrFmjl156if93wi20bNlS119/vSwWi9q1a6dLLrlER48evWDGpkeET17hgvMhPDzcOe5SU1MVERGhkJAQ7dixQ0VFRSouLlZmZqZ69eqlfv36aePGjZKkTZs26W9/+5u8vb3VsWNHbd++vco++vTpo82bN6u8vFy5ubnKy8tTp06dztt5wr399ttveuqpp/Tqq6+qefPmkhibcB/bt2/XsmXLJP37FpmSkhLGJ9zCc889p7Vr1+qdd95RdHS0Jk2axNiEW0hOTtbSpUslSQ6HQ4cPH9aIESMumLFpMdyh/loLzzzzjLZv3+58hUvXrl3Pd5fQgOzcuVNPPvmkDh48KC8vL7Vs2VLPPPOM5syZo+PHj6t169Z6/PHH5e3trY0bN2rp0qWyWCyKi4vTTTfdpIqKCiUkJOjnn3+W1WrVE088oUsvvVTZ2dmaP3++Tp06pZCQEM2dO1eStHLlSr3//vuyWCyaPn26+vbte56vANxVYmKiFi1apA4dOjjbnnjiCSUkJDA2cd6VlZVp3rx5ysnJUVlZmaZMmaIePXpo9uzZjE+4jUWLFqlNmzbq378/YxPn3bFjxzRz5kwVFRXpxIkTmjJlirp163bBjE2PCZ8AAAAAAM/lEdNuAQAAAACejfAJAAAAADAd4RMAAAAAYDrCJwAAAADAdIRPAAAAAIDpCJ8AgAatoqJCo0aNUnl5ebXrjB49WoGBgSooKJAkbdy4UYGBgVq0aJEk6eDBgxo3bpx69uyp0NBQ3XTTTUpLSzvjvgIDAxUYGKgePXqoX79+mjRpkr7//vta9TUwMFDDhw+X9O/XQwQGBjrf5wYAgKcjfAIAGqznnntOISEh+uqrrxQSEqIpU6ac1X4ef/xxpaWlaeLEiZozZ46Cg4NVWFhY7fqtWrXSI488osjISG3ZskWxsbHKzs4+29P4U06ePFkvxwEA4M/yOt8dAADADLm5uXr55Zd13XXX6ccff9T48eO1f//+s9rXjz/+KC8vLw0YMEBdu3ZVTExMjev7+fkpKipKUVFRuuSSS/SPf/xDr732mp566in98MMPeuSRR7Rjxw41a9ZMI0eO1KRJk2SxWGrcZ0xMjLKzs1VRUaErrrhC8fHx6tWrl9LT0zVmzBgNGDBAhYWFOnXqlJ555hnNnj1bu3fv1l/+8hd17txZq1atOqtzBwCgrlD5BAA0SBaLRRaLRQ6HQxUVFerZs6cmTpx4Vvvq1auXjh8/rptvvln9+/fXgw8+qCNHjtRq2wEDBkiSdu7cqRMnTmjixIn65ptvNH36dAUGBuqFF17Q2rVrXe4nPDxcc+fO1ZQpU+RwOBQfH19leVpamoYNG6axY8dq1apV2rFjhx544AHdf//9at269Z8/aQAA6hiVTwBAg2S32zV79my9+uqrKiws1NVXX63IyEj94x//OK3K+MfPhmFUaU9ISFC7du2UmpqqnTt3atWqVSosLNRzzz3nsh+/39dPP/2k/fv3a/jw4c5q5aZNm/Tpp59q5MiR1e6juLhY3333nV577TVVVFQ428vKypx/HzRokMaPHy9JKioqkmEY2rJli4KCgjRmzBiX/QQAwGxUPgEADdZdd92lL774QkFBQbrjjjv00Ucfaffu3aetFxAQIElyOBySpLy8PElSy5Ytnevcfffdeuedd7Rx40ZZLBb98MMPterDv/71L0lS9+7dnW2VodbVVNtKycnJ2rJliyIjI7V06VLnvn7/ECW73e78e1xcnJYvX66goCB98sknuu222/Tjjz/W6lgAAJiFyicAoEHau3evnn32WfXt21clJSXOabI+Pj6nrRsREaEPPvhA8fHxCg8P17p16+Tt7a0+ffpIksaOHavOnTure/fuOnTokAzDUJcuXao99m+//ab169dr586dWr16tXx9fXXvvfeqffv2ateunT755BOtXLlSX3zxhSRp4MCBtTqn4uJi7d69W3v27KlxvbfffluFhYVq37692rdvr927d+vw4cPq2LFjrY4DAIAZCJ8AgAapefPmqqio0IsvvqgjR46ooKBAU6dO1eWXX37aujfffLMOHjyotWvX6o033lD79u310EMPqW3btpKk/v3764MPPtB7770nLy8vDRo0SLNnz6722L/++qsSEhLUvHlzDRw4UFOnTlWnTp0kSS+99JIefvhhLVy4UM2aNdN9992nESNG1HguN954o1JTU51htXfv3s6/n4nVatW6dev066+/qkmTJrrjjjsUFhbm6pIBAGAqi1F5MwoAAA3U6NGjtXLlyvPdDQAALmjc8wkAAAAAMB2VTwAAAACA6ah8AgAAAABMR/gEAAAAAJiO8AkAAAAAMB3hEwAAAABgOsInAAAAAMB0hE8AAAAAgOn+F36fEXC1gmIzAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9TMSdAAjcr4o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44ae8363-cb21-4806-d5e5-8f33bddbd234"
      },
      "source": [
        "y = df_train.median_house_value.values + 1e-10\n",
        "y ### for supervised learning: output vector y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 66900.,  80100.,  85700., ..., 103600.,  85800.,  94600.])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FOeHvi3cu1n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "outputId": "4d01f677-6db7-4f84-f993-dc3a679024d6"
      },
      "source": [
        "# List first rows (post-cleaning):\n",
        "\n",
        "df_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
              "0    -114.31     34.19                15.0       5612.0          1283.0   \n",
              "1    -114.47     34.40                19.0       7650.0          1901.0   \n",
              "2    -114.56     33.69                17.0        720.0           174.0   \n",
              "3    -114.57     33.64                14.0       1501.0           337.0   \n",
              "4    -114.57     33.57                20.0       1454.0           326.0   \n",
              "\n",
              "   population  households  median_income  median_house_value  \n",
              "0      1015.0       472.0         1.4936             66900.0  \n",
              "1      1129.0       463.0         1.8200             80100.0  \n",
              "2       333.0       117.0         1.6509             85700.0  \n",
              "3       515.0       226.0         3.1917             73400.0  \n",
              "4       624.0       262.0         1.9250             65500.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5bbe3f46-7433-4f70-a8b2-259a3fe32d18\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>longitude</th>\n",
              "      <th>latitude</th>\n",
              "      <th>housing_median_age</th>\n",
              "      <th>total_rooms</th>\n",
              "      <th>total_bedrooms</th>\n",
              "      <th>population</th>\n",
              "      <th>households</th>\n",
              "      <th>median_income</th>\n",
              "      <th>median_house_value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-114.31</td>\n",
              "      <td>34.19</td>\n",
              "      <td>15.0</td>\n",
              "      <td>5612.0</td>\n",
              "      <td>1283.0</td>\n",
              "      <td>1015.0</td>\n",
              "      <td>472.0</td>\n",
              "      <td>1.4936</td>\n",
              "      <td>66900.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-114.47</td>\n",
              "      <td>34.40</td>\n",
              "      <td>19.0</td>\n",
              "      <td>7650.0</td>\n",
              "      <td>1901.0</td>\n",
              "      <td>1129.0</td>\n",
              "      <td>463.0</td>\n",
              "      <td>1.8200</td>\n",
              "      <td>80100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-114.56</td>\n",
              "      <td>33.69</td>\n",
              "      <td>17.0</td>\n",
              "      <td>720.0</td>\n",
              "      <td>174.0</td>\n",
              "      <td>333.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>1.6509</td>\n",
              "      <td>85700.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-114.57</td>\n",
              "      <td>33.64</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1501.0</td>\n",
              "      <td>337.0</td>\n",
              "      <td>515.0</td>\n",
              "      <td>226.0</td>\n",
              "      <td>3.1917</td>\n",
              "      <td>73400.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-114.57</td>\n",
              "      <td>33.57</td>\n",
              "      <td>20.0</td>\n",
              "      <td>1454.0</td>\n",
              "      <td>326.0</td>\n",
              "      <td>624.0</td>\n",
              "      <td>262.0</td>\n",
              "      <td>1.9250</td>\n",
              "      <td>65500.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5bbe3f46-7433-4f70-a8b2-259a3fe32d18')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5bbe3f46-7433-4f70-a8b2-259a3fe32d18 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5bbe3f46-7433-4f70-a8b2-259a3fe32d18');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-lT9BBicw4P",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "f0a550a3-b582-4515-ea45-57287c77dda0"
      },
      "source": [
        "X = df_train.drop(['median_house_value'], axis = 1)\n",
        "X.head() ### for supervised learning: input matrix X"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
              "0    -114.31     34.19                15.0       5612.0          1283.0   \n",
              "1    -114.47     34.40                19.0       7650.0          1901.0   \n",
              "2    -114.56     33.69                17.0        720.0           174.0   \n",
              "3    -114.57     33.64                14.0       1501.0           337.0   \n",
              "4    -114.57     33.57                20.0       1454.0           326.0   \n",
              "\n",
              "   population  households  median_income  \n",
              "0      1015.0       472.0         1.4936  \n",
              "1      1129.0       463.0         1.8200  \n",
              "2       333.0       117.0         1.6509  \n",
              "3       515.0       226.0         3.1917  \n",
              "4       624.0       262.0         1.9250  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b3378db3-bffd-4a7c-a6d3-35095e66c9cf\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>longitude</th>\n",
              "      <th>latitude</th>\n",
              "      <th>housing_median_age</th>\n",
              "      <th>total_rooms</th>\n",
              "      <th>total_bedrooms</th>\n",
              "      <th>population</th>\n",
              "      <th>households</th>\n",
              "      <th>median_income</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-114.31</td>\n",
              "      <td>34.19</td>\n",
              "      <td>15.0</td>\n",
              "      <td>5612.0</td>\n",
              "      <td>1283.0</td>\n",
              "      <td>1015.0</td>\n",
              "      <td>472.0</td>\n",
              "      <td>1.4936</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-114.47</td>\n",
              "      <td>34.40</td>\n",
              "      <td>19.0</td>\n",
              "      <td>7650.0</td>\n",
              "      <td>1901.0</td>\n",
              "      <td>1129.0</td>\n",
              "      <td>463.0</td>\n",
              "      <td>1.8200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-114.56</td>\n",
              "      <td>33.69</td>\n",
              "      <td>17.0</td>\n",
              "      <td>720.0</td>\n",
              "      <td>174.0</td>\n",
              "      <td>333.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>1.6509</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-114.57</td>\n",
              "      <td>33.64</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1501.0</td>\n",
              "      <td>337.0</td>\n",
              "      <td>515.0</td>\n",
              "      <td>226.0</td>\n",
              "      <td>3.1917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-114.57</td>\n",
              "      <td>33.57</td>\n",
              "      <td>20.0</td>\n",
              "      <td>1454.0</td>\n",
              "      <td>326.0</td>\n",
              "      <td>624.0</td>\n",
              "      <td>262.0</td>\n",
              "      <td>1.9250</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b3378db3-bffd-4a7c-a6d3-35095e66c9cf')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b3378db3-bffd-4a7c-a6d3-35095e66c9cf button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b3378db3-bffd-4a7c-a6d3-35095e66c9cf');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eC8SDPzczNY"
      },
      "source": [
        "### Optimum rmse: regression model objective function is Root Mean Square Error (RMSE); \n",
        "### Should be minimized (as close to zero as possible):\n",
        "\n",
        "y_global_orig = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GoTmWEhSc1qQ"
      },
      "source": [
        "### Bayesian Optimization - inputs:\n",
        "\n",
        "obj_func = 'XGBoost'\n",
        "n_test = 500 # test points\n",
        "\n",
        "util_gp = 'CBMinimized'\n",
        "util_stp = 'tCBMinimized'\n",
        "n_init = 5 # random initialisations\n",
        "opt = True\n",
        "\n",
        "test_perc = 0.90\n",
        "train_perc = 1 - test_perc\n",
        "\n",
        "n_test = int(len(df_train) * test_perc)\n",
        "n_train = int(len(df_train) - n_test)\n",
        "\n",
        "eps = 1e-08\n",
        "\n",
        "df = 3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2ngnRxbc7cg"
      },
      "source": [
        "### Objective function:\n",
        "\n",
        "if obj_func == 'XGBoost': # 6-D\n",
        "            \n",
        "    # Constraints:\n",
        "    param_lb_alpha = 0\n",
        "    param_ub_alpha = 10\n",
        "    \n",
        "    param_lb_gamma = 0\n",
        "    param_ub_gamma = 10\n",
        "    \n",
        "    param_lb_max_depth = 5\n",
        "    param_ub_max_depth = 15\n",
        "    \n",
        "    param_lb_min_child_weight = 1\n",
        "    param_ub_min_child_weight = 20\n",
        "    \n",
        "    param_lb_subsample = .5\n",
        "    param_ub_subsample = 1\n",
        "    \n",
        "    param_lb_colsample = .1\n",
        "    param_ub_colsample = 1\n",
        "    \n",
        "    # 6-D inputs' parameter bounds:\n",
        "    param = { 'alpha':  ('cont', (param_lb_alpha, param_ub_alpha)),\n",
        "         'gamma':  ('cont', (param_lb_gamma, param_ub_gamma)),     \n",
        "         'max_depth':  ('int', (param_lb_max_depth, param_ub_max_depth)),\n",
        "         'subsample':  ('cont', (param_lb_subsample, param_ub_subsample)),\n",
        "          'min_child_weight':  ('int', (param_lb_min_child_weight, param_ub_min_child_weight)),\n",
        "            'colsample': ('cont', (param_lb_colsample, param_ub_colsample))\n",
        "        }\n",
        "       \n",
        "    # True y bounds:\n",
        "    dim = 6\n",
        "    \n",
        "    max_iter = 30  # iterations of Bayesian optimization\n",
        "    \n",
        "    operator = 1 \n",
        "    \n",
        "    n_est = 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3pmZYhVl9Hb"
      },
      "source": [
        "n_start_AcqFunc = max_iter\n",
        "cov_func = squaredExponential()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9ZuEB2VdE0W"
      },
      "source": [
        "### Set-seeds:\n",
        "\n",
        "run_num_1 = 1\n",
        "run_num_2 = 2\n",
        "run_num_3 = 3\n",
        "run_num_4 = 4\n",
        "run_num_5 = 5\n",
        "run_num_6 = 6\n",
        "run_num_7 = 7\n",
        "run_num_8 = 8\n",
        "run_num_9 = 9\n",
        "run_num_10 = 10\n",
        "run_num_11 = 11\n",
        "run_num_12 = 12\n",
        "run_num_13 = 13\n",
        "run_num_14 = 14\n",
        "run_num_15 = 15\n",
        "run_num_16 = 16\n",
        "run_num_17 = 17\n",
        "run_num_18 = 18\n",
        "run_num_19 = 19\n",
        "run_num_20 = 20\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XgHMFEyPdCk4"
      },
      "source": [
        "### Cumulative Regret Calculator:\n",
        "\n",
        "def min_max_array(x):\n",
        "    new_list = []\n",
        "    for i, num in enumerate(x):\n",
        "            new_list.append(np.min(x[0:i+1]))\n",
        "    return new_list\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Add exact acquisition function gradient as attribute:\n",
        "\n",
        "Beta_CBM = 1.5 #dim\n",
        "\n",
        "class Acquisition_new(Acquisition):    \n",
        "    def __init__(self, mode, eps=1e-06, **params):\n",
        "        \n",
        "        self.params = params\n",
        "        self.eps = eps\n",
        "\n",
        "        mode_dict = {\n",
        "            'CBMinimized': self.CBMinimized,\n",
        "            'tCBMinimized': self.tCBMinimized\n",
        "        }\n",
        "\n",
        "        self.f = mode_dict[mode]\n",
        "   \n",
        "    def CBMinimized(self, tau, mean, std):\n",
        "        \n",
        "        gamma = (mean - y_global_orig - self.eps) / (std + self.eps)\n",
        "        return (std + self.eps) * (gamma + np.sqrt(Beta_CBM))\n",
        "    \n",
        "    def tCBMinimized(self, tau, mean, std, nu=3.0):\n",
        "        \n",
        "        gamma = (mean - y_global_orig - self.eps) / (std + self.eps)\n",
        "        return (std + self.eps) * (gamma + np.sqrt(Beta_CBM))\n"
      ],
      "metadata": {
        "id": "ZIh5RYGkwBUZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlilveEgdIR_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a5efde7-a16d-4d7a-c84c-2601c54b16ff"
      },
      "source": [
        "start_gp = time.time()\n",
        "start_gp"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1663086027.2050498"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wlzDSHbUG-c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "feae5151-edd2-493d-8324-e280b26560b3"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'gp' Acquisition Function run number = 1\n",
        "\n",
        "np.random.seed(run_num_1)\n",
        "surrogate_gp_1 = GaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train1, X_test1, y_train1, y_test1 = train_test_split(X, y, test_size=test_perc, random_state=run_num_1)\n",
        "\n",
        "def f_syn_polarity1(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_1, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train1, y=y_train1).mean())\n",
        "    return operator * score\n",
        "\n",
        "gp_1 = GPGO(surrogate_gp_1, Acquisition_new(util_gp), f_syn_polarity1, param, n_jobs = -1) # define BayesOpt\n",
        "gp_1.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_gp_1 = gp_1.getResult()[0]\n",
        "params_gp_1['max_depth'] = int(params_gp_1['max_depth'])\n",
        "params_gp_1['min_child_weight'] = int(params_gp_1['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_gp_train1 = xgb.DMatrix(X_train1, y_train1)\n",
        "dX_gp_test1 = xgb.DMatrix(X_test1, y_test1)\n",
        "model_gp_1 = xgb.train(params_gp_1, dX_gp_train1)\n",
        "pred_gp_1 = model_gp_1.predict(dX_gp_test1)\n",
        "\n",
        "rmse_gp_1 = np.sqrt(mean_squared_error(pred_gp_1, y_test1))\n",
        "rmse_gp_1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 4.17022005  7.20324493 14.          0.65116629 16.          0.31248008]. \t  -1.9958892406678181 \t -1.927633642985235\n",
            "init   \t [ 3.96580727  3.87910741 11.          0.96776954  6.          0.71669755]. \t  -1.9397531362536724 \t -1.927633642985235\n",
            "init   \t [ 2.0445225   8.78117436  7.          0.95698101 10.          0.48762871]. \t  -1.9976238165476006 \t -1.927633642985235\n",
            "init   \t [ 9.39127789  7.78389236 14.          0.98413079  2.          0.87851823]. \t  -1.927633642985235 \t -1.927633642985235\n",
            "init   \t [8.29146907 8.29603359 8.         0.58491521 9.         0.18851215]. \t  -1.9902043452530749 \t -1.927633642985235\n",
            "1      \t [ 7.86951474  0.6406733  11.          0.78919481 19.          0.44182296]. \t  -1.9906604186473822 \t -1.927633642985235\n",
            "2      \t [3.3802338  7.90980166 8.         0.59612501 4.         0.17409348]. \t  -1.9902505685541254 \t -1.927633642985235\n",
            "3      \t [ 8.37248824  9.47571383  8.          0.69744113 18.          0.18664136]. \t  -1.9890386123917083 \t -1.927633642985235\n",
            "4      \t [ 1.90283483  0.05880981 13.          0.97974743 12.          0.72805749]. \t  -1.9364014398393128 \t -1.927633642985235\n",
            "5      \t [ 1.00976957  0.43990226  7.          0.76329142 19.          0.42775327]. \t  -1.9920881895077596 \t -1.927633642985235\n",
            "6      \t [3.05510661 5.4757456  8.         0.54925797 8.         0.35828538]. \t  -2.0062018277721276 \t -1.927633642985235\n",
            "7      \t [8.6650221  9.45569726 5.         0.8687539  2.         0.61530184]. \t  -1.9435030912708722 \t -1.927633642985235\n",
            "8      \t [7.48628498 1.51155622 6.         0.85807268 7.         0.37628775]. \t  -1.988595480224547 \t -1.927633642985235\n",
            "9      \t [ 9.60267493  1.35769118 13.          0.53476196  4.          0.98190352]. \t  -1.9416487324554375 \t -1.927633642985235\n",
            "10     \t [ 8.34390322  5.19477205 14.          0.98978018 10.          0.74085569]. \t  -1.938049078056728 \t -1.927633642985235\n",
            "11     \t [0.00729349 0.2106352  5.         0.83783904 2.         0.22549491]. \t  -1.9909716278444975 \t -1.927633642985235\n",
            "12     \t [ 0.56339726  6.06402372 13.          0.80924496  1.          0.67699453]. \t  -1.9452956704424498 \t -1.927633642985235\n",
            "13     \t [ 1.62105016  8.31766977  5.          0.75528328 18.          0.92641593]. \t  -1.9352716605340656 \t -1.927633642985235\n",
            "14     \t [ 9.7363727   0.6255235   9.          0.54070869 13.          0.18496547]. \t  -1.99535503671065 \t -1.927633642985235\n",
            "15     \t [ 2.03031173  0.23949832  6.          0.55958895 13.          0.63870934]. \t  -1.9475539594288065 \t -1.927633642985235\n",
            "16     \t [6.6130101  2.58363418 7.         0.88754148 1.         0.27712939]. \t  -1.9993770365853494 \t -1.927633642985235\n",
            "17     \t [ 5.78844777  4.19960853  6.          0.96640243 19.          0.89492644]. \t  \u001b[92m-1.9168144020683993\u001b[0m \t -1.9168144020683993\n",
            "18     \t [ 1.16665483  4.54662538 12.          0.86961684 19.          0.72573065]. \t  -1.9371993792461217 \t -1.9168144020683993\n",
            "19     \t [ 4.77975644  0.94451392 13.          0.69457032  1.          0.38776484]. \t  -2.000235139458975 \t -1.9168144020683993\n",
            "20     \t [ 7.20798197  0.         11.35641014  0.64426958  8.66144225  0.1       ]. \t  -1.9945671870604333 \t -1.9168144020683993\n",
            "21     \t [ 7.26077517  6.12663875  5.          0.88530553 13.          0.85587133]. \t  -1.9369798752432015 \t -1.9168144020683993\n",
            "22     \t [ 0.60865208  8.58414309 13.          0.92559776 10.          0.96073762]. \t  \u001b[92m-1.9152582474292181\u001b[0m \t -1.9152582474292181\n",
            "23     \t [1.42430107 0.         8.30629889 0.5        7.80627136 1.        ]. \t  -1.9333461163927879 \t -1.9152582474292181\n",
            "24     \t [ 9.87505792  6.66837778 13.          0.73663566 16.          0.35730739]. \t  -1.991102986798877 \t -1.9152582474292181\n",
            "25     \t [ 0.18256843  9.80114086 11.          0.99093287 18.          0.37632134]. \t  -1.9886334646424877 \t -1.9152582474292181\n",
            "26     \t [ 0.45997981  0.06225002 14.          0.83843842  5.          0.61806168]. \t  -1.9490635799481997 \t -1.9152582474292181\n",
            "27     \t [ 1.46423465  5.3876255   9.          0.62147438 14.          0.83389472]. \t  -1.9440764888514235 \t -1.9152582474292181\n",
            "28     \t [ 3.84855956  0.11826814 14.          0.65781536 17.          0.65927332]. \t  -1.9442862447599623 \t -1.9152582474292181\n",
            "29     \t [ 7.28587864  2.24783242 14.          0.73021029 12.          0.81296805]. \t  -1.9337359833122392 \t -1.9152582474292181\n",
            "30     \t [ 7.99100795 10.         15.          1.         12.3358301   1.        ]. \t  \u001b[92m-1.9124814486754858\u001b[0m \t -1.9124814486754858\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60754.16307826351"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClJ9rN2KUJzy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbcad435-781f-4264-b436-825a08ca3cc0"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'gp' Acquisition Function run number = 2\n",
        "\n",
        "np.random.seed(run_num_2)\n",
        "surrogate_gp_2 = GaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(X, y, test_size=test_perc, random_state=run_num_2)\n",
        "\n",
        "def f_syn_polarity2(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_2, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train2, y=y_train2).mean())\n",
        "    return operator * score\n",
        "\n",
        "gp_2 = GPGO(surrogate_gp_2, Acquisition_new(util_gp), f_syn_polarity2, param, n_jobs = -1) # define BayesOpt\n",
        "gp_2.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_gp_2 = gp_2.getResult()[0]\n",
        "params_gp_2['max_depth'] = int(params_gp_2['max_depth'])\n",
        "params_gp_2['min_child_weight'] = int(params_gp_2['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_gp_train2 = xgb.DMatrix(X_train2, y_train2)\n",
        "dX_gp_test2 = xgb.DMatrix(X_test2, y_test2)\n",
        "model_gp_2 = xgb.train(params_gp_2, dX_gp_train2)\n",
        "pred_gp_2 = model_gp_2.predict(dX_gp_test2)\n",
        "\n",
        "rmse_gp_2 = np.sqrt(mean_squared_error(pred_gp_2, y_test2))\n",
        "rmse_gp_2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 4.35994902  0.25926232 11.          0.97386531 12.          0.47833102]. \t  -2.0298081650952664 \t -1.9841229044560336\n",
            "init   \t [ 3.30334821  2.04648634 10.          0.55997527  6.          0.71472339]. \t  -2.0048957563444234 \t -1.9841229044560336\n",
            "init   \t [ 4.9856117   5.86796978  8.          0.89266757 11.          0.59158659]. \t  -1.9841229044560336 \t -1.9841229044560336\n",
            "init   \t [ 4.07307832  1.76984624 13.          0.75262305  7.          0.35908193]. \t  -2.0696980515920655 \t -1.9841229044560336\n",
            "init   \t [ 1.16193318  1.81727038  9.          0.79837265 19.          0.29965165]. \t  -2.061218552452579 \t -1.9841229044560336\n",
            "1      \t [9.68290573 5.74953535 8.         0.93445831 2.         0.81872709]. \t  \u001b[92m-1.9816402148241052\u001b[0m \t -1.9816402148241052\n",
            "2      \t [ 8.78180153  6.61060882 12.          0.91523653 18.          0.29687212]. \t  -2.0625378531808507 \t -1.9816402148241052\n",
            "3      \t [ 0.66591974  9.26661294 14.          0.96342421 18.          0.94909068]. \t  \u001b[92m-1.9600810016378762\u001b[0m \t -1.9600810016378762\n",
            "4      \t [0.53023554 8.79041977 6.         0.85342606 1.         0.93968064]. \t  -1.9710210867331248 \t -1.9600810016378762\n",
            "5      \t [ 2.90965473  9.60484926 14.          0.96745917  2.          0.76388947]. \t  -1.9836549037974958 \t -1.9600810016378762\n",
            "6      \t [ 8.57602235  9.83360074 12.          0.99133635  7.          0.25584574]. \t  -2.073360437638249 \t -1.9600810016378762\n",
            "7      \t [ 9.77744834  2.26597384  5.          0.98618685 19.          0.58642903]. \t  -1.9815535400845103 \t -1.9600810016378762\n",
            "8      \t [ 1.82124551  9.97992306  7.          0.66460563 15.          0.68270076]. \t  -1.989156510671623 \t -1.9600810016378762\n",
            "9      \t [ 5.76886466  6.30636441 11.          0.85075313  6.          0.94564556]. \t  -1.9685258385323288 \t -1.9600810016378762\n",
            "10     \t [ 0.92680624  0.80829442  5.          0.99163751 10.          0.48273491]. \t  -2.027348177617255 \t -1.9600810016378762\n",
            "11     \t [ 8.66397635  9.94226364  5.          0.61754568 19.          0.46861962]. \t  -2.033276199037532 \t -1.9600810016378762\n",
            "12     \t [ 0.03855324  8.9930469  12.          0.98249334  8.          0.88557845]. \t  -1.9665018013580142 \t -1.9600810016378762\n",
            "13     \t [ 9.78109337  2.52726344  5.          0.62902817 11.          0.70291169]. \t  -1.9957339590420176 \t -1.9600810016378762\n",
            "14     \t [ 2.61078484  8.48438058 14.          0.79784401 12.          0.37480602]. \t  -2.0636983248476284 \t -1.9600810016378762\n",
            "15     \t [ 8.35914343  2.39349698 13.          0.9820231   1.          0.65048694]. \t  -1.9922723524942718 \t -1.9600810016378762\n",
            "16     \t [9.62212538 0.02188724 6.         0.71871951 5.         0.99422834]. \t  -1.9724245783625254 \t -1.9600810016378762\n",
            "17     \t [1.70838606 1.7073017  5.         0.64676695 1.         0.90384668]. \t  -1.9825651616032132 \t -1.9600810016378762\n",
            "18     \t [ 8.08580133  4.76452432 13.          0.87438829 11.          0.13864055]. \t  -2.0670641105170318 \t -1.9600810016378762\n",
            "19     \t [5.71127179 8.62909383 6.         0.9145048  4.         0.23844251]. \t  -2.069779422271244 \t -1.9600810016378762\n",
            "20     \t [ 0.40164348  1.66439141 14.          0.96476321  1.          0.14148109]. \t  -2.0704885954858554 \t -1.9600810016378762\n",
            "21     \t [ 0.          2.14748108 15.          0.5        11.74529189  1.        ]. \t  -1.9745489165920382 \t -1.9600810016378762\n",
            "22     \t [ 9.82502828  9.60705161  7.          0.82204279 10.          0.53606301]. \t  -1.9792346773428562 \t -1.9600810016378762\n",
            "23     \t [ 8.20282777  1.10989571 14.          0.76173732 19.          0.96560411]. \t  -1.9678129542863527 \t -1.9600810016378762\n",
            "24     \t [ 9.52708013  8.87907405 14.          0.61965333  2.          0.85399372]. \t  -2.001219952428713 \t -1.9600810016378762\n",
            "25     \t [10.          2.09092498 12.48779393  0.5         6.61563754  0.1       ]. \t  -2.0771568027561633 \t -1.9600810016378762\n",
            "26     \t [ 3.01982698  3.53132183 13.43245376  1.         16.49957248  0.1       ]. \t  -2.024343664515626 \t -1.9600810016378762\n",
            "27     \t [ 2.34474445 10.          6.91940521  0.5         8.56610466  0.22172464]. \t  -2.0761210463689883 \t -1.9600810016378762\n",
            "28     \t [ 3.59503153  3.0430168   6.          0.69422875 15.          0.61511341]. \t  -1.990811090851968 \t -1.9600810016378762\n",
            "29     \t [ 4.50289646  9.52028371 10.          0.92016613 19.          0.98574835]. \t  -1.962217499342587 \t -1.9600810016378762\n",
            "30     \t [10.          1.40213134 11.56058867  1.         14.60054174  0.1       ]. \t  -2.0260852929299893 \t -1.9600810016378762\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60928.26805906831"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-45l3NU4UNiI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d540f66f-5f6c-45e9-951d-1e82403532e5"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'gp' Acquisition Function run number = 3\n",
        "\n",
        "np.random.seed(run_num_3)\n",
        "surrogate_gp_3 = GaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train3, X_test3, y_train3, y_test3 = train_test_split(X, y, test_size=test_perc, random_state=run_num_3)\n",
        "\n",
        "def f_syn_polarity3(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_3, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train3, y=y_train3).mean())\n",
        "    return operator * score\n",
        "\n",
        "gp_3 = GPGO(surrogate_gp_3, Acquisition_new(util_gp), f_syn_polarity3, param, n_jobs = -1) # define BayesOpt\n",
        "gp_3.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_gp_3 = gp_3.getResult()[0]\n",
        "params_gp_3['max_depth'] = int(params_gp_3['max_depth'])\n",
        "params_gp_3['min_child_weight'] = int(params_gp_3['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_gp_train3 = xgb.DMatrix(X_train3, y_train3)\n",
        "dX_gp_test3 = xgb.DMatrix(X_test3, y_test3)\n",
        "model_gp_3 = xgb.train(params_gp_3, dX_gp_train3)\n",
        "pred_gp_3 = model_gp_3.predict(dX_gp_test3)\n",
        "\n",
        "rmse_gp_3 = np.sqrt(mean_squared_error(pred_gp_3, y_test3))\n",
        "rmse_gp_3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 5.50797903  7.08147823 13.          0.56066429 11.          0.11687321]. \t  -2.1327354912839973 \t -1.9956488227380944\n",
            "init   \t [ 0.40630737  2.47888297 11.          0.72040492 13.          0.23083313]. \t  -2.1286878580840187 \t -1.9956488227380944\n",
            "init   \t [ 4.53172301  2.15577008 11.          0.74631796  2.          0.60296868]. \t  -1.9956488227380944 \t -1.9956488227380944\n",
            "init   \t [ 2.59252447  4.15101197 13.          0.79330998  8.          0.24118096]. \t  -2.1306652618833883 \t -1.9956488227380944\n",
            "init   \t [ 5.44649018  7.80314765 10.          0.62879264 18.          0.44917413]. \t  -2.051679716515038 \t -1.9956488227380944\n",
            "1      \t [1.56262424 9.7795241  5.         0.91450054 5.         0.53102391]. \t  -1.9989939830559114 \t -1.9956488227380944\n",
            "2      \t [ 8.93142368  1.52910591 13.          0.84039318 17.          0.60846833]. \t  \u001b[92m-1.9953686415021132\u001b[0m \t -1.9953686415021132\n",
            "3      \t [9.68641233 7.7212035  5.         0.60078619 2.         0.57796031]. \t  -2.003566930549266 \t -1.9953686415021132\n",
            "4      \t [ 1.02918863  9.32189805 13.          0.88333707  1.          0.86998588]. \t  -2.0050604989880227 \t -1.9953686415021132\n",
            "5      \t [ 9.74929058  1.51205926 11.          0.50025602  8.          0.46132437]. \t  -2.0541445686203503 \t -1.9953686415021132\n",
            "6      \t [ 9.45052852  8.62641484  7.          0.79615518 14.          0.32790361]. \t  -2.0769770070341353 \t -1.9953686415021132\n",
            "7      \t [ 8.92744991  9.09956287 12.          0.74944313  3.          0.11030352]. \t  -2.1316968930284994 \t -1.9953686415021132\n",
            "8      \t [0.28002919 1.86471402 5.         0.90893429 3.         0.44808833]. \t  -2.0444642827108863 \t -1.9953686415021132\n",
            "9      \t [ 6.05702602  0.88990025  5.          0.89549846 14.          0.28308539]. \t  -2.0768586481491047 \t -1.9953686415021132\n",
            "10     \t [ 1.60321997  5.10906454  5.          0.64421712 17.          0.93059667]. \t  -2.00695112305836 \t -1.9953686415021132\n",
            "11     \t [ 3.07505056  9.78732799  6.          0.96847152 12.          0.34771766]. \t  -2.0792248354152894 \t -1.9953686415021132\n",
            "12     \t [ 9.78712557  1.33421863 14.          0.76006252  3.          0.92913188]. \t  -2.003280218425572 \t -1.9953686415021132\n",
            "13     \t [2.99254427 2.69228882 7.         0.63915731 9.         0.21678027]. \t  -2.1313948591378016 \t -1.9953686415021132\n",
            "14     \t [8.8237369  0.04240955 5.         0.7158964  1.         0.99950517]. \t  -1.9964548101090434 \t -1.9953686415021132\n",
            "15     \t [ 5.7586577   1.42812945 10.          0.74022438  8.          0.79053147]. \t  -2.004780908170871 \t -1.9953686415021132\n",
            "16     \t [9.25339855 3.80341124 5.         0.92679998 9.         0.56391072]. \t  -1.9983819336331847 \t -1.9953686415021132\n",
            "17     \t [ 0.94336997  1.29293405 12.          0.62917786 19.          0.81056172]. \t  -2.0049701566396494 \t -1.9953686415021132\n",
            "18     \t [ 0.43257892  6.2901565  12.63920396  0.5        16.86349886  1.        ]. \t  \u001b[92m-1.990584247136739\u001b[0m \t -1.990584247136739\n",
            "19     \t [ 7.56254766  4.2696935   6.          0.61616459 18.          0.87307804]. \t  -2.0021014417615306 \t -1.990584247136739\n",
            "20     \t [8.69445334 9.32412616 7.         0.88093126 7.         0.17908776]. \t  -2.125796631029165 \t -1.990584247136739\n",
            "21     \t [ 6.40272995  1.06358237 14.          0.62818522 12.          0.41787453]. \t  -2.0551821372294024 \t -1.990584247136739\n",
            "22     \t [ 8.10601891 10.         14.10549695  1.         15.32639821  0.88663659]. \t  -1.996640392737934 \t -1.990584247136739\n",
            "23     \t [ 5.76527456  4.01018086  9.          0.81180183 13.          0.81206766]. \t  \u001b[92m-1.9894937228366665\u001b[0m \t -1.9894937228366665\n",
            "24     \t [1.52170238 5.56235877 9.         0.83783695 5.         0.52222813]. \t  -1.9957552049196514 \t -1.9894937228366665\n",
            "25     \t [ 0.          0.          6.73580485  0.89126965 16.77188201  0.1       ]. \t  -2.124583804439875 \t -1.9894937228366665\n",
            "26     \t [ 9.57846798  5.67492818 11.          0.9450323  15.          0.64577167]. \t  -1.9962251459501617 \t -1.9894937228366665\n",
            "27     \t [ 1.25153686  8.78207989 11.          0.88112964  9.          0.97144988]. \t  -1.9946164277037994 \t -1.9894937228366665\n",
            "28     \t [ 1.49730247  0.83144325 14.          0.60476723  9.          0.25549349]. \t  -2.080075314012411 \t -1.9894937228366665\n",
            "29     \t [ 0.10026874  3.99596933 14.          0.6822027   3.          0.96481664]. \t  -1.9969942735887467 \t -1.9894937228366665\n",
            "30     \t [ 4.90783141 10.         15.          0.5         6.67084625  0.1       ]. \t  -2.140437737672041 \t -1.9894937228366665\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "59850.95807424735"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "voPfk1UDUQU0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce299759-e230-4de1-f56f-fb793c197608"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'gp' Acquisition Function run number = 4\n",
        "\n",
        "np.random.seed(run_num_4)\n",
        "surrogate_gp_4 = GaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train4, X_test4, y_train4, y_test4 = train_test_split(X, y, test_size=test_perc, random_state=run_num_4)\n",
        "\n",
        "def f_syn_polarity4(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_4, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train4, y=y_train4).mean())\n",
        "    return operator * score\n",
        "\n",
        "gp_4 = GPGO(surrogate_gp_4, Acquisition_new(util_gp), f_syn_polarity4, param, n_jobs = -1) # define BayesOpt\n",
        "gp_4.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_gp_4 = gp_4.getResult()[0]\n",
        "params_gp_4['max_depth'] = int(params_gp_4['max_depth'])\n",
        "params_gp_4['min_child_weight'] = int(params_gp_4['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_gp_train4 = xgb.DMatrix(X_train4, y_train4)\n",
        "dX_gp_test4 = xgb.DMatrix(X_test4, y_test4)\n",
        "model_gp_4 = xgb.train(params_gp_4, dX_gp_train4)\n",
        "pred_gp_4 = model_gp_4.predict(dX_gp_test4)\n",
        "\n",
        "rmse_gp_4 = np.sqrt(mean_squared_error(pred_gp_4, y_test4))\n",
        "rmse_gp_4"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [9.67029839 5.47232249 6.         0.92781047 9.         0.72795594]. \t  -1.9389833982070896 \t -1.9185014978322321\n",
            "init   \t [ 2.16089496  9.76274455 12.          0.62649118  9.          0.66966679]. \t  -1.9445149590744684 \t -1.9185014978322321\n",
            "init   \t [ 0.05159149  5.72356491  9.          0.99170034 10.          0.10808749]. \t  -2.1102338527761537 \t -1.9185014978322321\n",
            "init   \t [ 3.86571283  0.44160058 10.          0.90553105 18.          0.95407958]. \t  -1.9185014978322321 \t -1.9185014978322321\n",
            "init   \t [ 7.86305986  8.66289299  6.          0.53285477 14.          0.25117497]. \t  -1.9862504726191532 \t -1.9185014978322321\n",
            "1      \t [ 8.45443649  8.61014312 11.          0.83475494  1.          0.14018305]. \t  -2.1075864515395755 \t -1.9185014978322321\n",
            "2      \t [ 0.77431146  1.96668116 12.          0.50723361  3.          0.74768925]. \t  -1.9573746201697617 \t -1.9185014978322321\n",
            "3      \t [2.27858743 6.23199766 5.         0.58705984 2.         0.80794289]. \t  -1.9714199193992887 \t -1.9185014978322321\n",
            "4      \t [ 6.832625    9.87635293 14.          0.84450885 19.          0.20389666]. \t  -2.1075635354065776 \t -1.9185014978322321\n",
            "5      \t [ 7.37255369  2.03491596 13.          0.8921741   9.          0.46934318]. \t  -1.979645832209521 \t -1.9185014978322321\n",
            "6      \t [ 0.05992751  6.06320143 14.          0.89322475 17.          0.32211096]. \t  -1.981246352695735 \t -1.9185014978322321\n",
            "7      \t [ 0.79250634  6.36332745  6.          0.84703891 17.          0.8628914 ]. \t  -1.949610991693739 \t -1.9185014978322321\n",
            "8      \t [9.26767626 0.09691703 5.         0.59554562 3.         0.95249041]. \t  -1.9400880411854338 \t -1.9185014978322321\n",
            "9      \t [ 9.93824172  2.34876498  7.          0.94210707 16.          0.6947317 ]. \t  -1.9417584484529364 \t -1.9185014978322321\n",
            "10     \t [3.43076773 0.51115291 6.         0.80398076 7.         0.163561  ]. \t  -2.1139902082782394 \t -1.9185014978322321\n",
            "11     \t [8.12039932 9.82838311 5.         0.6851891  3.         0.87462757]. \t  -1.9612928006763783 \t -1.9185014978322321\n",
            "12     \t [ 1.84964073  7.72151946 12.          0.69698122  2.          0.31110026]. \t  -1.9974789854715655 \t -1.9185014978322321\n",
            "13     \t [ 9.03174101  2.34471053 13.          0.52042845  3.          0.20136175]. \t  -2.112576606759479 \t -1.9185014978322321\n",
            "14     \t [ 9.29091353  0.24848851 14.          0.65742606 17.          0.33836791]. \t  -1.9934523680937175 \t -1.9185014978322321\n",
            "15     \t [3.19488299 9.73527155 6.         0.65266597 9.         0.60657999]. \t  -1.9940499328268757 \t -1.9185014978322321\n",
            "16     \t [ 1.76735513  0.         14.          1.         12.61539615  0.30744081]. \t  -1.9817211941108872 \t -1.9185014978322321\n",
            "17     \t [ 7.85427932  8.81949282 14.          0.936894    6.          0.6768425 ]. \t  -1.9396350670563138 \t -1.9185014978322321\n",
            "18     \t [6.77309206 4.72750244 5.         0.64974712 9.         0.52869381]. \t  -1.998803370557517 \t -1.9185014978322321\n",
            "19     \t [ 9.20682244  7.19880877 12.          0.9939086  15.          0.55833076]. \t  -1.9876464134261043 \t -1.9185014978322321\n",
            "20     \t [ 0.65787882  1.52536753  7.          0.582989   13.          0.8348692 ]. \t  -1.9582121365354577 \t -1.9185014978322321\n",
            "21     \t [3.70467295 0.42865714 5.         0.65772579 1.         0.52937485]. \t  -2.004022545048247 \t -1.9185014978322321\n",
            "22     \t [ 4.87796269  9.76915883  8.          0.70370432 19.          0.96700567]. \t  -1.935402146613446 \t -1.9185014978322321\n",
            "23     \t [ 3.14147744  5.3165008  14.          0.6337111  12.          0.96782581]. \t  -1.9331722348814229 \t -1.9185014978322321\n",
            "24     \t [ 9.96054571  0.56614043  5.          0.5        10.49554128  0.93934763]. \t  -1.9388519354753697 \t -1.9185014978322321\n",
            "25     \t [ 6.11542971  4.73500754  5.          0.71416589 19.          0.49348915]. \t  -1.9955325136969908 \t -1.9185014978322321\n",
            "26     \t [ 7.98552621  8.73091399 10.          0.97332035 10.          0.39737145]. \t  -1.9828502292611803 \t -1.9185014978322321\n",
            "27     \t [ 5.04279197  5.43339495 10.          0.92042275  6.          0.94062191]. \t  -1.9224023984316976 \t -1.9185014978322321\n",
            "28     \t [ 1.25383319  9.74936763  9.4664228   1.         14.42026183  0.94793657]. \t  -1.9376868038293555 \t -1.9185014978322321\n",
            "29     \t [ 5.86415083  3.91677268 14.          0.93272864 19.          0.92226844]. \t  -1.9187186195968668 \t -1.9185014978322321\n",
            "30     \t [1.53775874 8.7762349  8.         0.52832142 5.         0.57409152]. \t  -1.9946108167691683 \t -1.9185014978322321\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "61055.818606721616"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kEnTd7MUdlv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d65ab4e-6943-4c5e-9c2c-5ee399367ba9"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'gp' Acquisition Function run number = 5\n",
        "\n",
        "np.random.seed(run_num_5)\n",
        "surrogate_gp_5 = GaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train5, X_test5, y_train5, y_test5 = train_test_split(X, y, test_size=test_perc, random_state=run_num_5)\n",
        "\n",
        "def f_syn_polarity5(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_5, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train5, y=y_train5).mean())\n",
        "    return operator * score\n",
        "\n",
        "gp_5 = GPGO(surrogate_gp_5, Acquisition_new(util_gp), f_syn_polarity5, param, n_jobs = -1) # define BayesOpt\n",
        "gp_5.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_gp_5 = gp_5.getResult()[0]\n",
        "params_gp_5['max_depth'] = int(params_gp_5['max_depth'])\n",
        "params_gp_5['min_child_weight'] = int(params_gp_5['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_gp_train5 = xgb.DMatrix(X_train5, y_train5)\n",
        "dX_gp_test5 = xgb.DMatrix(X_test5, y_test5)\n",
        "model_gp_5 = xgb.train(params_gp_5, dX_gp_train5)\n",
        "pred_gp_5 = model_gp_5.predict(dX_gp_test5)\n",
        "\n",
        "rmse_gp_5 = np.sqrt(mean_squared_error(pred_gp_5, y_test5))\n",
        "rmse_gp_5"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 2.21993171  8.70732306 11.          0.68186845 10.          0.53957007]. \t  -1.9599422560077813 \t -1.9013654264108653\n",
            "init   \t [ 6.11743863  7.65907856  5.          0.64840025 16.          0.82745351]. \t  -1.9013654264108653 \t -1.9013654264108653\n",
            "init   \t [ 6.49458883  8.19472793  6.          0.93996852 19.          0.36647194]. \t  -2.005840325693773 \t -1.9013654264108653\n",
            "init   \t [ 6.28787909  5.7983781   6.          0.63290956 17.          0.18402673]. \t  -2.0055006279610965 \t -1.9013654264108653\n",
            "init   \t [8.26554249 8.33492742 9.         0.97900675 3.         0.26957319]. \t  -2.0104758642779474 \t -1.9013654264108653\n",
            "1      \t [1.95474956 1.21548467 5.         0.65548996 6.         0.3261206 ]. \t  -2.0061716974922197 \t -1.9013654264108653\n",
            "2      \t [ 0.09956678  5.3014067  14.          0.6298658  17.          0.94976952]. \t  \u001b[92m-1.8681155157955736\u001b[0m \t -1.8681155157955736\n",
            "3      \t [ 8.96005069  0.40158558 13.          0.99993231  1.          0.57714848]. \t  -1.9743761204144004 \t -1.8681155157955736\n",
            "4      \t [ 9.87326458  3.08165071 13.          0.89537491 17.          0.48678657]. \t  -1.9843552439502055 \t -1.8681155157955736\n",
            "5      \t [ 0.42801231  0.53056997 14.          0.88001393  3.          0.60870677]. \t  -1.9693627127747881 \t -1.8681155157955736\n",
            "6      \t [ 9.41789049  5.24678791 11.          0.78426601 10.          0.31189288]. \t  -2.0123407211850113 \t -1.8681155157955736\n",
            "7      \t [ 0.15773168  2.32643207  7.          0.74406654 13.          0.24500907]. \t  -2.0074196136021305 \t -1.8681155157955736\n",
            "8      \t [ 0.5259471   9.7567347  14.          0.91097263  1.          0.64281486]. \t  -1.9408048308052082 \t -1.8681155157955736\n",
            "9      \t [ 7.68019847  0.14272251  5.          0.84271757 13.          0.46064437]. \t  -1.9895292141970073 \t -1.8681155157955736\n",
            "10     \t [1.24717977 9.40645683 5.         0.65383928 3.         0.68852908]. \t  -1.9086666742183518 \t -1.8681155157955736\n",
            "11     \t [8.5765283  1.77730566 7.         0.63994635 4.         0.42153661]. \t  -1.992019890207755 \t -1.8681155157955736\n",
            "12     \t [7.9980796  9.13466128 6.         0.81085598 9.         0.18640376]. \t  -2.010288731629506 \t -1.8681155157955736\n",
            "13     \t [ 5.39228464  0.17784539 13.          0.57001227  9.          0.60313835]. \t  -1.963937440966379 \t -1.8681155157955736\n",
            "14     \t [ 3.9042494   1.34731655 10.          0.83969498 18.          0.52845925]. \t  -1.9532127066437064 \t -1.8681155157955736\n",
            "15     \t [2.03762865 4.34961943 8.         0.53797581 1.         0.36410352]. \t  -2.01753314549905 \t -1.8681155157955736\n",
            "16     \t [ 7.87772257  8.71340044 12.          0.8589136  15.          0.7305315 ]. \t  -1.9085759937383635 \t -1.8681155157955736\n",
            "17     \t [ 6.80615583  6.45556443 14.          0.61036314  1.          0.8555849 ]. \t  -1.907845049428511 \t -1.8681155157955736\n",
            "18     \t [ 0.39655743  9.88537948  7.          0.8395494  15.          0.83639512]. \t  -1.893244314519989 \t -1.8681155157955736\n",
            "19     \t [0.86243549 8.92584837 5.         0.6740487  9.         0.55305648]. \t  -1.964018172954947 \t -1.8681155157955736\n",
            "20     \t [ 0.08863462  6.57371192 11.          0.96556049  5.          0.14575448]. \t  -2.0073189170480044 \t -1.8681155157955736\n",
            "21     \t [ 0.99809017  3.61800184 14.          0.6766942  10.          0.82487543]. \t  -1.8969064673487583 \t -1.8681155157955736\n",
            "22     \t [ 0.          0.         15.          0.81142577 15.22802943  1.        ]. \t  \u001b[92m-1.8463403476076716\u001b[0m \t -1.8463403476076716\n",
            "23     \t [ 6.81691807  8.87161629 14.          0.87860353  9.          0.18458297]. \t  -2.0090422531627317 \t -1.8463403476076716\n",
            "24     \t [10.          0.54174467 15.          0.5        12.16282422  0.1       ]. \t  -2.009595144839893 \t -1.8463403476076716\n",
            "25     \t [ 0.09378584  0.46225465  6.          0.94133859 19.          0.52002331]. \t  -1.9596628189423821 \t -1.8463403476076716\n",
            "26     \t [ 0.80787331 10.         14.41284302  0.5        20.          1.        ]. \t  -1.8582097789224545 \t -1.8463403476076716\n",
            "27     \t [ 2.99950681 10.         15.          0.5        15.00007499  0.1       ]. \t  -2.0086054657529764 \t -1.8463403476076716\n",
            "28     \t [ 8.43934599  0.8447506   5.          0.83249299 19.          0.31289567]. \t  -2.000026814624874 \t -1.8463403476076716\n",
            "29     \t [10.          4.8444724   8.92935853  0.66038879 20.          0.1       ]. \t  -2.0063968274594117 \t -1.8463403476076716\n",
            "30     \t [ 4.88751047  0.         15.          0.5        19.05482167  1.        ]. \t  -1.8582102899967403 \t -1.8463403476076716\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60210.54886703936"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjVSH6caUgyy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45e1e1b0-1c6d-4612-9f89-c5b663306b43"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'gp' Acquisition Function run number = 6\n",
        "\n",
        "np.random.seed(run_num_6)\n",
        "surrogate_gp_6 = GaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train6, X_test6, y_train6, y_test6 = train_test_split(X, y, test_size=test_perc, random_state=run_num_6)\n",
        "\n",
        "def f_syn_polarity6(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_6, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train6, y=y_train6).mean())\n",
        "    return operator * score\n",
        "\n",
        "gp_6 = GPGO(surrogate_gp_6, Acquisition_new(util_gp), f_syn_polarity6, param, n_jobs = -1) # define BayesOpt\n",
        "gp_6.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_gp_6 = gp_6.getResult()[0]\n",
        "params_gp_6['max_depth'] = int(params_gp_6['max_depth'])\n",
        "params_gp_6['min_child_weight'] = int(params_gp_6['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_gp_train6 = xgb.DMatrix(X_train6, y_train6)\n",
        "dX_gp_test6 = xgb.DMatrix(X_test6, y_test6)\n",
        "model_gp_6 = xgb.train(params_gp_6, dX_gp_train6)\n",
        "pred_gp_6 = model_gp_6.predict(dX_gp_test6)\n",
        "\n",
        "rmse_gp_6 = np.sqrt(mean_squared_error(pred_gp_6, y_test6))\n",
        "rmse_gp_6"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [8.92860151 3.31979805 5.         0.99251441 2.         0.57683563]. \t  -2.0905801027256743 \t -2.020381853595591\n",
            "init   \t [4.18807429 3.35407849 9.         0.87750649 3.         0.56623277]. \t  -2.104747753924113 \t -2.020381853595591\n",
            "init   \t [ 5.788586    6.45355096 14.          0.70660047 12.          0.82154882]. \t  -2.020381853595591 \t -2.020381853595591\n",
            "init   \t [4.58184578 6.73834679 5.         0.90108528 3.         0.65482895]. \t  -2.0496910493799936 \t -2.020381853595591\n",
            "init   \t [ 4.42510505  5.75952352 14.          0.97882365 15.          0.29525604]. \t  -2.1564159616109135 \t -2.020381853595591\n",
            "1      \t [ 2.61343239  0.80193947  5.          0.83898129 13.          0.84644718]. \t  -2.02621196060558 \t -2.020381853595591\n",
            "2      \t [ 9.72322443  9.21177696  5.          0.87917074 11.          0.86681736]. \t  \u001b[92m-2.0193657462286696\u001b[0m \t -2.0193657462286696\n",
            "3      \t [ 0.5654966   9.52584762 14.          0.82016688  4.          0.10717254]. \t  -2.1487300851829487 \t -2.0193657462286696\n",
            "4      \t [ 2.98453858  8.8700865   6.          0.73955182 19.          0.28620498]. \t  -2.1410241416778923 \t -2.0193657462286696\n",
            "5      \t [ 9.98276075  2.51129284  8.          0.78524028 18.          0.90705498]. \t  \u001b[92m-1.9750150418567827\u001b[0m \t -1.9750150418567827\n",
            "6      \t [ 0.58299146  9.62458538  9.          0.94830232 11.          0.21492907]. \t  -2.151749439048735 \t -1.9750150418567827\n",
            "7      \t [ 9.32984285  9.13994472 13.          0.80971831  3.          0.95492455]. \t  -1.9849310299252205 \t -1.9750150418567827\n",
            "8      \t [ 9.32420466  6.39616005 13.          0.93300527 17.          0.34904443]. \t  -2.146533426426378 \t -1.9750150418567827\n",
            "9      \t [ 5.79804816  0.18524154 13.          0.91373451 12.          0.1336305 ]. \t  -2.148175537742926 \t -1.9750150418567827\n",
            "10     \t [ 9.18133243  4.09376148 10.          0.96038921  5.          0.75655401]. \t  -2.020577079327632 \t -1.9750150418567827\n",
            "11     \t [0.50322511 5.36549123 5.         0.63452016 9.         0.79019916]. \t  -2.021821805543622 \t -1.9750150418567827\n",
            "12     \t [ 1.90877122  0.88669904 11.          0.72802974 19.          0.27519153]. \t  -2.145985178580054 \t -1.9750150418567827\n",
            "13     \t [ 8.84415462  2.89803683  6.          0.75669789 10.          0.66428199]. \t  -2.0537460074911182 \t -1.9750150418567827\n",
            "14     \t [10.          0.         14.28117006  0.5        18.4216642   1.        ]. \t  -1.9876962104420954 \t -1.9750150418567827\n",
            "15     \t [ 2.2641389   2.87702266 14.          0.73531552  7.          0.33037804]. \t  -2.1548264634319656 \t -1.9750150418567827\n",
            "16     \t [ 0.05509359  8.13873516 11.          0.83199834 17.          0.87257216]. \t  -2.023921519691978 \t -1.9750150418567827\n",
            "17     \t [6.81400827 9.89935465 8.         0.72740578 7.         0.33091033]. \t  -2.1503476153986534 \t -1.9750150418567827\n",
            "18     \t [ 5.15326097  6.52926284  8.          0.65974702 13.          0.97847666]. \t  -1.9791717792306485 \t -1.9750150418567827\n",
            "19     \t [ 0.17525712  4.19183624 13.          0.93093846  1.          0.77496282]. \t  -2.0309197792559224 \t -1.9750150418567827\n",
            "20     \t [ 8.62417079  9.77001908  6.          0.73303607 17.          0.10871273]. \t  -2.1476342380494104 \t -1.9750150418567827\n",
            "21     \t [ 1.96438538  2.93800461  5.          0.78368424 19.          0.63390012]. \t  -2.0548267575812753 \t -1.9750150418567827\n",
            "22     \t [ 0.50073585  2.52813513 13.          0.75574888 14.          0.36976835]. \t  -2.1412507771072593 \t -1.9750150418567827\n",
            "23     \t [ 7.95532776 10.         15.          0.5         8.41310887  0.1       ]. \t  -2.135237187312223 \t -1.9750150418567827\n",
            "24     \t [8.67537333 9.8187462  5.         0.97889521 1.         0.23239827]. \t  -2.1530080746235982 \t -1.9750150418567827\n",
            "25     \t [0.09585589 9.00028343 9.         0.81352481 2.         0.45635034]. \t  -2.1055997479408335 \t -1.9750150418567827\n",
            "26     \t [ 6.78501766  0.03433927 14.          0.61227345  3.          0.98696086]. \t  -1.9875559372690426 \t -1.9750150418567827\n",
            "27     \t [10.          5.65400423 10.97575514  0.5        11.2954809   0.1       ]. \t  -2.13471919176059 \t -1.9750150418567827\n",
            "28     \t [ 6.58207487  5.03922398 14.          0.94427329  1.          0.57216147]. \t  -2.1140529938246426 \t -1.9750150418567827\n",
            "29     \t [ 4.59985895 10.         11.26576806  0.5        20.          0.1       ]. \t  -2.134525862943975 \t -1.9750150418567827\n",
            "30     \t [0.         3.09744863 5.         1.         1.         1.        ]. \t  -1.9817605576460167 \t -1.9750150418567827\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60442.43826184427"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1WsphKSUj19",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6497b60c-2f93-4b45-f893-98ba583c9a08"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'gp' Acquisition Function run number = 7\n",
        "\n",
        "np.random.seed(run_num_7)\n",
        "surrogate_gp_7 = GaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train7, X_test7, y_train7, y_test7 = train_test_split(X, y, test_size=test_perc, random_state=run_num_7)\n",
        "\n",
        "def f_syn_polarity7(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_7, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train7, y=y_train7).mean())\n",
        "    return operator * score\n",
        "\n",
        "gp_7 = GPGO(surrogate_gp_7, Acquisition_new(util_gp), f_syn_polarity7, param, n_jobs = -1) # define BayesOpt\n",
        "gp_7.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_gp_7 = gp_7.getResult()[0]\n",
        "params_gp_7['max_depth'] = int(params_gp_7['max_depth'])\n",
        "params_gp_7['min_child_weight'] = int(params_gp_7['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_gp_train7 = xgb.DMatrix(X_train7, y_train7)\n",
        "dX_gp_test7 = xgb.DMatrix(X_test7, y_test7)\n",
        "model_gp_7 = xgb.train(params_gp_7, dX_gp_train7)\n",
        "pred_gp_7 = model_gp_7.predict(dX_gp_test7)\n",
        "\n",
        "rmse_gp_7 = np.sqrt(mean_squared_error(pred_gp_7, y_test7))\n",
        "rmse_gp_7"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.76308289 7.79918792 8.         0.98911145 8.         0.98019056]. \t  -1.9078690836840042 \t -1.9078690836840042\n",
            "init   \t [ 5.3849587   5.01120464 13.          0.74994125  5.          0.88192131]. \t  -1.9193284947185432 \t -1.9078690836840042\n",
            "init   \t [ 3.30839249  3.9294231  12.          0.6440728  13.          0.41137564]. \t  -1.9707847574302377 \t -1.9078690836840042\n",
            "init   \t [9.29528191 2.6258377  5.         0.80027446 1.         0.86616513]. \t  -1.955231925484334 \t -1.9078690836840042\n",
            "init   \t [ 1.74052764  7.90763512 14.          0.7244129   4.          0.77536887]. \t  -1.94667647934123 \t -1.9078690836840042\n",
            "1      \t [3.70351083 4.59092978 6.         0.70937861 6.         0.814213  ]. \t  -1.9596547112058986 \t -1.9078690836840042\n",
            "2      \t [ 0.03374059  5.72098042  5.          0.61235924 18.          0.8711559 ]. \t  -1.9589402156911349 \t -1.9078690836840042\n",
            "3      \t [ 9.12127254  9.64651695 14.          0.53624962  1.          0.38247449]. \t  -1.983787343748326 \t -1.9078690836840042\n",
            "4      \t [ 8.15448719  3.4710932   7.          0.61547067 18.          0.53291628]. \t  -1.9768483459531683 \t -1.9078690836840042\n",
            "5      \t [ 9.19979425  8.97441441 13.          0.88387282 19.          0.6456674 ]. \t  -1.9660056122558085 \t -1.9078690836840042\n",
            "6      \t [9.43260743 8.53539628 9.         0.68880888 9.         0.5954756 ]. \t  -1.9783761196744543 \t -1.9078690836840042\n",
            "7      \t [ 7.73252727  0.7079457   5.          0.93170437 11.          0.47373855]. \t  -1.9666404523918488 \t -1.9078690836840042\n",
            "8      \t [ 0.04434682  1.14105742 10.          0.89864231  2.          0.82027014]. \t  -1.9354139372919419 \t -1.9078690836840042\n",
            "9      \t [ 1.29932493  8.0055142  14.          0.51325501 19.          0.83654101]. \t  -1.9515012533789764 \t -1.9078690836840042\n",
            "10     \t [1.52216216 8.41306408 5.         0.57743997 1.         0.26594603]. \t  -2.0703839538380793 \t -1.9078690836840042\n",
            "11     \t [ 5.67407045  9.94967311  6.          0.75213901 15.          0.78517579]. \t  -1.9446966121536442 \t -1.9078690836840042\n",
            "12     \t [ 9.94824081  0.39149062 12.          0.59113076  1.          0.49709751]. \t  -1.9834435881990262 \t -1.9078690836840042\n",
            "13     \t [ 9.50485243  0.62770054 13.          0.93971373  9.          0.8838596 ]. \t  -1.9130862713548011 \t -1.9078690836840042\n",
            "14     \t [ 3.34596156  0.67230605 11.          0.7366642  19.          0.29949997]. \t  -2.061190783602228 \t -1.9078690836840042\n",
            "15     \t [ 2.46176728  0.50526411  8.          0.70541011 10.          0.67627912]. \t  -1.9713846842448306 \t -1.9078690836840042\n",
            "16     \t [ 1.43297985  0.60163245 14.          0.83220406  8.          0.35678245]. \t  -2.054879545215944 \t -1.9078690836840042\n",
            "17     \t [ 5.07215524  9.54440855 14.          0.82673842 10.          0.75906001]. \t  -1.941363060362939 \t -1.9078690836840042\n",
            "18     \t [ 8.09171007  1.0036208  14.          0.56241102 16.          0.73442263]. \t  -1.9727832151120288 \t -1.9078690836840042\n",
            "19     \t [1.23898345 0.         5.         0.5        4.89324704 0.83141373]. \t  -1.9546744785127725 \t -1.9078690836840042\n",
            "20     \t [ 4.89919929  6.40860935  6.          0.86581969 12.          0.5519614 ]. \t  -1.9690945297846678 \t -1.9078690836840042\n",
            "21     \t [ 0.11818298  8.16975133  9.          0.52445152 14.          0.81513004]. \t  -1.9496059667676626 \t -1.9078690836840042\n",
            "22     \t [ 5.08446652  8.91354164 10.          0.78618996  1.          0.52971559]. \t  -1.9771747846059555 \t -1.9078690836840042\n",
            "23     \t [8.90713551 8.14959916 5.         0.87117507 3.         0.7070946 ]. \t  -1.9703164626294885 \t -1.9078690836840042\n",
            "24     \t [ 2.98760852  8.6340746   9.          0.99150841 19.          0.12804778]. \t  -2.1106752010865844 \t -1.9078690836840042\n",
            "25     \t [ 7.04212807  2.0964224   6.          0.68354682 18.          0.40452404]. \t  -1.9725379531265297 \t -1.9078690836840042\n",
            "26     \t [8.97724042 2.45771723 7.         0.8512854  6.         0.30764744]. \t  -2.05540425148707 \t -1.9078690836840042\n",
            "27     \t [ 0.          8.59734664 15.          1.         13.01554397  1.        ]. \t  -1.9111553085296873 \t -1.9078690836840042\n",
            "28     \t [10.          2.28004583  9.24180784  1.         13.07725722  0.97511066]. \t  -1.9212151514266083 \t -1.9078690836840042\n",
            "29     \t [10.          5.49050482 10.91383135  1.          2.99045229  0.1       ]. \t  -2.019949822526127 \t -1.9078690836840042\n",
            "30     \t [10.          0.         10.94324284  0.5        20.          0.1       ]. \t  -2.122259155200623 \t -1.9078690836840042\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "61351.93418054509"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hI8sFP4ZUmOs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec2f0708-5977-478b-be10-ef670ac2c898"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'gp' Acquisition Function run number = 8\n",
        "\n",
        "np.random.seed(run_num_8)\n",
        "surrogate_gp_8 = GaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train8, X_test8, y_train8, y_test8 = train_test_split(X, y, test_size=test_perc, random_state=run_num_8)\n",
        "\n",
        "def f_syn_polarity8(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_8, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train8, y=y_train8).mean())\n",
        "    return operator * score\n",
        "\n",
        "gp_8 = GPGO(surrogate_gp_8, Acquisition_new(util_gp), f_syn_polarity8, param, n_jobs = -1) # define BayesOpt\n",
        "gp_8.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_gp_8 = gp_8.getResult()[0]\n",
        "params_gp_8['max_depth'] = int(params_gp_8['max_depth'])\n",
        "params_gp_8['min_child_weight'] = int(params_gp_8['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_gp_train8 = xgb.DMatrix(X_train8, y_train8)\n",
        "dX_gp_test8 = xgb.DMatrix(X_test8, y_test8)\n",
        "model_gp_8 = xgb.train(params_gp_8, dX_gp_train8)\n",
        "pred_gp_8 = model_gp_8.predict(dX_gp_test8)\n",
        "\n",
        "rmse_gp_8 = np.sqrt(mean_squared_error(pred_gp_8, y_test8))\n",
        "rmse_gp_8"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 8.73429403  9.68540663 10.          0.68875849  9.          0.48011572]. \t  -1.9120326417702995 \t -1.8978279741265411\n",
            "init   \t [ 6.12033333  7.66062926  8.          0.76133734 13.          0.93379456]. \t  -1.8978279741265411 \t -1.8978279741265411\n",
            "init   \t [ 1.46524679  7.01527914  7.          0.90913299 10.          0.36016753]. \t  -1.9465178144863287 \t -1.8978279741265411\n",
            "init   \t [ 9.73855241  3.33774046 14.          0.53290419  7.          0.7088681 ]. \t  -1.921087044254333 \t -1.8978279741265411\n",
            "init   \t [ 3.00618018  1.82702795 11.          0.75681389 14.          0.98627449]. \t  -1.8997134238136284 \t -1.8978279741265411\n",
            "1      \t [4.42022545 5.48487111 9.         0.97165909 3.         0.63617522]. \t  \u001b[92m-1.8908646806075349\u001b[0m \t -1.8908646806075349\n",
            "2      \t [ 9.3432851   3.80536023 13.          0.82203895 19.          0.99569116]. \t  -1.89272590205946 \t -1.8908646806075349\n",
            "3      \t [ 2.52429836  9.02824683 14.          0.59641093 17.          0.61934886]. \t  -1.914756151644013 \t -1.8908646806075349\n",
            "4      \t [7.40075515 0.0926694  7.         0.94431092 3.         0.16026769]. \t  -2.026180933297388 \t -1.8908646806075349\n",
            "5      \t [ 1.35924905  5.41793837 14.          0.87246457  8.          0.19493237]. \t  -2.02973732995301 \t -1.8908646806075349\n",
            "6      \t [ 2.42575645  9.87357367  5.          0.61143882 19.          0.11833201]. \t  -2.0343401141761657 \t -1.8908646806075349\n",
            "7      \t [ 8.67626106  0.1397848   6.          0.55771681 18.          0.89120888]. \t  -1.9156445078171866 \t -1.8908646806075349\n",
            "8      \t [ 3.43855934  0.02041647 14.          0.50910442  1.          0.11324275]. \t  -2.0471159559947667 \t -1.8908646806075349\n",
            "9      \t [9.37270975 3.66850351 5.         0.50317335 9.         0.89158967]. \t  -1.9285733543839492 \t -1.8908646806075349\n",
            "10     \t [0.55400363 9.97465254 6.         0.64565646 3.         0.58326638]. \t  -1.9103129899021911 \t -1.8908646806075349\n",
            "11     \t [ 3.91346958  0.0847236   6.          0.6507141  10.          0.70303506]. \t  -1.9111311248386393 \t -1.8908646806075349\n",
            "12     \t [ 8.64114959  9.77378659 13.          0.70780119 19.          0.44594316]. \t  -1.9113801752990394 \t -1.8908646806075349\n",
            "13     \t [ 7.45033804  3.35443798  5.          0.94602269 18.          0.6516591 ]. \t  -1.8957389990249838 \t -1.8908646806075349\n",
            "14     \t [ 0.24957112  3.26102415  5.          0.59065773 17.          0.91920206]. \t  -1.914518808429288 \t -1.8908646806075349\n",
            "15     \t [9.99181107 8.28453416 5.         0.63682454 3.         0.29007423]. \t  -1.9655954643729743 \t -1.8908646806075349\n",
            "16     \t [ 8.59739123  5.64531547 14.          0.74303385 13.          0.81753843]. \t  -1.901819999848286 \t -1.8908646806075349\n",
            "17     \t [ 9.3183355   3.29262794 14.          0.86350712  1.          0.18562794]. \t  -2.0293648473947963 \t -1.8908646806075349\n",
            "18     \t [0.03921723 3.25792607 5.         0.55599086 5.         0.35467445]. \t  -1.9697358358274157 \t -1.8908646806075349\n",
            "19     \t [ 3.37466726  9.12246001 12.          0.91245467 11.          0.22387263]. \t  -2.023955469802661 \t -1.8908646806075349\n",
            "20     \t [ 6.68744311  8.81728204 13.          0.79205386  1.          0.27645475]. \t  -1.9596166167790414 \t -1.8908646806075349\n",
            "21     \t [ 0.04759975  0.58180684 11.          0.64306949  8.          0.92001253]. \t  -1.9140442404949567 \t -1.8908646806075349\n",
            "22     \t [1.98911669 0.28993142 6.         0.83354053 1.         0.7517807 ]. \t  -1.9031948931501486 \t -1.8908646806075349\n",
            "23     \t [ 5.67858034 10.          5.          0.5         7.74999943  0.1       ]. \t  -2.0422322962518367 \t -1.8908646806075349\n",
            "24     \t [ 1.60607112  6.72050918 14.61770424  0.5         1.          1.        ]. \t  -1.913838162075919 \t -1.8908646806075349\n",
            "25     \t [ 0.54777791  3.09782342 14.          0.64396842 19.          0.55122597]. \t  -1.9135040332946247 \t -1.8908646806075349\n",
            "26     \t [ 9.52773829  9.74841019  7.          0.53250812 18.          0.59000663]. \t  -1.9174523318961256 \t -1.8908646806075349\n",
            "27     \t [ 5.68801877  4.1503627  11.08527826  0.5         9.15160437  0.1       ]. \t  -2.0396892752913107 \t -1.8908646806075349\n",
            "28     \t [ 0.          3.19038801 11.85282781  0.5         3.40479983  0.1       ]. \t  -2.042965110033684 \t -1.8908646806075349\n",
            "29     \t [ 5.91879558  8.53687192 15.          0.5         6.9406103   1.        ]. \t  -1.9111935510643616 \t -1.8908646806075349\n",
            "30     \t [ 1.11876939  7.24313213 10.          0.85243584 15.          0.37907169]. \t  -1.9053224406073401 \t -1.8908646806075349\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60822.98185938519"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vw5IYus6UpAn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a1bd879-fe52-4d17-8810-d8e11c3892b5"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'gp' Acquisition Function run number = 9\n",
        "\n",
        "np.random.seed(run_num_9)\n",
        "surrogate_gp_9 = GaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train9, X_test9, y_train9, y_test9 = train_test_split(X, y, test_size=test_perc, random_state=run_num_9)\n",
        "\n",
        "def f_syn_polarity9(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_9, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train9, y=y_train9).mean())\n",
        "    return operator * score\n",
        "\n",
        "gp_9 = GPGO(surrogate_gp_9, Acquisition_new(util_gp), f_syn_polarity9, param, n_jobs = -1) # define BayesOpt\n",
        "gp_9.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_gp_9 = gp_9.getResult()[0]\n",
        "params_gp_9['max_depth'] = int(params_gp_9['max_depth'])\n",
        "params_gp_9['min_child_weight'] = int(params_gp_9['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_gp_train9 = xgb.DMatrix(X_train9, y_train9)\n",
        "dX_gp_test9 = xgb.DMatrix(X_test9, y_test9)\n",
        "model_gp_9 = xgb.train(params_gp_9, dX_gp_train9)\n",
        "pred_gp_9 = model_gp_9.predict(dX_gp_test9)\n",
        "\n",
        "rmse_gp_9 = np.sqrt(mean_squared_error(pred_gp_9, y_test9))\n",
        "rmse_gp_9"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 0.10374154  5.01874592 11.          0.50377155  2.          0.29670281]. \t  -2.165522561386585 \t -1.963183361033061\n",
            "init   \t [ 4.18508181  2.48101168 13.          0.69794293  2.          0.25009871]. \t  -2.1585464315559983 \t -1.963183361033061\n",
            "init   \t [ 8.78559086  9.50964032 13.          0.98395204 11.          0.90820641]. \t  -1.963183361033061 \t -1.963183361033061\n",
            "init   \t [ 6.66898973  5.47837783  6.          0.97165345 12.          0.72499481]. \t  -2.0332026844846673 \t -1.963183361033061\n",
            "init   \t [ 8.24870465  4.65668475 13.          0.68760467  9.          0.98502332]. \t  -1.990093015638481 \t -1.963183361033061\n",
            "1      \t [6.73714319 2.39608167 5.         0.58130302 3.         0.163077  ]. \t  -2.141000706961993 \t -1.963183361033061\n",
            "2      \t [ 1.89773665  4.24398106 11.          0.60135502  9.          0.22312501]. \t  -2.1420691289307263 \t -1.963183361033061\n",
            "3      \t [ 3.60566534  9.79805332 11.          0.62032576 16.          0.3578496 ]. \t  -2.1523125446424403 \t -1.963183361033061\n",
            "4      \t [ 4.86601509  0.61279594  8.          0.72162785 18.          0.68911833]. \t  -2.0367494366398486 \t -1.963183361033061\n",
            "5      \t [9.39353565 9.93046622 5.         0.57188784 4.         0.83501032]. \t  -2.0407674386690404 \t -1.963183361033061\n",
            "6      \t [1.13863488 5.86180669 5.         0.9953054  3.         0.88639082]. \t  -1.9733707814909445 \t -1.963183361033061\n",
            "7      \t [4.58728604 0.17361597 5.         0.87465126 8.         0.75024655]. \t  -2.0191440000719005 \t -1.963183361033061\n",
            "8      \t [ 7.07313313  8.94084339  5.          0.99439529 19.          0.33798274]. \t  -2.1423980804760943 \t -1.963183361033061\n",
            "9      \t [ 9.5805444   7.83819543 12.          0.79715932  3.          0.61699162]. \t  -2.041877784583074 \t -1.963183361033061\n",
            "10     \t [ 9.89680111  6.16985579 13.          0.58428363 17.          0.77251451]. \t  -2.030413459145069 \t -1.963183361033061\n",
            "11     \t [ 8.41810681  0.28363289 14.          0.70665052 14.          0.98883394]. \t  -1.9880347834610952 \t -1.963183361033061\n",
            "12     \t [ 1.960699    0.55073612 14.          0.55131138 15.          0.12137879]. \t  -2.1431732006298994 \t -1.963183361033061\n",
            "13     \t [ 1.98261944  9.85597834 14.          0.56925415  7.          0.93739664]. \t  -1.9938845051252645 \t -1.963183361033061\n",
            "14     \t [ 0.80844375  8.9121894   5.          0.56134557 18.          0.84901701]. \t  -2.0399284199132373 \t -1.963183361033061\n",
            "15     \t [4.62485155 9.65182222 5.         0.58896427 8.         0.36022331]. \t  -2.144608988438663 \t -1.963183361033061\n",
            "16     \t [ 0.4015988   2.55687657 10.          0.59113707 16.          0.83948651]. \t  -2.031032645610862 \t -1.963183361033061\n",
            "17     \t [ 3.89448326  9.77793126 11.          0.87312755  1.          0.25420157]. \t  -2.15150989851923 \t -1.963183361033061\n",
            "18     \t [ 9.9650824   0.70561372  5.          0.81536816 14.          0.22588839]. \t  -2.1421772905723664 \t -1.963183361033061\n",
            "19     \t [ 6.17111344  2.78900239 13.          0.52513592 19.          0.72053081]. \t  -2.0566050196721997 \t -1.963183361033061\n",
            "20     \t [ 1.22215427  7.33112015  6.          0.52333702 12.          0.67873863]. \t  -2.0688664080682995 \t -1.963183361033061\n",
            "21     \t [ 0.91966398  0.87416201  5.          0.51201636 15.          0.13639737]. \t  -2.151146830898276 \t -1.963183361033061\n",
            "22     \t [0.         2.30275676 6.22101844 0.5        9.7708591  0.1       ]. \t  -2.1511324741669853 \t -1.963183361033061\n",
            "23     \t [ 0.26688497  6.61712564 13.          0.73462536 13.          0.88698981]. \t  -1.9870408909389972 \t -1.963183361033061\n",
            "24     \t [9.0223237  0.52522072 9.         0.65667592 8.         0.49977193]. \t  -2.0798861610447408 \t -1.963183361033061\n",
            "25     \t [ 9.30371346  2.53887936 11.45119963  0.5         3.69733271  0.1524374 ]. \t  -2.1516629053292253 \t -1.963183361033061\n",
            "26     \t [ 4.59866707  1.51696625  9.          0.86264971 12.          0.40546822]. \t  -2.073851233326944 \t -1.963183361033061\n",
            "27     \t [ 0.41452964  0.16094648 14.          0.52700762  7.          0.94797412]. \t  -2.000459944751068 \t -1.963183361033061\n",
            "28     \t [1.20557164 0.86154404 8.53345944 1.         4.32780791 0.79750374]. \t  \u001b[92m-1.9574501737013157\u001b[0m \t -1.9574501737013157\n",
            "29     \t [4.46515863 7.30120145 9.         0.58490935 5.         0.60093974]. \t  -2.0551530571823973 \t -1.9574501737013157\n",
            "30     \t [ 5.11587877 10.          5.54194636  0.5         1.          1.        ]. \t  -2.015049990016471 \t -1.9574501737013157\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60883.36599056475"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YD494io_Ur7V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20bf1146-378c-40d2-a223-9b053b7caeb5"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'gp' Acquisition Function run number = 10\n",
        "\n",
        "np.random.seed(run_num_10)\n",
        "surrogate_gp_10 = GaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train10, X_test10, y_train10, y_test10 = train_test_split(X, y, test_size=test_perc, random_state=run_num_10)\n",
        "\n",
        "def f_syn_polarity10(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_10, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train10, y=y_train10).mean())\n",
        "    return operator * score\n",
        "\n",
        "gp_10 = GPGO(surrogate_gp_10, Acquisition_new(util_gp), f_syn_polarity10, param, n_jobs = -1) # define BayesOpt\n",
        "gp_10.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_gp_10 = gp_10.getResult()[0]\n",
        "params_gp_10['max_depth'] = int(params_gp_10['max_depth'])\n",
        "params_gp_10['min_child_weight'] = int(params_gp_10['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_gp_train10 = xgb.DMatrix(X_train10, y_train10)\n",
        "dX_gp_test10 = xgb.DMatrix(X_test10, y_test10)\n",
        "model_gp_10 = xgb.train(params_gp_10, dX_gp_train10)\n",
        "pred_gp_10 = model_gp_10.predict(dX_gp_test10)\n",
        "\n",
        "rmse_gp_10 = np.sqrt(mean_squared_error(pred_gp_10, y_test10))\n",
        "rmse_gp_10"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 7.71320643  0.20751949  5.          0.72150747 17.          0.12265456]. \t  -2.120578178283629 \t -1.940587000655573\n",
            "init   \t [ 7.0920801   2.65566127 13.          0.57518893 17.          0.83494165]. \t  -1.9492101131384572 \t -1.940587000655573\n",
            "init   \t [ 3.36071584  8.90816531  6.          0.86087766 15.          0.75469196]. \t  -1.940587000655573 \t -1.940587000655573\n",
            "init   \t [ 5.40880931  1.31458152  8.          0.57108502 14.          0.62551123]. \t  -1.9531076777438756 \t -1.940587000655573\n",
            "init   \t [1.82631436 8.26082248 6.         0.80888349 5.         0.15900694]. \t  -2.117914211014308 \t -1.940587000655573\n",
            "1      \t [8.31989768 3.09778055 7.         0.64798085 3.         0.98471878]. \t  -1.9418208809914852 \t -1.940587000655573\n",
            "2      \t [ 1.51483713  6.46720195 14.          0.87676044  8.          0.10934204]. \t  -2.1137891529220116 \t -1.940587000655573\n",
            "3      \t [ 0.44494294  2.20797313 10.          0.76097539  2.          0.34290111]. \t  -2.047774573640905 \t -1.940587000655573\n",
            "4      \t [ 6.23532773  8.31439809 13.          0.65134225  1.          0.75774237]. \t  -1.944930422519724 \t -1.940587000655573\n",
            "5      \t [ 9.32103763  8.04997374 14.          0.76165598 11.          0.58576369]. \t  -1.94715310296014 \t -1.940587000655573\n",
            "6      \t [ 0.17864568  6.30557409 14.          0.94841763 16.          0.27279561]. \t  -2.0417362630376 \t -1.940587000655573\n",
            "7      \t [ 9.16520307  0.72602801 12.          0.91999471  9.          0.54336218]. \t  -1.942906357007064 \t -1.940587000655573\n",
            "8      \t [ 0.13114685  2.69967978  5.          0.89490476 19.          0.55706236]. \t  -1.9467516181423725 \t -1.940587000655573\n",
            "9      \t [ 9.57603828  8.81375557  5.          0.56495862 19.          0.45710368]. \t  -1.9933028759284936 \t -1.940587000655573\n",
            "10     \t [ 9.82501514  7.31311253  5.          0.75029053 12.          0.39735105]. \t  -1.9923385444831923 \t -1.940587000655573\n",
            "11     \t [9.53733075 9.92797623 5.         0.78642342 2.         0.9933049 ]. \t  \u001b[92m-1.9394486724855446\u001b[0m \t -1.9394486724855446\n",
            "12     \t [1.69575137 2.28628662 5.         0.76046389 8.         0.60065268]. \t  -1.953232928578156 \t -1.9394486724855446\n",
            "13     \t [ 6.15733989  0.33396443 13.          0.69796716  1.          0.92875212]. \t  -1.9420397440154662 \t -1.9394486724855446\n",
            "14     \t [ 9.40820236  7.3159025  11.          0.68831328  6.          0.15637769]. \t  -2.1165621381230264 \t -1.9394486724855446\n",
            "15     \t [ 7.91949367  9.14393005 12.          0.63479094 17.          0.63070435]. \t  -1.9448970813732682 \t -1.9394486724855446\n",
            "16     \t [9.84430628 0.         5.51623521 0.5        8.62869122 0.1       ]. \t  -2.125013252177847 \t -1.9394486724855446\n",
            "17     \t [ 4.04679616  0.10387914 14.          0.5791768   7.          0.52471155]. \t  -1.9556522135440981 \t -1.9394486724855446\n",
            "18     \t [7.60796195 7.8170794  5.         0.85145938 8.         0.57832563]. \t  -1.9457808537343264 \t -1.9394486724855446\n",
            "19     \t [ 0.40502173  0.97349338 14.          0.99335875 14.          0.65172397]. \t  -1.9447903401760698 \t -1.9394486724855446\n",
            "20     \t [ 1.11903492  9.93958695  9.          0.79898321 10.          0.44087381]. \t  -1.9932266915217973 \t -1.9394486724855446\n",
            "21     \t [ 3.33987196  0.40079727 10.          0.95347406 19.          0.49593048]. \t  -1.9867581180882616 \t -1.9394486724855446\n",
            "22     \t [ 0.22301119  8.13641514  9.          0.77586676 19.          0.85166424]. \t  -1.9423383709591195 \t -1.9394486724855446\n",
            "23     \t [ 4.52413477  5.4961537  10.          0.88078978  4.          0.83651489]. \t  -1.9460442722999218 \t -1.9394486724855446\n",
            "24     \t [ 5.67584001  6.10965226 11.          0.59976919 12.          0.86715313]. \t  \u001b[92m-1.936568895855317\u001b[0m \t -1.936568895855317\n",
            "25     \t [ 0.          1.66555229 13.7181852   0.5        19.92920351  1.        ]. \t  -1.9413301320417073 \t -1.936568895855317\n",
            "26     \t [ 0.          5.09273467  5.          1.         12.73349022  0.1       ]. \t  -2.1158831444195334 \t -1.936568895855317\n",
            "27     \t [5.12093083 1.17332681 9.         0.8113374  8.         0.64578088]. \t  -1.9505420739439547 \t -1.936568895855317\n",
            "28     \t [ 0.23364761  7.80831218 12.          0.81369003  1.          0.89781585]. \t  -1.952206672557513 \t -1.936568895855317\n",
            "29     \t [ 4.30344486  5.50312261  7.          0.75709362 19.          0.75680674]. \t  -1.943627157743095 \t -1.936568895855317\n",
            "30     \t [2.33592839 4.93187823 6.         0.68212822 1.         0.608455  ]. \t  -1.9459811993657545 \t -1.936568895855317\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "61853.758403879976"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N03Sq0TvUuhp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8f99a7f-e65e-4149-ec83-c3a0446da6db"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'gp' Acquisition Function run number = 11\n",
        "\n",
        "np.random.seed(run_num_11)\n",
        "surrogate_gp_11 = GaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train11, X_test11, y_train11, y_test11 = train_test_split(X, y, test_size=test_perc, random_state=run_num_11)\n",
        "\n",
        "def f_syn_polarity11(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_11, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train11, y=y_train11).mean())\n",
        "    return operator * score\n",
        "\n",
        "gp_11 = GPGO(surrogate_gp_11, Acquisition_new(util_gp), f_syn_polarity11, param, n_jobs = -1) # define BayesOpt\n",
        "gp_11.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_gp_11 = gp_11.getResult()[0]\n",
        "params_gp_11['max_depth'] = int(params_gp_11['max_depth'])\n",
        "params_gp_11['min_child_weight'] = int(params_gp_11['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_gp_train11 = xgb.DMatrix(X_train11, y_train11)\n",
        "dX_gp_test11 = xgb.DMatrix(X_test11, y_test11)\n",
        "model_gp_11 = xgb.train(params_gp_11, dX_gp_train11)\n",
        "pred_gp_11 = model_gp_11.predict(dX_gp_test11)\n",
        "\n",
        "rmse_gp_11 = np.sqrt(mean_squared_error(pred_gp_11, y_test11))\n",
        "rmse_gp_11"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 1.80269689  0.19475241  6.          0.59705781 13.          0.47818324]. \t  -1.9015016338784072 \t -1.8483088481664438\n",
            "init   \t [ 4.85427098  0.12780815  5.          0.91309068 14.          0.86571558]. \t  -1.8541246115708696 \t -1.8483088481664438\n",
            "init   \t [ 7.2996447   1.08736072 10.          0.92857712 18.          0.66910061]. \t  -1.8532385782615584 \t -1.8483088481664438\n",
            "init   \t [ 0.20483613  1.16737269  7.          0.57895615 16.          0.83644782]. \t  -1.8483088481664438 \t -1.8483088481664438\n",
            "init   \t [ 3.44624491  3.18798797 14.          0.54197657 15.          0.63958906]. \t  -1.8544028395211494 \t -1.8483088481664438\n",
            "1      \t [9.77136617 6.6548802  7.         0.51036649 9.         0.81011527]. \t  -1.857805309121489 \t -1.8483088481664438\n",
            "2      \t [0.5279662  8.15331655 5.         0.83127487 9.         0.53242685]. \t  -1.8583090737384367 \t -1.8483088481664438\n",
            "3      \t [8.62555756 1.5478147  8.         0.99964468 2.         0.74874718]. \t  -1.8519845859133308 \t -1.8483088481664438\n",
            "4      \t [ 0.90299561  9.42808632 14.          0.71344248  9.          0.5250902 ]. \t  -1.8560986061392328 \t -1.8483088481664438\n",
            "5      \t [ 0.07122179  2.9458437  13.          0.89742149  2.          0.63052749]. \t  -1.8559044305734542 \t -1.8483088481664438\n",
            "6      \t [ 8.80621297  1.41648139 14.          0.58742169  8.          0.82618778]. \t  -1.8573035206957946 \t -1.8483088481664438\n",
            "7      \t [ 8.68943806  9.29354072 13.          0.58241565  2.          0.90282292]. \t  \u001b[92m-1.8428237838756616\u001b[0m \t -1.8428237838756616\n",
            "8      \t [0.47065357 6.80536856 5.         0.94482943 1.         0.93677618]. \t  \u001b[92m-1.8404628329061805\u001b[0m \t -1.8404628329061805\n",
            "9      \t [ 9.7975974   8.60326626  5.          0.83535605 19.          0.47008667]. \t  -1.8910632154003886 \t -1.8404628329061805\n",
            "10     \t [ 0.731097    9.22001741 10.          0.740611   19.          0.69778336]. \t  -1.8529617219679229 \t -1.8404628329061805\n",
            "11     \t [ 8.61765552  0.94349031 10.          0.85641829  4.          0.91576259]. \t  \u001b[92m-1.8381433785201957\u001b[0m \t -1.8381433785201957\n",
            "12     \t [3.50049766 0.06230783 7.         0.82711607 1.         0.94515625]. \t  \u001b[92m-1.8316991110169962\u001b[0m \t -1.8316991110169962\n",
            "13     \t [ 8.32040378  7.9243385  14.          0.97104566 12.          0.2674345 ]. \t  -2.0037940735544373 \t -1.8316991110169962\n",
            "14     \t [ 8.40730244  5.3235921  14.          0.57824885  9.          0.96689527]. \t  -1.8413325855281535 \t -1.8316991110169962\n",
            "15     \t [6.32091993 7.9515921  7.         0.96143544 3.         0.26763357]. \t  -2.0062523134131256 \t -1.8316991110169962\n",
            "16     \t [ 1.62679665  9.41000757 13.          0.73103911  2.          0.19462364]. \t  -2.0353042010418547 \t -1.8316991110169962\n",
            "17     \t [ 8.54318912  8.37398397 11.          0.93167688 18.          0.44938036]. \t  -1.8981183552215186 \t -1.8316991110169962\n",
            "18     \t [ 6.19006075  3.41925871 11.          0.95286331  6.          0.39133224]. \t  -1.9088899501060776 \t -1.8316991110169962\n",
            "19     \t [0.77256475 1.22732493 7.         0.97692145 7.         0.9071396 ]. \t  -1.834153229976279 \t -1.8316991110169962\n",
            "20     \t [ 5.03635286  6.98757662  5.          0.92805766 16.          0.13729535]. \t  -2.033952644006515 \t -1.8316991110169962\n",
            "21     \t [9.82321291 1.67109643 5.         0.98972139 8.         0.83738363]. \t  -1.8507145310767954 \t -1.8316991110169962\n",
            "22     \t [ 0.48311192  6.42761162 10.          0.61373805 14.          0.94748816]. \t  -1.8400690052133961 \t -1.8316991110169962\n",
            "23     \t [ 5.00467726  8.92656094  9.          0.71912853 10.          0.31592385]. \t  -2.010413361366229 \t -1.8316991110169962\n",
            "24     \t [ 7.04282427  0.78798519 10.          0.75749178 12.          0.45631386]. \t  -1.8987465185459353 \t -1.8316991110169962\n",
            "25     \t [10.          2.49909187 15.          0.5        20.          1.        ]. \t  -1.841678001716519 \t -1.8316991110169962\n",
            "26     \t [ 1.72752232  2.52554195 14.          0.79226679  9.          0.7847087 ]. \t  -1.8563703751338188 \t -1.8316991110169962\n",
            "27     \t [ 3.01813359 10.         14.65870044  0.5        14.08533632  0.1       ]. \t  -2.0379054384242576 \t -1.8316991110169962\n",
            "28     \t [ 5.59910258  1.26423688 14.          0.97318774  1.          0.54144173]. \t  -1.8599961869387194 \t -1.8316991110169962\n",
            "29     \t [ 7.36190993  8.79630973  5.          0.82949201 12.          0.64478292]. \t  -1.8524055616314634 \t -1.8316991110169962\n",
            "30     \t [ 9.0698787   3.48334088  5.30560298  0.5        17.78964905  0.1       ]. \t  -2.035463204925669 \t -1.8316991110169962\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "62120.738966925026"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_nP9lQjUztV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "228b2911-ee08-42fd-c532-09f10c265b5c"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'gp' Acquisition Function run number = 12\n",
        "\n",
        "np.random.seed(run_num_12)\n",
        "surrogate_gp_12 = GaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train12, X_test12, y_train12, y_test12 = train_test_split(X, y, test_size=test_perc, random_state=run_num_12)\n",
        "\n",
        "def f_syn_polarity12(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_12, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train12, y=y_train12).mean())\n",
        "    return operator * score\n",
        "\n",
        "gp_12 = GPGO(surrogate_gp_12, Acquisition_new(util_gp), f_syn_polarity12, param, n_jobs = -1) # define BayesOpt\n",
        "gp_12.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_gp_12 = gp_12.getResult()[0]\n",
        "params_gp_12['max_depth'] = int(params_gp_12['max_depth'])\n",
        "params_gp_12['min_child_weight'] = int(params_gp_12['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_gp_train12 = xgb.DMatrix(X_train12, y_train12)\n",
        "dX_gp_test12 = xgb.DMatrix(X_test12, y_test12)\n",
        "model_gp_12 = xgb.train(params_gp_12, dX_gp_train12)\n",
        "pred_gp_12 = model_gp_12.predict(dX_gp_test12)\n",
        "\n",
        "rmse_gp_12 = np.sqrt(mean_squared_error(pred_gp_12, y_test12))\n",
        "rmse_gp_12"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [1.54162842 7.40049697 6.         0.54321714 4.         0.11311747]. \t  -2.1334526770789597 \t -2.024051333725814\n",
            "init   \t [ 9.18747008  9.00714854 14.          0.97847467 11.          0.35544552]. \t  -2.1193628264859967 \t -2.024051333725814\n",
            "init   \t [ 6.06083184  9.44225136 14.          0.95626942  5.          0.56910342]. \t  -2.0441668248397766 \t -2.024051333725814\n",
            "init   \t [ 5.52037633  4.85377414  7.          0.97886436 17.          0.78810441]. \t  -2.024051333725814 \t -2.024051333725814\n",
            "init   \t [ 0.20809798  1.35210178  5.          0.65494879 16.          0.36062811]. \t  -2.1361168864432996 \t -2.024051333725814\n",
            "1      \t [8.63751826 0.13862581 5.         0.68795787 5.         0.56136101]. \t  -2.0796638469522035 \t -2.024051333725814\n",
            "2      \t [9.04256367 2.61736915 8.         0.66026854 8.         0.14510453]. \t  -2.131446620940571 \t -2.024051333725814\n",
            "3      \t [ 6.53994588  2.3076831  14.          0.85412016 14.          0.68100975]. \t  \u001b[92m-2.0197385323301793\u001b[0m \t -2.0197385323301793\n",
            "4      \t [ 0.80213572  3.81577068 14.          0.79504785  3.          0.9667177 ]. \t  \u001b[92m-1.9987866591517887\u001b[0m \t -1.9987866591517887\n",
            "5      \t [4.73471757 0.55734966 9.         0.86099544 3.         0.4159103 ]. \t  -2.132893459007433 \t -1.9987866591517887\n",
            "6      \t [ 6.12519689  9.03489206 14.          0.50242809 19.          0.36351298]. \t  -2.1454654454188167 \t -1.9987866591517887\n",
            "7      \t [ 0.68861419  5.7541736   8.          0.69430506 11.          0.52040141]. \t  -2.060545416523118 \t -1.9987866591517887\n",
            "8      \t [ 1.77450628  1.48504026 14.          0.51849896 19.          0.12332361]. \t  -2.141110323940344 \t -1.9987866591517887\n",
            "9      \t [8.33127678 9.07540796 7.         0.78612378 4.         0.72483468]. \t  -2.020022243871724 \t -1.9987866591517887\n",
            "10     \t [ 1.12582676  8.93847045 12.          0.90253051 15.          0.22616186]. \t  -2.1187834011927307 \t -1.9987866591517887\n",
            "11     \t [ 7.63578483  4.07501457 14.          0.97723751  1.          0.2033266 ]. \t  -2.1198083168937556 \t -1.9987866591517887\n",
            "12     \t [ 9.06259994  1.4172751   5.          0.81347212 19.          0.38881712]. \t  -2.127445093611703 \t -1.9987866591517887\n",
            "13     \t [ 8.78320366  8.79913444  6.          0.99071139 11.          0.95942355]. \t  -2.0082218142008337 \t -1.9987866591517887\n",
            "14     \t [ 4.55964005  0.30434123  5.          0.52399968 11.          0.14256504]. \t  -2.1397255762522662 \t -1.9987866591517887\n",
            "15     \t [ 4.37171805  0.         14.00082956  0.5         7.67975718  1.        ]. \t  -2.014241481240476 \t -1.9987866591517887\n",
            "16     \t [ 8.33925252  9.93812036  6.          0.82854794 19.          0.41239927]. \t  -2.1251659590112206 \t -1.9987866591517887\n",
            "17     \t [ 8.91205319  4.02087169 12.          0.99464333 19.          0.8912451 ]. \t  -2.001055145742274 \t -1.9987866591517887\n",
            "18     \t [ 2.13991662  8.60337507 11.          0.9530108   1.          0.84281985]. \t  -2.021793339870493 \t -1.9987866591517887\n",
            "19     \t [ 9.56103036  2.69189352  5.          0.51874789 13.          0.83592686]. \t  -2.0458840126261664 \t -1.9987866591517887\n",
            "20     \t [0. 0. 5. 1. 1. 1.]. \t  -2.0134033766359716 \t -1.9987866591517887\n",
            "21     \t [ 9.92436044  0.51709795 10.          0.94838244 15.          0.20217928]. \t  -2.12056560426173 \t -1.9987866591517887\n",
            "22     \t [ 3.52246241  5.09107771 13.          0.74976502 10.          0.74409327]. \t  -2.0204982684383976 \t -1.9987866591517887\n",
            "23     \t [ 0.65691806  1.16147161 10.          0.88913171  7.          0.51502961]. \t  -2.0453054929333887 \t -1.9987866591517887\n",
            "24     \t [ 0.         10.         12.93720322  0.5         9.13156293  0.1       ]. \t  -2.137444481465848 \t -1.9987866591517887\n",
            "25     \t [ 0.13771407  0.84612219 11.          0.80104102 13.          0.72215549]. \t  -2.0154121453999174 \t -1.9987866591517887\n",
            "26     \t [ 0.27692571  4.11866217 15.          0.5        13.56559134  0.1       ]. \t  -2.139105522311416 \t -1.9987866591517887\n",
            "27     \t [10.          0.         13.50254684  1.          9.95113138  1.        ]. \t  -2.0021191530438665 \t -1.9987866591517887\n",
            "28     \t [5.61017124 5.18635356 5.         0.57883217 7.         0.93066558]. \t  -2.0105483321747433 \t -1.9987866591517887\n",
            "29     \t [6.14395992 7.03011226 9.         0.94141968 9.         0.10801224]. \t  -2.1204338278275854 \t -1.9987866591517887\n",
            "30     \t [ 0.78346066  9.5353185   8.          0.51402615 18.          0.68884069]. \t  -2.032200759965595 \t -1.9987866591517887\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "62561.0199556965"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDI2Bi9vU05U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56861961-ee2b-48bf-8b0a-b103a05a19dc"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'gp' Acquisition Function run number = 13\n",
        "\n",
        "np.random.seed(run_num_13)\n",
        "surrogate_gp_13 = GaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train13, X_test13, y_train13, y_test13 = train_test_split(X, y, test_size=test_perc, random_state=run_num_13)\n",
        "\n",
        "def f_syn_polarity13(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_13, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train13, y=y_train13).mean())\n",
        "    return operator * score\n",
        "\n",
        "gp_13 = GPGO(surrogate_gp_13, Acquisition_new(util_gp), f_syn_polarity13, param, n_jobs = -1) # define BayesOpt\n",
        "gp_13.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_gp_13 = gp_13.getResult()[0]\n",
        "params_gp_13['max_depth'] = int(params_gp_13['max_depth'])\n",
        "params_gp_13['min_child_weight'] = int(params_gp_13['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_gp_train13 = xgb.DMatrix(X_train13, y_train13)\n",
        "dX_gp_test13 = xgb.DMatrix(X_test13, y_test13)\n",
        "model_gp_13 = xgb.train(params_gp_13, dX_gp_train13)\n",
        "pred_gp_13 = model_gp_13.predict(dX_gp_test13)\n",
        "\n",
        "rmse_gp_13 = np.sqrt(mean_squared_error(pred_gp_13, y_test13))\n",
        "rmse_gp_13"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 7.77702411  2.3754122  11.          0.94649135 13.          0.7827256 ]. \t  -1.9378879688573776 \t -1.9378879688573776\n",
            "init   \t [ 7.51661514  6.07343344 11.          0.69402149 11.          0.13153287]. \t  -2.1281814260438034 \t -1.9378879688573776\n",
            "init   \t [ 2.98449471  0.58512492 10.          0.73579614 12.          0.33065195]. \t  -2.035439141741416 \t -1.9378879688573776\n",
            "init   \t [ 3.47581215  0.0941277  11.          0.86143432  8.          0.58454932]. \t  -1.9849077466482243 \t -1.9378879688573776\n",
            "init   \t [ 4.70137857  6.24432527 10.          0.8149145  18.          0.10784416]. \t  -2.129754084431454 \t -1.9378879688573776\n",
            "1      \t [1.51786663 9.25994479 9.         0.99792981 2.         0.61199673]. \t  -1.9877621530540666 \t -1.9378879688573776\n",
            "2      \t [ 8.98888343  8.3187307  12.          0.8674744   2.          0.79321204]. \t  -1.9449521808507277 \t -1.9378879688573776\n",
            "3      \t [ 2.15576965  9.94171254  5.          0.86819662 11.          0.93589556]. \t  -1.9399105675953052 \t -1.9378879688573776\n",
            "4      \t [9.56183168 0.58146885 8.         0.70816908 2.         0.91494753]. \t  -1.9528094176941089 \t -1.9378879688573776\n",
            "5      \t [ 0.06338612  1.25078283  6.          0.89144883 18.          0.43402566]. \t  -1.9917740920889266 \t -1.9378879688573776\n",
            "6      \t [0.75135379 4.33666257 5.         0.52792906 6.         0.30010782]. \t  -2.0324954030649804 \t -1.9378879688573776\n",
            "7      \t [ 9.14713824  0.07484253  6.          0.59644494 18.          0.23277246]. \t  -2.1303726688090716 \t -1.9378879688573776\n",
            "8      \t [ 1.31863824  8.38888205 14.          0.95097909  8.          0.13910651]. \t  -2.129026813194881 \t -1.9378879688573776\n",
            "9      \t [8.85934669 7.20257433 5.         0.6906114  7.         0.88958995]. \t  -1.944466760904125 \t -1.9378879688573776\n",
            "10     \t [ 8.39231109  0.32510731 14.          0.5902879  19.          0.62232309]. \t  -1.9957846881275045 \t -1.9378879688573776\n",
            "11     \t [ 8.95958255  8.68558585  7.          0.83565872 16.          0.19670804]. \t  -2.1314765258067823 \t -1.9378879688573776\n",
            "12     \t [ 3.29983413  0.94019517 14.          0.95545191  1.          0.90508732]. \t  -1.9479412475792763 \t -1.9378879688573776\n",
            "13     \t [ 0.21953253  3.99186433 14.          0.58641005 17.          0.5656381 ]. \t  -1.995917210822471 \t -1.9378879688573776\n",
            "14     \t [5.15880003 5.0230589  5.         0.52962923 1.         0.65578751]. \t  -1.948733977474307 \t -1.9378879688573776\n",
            "15     \t [ 2.48128047  9.70146472  6.          0.59664322 19.          0.9781653 ]. \t  -1.937900504676573 \t -1.9378879688573776\n",
            "16     \t [ 9.09613404  6.96821732 14.          0.62482035 17.          0.21532186]. \t  -2.124951430371209 \t -1.9378879688573776\n",
            "17     \t [ 2.18971091  9.77624605 11.          0.50913855 13.          0.41347239]. \t  -1.997710532011596 \t -1.9378879688573776\n",
            "18     \t [ 9.84588735  7.11672525 14.          0.8159892   7.          0.97950485]. \t  -1.9402483147023333 \t -1.9378879688573776\n",
            "19     \t [ 7.77731865  0.46886504  6.          0.89516882 10.          0.67837617]. \t  -1.9516673783729204 \t -1.9378879688573776\n",
            "20     \t [ 4.19157878  4.93972532  6.          0.83652146 13.          0.60572081]. \t  -1.991451655597506 \t -1.9378879688573776\n",
            "21     \t [1.47970005 2.98716454 9.         0.86687241 1.         0.89791055]. \t  -1.9529636431554795 \t -1.9378879688573776\n",
            "22     \t [ 8.44321164  0.812026   13.          0.88050192  6.          0.95533043]. \t  -1.9429231098027313 \t -1.9378879688573776\n",
            "23     \t [ 5.89227541  5.55696004 10.          0.61701165  5.          0.95350045]. \t  -1.9443905678522007 \t -1.9378879688573776\n",
            "24     \t [ 0.          4.10571057 11.40834345  0.5         6.64428917  1.        ]. \t  -1.9525406151246343 \t -1.9378879688573776\n",
            "25     \t [ 6.53409393 10.          6.67742013  0.5         1.          0.1       ]. \t  -2.134647993990901 \t -1.9378879688573776\n",
            "26     \t [10.       10.        9.849518  1.       20.        1.      ]. \t  \u001b[92m-1.9229328449521268\u001b[0m \t -1.9229328449521268\n",
            "27     \t [10.         10.          8.03492663  0.5        10.21742042  1.        ]. \t  -1.947255592290673 \t -1.9229328449521268\n",
            "28     \t [ 3.67763817  8.10792931 14.73846048  0.5         1.          0.1       ]. \t  -2.1364968163388545 \t -1.9229328449521268\n",
            "29     \t [ 3.2569353   3.18728918 11.          0.75726487 14.          0.49398999]. \t  -1.9911394299982526 \t -1.9229328449521268\n",
            "30     \t [ 8.63153223  3.27586736 14.          0.55827322  1.          0.47866172]. \t  -1.9997698864695905 \t -1.9229328449521268\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60649.53896388737"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2F_Q194U3uu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8486d8ea-22dc-4792-b3ab-14f47a913368"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'gp' Acquisition Function run number = 14\n",
        "\n",
        "np.random.seed(run_num_14)\n",
        "surrogate_gp_14 = GaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train14, X_test14, y_train14, y_test14 = train_test_split(X, y, test_size=test_perc, random_state=run_num_14)\n",
        "\n",
        "def f_syn_polarity14(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_14, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train14, y=y_train14).mean())\n",
        "    return operator * score\n",
        "\n",
        "gp_14 = GPGO(surrogate_gp_14, Acquisition_new(util_gp), f_syn_polarity14, param, n_jobs = -1) # define BayesOpt\n",
        "gp_14.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_gp_14 = gp_14.getResult()[0]\n",
        "params_gp_14['max_depth'] = int(params_gp_14['max_depth'])\n",
        "params_gp_14['min_child_weight'] = int(params_gp_14['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_gp_train14 = xgb.DMatrix(X_train14, y_train14)\n",
        "dX_gp_test14 = xgb.DMatrix(X_test14, y_test14)\n",
        "model_gp_14 = xgb.train(params_gp_14, dX_gp_train14)\n",
        "pred_gp_14 = model_gp_14.predict(dX_gp_test14)\n",
        "\n",
        "rmse_gp_14 = np.sqrt(mean_squared_error(pred_gp_14, y_test14))\n",
        "rmse_gp_14"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 5.13943344  7.73165052 12.          0.6831412  11.          0.37876233]. \t  -2.0164943249949188 \t -1.9500125911148154\n",
            "init   \t [ 9.57603739  5.13116712 14.          0.76959997 12.          0.71328228]. \t  -1.9699703337255101 \t -1.9500125911148154\n",
            "init   \t [5.34950319 2.47493539 5.         0.50293689 6.         0.29706373]. \t  -2.0377420945059783 \t -1.9500125911148154\n",
            "init   \t [ 2.94506579  3.45329697  8.          0.87620946 14.          0.9783044 ]. \t  -1.9500125911148154 \t -1.9500125911148154\n",
            "init   \t [ 1.11811929  1.73004086  5.          0.73745288 12.          0.20586008]. \t  -2.0557846580952273 \t -1.9500125911148154\n",
            "1      \t [ 6.50637223  2.67617722 14.          0.53562507  1.          0.16862152]. \t  -2.065483651943695 \t -1.9500125911148154\n",
            "2      \t [ 9.22243919  0.59642165  6.          0.72537748 19.          0.46639325]. \t  -2.0211824238378755 \t -1.9500125911148154\n",
            "3      \t [ 5.79577795  1.8570688  14.          0.83128935 19.          0.71549729]. \t  -1.974511320981101 \t -1.9500125911148154\n",
            "4      \t [9.32373648 9.05676215 9.         0.53064322 3.         0.70657534]. \t  -1.9867881195553743 \t -1.9500125911148154\n",
            "5      \t [ 9.52454394  8.82757271  9.          0.90064956 19.          0.16022914]. \t  -2.052682286285491 \t -1.9500125911148154\n",
            "6      \t [ 3.61508571  7.70718733 10.          0.62042707  5.          0.12186292]. \t  -2.054423315700128 \t -1.9500125911148154\n",
            "7      \t [ 0.05037086  7.50461284  5.          0.70076046 19.          0.10543546]. \t  -2.051384439295456 \t -1.9500125911148154\n",
            "8      \t [ 9.40430013  0.15700131  7.          0.99940272 12.          0.43771306]. \t  -2.013853982401966 \t -1.9500125911148154\n",
            "9      \t [ 0.40405522  2.81796516 11.          0.8908648   1.          0.54002187]. \t  -1.9742051884562268 \t -1.9500125911148154\n",
            "10     \t [ 2.08494663  9.70581169 14.          0.64307382  3.          0.10613693]. \t  -2.0525265381353774 \t -1.9500125911148154\n",
            "11     \t [ 1.55781918  0.46142569 10.          0.80240433 16.          0.22604037]. \t  -2.0517106112449888 \t -1.9500125911148154\n",
            "12     \t [ 8.32471637  8.64868248  5.          0.80719895 12.          0.64183859]. \t  -1.9814066722728896 \t -1.9500125911148154\n",
            "13     \t [ 1.63603408  9.08540306 13.          0.75743361 17.          0.35594014]. \t  -2.0172876609396297 \t -1.9500125911148154\n",
            "14     \t [ 2.19312776  1.39765821 13.          0.6652195   7.          0.63762954]. \t  -1.9757937384712718 \t -1.9500125911148154\n",
            "15     \t [9.46744067 0.0339838  9.         0.74305504 6.         0.26947831]. \t  -2.0127786392667426 \t -1.9500125911148154\n",
            "16     \t [ 0.         10.          6.58843771  0.5         1.          1.        ]. \t  -1.9704369862404796 \t -1.9500125911148154\n",
            "17     \t [ 3.43075392  3.21961062 14.          0.99813107 13.          0.94340707]. \t  \u001b[92m-1.9460711839509812\u001b[0m \t -1.9460711839509812\n",
            "18     \t [ 2.97507046  9.85127832  5.          0.75729568 12.          0.23402253]. \t  -2.0517743294083326 \t -1.9460711839509812\n",
            "19     \t [ 9.95126131  9.64022555 11.          0.74273384  9.          0.68757519]. \t  -1.9740277193497149 \t -1.9460711839509812\n",
            "20     \t [ 7.50974882  6.12589601 14.          0.77913808  6.          0.27444251]. \t  -2.010416502590216 \t -1.9460711839509812\n",
            "21     \t [10.         10.         14.67485413  1.          2.07668726  0.1       ]. \t  -2.04961590875149 \t -1.9460711839509812\n",
            "22     \t [ 0.          4.62683643 15.          1.         20.          1.        ]. \t  \u001b[92m-1.937815243361694\u001b[0m \t -1.937815243361694\n",
            "23     \t [10.         10.         15.          1.         14.38870513  0.1       ]. \t  -2.0484354431451046 \t -1.937815243361694\n",
            "24     \t [ 0.   0.   5.   1.  20.   0.1]. \t  -2.050880848472251 \t -1.937815243361694\n",
            "25     \t [ 7.27945936  0.83948224 15.          1.          9.55796704  0.1       ]. \t  -2.0479961949838072 \t -1.937815243361694\n",
            "26     \t [4.98125015 9.32607017 6.         0.79018295 8.         0.37250842]. \t  -2.0161974447240953 \t -1.937815243361694\n",
            "27     \t [5.01514227 5.59113515 5.         0.59545349 1.         0.41032938]. \t  -2.0340861126860315 \t -1.937815243361694\n",
            "28     \t [ 2.74266123  7.05787468 14.          0.61105672  5.          0.17080638]. \t  -2.0554048363059882 \t -1.937815243361694\n",
            "29     \t [ 5.70761228  7.1006081   5.          0.93093792 19.          0.82226377]. \t  -1.9547831986747677 \t -1.937815243361694\n",
            "30     \t [8.9087611  4.04640763 9.0011032  1.         1.69506513 0.88116869]. \t  -1.9604502274618234 \t -1.937815243361694\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60569.1703919756"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Po5wImJaU6VC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b282407b-38c7-403f-d249-0c752e32f795"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'gp' Acquisition Function run number = 15\n",
        "\n",
        "np.random.seed(run_num_15)\n",
        "surrogate_gp_15 = GaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train15, X_test15, y_train15, y_test15 = train_test_split(X, y, test_size=test_perc, random_state=run_num_15)\n",
        "\n",
        "def f_syn_polarity15(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_15, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train15, y=y_train15).mean())\n",
        "    return operator * score\n",
        "\n",
        "gp_15 = GPGO(surrogate_gp_15, Acquisition_new(util_gp), f_syn_polarity15, param, n_jobs = -1) # define BayesOpt\n",
        "gp_15.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_gp_15 = gp_15.getResult()[0]\n",
        "params_gp_15['max_depth'] = int(params_gp_15['max_depth'])\n",
        "params_gp_15['min_child_weight'] = int(params_gp_15['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_gp_train15 = xgb.DMatrix(X_train15, y_train15)\n",
        "dX_gp_test15 = xgb.DMatrix(X_test15, y_test15)\n",
        "model_gp_15 = xgb.train(params_gp_15, dX_gp_train15)\n",
        "pred_gp_15 = model_gp_15.predict(dX_gp_test15)\n",
        "\n",
        "rmse_gp_15 = np.sqrt(mean_squared_error(pred_gp_15, y_test15))\n",
        "rmse_gp_15"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 8.48817697  1.78895925 12.          0.55549316  8.          0.93397854]. \t  -1.9771020004296471 \t -1.9771020004296471\n",
            "init   \t [ 0.24953032  8.22298097 12.          0.62494951 11.          0.12924598]. \t  -2.039987754752231 \t -1.9771020004296471\n",
            "init   \t [ 5.02017228  5.50882771 11.          0.85295832 19.          0.13548008]. \t  -2.0342163062344127 \t -1.9771020004296471\n",
            "init   \t [2.0023081  9.98543403 7.         0.6295772  2.         0.526127  ]. \t  -1.9991206593771125 \t -1.9771020004296471\n",
            "init   \t [ 5.09715306  9.45038417 11.          0.7388277  16.          0.22739973]. \t  -2.0362669401948086 \t -1.9771020004296471\n",
            "1      \t [ 0.29158961  4.9949242  12.          0.89124583  3.          0.67554049]. \t  -1.9851996507567322 \t -1.9771020004296471\n",
            "2      \t [ 0.67158936  0.34278237  6.          0.51048023 11.          0.77715736]. \t  -2.003673551363784 \t -1.9771020004296471\n",
            "3      \t [9.75991344 6.15203198 6.         0.65490407 1.         0.73816291]. \t  -1.9902880644776384 \t -1.9771020004296471\n",
            "4      \t [ 9.51793103  9.55070381  6.          0.93315157 11.          0.40416985]. \t  -2.0266063382197212 \t -1.9771020004296471\n",
            "5      \t [ 6.65116837  8.16324548 14.          0.95750787  1.          0.74925927]. \t  -1.9860731725177483 \t -1.9771020004296471\n",
            "6      \t [ 6.91871764  2.49647079 12.          0.91394395 13.          0.42184903]. \t  -2.026062956743946 \t -1.9771020004296471\n",
            "7      \t [ 7.77234852  1.95889592  5.          0.55968406 18.          0.52767162]. \t  -2.008135120690471 \t -1.9771020004296471\n",
            "8      \t [3.08968857 1.08940277 5.         0.75575035 2.         0.4049356 ]. \t  -2.0295630153651567 \t -1.9771020004296471\n",
            "9      \t [ 0.53269319  3.10786722 14.          0.59617872 16.          0.1338107 ]. \t  -2.042364057019339 \t -1.9771020004296471\n",
            "10     \t [8.41830164 2.50834975 6.         0.52592121 5.         0.6895569 ]. \t  -2.013827670350264 \t -1.9771020004296471\n",
            "11     \t [ 2.97928851  7.73905112  6.          0.87870551 18.          0.36796416]. \t  -2.02573754736145 \t -1.9771020004296471\n",
            "12     \t [3.64506006 7.67743205 6.         0.54492601 9.         0.39730379]. \t  -2.031177558233961 \t -1.9771020004296471\n",
            "13     \t [ 1.41127451  0.02455301 14.          0.99438541  9.          0.56009967]. \t  -1.9824591808375935 \t -1.9771020004296471\n",
            "14     \t [ 9.9193931   8.28526555 13.          0.70468818 12.          0.10333636]. \t  -2.0370060855658507 \t -1.9771020004296471\n",
            "15     \t [ 9.71215516  9.31848438 12.          0.64520711  3.          0.99268325]. \t  \u001b[92m-1.9677138763213804\u001b[0m \t -1.9677138763213804\n",
            "16     \t [ 0.         10.         15.          0.5        15.99999545  1.        ]. \t  \u001b[92m-1.9523773088312972\u001b[0m \t -1.9523773088312972\n",
            "17     \t [ 0.11138125  2.32868485  8.          0.89421542 19.          0.22148224]. \t  -2.0349084852071853 \t -1.9523773088312972\n",
            "18     \t [ 5.98167893  0.08618795 13.          0.7695922   2.          0.35350923]. \t  -2.0409148258740153 \t -1.9523773088312972\n",
            "19     \t [ 6.83250908  6.61770001 14.          0.94185045  7.          0.26050848]. \t  -2.0368993708761356 \t -1.9523773088312972\n",
            "20     \t [0.14918292 2.39374074 7.         0.95064473 6.         0.97840647]. \t  \u001b[92m-1.9456993002636278\u001b[0m \t -1.9456993002636278\n",
            "21     \t [ 8.84960903  8.59512798  5.          0.60381884 16.6408753   0.9741859 ]. \t  -1.9747050580753203 \t -1.9456993002636278\n",
            "22     \t [ 8.46129671  4.35670928  6.          0.76903974 11.          0.70818053]. \t  -1.990315026829472 \t -1.9456993002636278\n",
            "23     \t [ 9.61182953  2.7219792  14.          0.99540961 19.          0.89836069]. \t  \u001b[92m-1.9425878747227778\u001b[0m \t -1.9425878747227778\n",
            "24     \t [ 0.27038736  9.88675822 10.          0.52771659 19.          0.26392742]. \t  -2.0422025067341103 \t -1.9425878747227778\n",
            "25     \t [ 2.94695031  4.05018144  8.          0.70887203 14.          0.60913175]. \t  -1.9956120777464221 \t -1.9425878747227778\n",
            "26     \t [9.25730966 0.80457908 9.         0.59559506 1.         0.63116286]. \t  -2.0163200338037632 \t -1.9425878747227778\n",
            "27     \t [ 4.6463709   6.65977578 14.9816249   1.         12.33919646  1.        ]. \t  \u001b[92m-1.930243491811827\u001b[0m \t -1.930243491811827\n",
            "28     \t [4.73863428 5.70462999 8.         0.56646782 1.         0.57256121]. \t  -2.0130233272127525 \t -1.930243491811827\n",
            "29     \t [9.46848488 7.29727244 9.         0.94882895 7.         0.81669765]. \t  -1.9760238306640676 \t -1.930243491811827\n",
            "30     \t [ 1.56875382  9.67686177 13.          0.90052008  5.          0.70018504]. \t  -1.984450644835181 \t -1.930243491811827\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60398.20672941871"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HrAQN-pU9Qo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5aa3301f-1790-4e8d-bc3a-90a46d5b7c70"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'gp' Acquisition Function run number = 16\n",
        "\n",
        "np.random.seed(run_num_16)\n",
        "surrogate_gp_16 = GaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train16, X_test16, y_train16, y_test16 = train_test_split(X, y, test_size=test_perc, random_state=run_num_16)\n",
        "\n",
        "def f_syn_polarity16(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_16, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train16, y=y_train16).mean())\n",
        "    return operator * score\n",
        "\n",
        "gp_16 = GPGO(surrogate_gp_16, Acquisition_new(util_gp), f_syn_polarity16, param, n_jobs = -1) # define BayesOpt\n",
        "gp_16.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_gp_16 = gp_16.getResult()[0]\n",
        "params_gp_16['max_depth'] = int(params_gp_16['max_depth'])\n",
        "params_gp_16['min_child_weight'] = int(params_gp_16['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_gp_train16 = xgb.DMatrix(X_train16, y_train16)\n",
        "dX_gp_test16 = xgb.DMatrix(X_test16, y_test16)\n",
        "model_gp_16 = xgb.train(params_gp_16, dX_gp_train16)\n",
        "pred_gp_16 = model_gp_16.predict(dX_gp_test16)\n",
        "\n",
        "rmse_gp_16 = np.sqrt(mean_squared_error(pred_gp_16, y_test16))\n",
        "rmse_gp_16"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [2.23291079 5.23163341 6.         0.65430839 5.         0.30077285]. \t  -2.0565156149305297 \t -2.035211151920518\n",
            "init   \t [6.88726162 1.63731425 7.         0.97050543 2.         0.25392012]. \t  -2.055048050691712 \t -2.035211151920518\n",
            "init   \t [ 5.94328983  5.6393473   5.          0.67602695 19.          0.42538144]. \t  -2.035211151920518 \t -2.035211151920518\n",
            "init   \t [ 0.88741148  3.08148142 14.          0.56043938  9.          0.27515386]. \t  -2.0784041797925226 \t -2.035211151920518\n",
            "init   \t [ 2.74631586  1.30996118 11.          0.52160786  8.          0.27956463]. \t  -2.070688794097313 \t -2.035211151920518\n",
            "1      \t [ 7.8937256   1.5972923  14.          0.61610774 17.          0.78739284]. \t  \u001b[92m-1.9211628477361509\u001b[0m \t -1.9211628477361509\n",
            "2      \t [ 9.01655783  8.21383177  9.          0.60772965 10.          0.9401803 ]. \t  \u001b[92m-1.8833303967241242\u001b[0m \t -1.8833303967241242\n",
            "3      \t [ 4.35132073  9.89698316 12.          0.94137984 16.          0.57741056]. \t  -1.97819725226882 \t -1.8833303967241242\n",
            "4      \t [ 9.99266675  2.3482113  14.          0.65036483  2.          0.18233953]. \t  -2.063280175992589 \t -1.8833303967241242\n",
            "5      \t [ 0.02157337  9.97534925  5.          0.75404051 13.          0.40760752]. \t  -2.0247293958409025 \t -1.8833303967241242\n",
            "6      \t [ 0.19317903  0.6596816   6.          0.86233301 15.          0.41906313]. \t  -2.0192307301965045 \t -1.8833303967241242\n",
            "7      \t [ 3.4112379   7.22921505 12.          0.51794009  1.          0.9590442 ]. \t  -1.8988148247327985 \t -1.8833303967241242\n",
            "8      \t [ 1.22130867  0.64008351 12.          0.59515137 19.          0.65193522]. \t  -1.9820463830680937 \t -1.8833303967241242\n",
            "9      \t [8.31596139 8.08775071 5.         0.5698323  1.         0.11769544]. \t  -2.0667662116388583 \t -1.8833303967241242\n",
            "10     \t [ 9.39421065  1.15238895 10.          0.86257926 10.          0.82976642]. \t  -1.9154020559223555 \t -1.8833303967241242\n",
            "11     \t [ 9.5010608   0.88423622  7.          0.68524636 18.          0.38496824]. \t  -2.0373102083901604 \t -1.8833303967241242\n",
            "12     \t [ 4.93583282  3.95579207  5.          0.78393748 11.          0.19828753]. \t  -2.0507830298087946 \t -1.8833303967241242\n",
            "13     \t [ 0.31878638  7.7064847   9.          0.53908047 19.          0.69534532]. \t  -1.9877741315823578 \t -1.8833303967241242\n",
            "14     \t [2.43756281e-03 1.86203502e-01 1.10000000e+01 5.84519618e-01\n",
            " 1.30000000e+01 2.30149841e-01]. \t  -2.0641995781036115 \t -1.8833303967241242\n",
            "15     \t [ 3.22380477  8.8210053  12.          0.91827732  7.          0.1365336 ]. \t  -2.049645314312633 \t -1.8833303967241242\n",
            "16     \t [ 1.87615966  0.2032349  10.          0.89545954  2.          0.86993332]. \t  -1.9348315060565047 \t -1.8833303967241242\n",
            "17     \t [ 0.          7.70114675 15.          0.5        12.86915415  1.        ]. \t  -1.886397492086126 \t -1.8833303967241242\n",
            "18     \t [ 6.86779017  4.50453048 14.          0.571211    7.          0.9988365 ]. \t  -1.8835902734915937 \t -1.8833303967241242\n",
            "19     \t [ 9.51378666  7.51596488 11.          0.92606042 19.          0.78246721]. \t  -1.908299847883176 \t -1.8833303967241242\n",
            "20     \t [ 4.77306317  4.41011512 11.          0.84776341 14.          0.81171734]. \t  -1.919767559692652 \t -1.8833303967241242\n",
            "21     \t [ 9.011038    7.35466512 11.          0.76907272  3.          0.63526495]. \t  -1.9895134073017346 \t -1.8833303967241242\n",
            "22     \t [ 6.28925136  9.29620957  5.          0.88938679 14.          0.35063324]. \t  -2.0450757191900566 \t -1.8833303967241242\n",
            "23     \t [ 0.55708858  6.23454451 15.          0.5        20.          0.1       ]. \t  -2.069522949663173 \t -1.8833303967241242\n",
            "24     \t [ 9.32791107  8.26216826 14.          0.84053349 12.          0.21556049]. \t  -2.0522712137304984 \t -1.8833303967241242\n",
            "25     \t [ 6.36544031  9.60673989 15.          1.          4.02211326  0.46616585]. \t  -1.986933990966201 \t -1.8833303967241242\n",
            "26     \t [5.21856129 9.8425276  6.         0.68318479 8.         0.50125207]. \t  -1.988770983489988 \t -1.8833303967241242\n",
            "27     \t [ 5.51954089  0.67514983 14.          0.56532869  4.          0.54553004]. \t  -2.016125293054148 \t -1.8833303967241242\n",
            "28     \t [3.59656844 9.9695951  7.         0.83605282 1.         0.20261409]. \t  -2.054582434292334 \t -1.8833303967241242\n",
            "29     \t [0.65695569 0.30127043 5.         0.56436611 9.         0.10012212]. \t  -2.0666994830749843 \t -1.8833303967241242\n",
            "30     \t [10.          5.29446168  5.          1.          6.96501615  1.        ]. \t  \u001b[92m-1.8694485046136453\u001b[0m \t -1.8694485046136453\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "63530.395622310556"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXelbcAVVCqO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0213870a-996d-43f3-ba62-9dad36c9db76"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'gp' Acquisition Function run number = 17\n",
        "\n",
        "np.random.seed(run_num_17)\n",
        "surrogate_gp_17 = GaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train17, X_test17, y_train17, y_test17 = train_test_split(X, y, test_size=test_perc, random_state=run_num_17)\n",
        "\n",
        "def f_syn_polarity17(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_17, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train17, y=y_train17).mean())\n",
        "    return operator * score\n",
        "\n",
        "gp_17 = GPGO(surrogate_gp_17, Acquisition_new(util_gp), f_syn_polarity17, param, n_jobs = -1) # define BayesOpt\n",
        "gp_17.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_gp_17 = gp_17.getResult()[0]\n",
        "params_gp_17['max_depth'] = int(params_gp_17['max_depth'])\n",
        "params_gp_17['min_child_weight'] = int(params_gp_17['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_gp_train17 = xgb.DMatrix(X_train17, y_train17)\n",
        "dX_gp_test17 = xgb.DMatrix(X_test17, y_test17)\n",
        "model_gp_17 = xgb.train(params_gp_17, dX_gp_train17)\n",
        "pred_gp_17 = model_gp_17.predict(dX_gp_test17)\n",
        "\n",
        "rmse_gp_17 = np.sqrt(mean_squared_error(pred_gp_17, y_test17))\n",
        "rmse_gp_17"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 2.94665003  5.30586756 11.          0.94443241 14.          0.80828691]. \t  -2.0339055477365475 \t -2.0339055477365475\n",
            "init   \t [ 6.56333522  6.37520896 12.          0.81487881 18.          0.42203224]. \t  -2.0931879884342264 \t -2.0339055477365475\n",
            "init   \t [ 9.45683187  0.6004468  11.          0.5171566  10.          0.53881211]. \t  -2.0781263774021443 \t -2.0339055477365475\n",
            "init   \t [2.72705857 1.19063434 6.         0.74176431 6.         0.10101151]. \t  -2.1016571617786393 \t -2.0339055477365475\n",
            "init   \t [ 4.77631812  5.24671297 13.          0.66254476 19.          0.36708086]. \t  -2.0994481639151874 \t -2.0339055477365475\n",
            "1      \t [ 0.65702322  5.79284078 13.          0.75136902  1.          0.30306068]. \t  -2.1101246565070526 \t -2.0339055477365475\n",
            "2      \t [ 6.93446178  8.68032298 13.          0.78195789  7.          0.91906958]. \t  \u001b[92m-1.9718672938390385\u001b[0m \t -1.9718672938390385\n",
            "3      \t [9.72843652 3.88893279 9.         0.6901555  1.         0.31608219]. \t  -2.107188511168377 \t -1.9718672938390385\n",
            "4      \t [ 9.65057736  8.52725784  5.          0.68420234 13.          0.40008732]. \t  -2.0942422544024124 \t -1.9718672938390385\n",
            "5      \t [ 4.97204887  2.40072226  5.          0.54268748 19.          0.30995407]. \t  -2.1050552165746326 \t -1.9718672938390385\n",
            "6      \t [0.12174033 8.73496008 5.         0.89827646 5.         0.85354798]. \t  -2.0440226052468478 \t -1.9718672938390385\n",
            "7      \t [ 2.91443079  0.16723755 13.          0.598201    6.          0.91729605]. \t  -1.975547562855126 \t -1.9718672938390385\n",
            "8      \t [7.20615247 9.36901627 6.         0.85465034 7.         0.6878262 ]. \t  -2.0705326436343534 \t -1.9718672938390385\n",
            "9      \t [ 9.02586164  0.59354638 10.          0.86038693 18.          0.90794111]. \t  \u001b[92m-1.9577161110723817\u001b[0m \t -1.9577161110723817\n",
            "10     \t [ 0.          5.58185906  5.          0.5        12.5306288   0.1       ]. \t  -2.1057848473579206 \t -1.9577161110723817\n",
            "11     \t [ 0.12410542  7.60180472 13.          0.97425003  8.          0.76245421]. \t  -2.0241362397717504 \t -1.9577161110723817\n",
            "12     \t [ 2.44282715  9.71851747  7.          0.86792183 17.          0.93015556]. \t  -1.9587190471635343 \t -1.9577161110723817\n",
            "13     \t [9.59190042 1.26233772 5.         0.55398722 6.         0.46259714]. \t  -2.1027050940575314 \t -1.9577161110723817\n",
            "14     \t [ 9.68940671  7.87041206  5.28038696  0.5        20.          0.1       ]. \t  -2.1045908026491835 \t -1.9577161110723817\n",
            "15     \t [ 0.59590325  0.30071901  8.          0.9148403  16.          0.62633871]. \t  -2.0739873895509007 \t -1.9577161110723817\n",
            "16     \t [ 8.69529605  0.27226865 14.          0.90636352  1.          0.39638219]. \t  -2.113185182079088 \t -1.9577161110723817\n",
            "17     \t [ 5.5997101   2.80089542 11.          0.91397635  4.          0.58148876]. \t  -2.063555181444724 \t -1.9577161110723817\n",
            "18     \t [ 6.93626187  1.89640942  5.          1.         11.4485445   0.23449644]. \t  -2.0892209600540834 \t -1.9577161110723817\n",
            "19     \t [ 8.34933229  9.44839603 12.          0.7237677   1.          0.61392301]. \t  -2.085908672599236 \t -1.9577161110723817\n",
            "20     \t [5.68286365 5.81484664 5.         0.58385602 2.         0.89128016]. \t  -1.9791639485338823 \t -1.9577161110723817\n",
            "21     \t [10.  10.   5.   1.   1.   0.1]. \t  -2.088768962706124 \t -1.9577161110723817\n",
            "22     \t [ 3.45521931  9.78963512 10.          0.71985214  3.          0.38449583]. \t  -2.10731358956697 \t -1.9577161110723817\n",
            "23     \t [10.          5.82678162 15.          1.          2.85890526  1.        ]. \t  \u001b[92m-1.9500429252161013\u001b[0m \t -1.9500429252161013\n",
            "24     \t [ 7.84336277  9.04289947 12.          0.51579971 13.          0.2539995 ]. \t  -2.107963391043976 \t -1.9500429252161013\n",
            "25     \t [ 0.17278073  0.04498009 14.          0.7905257  14.          0.72677309]. \t  -2.075505699973587 \t -1.9500429252161013\n",
            "26     \t [3.50489783 5.50811934 8.         0.9854684  9.         0.45141256]. \t  -2.0876087023384637 \t -1.9500429252161013\n",
            "27     \t [4.57368896 0.         6.6899077  1.         1.         1.        ]. \t  -1.9532385187664196 \t -1.9500429252161013\n",
            "28     \t [ 0.          4.60507279  8.10849193  0.5        19.49357382  1.        ]. \t  -1.9895702321670956 \t -1.9500429252161013\n",
            "29     \t [ 0.          0.84563476 10.886456    0.5         1.5324656   0.1       ]. \t  -2.1073195685065453 \t -1.9500429252161013\n",
            "30     \t [ 2.26466106  9.541291   15.          1.         15.90375692  1.        ]. \t  \u001b[92m-1.9438134552981652\u001b[0m \t -1.9438134552981652\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60093.9507643081"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJG2fAtAVFDZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c48eb16-1a18-4210-f351-18b082f58aa6"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'gp' Acquisition Function run number = 18\n",
        "\n",
        "np.random.seed(run_num_18)\n",
        "surrogate_gp_18 = GaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train18, X_test18, y_train18, y_test18 = train_test_split(X, y, test_size=test_perc, random_state=run_num_18)\n",
        "\n",
        "def f_syn_polarity18(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_11, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train18, y=y_train18).mean())\n",
        "    return operator * score\n",
        "\n",
        "gp_18 = GPGO(surrogate_gp_18, Acquisition_new(util_gp), f_syn_polarity18, param, n_jobs = -1) # define BayesOpt\n",
        "gp_18.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_gp_18 = gp_18.getResult()[0]\n",
        "params_gp_18['max_depth'] = int(params_gp_18['max_depth'])\n",
        "params_gp_18['min_child_weight'] = int(params_gp_18['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_gp_train18 = xgb.DMatrix(X_train18, y_train18)\n",
        "dX_gp_test18 = xgb.DMatrix(X_test18, y_test18)\n",
        "model_gp_18 = xgb.train(params_gp_18, dX_gp_train18)\n",
        "pred_gp_18 = model_gp_18.predict(dX_gp_test18)\n",
        "\n",
        "rmse_gp_18 = np.sqrt(mean_squared_error(pred_gp_18, y_test18))\n",
        "rmse_gp_18"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [6.50374242 5.05453374 6.         0.59092011 3.         0.28357516]. \t  -2.124076612902688 \t -1.9684597267146717\n",
            "init   \t [0.11506734 4.26891483 9.         0.81785956 5.         0.63489043]. \t  -1.970130070404765 \t -1.9684597267146717\n",
            "init   \t [ 2.8861259   6.35547834 11.          0.64267955 14.          0.27877092]. \t  -2.1124427977128897 \t -1.9684597267146717\n",
            "init   \t [6.57189031 6.99655629 8.         0.63235896 4.         0.52894035]. \t  -1.9684597267146717 \t -1.9684597267146717\n",
            "init   \t [ 6.66600348  2.11312037 14.          0.74363461  4.          0.73174558]. \t  -1.9716784325247372 \t -1.9684597267146717\n",
            "1      \t [ 8.67093232  0.11649132  5.          0.92962202 15.          0.53672863]. \t  \u001b[92m-1.9671214996935293\u001b[0m \t -1.9671214996935293\n",
            "2      \t [ 8.43851229  2.41114508 13.          0.75771586 19.          0.86905071]. \t  \u001b[92m-1.9575740050743662\u001b[0m \t -1.9575740050743662\n",
            "3      \t [ 9.44281001  9.01534322  7.          0.99142432 16.          0.37631199]. \t  -2.0120948954687896 \t -1.9575740050743662\n",
            "4      \t [ 3.19538294  9.91737336 14.          0.7976317   5.          0.25704487]. \t  -2.119859246765158 \t -1.9575740050743662\n",
            "5      \t [ 0.21200191  9.95034596  6.          0.77719285 19.          0.61346381]. \t  -1.962954314328573 \t -1.9575740050743662\n",
            "6      \t [ 1.26601315  0.31299408  6.          0.95296222 16.          0.13649883]. \t  -2.143354411308936 \t -1.9575740050743662\n",
            "7      \t [ 1.2588084   9.80413977  5.          0.75618546 12.          0.53020258]. \t  -1.9642910077324605 \t -1.9575740050743662\n",
            "8      \t [ 6.63763513  1.21594617 14.          0.92753462 12.          0.25002233]. \t  -2.1139277363859703 \t -1.9575740050743662\n",
            "9      \t [ 7.49192948  9.60283663 14.          0.93718151 19.          0.24625933]. \t  -2.1444983018281425 \t -1.9575740050743662\n",
            "10     \t [ 4.47885244  2.43320277  7.          0.94199375 10.          0.18110335]. \t  -2.144630445548865 \t -1.9575740050743662\n",
            "11     \t [9.98653758 8.80568206 9.         0.86984433 9.         0.78984159]. \t  -1.9705913433744064 \t -1.9575740050743662\n",
            "12     \t [ 1.68019344  0.20490035 13.          0.89332378 19.          0.17761947]. \t  -2.142095573473406 \t -1.9575740050743662\n",
            "13     \t [0.58655573 8.89860432 5.         0.62593909 1.         0.46819727]. \t  -2.0165407903075154 \t -1.9575740050743662\n",
            "14     \t [ 4.25762222  4.02301922  9.          0.6129246  19.          0.59981465]. \t  -1.9625900374105825 \t -1.9575740050743662\n",
            "15     \t [9.66555931 0.03278214 7.         0.65118318 6.         0.28697131]. \t  -2.116768474693438 \t -1.9575740050743662\n",
            "16     \t [0.36563988 3.00217777 5.         0.82471304 1.         0.31430916]. \t  -2.1193949774551015 \t -1.9575740050743662\n",
            "17     \t [ 0.40313625  2.99614021 14.          0.85649477 11.          0.77047003]. \t  -1.9657533293202392 \t -1.9575740050743662\n",
            "18     \t [ 9.56072091  9.1368036  14.          0.68050527  1.          0.47597207]. \t  -2.027264801513656 \t -1.9575740050743662\n",
            "19     \t [ 5.83651625  4.96207441  5.          0.5        14.98829495  1.        ]. \t  -1.9628055152470492 \t -1.9575740050743662\n",
            "20     \t [ 8.30550574  9.29215658 13.          0.79696885 13.          0.71304653]. \t  -1.9641996064572649 \t -1.9575740050743662\n",
            "21     \t [ 0.81942638  9.11478864 14.          0.52915783 18.          0.56620019]. \t  -1.9741958400132802 \t -1.9575740050743662\n",
            "22     \t [ 0.264138    8.94439473 11.          0.65657896  9.          0.18095235]. \t  -2.142856494877799 \t -1.9575740050743662\n",
            "23     \t [ 3.21880816 10.          5.          1.          5.79496981  1.        ]. \t  -1.9618747356022652 \t -1.9575740050743662\n",
            "24     \t [ 1.5778572   0.1893032  12.          0.93866603  3.          0.21447896]. \t  -2.1439834285060533 \t -1.9575740050743662\n",
            "25     \t [3.67644078 0.14061137 5.         0.85872011 5.         0.55082355]. \t  -1.9729891884987616 \t -1.9575740050743662\n",
            "26     \t [0.         5.29573684 5.         0.5        8.4982649  0.1       ]. \t  -2.138968887084328 \t -1.9575740050743662\n",
            "27     \t [ 0.          0.          8.99806075  1.         10.16501632  1.        ]. \t  \u001b[92m-1.9490702700981708\u001b[0m \t -1.9490702700981708\n",
            "28     \t [10.          4.67576741  5.          0.5        10.36810674  1.        ]. \t  -1.9607987000592897 \t -1.9490702700981708\n",
            "29     \t [ 6.79045801  9.93979052  5.          0.86076424 12.          0.45417905]. \t  -2.0156952660226772 \t -1.9490702700981708\n",
            "30     \t [ 0.51829692  9.78805086 15.          1.         12.90614531  1.        ]. \t  \u001b[92m-1.947141443837936\u001b[0m \t -1.947141443837936\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60711.75357387342"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHidSEGcVHvG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "978f1150-71bf-4750-e41e-071ee9e48d09"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'gp' Acquisition Function run number = 19\n",
        "\n",
        "np.random.seed(run_num_19)\n",
        "surrogate_gp_19 = GaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train19, X_test19, y_train19, y_test19 = train_test_split(X, y, test_size=test_perc, random_state=run_num_19)\n",
        "\n",
        "def f_syn_polarity19(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_19, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train19, y=y_train19).mean())\n",
        "    return operator * score\n",
        "\n",
        "gp_19 = GPGO(surrogate_gp_19, Acquisition_new(util_gp), f_syn_polarity19, param, n_jobs = -1) # define BayesOpt\n",
        "gp_19.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_gp_19 = gp_19.getResult()[0]\n",
        "params_gp_19['max_depth'] = int(params_gp_19['max_depth'])\n",
        "params_gp_19['min_child_weight'] = int(params_gp_19['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_gp_train19 = xgb.DMatrix(X_train19, y_train19)\n",
        "dX_gp_test19 = xgb.DMatrix(X_test19, y_test19)\n",
        "model_gp_19 = xgb.train(params_gp_19, dX_gp_train19)\n",
        "pred_gp_19 = model_gp_19.predict(dX_gp_test19)\n",
        "\n",
        "rmse_gp_19 = np.sqrt(mean_squared_error(pred_gp_19, y_test19))\n",
        "rmse_gp_19"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 0.97533602  7.61249717 13.          0.85765469 11.          0.39830191]. \t  -2.1125055225907645 \t -2.0304436386765667\n",
            "init   \t [ 0.82999565  6.71977081  6.          0.50407413 19.          0.67209466]. \t  -2.1089329254044453 \t -2.0304436386765667\n",
            "init   \t [ 2.15923256  5.49027432 12.          0.52588686 10.          0.20235326]. \t  -2.2159557105709857 \t -2.0304436386765667\n",
            "init   \t [4.99659267 1.52108422 6.         0.73481085 4.         0.71949465]. \t  -2.0952304096019114 \t -2.0304436386765667\n",
            "init   \t [ 3.72927156  9.46160045  5.          0.80554614 18.          0.97708466]. \t  -2.0304436386765667 \t -2.0304436386765667\n",
            "1      \t [ 8.33060043  1.42030563  8.          0.92863724 14.          0.78606141]. \t  \u001b[92m-2.0145894949098326\u001b[0m \t -2.0145894949098326\n",
            "2      \t [ 4.70068371  4.9755295  14.          0.98901029  1.          0.96039614]. \t  \u001b[92m-2.013402847080974\u001b[0m \t -2.013402847080974\n",
            "3      \t [9.07948237 9.55063617 7.         0.80962147 4.         0.34142584]. \t  -2.1248912659379515 \t -2.013402847080974\n",
            "4      \t [ 3.65000245  2.90359952 13.          0.98940034 19.          0.29019455]. \t  -2.116419349636137 \t -2.013402847080974\n",
            "5      \t [0.25768796 8.33414072 6.         0.99948369 4.         0.66680619]. \t  -2.079171320001423 \t -2.013402847080974\n",
            "6      \t [ 8.89243569  4.2136102  10.          0.88870164  8.          0.77683659]. \t  -2.0169124310408906 \t -2.013402847080974\n",
            "7      \t [ 7.9630536   9.9112732  14.          0.53823001 14.          0.26777722]. \t  -2.142992535880758 \t -2.013402847080974\n",
            "8      \t [1.60895472e-01 8.27074864e-03 1.30000000e+01 6.91893018e-01\n",
            " 5.00000000e+00 4.60327119e-01]. \t  -2.116563020235236 \t -2.013402847080974\n",
            "9      \t [ 0.32873959  7.7155114   5.          0.56871173 11.          0.34471029]. \t  -2.1397351083012697 \t -2.013402847080974\n",
            "10     \t [ 6.55489773  0.06438745 14.          0.53351105 11.          0.76391016]. \t  -2.0417772467700233 \t -2.013402847080974\n",
            "11     \t [ 0.          0.         15.          1.         14.36498576  0.1       ]. \t  -2.1975582014339916 \t -2.013402847080974\n",
            "12     \t [ 4.31405249  0.92741236  7.          0.67333637 19.          0.97097788]. \t  -2.030507247318959 \t -2.013402847080974\n",
            "13     \t [ 0.07353347  8.4040255  13.          0.8931152   4.          0.37840671]. \t  -2.1097942686875157 \t -2.013402847080974\n",
            "14     \t [ 8.38895111  9.39819527 14.          0.57861776  4.          0.75378716]. \t  -2.0367209957075523 \t -2.013402847080974\n",
            "15     \t [0.22611985 0.1170465  7.         0.55795985 9.         0.86758401]. \t  -2.0380567319646445 \t -2.013402847080974\n",
            "16     \t [ 9.0780433   8.49155787  5.          0.8925855  13.          0.38273904]. \t  -2.1044467777655886 \t -2.013402847080974\n",
            "17     \t [ 2.66360123  9.86349513 14.          0.64775009 19.          0.29460461]. \t  -2.133308805976512 \t -2.013402847080974\n",
            "18     \t [ 9.98853921  1.87232076 12.          0.84692917  1.          0.82172483]. \t  -2.0341396389099726 \t -2.013402847080974\n",
            "19     \t [ 0.17032432  0.5511349   8.          0.8772351  15.          0.24483614]. \t  -2.2056093132615313 \t -2.013402847080974\n",
            "20     \t [ 7.30090971  9.67177732  9.          0.90074789 17.          0.50101804]. \t  -2.08575750257739 \t -2.013402847080974\n",
            "21     \t [ 9.63925033  0.21213822 12.          0.67633014 18.          0.33271761]. \t  -2.1338916764212468 \t -2.013402847080974\n",
            "22     \t [ 4.6555      3.95114831  7.          0.89703289 11.          0.79111143]. \t  -2.015915649177923 \t -2.013402847080974\n",
            "23     \t [ 8.43404304  3.70170316 14.92496498  0.5         5.62640174  0.72309548]. \t  -2.1182921120990286 \t -2.013402847080974\n",
            "24     \t [ 6.71632074  9.35507165 10.          0.92083626  9.          0.89295352]. \t  \u001b[92m-2.0114705116661695\u001b[0m \t -2.0114705116661695\n",
            "25     \t [0.14886079 3.10947104 7.         0.52818873 1.         0.88078996]. \t  -2.0431935427374084 \t -2.0114705116661695\n",
            "26     \t [ 6.01505153  4.63762737 12.50979116  1.         14.20900927  0.1       ]. \t  -2.1975584042652474 \t -2.0114705116661695\n",
            "27     \t [9.54369369 1.08133324 5.         0.81823057 8.         0.81568043]. \t  -2.031791531973689 \t -2.0114705116661695\n",
            "28     \t [9.96678192 3.92848881 5.         1.         3.45532038 0.1       ]. \t  -2.1972272486523976 \t -2.0114705116661695\n",
            "29     \t [ 4.49204209 10.          6.38459705  1.          1.          1.        ]. \t  \u001b[92m-2.0079345320231363\u001b[0m \t -2.0079345320231363\n",
            "30     \t [ 9.27901539  4.74113542  6.61467204  1.         20.          0.1       ]. \t  -2.197946197656635 \t -2.0079345320231363\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "63297.06051753857"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWGPYRJhVKsO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f79fd933-c278-4d17-a238-2bd4bfc4b6a7"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'gp' Acquisition Function run number = 20\n",
        "\n",
        "np.random.seed(run_num_20)\n",
        "surrogate_gp_20 = GaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train20, X_test20, y_train20, y_test20 = train_test_split(X, y, test_size=test_perc, random_state=run_num_20)\n",
        "\n",
        "def f_syn_polarity20(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_20, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train20, y=y_train20).mean())\n",
        "    return operator * score\n",
        "\n",
        "gp_20 = GPGO(surrogate_gp_20, Acquisition_new(util_gp), f_syn_polarity20, param, n_jobs = -1) # define BayesOpt\n",
        "gp_20.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_gp_20 = gp_20.getResult()[0]\n",
        "params_gp_20['max_depth'] = int(params_gp_20['max_depth'])\n",
        "params_gp_20['min_child_weight'] = int(params_gp_20['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_gp_train20 = xgb.DMatrix(X_train20, y_train20)\n",
        "dX_gp_test20 = xgb.DMatrix(X_test20, y_test20)\n",
        "model_gp_20 = xgb.train(params_gp_20, dX_gp_train20)\n",
        "pred_gp_20 = model_gp_20.predict(dX_gp_test20)\n",
        "\n",
        "rmse_gp_20 = np.sqrt(mean_squared_error(pred_gp_20, y_test20))\n",
        "rmse_gp_20"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 5.88130801  8.97713728 14.          0.81074445  8.          0.95540649]. \t  -1.909363007310379 \t -1.909363007310379\n",
            "init   \t [6.72865655 0.41173329 8.         0.6361582  7.         0.76174061]. \t  -1.945489761868388 \t -1.909363007310379\n",
            "init   \t [ 4.77387703  8.66202323 10.          0.51833215  7.          0.10123387]. \t  -2.0538318450351323 \t -1.909363007310379\n",
            "init   \t [ 5.75489985  4.74524381  8.          0.78084343 15.          0.26643049]. \t  -2.019385891619828 \t -1.909363007310379\n",
            "init   \t [ 4.53444     4.47342833  8.          0.91974896 18.          0.35997552]. \t  -2.0147074022409646 \t -1.909363007310379\n",
            "1      \t [ 7.96566073  7.15509535  7.          0.79906691 11.          0.34132075]. \t  -2.0240306652522984 \t -1.909363007310379\n",
            "2      \t [ 1.98667885  1.35773177 13.          0.57199118  2.          0.39498908]. \t  -2.0408843487652284 \t -1.909363007310379\n",
            "3      \t [ 0.05406024  0.42106765 14.          0.6066366  16.          0.86098378]. \t  -1.9411782541304745 \t -1.909363007310379\n",
            "4      \t [ 9.3606342   3.21248061 14.          0.65614013 17.          0.10926152]. \t  -2.0468162361461912 \t -1.909363007310379\n",
            "5      \t [8.0846212  5.99993376 6.         0.83941375 1.         0.46362124]. \t  -2.023086361344062 \t -1.909363007310379\n",
            "6      \t [0.61316554 1.36115087 5.         0.87944956 1.         0.21740227]. \t  -2.051987483090283 \t -1.909363007310379\n",
            "7      \t [ 9.84370742  3.98996088 10.          0.7550939  10.          0.27576467]. \t  -2.02200927401397 \t -1.909363007310379\n",
            "8      \t [ 8.98782607  7.92414171 14.          0.75886729  1.          0.89019906]. \t  -1.9182305750333986 \t -1.909363007310379\n",
            "9      \t [ 1.05749901  7.99672083 14.          0.81631651 16.          0.55026721]. \t  -2.014179662109196 \t -1.909363007310379\n",
            "10     \t [ 1.01814405  9.81807131 14.          0.52908047  1.          0.89345697]. \t  -1.9347003905034412 \t -1.909363007310379\n",
            "11     \t [ 8.67003361  9.97098415 10.          0.51640399 17.          0.80747375]. \t  -1.9468378810119815 \t -1.909363007310379\n",
            "12     \t [ 9.62878188  0.47045758 13.          0.73408624  1.          0.43054124]. \t  -2.030327991812984 \t -1.909363007310379\n",
            "13     \t [ 8.98143836  8.7693897  12.          0.89468403 12.          0.66552576]. \t  -1.970028672038877 \t -1.909363007310379\n",
            "14     \t [ 0.46658736  2.67419125  7.          0.696709   11.          0.41932261]. \t  -2.0218713401378308 \t -1.909363007310379\n",
            "15     \t [ 5.37444991  0.3056877   9.          0.99777328 15.          0.5903115 ]. \t  -2.0148906213566007 \t -1.909363007310379\n",
            "16     \t [ 0.03685635  8.99252991  7.          0.68273443 17.          0.92978046]. \t  -1.9103412054375848 \t -1.909363007310379\n",
            "17     \t [ 0.0269108   5.63927067 14.          0.80391219 10.          0.28928667]. \t  -2.0271221435857734 \t -1.909363007310379\n",
            "18     \t [ 0. 10.  5.  1. 11.  1.]. \t  -1.9176648000920422 \t -1.909363007310379\n",
            "19     \t [1.09003762 7.76809006 5.         0.56875731 3.         0.91973406]. \t  -1.9421865360505266 \t -1.909363007310379\n",
            "20     \t [ 5.85759876  3.27982844 14.          0.93055569  9.          0.74428671]. \t  -1.9715118790065826 \t -1.909363007310379\n",
            "21     \t [3.73561715 5.58051478 8.         0.81394826 4.         0.69830467]. \t  -1.9693474919509277 \t -1.909363007310379\n",
            "22     \t [ 9.95819648  7.0309212   5.          0.82962432 17.          0.9419792 ]. \t  -1.9157941015507227 \t -1.909363007310379\n",
            "23     \t [6.66579605 0.         5.         0.5        1.         0.1       ]. \t  -2.047538843227097 \t -1.909363007310379\n",
            "24     \t [ 7.82908981  0.          5.          1.         20.          0.1       ]. \t  -2.0514594395392227 \t -1.909363007310379\n",
            "25     \t [ 5.51589417  6.85570915 12.99853764  1.         19.28130274  1.        ]. \t  \u001b[92m-1.904533732353491\u001b[0m \t -1.904533732353491\n",
            "26     \t [ 1.59393922  1.22829879  5.          0.99175367 19.          0.68670776]. \t  -1.9694797210584014 \t -1.904533732353491\n",
            "27     \t [0.         0.         7.89836005 1.         5.53545401 0.1       ]. \t  -2.051981411475403 \t -1.904533732353491\n",
            "28     \t [ 8.76291662  0.48421497  6.          0.98090448 12.          0.31027582]. \t  -2.0183310242583583 \t -1.904533732353491\n",
            "29     \t [ 1.12930292  0.31644024 12.          0.71762668 11.          0.36909596]. \t  -2.0271410797206473 \t -1.904533732353491\n",
            "30     \t [10.          0.         14.47946847  0.5        10.55073016  1.        ]. \t  -1.9382123714199757 \t -1.904533732353491\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "59194.599001987306"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1d_1LyydIfe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ab4b7b0-7143-4172-ac53-d10a6a16b899"
      },
      "source": [
        "end_gp = time.time()\n",
        "end_gp\n",
        "\n",
        "time_gp = end_gp - start_gp\n",
        "time_gp\n",
        "\n",
        "start_stp = time.time()\n",
        "start_stp"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1663087124.2799814"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAyOw7XYVwAf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b8b916f-2d53-4963-f9d4-c10537d98c9a"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'stp' Acquisition Function run number = 1 \n",
        "\n",
        "np.random.seed(run_num_1)\n",
        "surrogate_stp_1 = tStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train1, X_test1, y_train1, y_test1 = train_test_split(X, y, test_size=test_perc, random_state=run_num_1)\n",
        "\n",
        "def f_syn_polarity1(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_1, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train1, y=y_train1).mean())\n",
        "    return operator * score\n",
        "\n",
        "stp_1 = GPGO(surrogate_stp_1, Acquisition_new(util_stp), f_syn_polarity1, param, n_jobs = -1) # Define BayesOpt\n",
        "stp_1.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_stp_1 = stp_1.getResult()[0]\n",
        "params_stp_1['max_depth'] = int(params_stp_1['max_depth'])\n",
        "params_stp_1['min_child_weight'] = int(params_stp_1['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_stp_train1 = xgb.DMatrix(X_train1, y_train1)\n",
        "dX_stp_test1 = xgb.DMatrix(X_test1, y_test1)\n",
        "model_stp_1 = xgb.train(params_stp_1, dX_stp_train1)\n",
        "pred_stp_1 = model_stp_1.predict(dX_stp_test1)\n",
        "\n",
        "rmse_stp_1 = np.sqrt(mean_squared_error(pred_stp_1, y_test1))\n",
        "rmse_stp_1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 4.17022005  7.20324493 14.          0.65116629 16.          0.31248008]. \t  -1.9958892406678181 \t -1.927633642985235\n",
            "init   \t [ 3.96580727  3.87910741 11.          0.96776954  6.          0.71669755]. \t  -1.9397531362536724 \t -1.927633642985235\n",
            "init   \t [ 2.0445225   8.78117436  7.          0.95698101 10.          0.48762871]. \t  -1.9976238165476006 \t -1.927633642985235\n",
            "init   \t [ 9.39127789  7.78389236 14.          0.98413079  2.          0.87851823]. \t  -1.927633642985235 \t -1.927633642985235\n",
            "init   \t [8.29146907 8.29603359 8.         0.58491521 9.         0.18851215]. \t  -1.9902043452530749 \t -1.927633642985235\n",
            "1      \t [ 6.16328945  0.35999436  5.          0.50627799 18.          0.9705487 ]. \t  -1.9418408349605791 \t -1.927633642985235\n",
            "2      \t [ 3.06550626  9.28266952  7.          0.97265422 12.          0.93288355]. \t  \u001b[92m-1.9149795339973708\u001b[0m \t -1.9149795339973708\n",
            "3      \t [ 9.9482187   2.21666862 14.          0.70855121 12.          0.29382696]. \t  -1.992010689905387 \t -1.9149795339973708\n",
            "4      \t [2.51203183 6.55760768 5.         0.93655975 2.         0.68134382]. \t  -1.9427461819134577 \t -1.9149795339973708\n",
            "5      \t [9.98806418 1.50440675 6.         0.54760374 1.         0.41555547]. \t  -2.0073996897560766 \t -1.9149795339973708\n",
            "6      \t [ 8.0300004   9.96141437 10.          0.69739405 19.          0.83217392]. \t  -1.9387782773160844 \t -1.9149795339973708\n",
            "7      \t [ 1.68565682  0.10514008  7.          0.78727968 11.          0.43396967]. \t  -1.9878156204899393 \t -1.9149795339973708\n",
            "8      \t [ 0.56142367  0.70996187 14.          0.5646257  16.          0.45400367]. \t  -1.9996036111278925 \t -1.9149795339973708\n",
            "9      \t [ 0.2895725   9.16484014 12.          0.97952638  3.          0.37187842]. \t  -1.9963760073850367 \t -1.9149795339973708\n",
            "10     \t [2.44016535 0.20486572 5.         0.58080082 4.         0.75843949]. \t  -1.9421939214570823 \t -1.9149795339973708\n",
            "11     \t [ 9.97762672  0.42324339  5.          0.53869034 12.          0.64060932]. \t  -1.945788185393318 \t -1.9149795339973708\n",
            "12     \t [ 0.95919451  9.17677749 14.          0.9947321  11.          0.39115781]. \t  -1.9909583168213731 \t -1.9149795339973708\n",
            "13     \t [8.62031057 8.96562821 5.         0.98233596 2.         0.11261412]. \t  -1.9957030293532587 \t -1.9149795339973708\n",
            "14     \t [ 2.17450061  7.42238239  6.          0.51360623 19.          0.62031106]. \t  -1.9525975947808827 \t -1.9149795339973708\n",
            "15     \t [ 1.83801149  0.8601691  14.          0.88915168  1.          0.69918851]. \t  -1.9394246686558876 \t -1.9149795339973708\n",
            "16     \t [ 6.15640361  8.42319415  6.          0.63476806 14.          0.78301957]. \t  -1.9429545393443326 \t -1.9149795339973708\n",
            "17     \t [ 7.86704415  4.02975578 10.          0.71051659  6.          0.4108879 ]. \t  -1.9956072132457088 \t -1.9149795339973708\n",
            "18     \t [ 5.46923351  1.69493643 10.          0.52097618 14.          0.51857578]. \t  -1.954426500574445 \t -1.9149795339973708\n",
            "19     \t [ 8.57684482  8.6390815  14.          0.73853245 12.          0.41443806]. \t  -1.9947445383876214 \t -1.9149795339973708\n",
            "20     \t [ 7.49641388  0.53451513 14.          0.53078358 16.          0.11212662]. \t  -1.992169982349536 \t -1.9149795339973708\n",
            "21     \t [ 0.          4.1322085  10.00176971  0.5         1.          0.1       ]. \t  -1.9963364479698609 \t -1.9149795339973708\n",
            "22     \t [ 9.23077207  6.68481158  5.          0.70512263 19.          0.4083344 ]. \t  -1.993133612154983 \t -1.9149795339973708\n",
            "23     \t [ 9.23992453  0.05133941 14.          0.88443663  5.          0.65530002]. \t  -1.9365619862671672 \t -1.9149795339973708\n",
            "24     \t [ 0.52953375  3.90262452 11.          0.88036588 12.          0.48397337]. \t  -1.9853723260490845 \t -1.9149795339973708\n",
            "25     \t [ 0.18256843  9.80114086 11.          0.99093287 18.          0.37632134]. \t  -1.9886334646424877 \t -1.9149795339973708\n",
            "26     \t [ 4.98158318  9.35475115 10.          0.82561507  1.          0.63641323]. \t  -1.9437367786937272 \t -1.9149795339973708\n",
            "27     \t [6.215297   4.07063538 5.         0.50621167 8.         0.96796628]. \t  -1.946882305958285 \t -1.9149795339973708\n",
            "28     \t [ 1.34303114  3.97881916 10.          0.54778021 19.          0.13206926]. \t  -1.9948455087895312 \t -1.9149795339973708\n",
            "29     \t [ 0.48409752  3.85018794 14.          0.7335318  10.          0.37896479]. \t  -1.992084229328635 \t -1.9149795339973708\n",
            "30     \t [ 5.50510172  2.97299502 11.          0.90570959  1.          0.49925329]. \t  -1.9976855121011006 \t -1.9149795339973708\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "61032.19618864838"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrDQbChpZ48F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b4900ed-5893-4c40-99c5-e85506394d4d"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'stp' Acquisition Function run number = 2 \n",
        "\n",
        "np.random.seed(run_num_2)\n",
        "surrogate_stp_2 = tStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(X, y, test_size=test_perc, random_state=run_num_2)\n",
        "\n",
        "def f_syn_polarity2(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_2, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train2, y=y_train2).mean())\n",
        "    return operator * score\n",
        "\n",
        "stp_2 = GPGO(surrogate_stp_2, Acquisition_new(util_stp), f_syn_polarity2, param, n_jobs = -1) # Define BayesOpt\n",
        "stp_2.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_stp_2 = stp_2.getResult()[0]\n",
        "params_stp_2['max_depth'] = int(params_stp_2['max_depth'])\n",
        "params_stp_2['min_child_weight'] = int(params_stp_2['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_stp_train2 = xgb.DMatrix(X_train2, y_train2)\n",
        "dX_stp_test2 = xgb.DMatrix(X_test2, y_test2)\n",
        "model_stp_2 = xgb.train(params_stp_2, dX_stp_train2)\n",
        "pred_stp_2 = model_stp_2.predict(dX_stp_test2)\n",
        "\n",
        "rmse_stp_2 = np.sqrt(mean_squared_error(pred_stp_2, y_test2))\n",
        "rmse_stp_2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 4.35994902  0.25926232 11.          0.97386531 12.          0.47833102]. \t  -2.0298081650952664 \t -1.9841229044560336\n",
            "init   \t [ 3.30334821  2.04648634 10.          0.55997527  6.          0.71472339]. \t  -2.0048957563444234 \t -1.9841229044560336\n",
            "init   \t [ 4.9856117   5.86796978  8.          0.89266757 11.          0.59158659]. \t  -1.9841229044560336 \t -1.9841229044560336\n",
            "init   \t [ 4.07307832  1.76984624 13.          0.75262305  7.          0.35908193]. \t  -2.0696980515920655 \t -1.9841229044560336\n",
            "init   \t [ 1.16193318  1.81727038  9.          0.79837265 19.          0.29965165]. \t  -2.061218552452579 \t -1.9841229044560336\n",
            "1      \t [9.68290573 5.74953535 8.         0.93445831 2.         0.81872709]. \t  \u001b[92m-1.9816402148241052\u001b[0m \t -1.9816402148241052\n",
            "2      \t [ 8.78180153  6.61060882 12.          0.91523653 18.          0.29687212]. \t  -2.0625378531808507 \t -1.9816402148241052\n",
            "3      \t [ 0.66591974  9.26661294 14.          0.96342421 18.          0.94909068]. \t  \u001b[92m-1.9600810016378762\u001b[0m \t -1.9600810016378762\n",
            "4      \t [0.53023554 8.79041977 6.         0.85342606 1.         0.93968064]. \t  -1.9710210867331248 \t -1.9600810016378762\n",
            "5      \t [ 2.90965473  9.60484926 14.          0.96745917  2.          0.76388947]. \t  -1.9836549037974958 \t -1.9600810016378762\n",
            "6      \t [ 8.57602235  9.83360074 12.          0.99133635  7.          0.25584574]. \t  -2.073360437638249 \t -1.9600810016378762\n",
            "7      \t [ 9.77744834  2.26597384  5.          0.98618685 19.          0.58642903]. \t  -1.9815535400845103 \t -1.9600810016378762\n",
            "8      \t [ 1.82124551  9.97992306  7.          0.66460563 15.          0.68270076]. \t  -1.989156510671623 \t -1.9600810016378762\n",
            "9      \t [ 5.76886466  6.30636441 11.          0.85075313  6.          0.94564556]. \t  -1.9685258385323288 \t -1.9600810016378762\n",
            "10     \t [ 0.92680624  0.80829442  5.          0.99163751 10.          0.48273491]. \t  -2.027348177617255 \t -1.9600810016378762\n",
            "11     \t [ 8.66397635  9.94226364  5.          0.61754568 19.          0.46861962]. \t  -2.033276199037532 \t -1.9600810016378762\n",
            "12     \t [ 0.03855324  8.9930469  12.          0.98249334  8.          0.88557845]. \t  -1.9665018013580142 \t -1.9600810016378762\n",
            "13     \t [ 9.78109337  2.52726344  5.          0.62902817 11.          0.70291169]. \t  -1.9957339590420176 \t -1.9600810016378762\n",
            "14     \t [ 2.61078484  8.48438058 14.          0.79784401 12.          0.37480602]. \t  -2.0636983248476284 \t -1.9600810016378762\n",
            "15     \t [ 8.35914343  2.39349698 13.          0.9820231   1.          0.65048694]. \t  -1.9922723524942718 \t -1.9600810016378762\n",
            "16     \t [ 5.06757471  9.7694234  13.          0.99093987 11.          0.67159137]. \t  -1.9845410627262219 \t -1.9600810016378762\n",
            "17     \t [ 1.36729794  4.89791321 13.          0.50996816  1.          0.64172429]. \t  -2.013248194129386 \t -1.9600810016378762\n",
            "18     \t [ 5.60637572  9.049847    5.          0.8061539  14.          0.24568718]. \t  -2.0646930516700577 \t -1.9600810016378762\n",
            "19     \t [5.71127179 8.62909383 6.         0.9145048  4.         0.23844251]. \t  -2.069779422271244 \t -1.9600810016378762\n",
            "20     \t [ 9.6238218   9.56471994 12.          0.53921739  3.          0.81851249]. \t  -2.005953290000792 \t -1.9600810016378762\n",
            "21     \t [ 7.9948003   1.98690882  9.          0.95281063 10.          0.19774757]. \t  -2.0712202013104988 \t -1.9600810016378762\n",
            "22     \t [6.33326146 0.4152582  6.         0.58461709 2.         0.45185514]. \t  -2.0373683398954925 \t -1.9600810016378762\n",
            "23     \t [5.50018025 9.05735749 6.         0.74065318 9.         0.99404516]. \t  -1.9692445074897638 \t -1.9600810016378762\n",
            "24     \t [ 3.1159181   2.39353913 14.          0.87323381  7.          0.92688621]. \t  -1.9677322858425748 \t -1.9600810016378762\n",
            "25     \t [ 6.38930875  0.28720349 11.          0.64885918 18.          0.54464511]. \t  -1.999459937695439 \t -1.9600810016378762\n",
            "26     \t [ 9.28062014  4.29835638 14.          0.82063155  8.          0.8961821 ]. \t  -1.9663717391497684 \t -1.9600810016378762\n",
            "27     \t [ 1.38351546  5.38052876  5.          0.8811976  19.          0.99902206]. \t  -1.9745539771066425 \t -1.9600810016378762\n",
            "28     \t [1.4618314  2.82027468 5.         0.87885193 3.         0.11824458]. \t  -2.0675851158439102 \t -1.9600810016378762\n",
            "29     \t [6.17992409 3.04518736 9.         0.99103502 3.         0.46093792]. \t  -2.0306606830382767 \t -1.9600810016378762\n",
            "30     \t [ 2.28984868  2.53597266 14.          0.81995774 11.          0.43177097]. \t  -2.0277435739562057 \t -1.9600810016378762\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60928.26805906831"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpUPyXRfZ95Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e258c02-7301-4f50-b6d7-a0986c7d8334"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'stp' Acquisition Function run number = 3 \n",
        "\n",
        "np.random.seed(run_num_3)\n",
        "surrogate_stp_3 = tStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train3, X_test3, y_train3, y_test3 = train_test_split(X, y, test_size=test_perc, random_state=run_num_3)\n",
        "\n",
        "def f_syn_polarity3(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_3, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train3, y=y_train3).mean())\n",
        "    return operator * score\n",
        "\n",
        "stp_3 = GPGO(surrogate_stp_3, Acquisition_new(util_stp), f_syn_polarity3, param, n_jobs = -1) # Define BayesOpt\n",
        "stp_3.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_stp_3 = stp_3.getResult()[0]\n",
        "params_stp_3['max_depth'] = int(params_stp_3['max_depth'])\n",
        "params_stp_3['min_child_weight'] = int(params_stp_3['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_stp_train3 = xgb.DMatrix(X_train3, y_train3)\n",
        "dX_stp_test3 = xgb.DMatrix(X_test3, y_test3)\n",
        "model_stp_3 = xgb.train(params_stp_3, dX_stp_train3)\n",
        "pred_stp_3 = model_stp_3.predict(dX_stp_test3)\n",
        "\n",
        "rmse_stp_3 = np.sqrt(mean_squared_error(pred_stp_3, y_test3))\n",
        "rmse_stp_3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 5.50797903  7.08147823 13.          0.56066429 11.          0.11687321]. \t  -2.1327354912839973 \t -1.9956488227380944\n",
            "init   \t [ 0.40630737  2.47888297 11.          0.72040492 13.          0.23083313]. \t  -2.1286878580840187 \t -1.9956488227380944\n",
            "init   \t [ 4.53172301  2.15577008 11.          0.74631796  2.          0.60296868]. \t  -1.9956488227380944 \t -1.9956488227380944\n",
            "init   \t [ 2.59252447  4.15101197 13.          0.79330998  8.          0.24118096]. \t  -2.1306652618833883 \t -1.9956488227380944\n",
            "init   \t [ 5.44649018  7.80314765 10.          0.62879264 18.          0.44917413]. \t  -2.051679716515038 \t -1.9956488227380944\n",
            "1      \t [4.88873245 9.27936348 6.         0.94344906 8.         0.25949204]. \t  -2.0788458529169214 \t -1.9956488227380944\n",
            "2      \t [ 8.93142368  1.52910591 13.          0.84039318 17.          0.60846833]. \t  \u001b[92m-1.9953686415021132\u001b[0m \t -1.9953686415021132\n",
            "3      \t [ 6.38594331  1.19109066  5.          0.81189053 13.          0.59164768]. \t  -1.995584493376127 \t -1.9953686415021132\n",
            "4      \t [ 1.02918863  9.32189805 13.          0.88333707  1.          0.86998588]. \t  -2.0050604989880227 \t -1.9953686415021132\n",
            "5      \t [ 9.74929058  1.51205926 11.          0.50025602  8.          0.46132437]. \t  -2.0541445686203503 \t -1.9953686415021132\n",
            "6      \t [ 1.10659828  9.06323562  6.          0.78045487 14.          0.88521866]. \t  \u001b[92m-1.9903379136068675\u001b[0m \t -1.9903379136068675\n",
            "7      \t [ 8.92744991  9.09956287 12.          0.74944313  3.          0.11030352]. \t  -2.1316968930284994 \t -1.9903379136068675\n",
            "8      \t [0.28002919 1.86471402 5.         0.90893429 3.         0.44808833]. \t  -2.0444642827108863 \t -1.9903379136068675\n",
            "9      \t [ 2.50233267  5.65022453 13.          0.972061   12.          0.65081115]. \t  -1.9942010906606533 \t -1.9903379136068675\n",
            "10     \t [9.43215663 9.14652183 5.         0.95117899 1.         0.516629  ]. \t  -1.9995138947395243 \t -1.9903379136068675\n",
            "11     \t [ 2.84857043  0.57472701  5.          0.53705172 19.          0.51858228]. \t  -1.9976367640801065 \t -1.9903379136068675\n",
            "12     \t [ 7.53107849  7.69097206  5.          0.83803957 14.          0.8043058 ]. \t  -1.99271447776682 \t -1.9903379136068675\n",
            "13     \t [2.99254427 2.69228882 7.         0.63915731 9.         0.21678027]. \t  -2.1313948591378016 \t -1.9903379136068675\n",
            "14     \t [8.8237369  0.04240955 5.         0.7158964  1.         0.99950517]. \t  -1.9964548101090434 \t -1.9903379136068675\n",
            "15     \t [ 5.7586577   1.42812945 10.          0.74022438  8.          0.79053147]. \t  -2.004780908170871 \t -1.9903379136068675\n",
            "16     \t [ 0.56385055  1.58792803 11.          0.96778339 10.          0.4958124 ]. \t  -2.037379547367043 \t -1.9903379136068675\n",
            "17     \t [ 0.94336997  1.29293405 12.          0.62917786 19.          0.81056172]. \t  -2.0049701566396494 \t -1.9903379136068675\n",
            "18     \t [9.11337912 5.11804282 5.         0.88549278 8.         0.34515366]. \t  -2.0782015668850065 \t -1.9903379136068675\n",
            "19     \t [ 8.47141069  4.67253675  7.          0.68194579 19.          0.40864272]. \t  -2.0518137118186486 \t -1.9903379136068675\n",
            "20     \t [4.27034104 6.89504758 8.         0.52242333 1.         0.93013039]. \t  -2.006419000224822 \t -1.9903379136068675\n",
            "21     \t [ 6.40272995  1.06358237 14.          0.62818522 12.          0.41787453]. \t  -2.0551821372294024 \t -1.9903379136068675\n",
            "22     \t [ 1.93605647  4.7311071   5.          0.69074604 16.          0.89166586]. \t  -1.9932264185899349 \t -1.9903379136068675\n",
            "23     \t [ 1.09978763  9.06043976 11.          0.8830514  19.          0.28872071]. \t  -2.074075865229721 \t -1.9903379136068675\n",
            "24     \t [ 5.1219844   6.28471498 12.          0.72675855  4.          0.42302906]. \t  -2.0505990892327057 \t -1.9903379136068675\n",
            "25     \t [7.52612901 1.89357745 6.         0.99443178 2.         0.40182912]. \t  -2.0421337821967684 \t -1.9903379136068675\n",
            "26     \t [ 9.57846798  5.67492818 11.          0.9450323  15.          0.64577167]. \t  -1.9962251459501617 \t -1.9903379136068675\n",
            "27     \t [ 9.6553331   0.78950956  5.          0.88539267 13.          0.42518008]. \t  -2.045969535531016 \t -1.9903379136068675\n",
            "28     \t [ 1.49730247  0.83144325 14.          0.60476723  9.          0.25549349]. \t  -2.080075314012411 \t -1.9903379136068675\n",
            "29     \t [ 0.10026874  3.99596933 14.          0.6822027   3.          0.96481664]. \t  -1.9969942735887467 \t -1.9903379136068675\n",
            "30     \t [ 1.39598812  9.90188838 13.          0.61873715  9.          0.19633416]. \t  -2.1355428105943988 \t -1.9903379136068675\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "61917.93931192609"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKX_nfEaaAwm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bce5d93b-1664-4ba5-dba5-d1235b62217e"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'stp' Acquisition Function run number = 4 \n",
        "\n",
        "np.random.seed(run_num_4)\n",
        "surrogate_stp_4 = tStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train4, X_test4, y_train4, y_test4 = train_test_split(X, y, test_size=test_perc, random_state=run_num_4)\n",
        "\n",
        "def f_syn_polarity4(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_4, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train4, y=y_train4).mean())\n",
        "    return operator * score\n",
        "\n",
        "stp_4 = GPGO(surrogate_stp_4, Acquisition_new(util_stp), f_syn_polarity4, param, n_jobs = -1) # Define BayesOpt\n",
        "stp_4.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_stp_4 = stp_4.getResult()[0]\n",
        "params_stp_4['max_depth'] = int(params_stp_4['max_depth'])\n",
        "params_stp_4['min_child_weight'] = int(params_stp_4['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_stp_train4 = xgb.DMatrix(X_train4, y_train4)\n",
        "dX_stp_test4 = xgb.DMatrix(X_test4, y_test4)\n",
        "model_stp_4 = xgb.train(params_stp_4, dX_stp_train4)\n",
        "pred_stp_4 = model_stp_4.predict(dX_stp_test4)\n",
        "\n",
        "rmse_stp_4 = np.sqrt(mean_squared_error(pred_stp_4, y_test4))\n",
        "rmse_stp_4"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [9.67029839 5.47232249 6.         0.92781047 9.         0.72795594]. \t  -1.9389833982070896 \t -1.9185014978322321\n",
            "init   \t [ 2.16089496  9.76274455 12.          0.62649118  9.          0.66966679]. \t  -1.9445149590744684 \t -1.9185014978322321\n",
            "init   \t [ 0.05159149  5.72356491  9.          0.99170034 10.          0.10808749]. \t  -2.1102338527761537 \t -1.9185014978322321\n",
            "init   \t [ 3.86571283  0.44160058 10.          0.90553105 18.          0.95407958]. \t  -1.9185014978322321 \t -1.9185014978322321\n",
            "init   \t [ 7.86305986  8.66289299  6.          0.53285477 14.          0.25117497]. \t  -1.9862504726191532 \t -1.9185014978322321\n",
            "1      \t [ 8.45443649  8.61014312 11.          0.83475494  1.          0.14018305]. \t  -2.1075864515395755 \t -1.9185014978322321\n",
            "2      \t [ 0.77431146  1.96668116 12.          0.50723361  3.          0.74768925]. \t  -1.9573746201697617 \t -1.9185014978322321\n",
            "3      \t [2.27858743 6.23199766 5.         0.58705984 2.         0.80794289]. \t  -1.9714199193992887 \t -1.9185014978322321\n",
            "4      \t [ 6.832625    9.87635293 14.          0.84450885 19.          0.20389666]. \t  -2.1075635354065776 \t -1.9185014978322321\n",
            "5      \t [ 7.37255369  2.03491596 13.          0.8921741   9.          0.46934318]. \t  -1.979645832209521 \t -1.9185014978322321\n",
            "6      \t [ 0.05992751  6.06320143 14.          0.89322475 17.          0.32211096]. \t  -1.981246352695735 \t -1.9185014978322321\n",
            "7      \t [ 0.79250634  6.36332745  6.          0.84703891 17.          0.8628914 ]. \t  -1.949610991693739 \t -1.9185014978322321\n",
            "8      \t [9.26767626 0.09691703 5.         0.59554562 3.         0.95249041]. \t  -1.9400880411854338 \t -1.9185014978322321\n",
            "9      \t [ 9.93824172  2.34876498  7.          0.94210707 16.          0.6947317 ]. \t  -1.9417584484529364 \t -1.9185014978322321\n",
            "10     \t [ 6.83932377  2.80061285 14.          0.57357337 12.          0.81140042]. \t  -1.9534680205303907 \t -1.9185014978322321\n",
            "11     \t [8.12039932 9.82838311 5.         0.6851891  3.         0.87462757]. \t  -1.9612928006763783 \t -1.9185014978322321\n",
            "12     \t [5.15416677 3.34800991 5.         0.62586519 7.         0.15848654]. \t  -2.1085200193134086 \t -1.9185014978322321\n",
            "13     \t [10.          0.         15.          0.5         2.98871606  1.        ]. \t  -1.9388144261763174 \t -1.9185014978322321\n",
            "14     \t [ 7.85637341  8.74565201 12.          0.75176647 12.          0.31176702]. \t  -1.9898997820946858 \t -1.9185014978322321\n",
            "15     \t [ 3.86011537  0.62713988  9.          0.91839365 12.          0.16506245]. \t  -2.1083212311633477 \t -1.9185014978322321\n",
            "16     \t [ 5.99047436  2.37202156  9.          0.99159406 15.          0.91638188]. \t  \u001b[92m-1.912827080264743\u001b[0m \t -1.912827080264743\n",
            "17     \t [8.92956793 0.67341707 9.         0.77288829 6.         0.75609554]. \t  -1.943497029420162 \t -1.912827080264743\n",
            "18     \t [ 1.36166264  7.62470863 10.          0.73063472  4.          0.26356518]. \t  -1.9945310922740114 \t -1.912827080264743\n",
            "19     \t [ 1.22798404  9.39676541 11.          0.99100533 19.          0.5212198 ]. \t  -1.983366942512357 \t -1.912827080264743\n",
            "20     \t [4.83812445 3.17331929 5.         0.65904618 3.         0.22287773]. \t  -2.1085107882159755 \t -1.912827080264743\n",
            "21     \t [ 2.42888334  9.64162427  5.          0.83437842 11.          0.93964634]. \t  -1.9299571594666887 \t -1.912827080264743\n",
            "22     \t [ 1.199353    0.81386739  5.          0.79955873 15.          0.37955531]. \t  -1.993147478305471 \t -1.912827080264743\n",
            "23     \t [ 8.46627336  4.03894822 14.          0.75527682 18.          0.97491516]. \t  -1.9291018331484246 \t -1.912827080264743\n",
            "24     \t [ 6.01914341  3.72327602 13.          0.58898295  2.          0.55487443]. \t  -1.9963086104335894 \t -1.912827080264743\n",
            "25     \t [ 6.11542971  4.73500754  5.          0.71416589 19.          0.49348915]. \t  -1.9955325136969908 \t -1.912827080264743\n",
            "26     \t [ 8.07479553  9.47429677 10.          0.60829209  6.          0.73383214]. \t  -1.9480593168623295 \t -1.912827080264743\n",
            "27     \t [ 0.58734764  5.07631915 14.          0.73690953 12.          0.86091553]. \t  -1.945161291969545 \t -1.912827080264743\n",
            "28     \t [9.72522943 4.96903784 5.         1.         1.         0.1       ]. \t  -2.104587960875503 \t -1.912827080264743\n",
            "29     \t [ 3.47524976  9.27226861 12.          0.90347022 15.          0.17738131]. \t  -2.1081204134960125 \t -1.912827080264743\n",
            "30     \t [0.05073688 9.52784774 5.         0.54923801 7.         0.20792694]. \t  -2.110369972368458 \t -1.912827080264743\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60684.47557007898"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJmI9saAaEG1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba5af09a-bd3d-4812-e0c8-6c3829604cb0"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'stp' Acquisition Function run number = 5 \n",
        "\n",
        "np.random.seed(run_num_5)\n",
        "surrogate_stp_5 = tStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train5, X_test5, y_train5, y_test5 = train_test_split(X, y, test_size=test_perc, random_state=run_num_5)\n",
        "\n",
        "def f_syn_polarity5(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_5, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train5, y=y_train5).mean())\n",
        "    return operator * score\n",
        "\n",
        "stp_5 = GPGO(surrogate_stp_5, Acquisition_new(util_stp), f_syn_polarity5, param, n_jobs = -1) # Define BayesOpt\n",
        "stp_5.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_stp_5 = stp_5.getResult()[0]\n",
        "params_stp_5['max_depth'] = int(params_stp_5['max_depth'])\n",
        "params_stp_5['min_child_weight'] = int(params_stp_5['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_stp_train5 = xgb.DMatrix(X_train5, y_train5)\n",
        "dX_stp_test5 = xgb.DMatrix(X_test5, y_test5)\n",
        "model_stp_5 = xgb.train(params_stp_5, dX_stp_train5)\n",
        "pred_stp_5 = model_stp_5.predict(dX_stp_test5)\n",
        "\n",
        "rmse_stp_5 = np.sqrt(mean_squared_error(pred_stp_5, y_test5))\n",
        "rmse_stp_5"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 2.21993171  8.70732306 11.          0.68186845 10.          0.53957007]. \t  -1.9599422560077813 \t -1.9013654264108653\n",
            "init   \t [ 6.11743863  7.65907856  5.          0.64840025 16.          0.82745351]. \t  -1.9013654264108653 \t -1.9013654264108653\n",
            "init   \t [ 6.49458883  8.19472793  6.          0.93996852 19.          0.36647194]. \t  -2.005840325693773 \t -1.9013654264108653\n",
            "init   \t [ 6.28787909  5.7983781   6.          0.63290956 17.          0.18402673]. \t  -2.0055006279610965 \t -1.9013654264108653\n",
            "init   \t [8.26554249 8.33492742 9.         0.97900675 3.         0.26957319]. \t  -2.0104758642779474 \t -1.9013654264108653\n",
            "1      \t [1.95474956 1.21548467 5.         0.65548996 6.         0.3261206 ]. \t  -2.0061716974922197 \t -1.9013654264108653\n",
            "2      \t [ 0.09956678  5.3014067  14.          0.6298658  17.          0.94976952]. \t  \u001b[92m-1.8681155157955736\u001b[0m \t -1.8681155157955736\n",
            "3      \t [ 8.96005069  0.40158558 13.          0.99993231  1.          0.57714848]. \t  -1.9743761204144004 \t -1.8681155157955736\n",
            "4      \t [ 9.87326458  3.08165071 13.          0.89537491 17.          0.48678657]. \t  -1.9843552439502055 \t -1.8681155157955736\n",
            "5      \t [ 0.42801231  0.53056997 14.          0.88001393  3.          0.60870677]. \t  -1.9693627127747881 \t -1.8681155157955736\n",
            "6      \t [ 9.41789049  5.24678791 11.          0.78426601 10.          0.31189288]. \t  -2.0123407211850113 \t -1.8681155157955736\n",
            "7      \t [ 0.15773168  2.32643207  7.          0.74406654 13.          0.24500907]. \t  -2.0074196136021305 \t -1.8681155157955736\n",
            "8      \t [ 0.5259471   9.7567347  14.          0.91097263  1.          0.64281486]. \t  -1.9408048308052082 \t -1.8681155157955736\n",
            "9      \t [ 7.68019847  0.14272251  5.          0.84271757 13.          0.46064437]. \t  -1.9895292141970073 \t -1.8681155157955736\n",
            "10     \t [1.24717977 9.40645683 5.         0.65383928 3.         0.68852908]. \t  -1.9086666742183518 \t -1.8681155157955736\n",
            "11     \t [8.5765283  1.77730566 7.         0.63994635 4.         0.42153661]. \t  -1.992019890207755 \t -1.8681155157955736\n",
            "12     \t [7.9980796  9.13466128 6.         0.81085598 9.         0.18640376]. \t  -2.010288731629506 \t -1.8681155157955736\n",
            "13     \t [ 5.39228464  0.17784539 13.          0.57001227  9.          0.60313835]. \t  -1.963937440966379 \t -1.8681155157955736\n",
            "14     \t [ 3.9042494   1.34731655 10.          0.83969498 18.          0.52845925]. \t  -1.9532127066437064 \t -1.8681155157955736\n",
            "15     \t [2.03762865 4.34961943 8.         0.53797581 1.         0.36410352]. \t  -2.01753314549905 \t -1.8681155157955736\n",
            "16     \t [ 7.87772257  8.71340044 12.          0.8589136  15.          0.7305315 ]. \t  -1.9085759937383635 \t -1.8681155157955736\n",
            "17     \t [ 6.80615583  6.45556443 14.          0.61036314  1.          0.8555849 ]. \t  -1.907845049428511 \t -1.8681155157955736\n",
            "18     \t [ 0.39655743  9.88537948  7.          0.8395494  15.          0.83639512]. \t  -1.893244314519989 \t -1.8681155157955736\n",
            "19     \t [0.86243549 8.92584837 5.         0.6740487  9.         0.55305648]. \t  -1.964018172954947 \t -1.8681155157955736\n",
            "20     \t [ 8.45122638  1.15079693 12.          0.61778548  9.          0.89305563]. \t  -1.8696147053073897 \t -1.8681155157955736\n",
            "21     \t [ 1.58289954  4.68935038 14.          0.95437528  3.          0.8239925 ]. \t  -1.900574601505123 \t -1.8681155157955736\n",
            "22     \t [ 0.05156214  1.34087568 14.          0.9748686  13.          0.19887658]. \t  -2.0109364298519155 \t -1.8681155157955736\n",
            "23     \t [ 6.81691807  8.87161629 14.          0.87860353  9.          0.18458297]. \t  -2.0090422531627317 \t -1.8681155157955736\n",
            "24     \t [ 5.00313371  9.06675042 11.          0.86085622 17.          0.45142646]. \t  -1.9843332369646902 \t -1.8681155157955736\n",
            "25     \t [6.32380627 0.66555573 7.         0.807462   4.         0.19962158]. \t  -2.0120823473247484 \t -1.8681155157955736\n",
            "26     \t [4.99058315 5.23658707 8.         0.96350135 6.         0.60792079]. \t  -1.9562752928239078 \t -1.8681155157955736\n",
            "27     \t [ 4.71492595  5.7713953   7.8154414   0.5        11.99756583  0.1       ]. \t  -2.009366715355902 \t -1.8681155157955736\n",
            "28     \t [ 8.72370168  9.67456444 12.          0.68874538  4.          0.84886916]. \t  -1.9089914514495465 \t -1.8681155157955736\n",
            "29     \t [ 9.53018418  3.89397642  7.          0.99503849 14.          0.35032841]. \t  -2.0064616158579054 \t -1.8681155157955736\n",
            "30     \t [0.         0.         9.32432826 1.         8.42383626 1.        ]. \t  \u001b[92m-1.8568685908443718\u001b[0m \t -1.8568685908443718\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "61776.60439291778"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulhEolsxaG4k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4239bb2c-697b-48dd-a342-b22a41d8697c"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'stp' Acquisition Function run number = 6 \n",
        "\n",
        "np.random.seed(run_num_6)\n",
        "surrogate_stp_6 = tStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train6, X_test6, y_train6, y_test6 = train_test_split(X, y, test_size=test_perc, random_state=run_num_6)\n",
        "\n",
        "def f_syn_polarity6(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=int(min_child_weight),\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_6, objective = 'reg:squarederror', eval_metric = 'rmse')\n",
        "    score = np.array(cross_val_score(reg, X=X_train6, y=y_train6).mean())\n",
        "    return operator * score\n",
        "\n",
        "stp_6 = GPGO(surrogate_stp_6, Acquisition_new(util_stp), f_syn_polarity6, param, n_jobs = -1) # Define BayesOpt\n",
        "stp_6.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_stp_6 = stp_6.getResult()[0]\n",
        "params_stp_6['max_depth'] = int(params_stp_6['max_depth'])\n",
        "params_stp_6['min_child_weight'] = int(params_stp_6['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_stp_train6 = xgb.DMatrix(X_train6, y_train6)\n",
        "dX_stp_test6 = xgb.DMatrix(X_test6, y_test6)\n",
        "model_stp_6 = xgb.train(params_stp_6, dX_stp_train6)\n",
        "pred_stp_6 = model_stp_6.predict(dX_stp_test6)\n",
        "\n",
        "rmse_stp_6 = np.sqrt(mean_squared_error(pred_stp_6, y_test6))\n",
        "rmse_stp_6"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [8.92860151 3.31979805 5.         0.99251441 2.         0.57683563]. \t  -2.0905801027256743 \t -2.020381853595591\n",
            "init   \t [4.18807429 3.35407849 9.         0.87750649 3.         0.56623277]. \t  -2.104747753924113 \t -2.020381853595591\n",
            "init   \t [ 5.788586    6.45355096 14.          0.70660047 12.          0.82154882]. \t  -2.020381853595591 \t -2.020381853595591\n",
            "init   \t [4.58184578 6.73834679 5.         0.90108528 3.         0.65482895]. \t  -2.0496910493799936 \t -2.020381853595591\n",
            "init   \t [ 4.42510505  5.75952352 14.          0.97882365 15.          0.29525604]. \t  -2.1564159616109135 \t -2.020381853595591\n",
            "1      \t [ 2.61343239  0.80193947  5.          0.83898129 13.          0.84644718]. \t  -2.02621196060558 \t -2.020381853595591\n",
            "2      \t [ 9.72322443  9.21177696  5.          0.87917074 11.          0.86681736]. \t  \u001b[92m-2.0193657462286696\u001b[0m \t -2.0193657462286696\n",
            "3      \t [ 0.5654966   9.52584762 14.          0.82016688  4.          0.10717254]. \t  -2.1487300851829487 \t -2.0193657462286696\n",
            "4      \t [ 2.98453858  8.8700865   6.          0.73955182 19.          0.28620498]. \t  -2.1410241416778923 \t -2.0193657462286696\n",
            "5      \t [ 9.78497949  3.70554688  8.          0.72818063 17.          0.66380896]. \t  -2.0530009885723075 \t -2.0193657462286696\n",
            "6      \t [ 0.58299146  9.62458538  9.          0.94830232 11.          0.21492907]. \t  -2.151749439048735 \t -2.0193657462286696\n",
            "7      \t [ 9.32984285  9.13994472 13.          0.80971831  3.          0.95492455]. \t  \u001b[92m-1.9849310299252205\u001b[0m \t -1.9849310299252205\n",
            "8      \t [ 9.32420466  6.39616005 13.          0.93300527 17.          0.34904443]. \t  -2.146533426426378 \t -1.9849310299252205\n",
            "9      \t [ 5.79804816  0.18524154 13.          0.91373451 12.          0.1336305 ]. \t  -2.148175537742926 \t -1.9849310299252205\n",
            "10     \t [ 9.18133243  4.09376148 10.          0.96038921  5.          0.75655401]. \t  -2.020577079327632 \t -1.9849310299252205\n",
            "11     \t [0.50322511 5.36549123 5.         0.63452016 9.         0.79019916]. \t  -2.021821805543622 \t -1.9849310299252205\n",
            "12     \t [ 1.90877122  0.88669904 11.          0.72802974 19.          0.27519153]. \t  -2.145985178580054 \t -1.9849310299252205\n",
            "13     \t [ 8.84415462  2.89803683  6.          0.75669789 10.          0.66428199]. \t  -2.0537460074911182 \t -1.9849310299252205\n",
            "14     \t [ 4.4133116   1.55939325 14.          0.77762123  6.          0.86802935]. \t  -2.0272793325597855 \t -1.9849310299252205\n",
            "15     \t [0.34300109 9.68403349 8.         0.54781067 3.         0.98074554]. \t  -1.9881611201421887 \t -1.9849310299252205\n",
            "16     \t [ 0.1193966   4.00087708 11.          0.63402737  8.          0.19613602]. \t  -2.137264476675719 \t -1.9849310299252205\n",
            "17     \t [9.27008032 1.3342566  8.         0.70563752 6.         0.17374623]. \t  -2.1491415031177805 \t -1.9849310299252205\n",
            "18     \t [ 5.15326097  6.52926284  8.          0.65974702 13.          0.97847666]. \t  \u001b[92m-1.9791717792306485\u001b[0m \t -1.9791717792306485\n",
            "19     \t [ 0.17525712  4.19183624 13.          0.93093846  1.          0.77496282]. \t  -2.0309197792559224 \t -1.9791717792306485\n",
            "20     \t [ 1.59392983  0.4187331   5.          0.53325118 19.          0.2829738 ]. \t  -2.1304014476628934 \t -1.9791717792306485\n",
            "21     \t [ 9.45838821  8.43771394  5.          0.837519   19.          0.66803955]. \t  -2.0439894857625576 \t -1.9791717792306485\n",
            "22     \t [ 0.50073585  2.52813513 13.          0.75574888 14.          0.36976835]. \t  -2.1412507771072593 \t -1.9791717792306485\n",
            "23     \t [8.85658963 1.07861601 8.         0.84497915 4.         0.67749442]. \t  -2.055333243614869 \t -1.9791717792306485\n",
            "24     \t [ 1.84453114  8.46717912 14.          0.86808076 12.          0.80313229]. \t  -2.02494051896206 \t -1.9791717792306485\n",
            "25     \t [9.27062068 8.45810835 5.         0.59716362 1.         0.21524086]. \t  -2.1375869578953384 \t -1.9791717792306485\n",
            "26     \t [ 7.26154915  0.75751462  8.          0.73283489 19.          0.51570742]. \t  -2.0958490801244882 \t -1.9791717792306485\n",
            "27     \t [ 1.3199389   7.2843554  10.          0.75314618 16.          0.28980931]. \t  -2.1427339816533935 \t -1.9791717792306485\n",
            "28     \t [ 4.7506992   1.3069747  12.          0.92660918 16.          0.74059114]. \t  -2.04001019924934 \t -1.9791717792306485\n",
            "29     \t [8.5365705  9.3035806  9.         0.76898816 8.         0.790144  ]. \t  -2.024488723646462 \t -1.9791717792306485\n",
            "30     \t [0.08695727 2.62365678 5.         0.53422645 4.         0.95383019]. \t  -1.9856263399511112 \t -1.9791717792306485\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "59866.06285748848"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYebx3RVaJ1w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c355a7d-3d12-4d11-88bd-dda81fe1a454"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'stp' Acquisition Function run number = 7 \n",
        "\n",
        "np.random.seed(run_num_7)\n",
        "surrogate_stp_7 = tStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train7, X_test7, y_train7, y_test7 = train_test_split(X, y, test_size=test_perc, random_state=run_num_7)\n",
        "\n",
        "def f_syn_polarity7(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_7, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train7, y=y_train7).mean())\n",
        "    return operator * score\n",
        "\n",
        "stp_7 = GPGO(surrogate_stp_7, Acquisition_new(util_stp), f_syn_polarity7, param, n_jobs = -1) # Define BayesOpt\n",
        "stp_7.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_stp_7 = stp_7.getResult()[0]\n",
        "params_stp_7['max_depth'] = int(params_stp_7['max_depth'])\n",
        "params_stp_7['min_child_weight'] = int(params_stp_7['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_stp_train7 = xgb.DMatrix(X_train7, y_train7)\n",
        "dX_stp_test7 = xgb.DMatrix(X_test7, y_test7)\n",
        "model_stp_7 = xgb.train(params_stp_7, dX_stp_train7)\n",
        "pred_stp_7 = model_stp_7.predict(dX_stp_test7)\n",
        "\n",
        "rmse_stp_7 = np.sqrt(mean_squared_error(pred_stp_7, y_test7))\n",
        "rmse_stp_7"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.76308289 7.79918792 8.         0.98911145 8.         0.98019056]. \t  -1.9078690836840042 \t -1.9078690836840042\n",
            "init   \t [ 5.3849587   5.01120464 13.          0.74994125  5.          0.88192131]. \t  -1.9193284947185432 \t -1.9078690836840042\n",
            "init   \t [ 3.30839249  3.9294231  12.          0.6440728  13.          0.41137564]. \t  -1.9707847574302377 \t -1.9078690836840042\n",
            "init   \t [9.29528191 2.6258377  5.         0.80027446 1.         0.86616513]. \t  -1.955231925484334 \t -1.9078690836840042\n",
            "init   \t [ 1.74052764  7.90763512 14.          0.7244129   4.          0.77536887]. \t  -1.94667647934123 \t -1.9078690836840042\n",
            "1      \t [3.70351083 4.59092978 6.         0.70937861 6.         0.814213  ]. \t  -1.9596547112058986 \t -1.9078690836840042\n",
            "2      \t [ 0.03374059  5.72098042  5.          0.61235924 18.          0.8711559 ]. \t  -1.9589402156911349 \t -1.9078690836840042\n",
            "3      \t [ 9.12127254  9.64651695 14.          0.53624962  1.          0.38247449]. \t  -1.983787343748326 \t -1.9078690836840042\n",
            "4      \t [ 8.15448719  3.4710932   7.          0.61547067 18.          0.53291628]. \t  -1.9768483459531683 \t -1.9078690836840042\n",
            "5      \t [ 9.19979425  8.97441441 13.          0.88387282 19.          0.6456674 ]. \t  -1.9660056122558085 \t -1.9078690836840042\n",
            "6      \t [9.43260743 8.53539628 9.         0.68880888 9.         0.5954756 ]. \t  -1.9783761196744543 \t -1.9078690836840042\n",
            "7      \t [ 7.73252727  0.7079457   5.          0.93170437 11.          0.47373855]. \t  -1.9666404523918488 \t -1.9078690836840042\n",
            "8      \t [ 0.04434682  1.14105742 10.          0.89864231  2.          0.82027014]. \t  -1.9354139372919419 \t -1.9078690836840042\n",
            "9      \t [ 1.29932493  8.0055142  14.          0.51325501 19.          0.83654101]. \t  -1.9515012533789764 \t -1.9078690836840042\n",
            "10     \t [ 5.06178038  6.72402797 12.          0.58648112 18.          0.49314138]. \t  -1.9788212859745122 \t -1.9078690836840042\n",
            "11     \t [ 5.67407045  9.94967311  6.          0.75213901 15.          0.78517579]. \t  -1.9446966121536442 \t -1.9078690836840042\n",
            "12     \t [ 0.49386103  1.76967458 14.          0.78110984 14.          0.99552961]. \t  -1.9190394688258876 \t -1.9078690836840042\n",
            "13     \t [ 9.5768206   0.06813076 11.          0.92793413  2.          0.73377388]. \t  -1.9726032342268696 \t -1.9078690836840042\n",
            "14     \t [9.78412355 9.15542954 6.         0.58671092 3.         0.40397987]. \t  -1.9765683710829305 \t -1.9078690836840042\n",
            "15     \t [ 2.28086985  0.05850709  5.          0.90922938 11.          0.53631831]. \t  -1.9697832893263425 \t -1.9078690836840042\n",
            "16     \t [ 0.54101623  0.39016798 11.          0.92560048 17.          0.838304  ]. \t  -1.9356396024692237 \t -1.9078690836840042\n",
            "17     \t [ 9.45137179  0.74358028 14.          0.78939199  9.          0.47186777]. \t  -1.9657747290122043 \t -1.9078690836840042\n",
            "18     \t [ 8.09171007  1.0036208  14.          0.56241102 16.          0.73442263]. \t  -1.9727832151120288 \t -1.9078690836840042\n",
            "19     \t [0.85940103 9.23813345 6.         0.78680458 2.         0.96797128]. \t  -1.9209823879194103 \t -1.9078690836840042\n",
            "20     \t [ 4.89919929  6.40860935  6.          0.86581969 12.          0.5519614 ]. \t  -1.9690945297846678 \t -1.9078690836840042\n",
            "21     \t [ 0.40555572  3.42473685 10.          0.85268567 19.          0.90758547]. \t  -1.9118244572843097 \t -1.9078690836840042\n",
            "22     \t [ 0.52577252  7.56995284 10.          0.50759159  1.          0.78199447]. \t  -1.9629614427466868 \t -1.9078690836840042\n",
            "23     \t [ 0.63748246  0.89960808 13.          0.88488698  8.          0.28008484]. \t  -2.0576190819244866 \t -1.9078690836840042\n",
            "24     \t [ 6.40169414  5.2904597  12.          0.63223036  7.          0.23912528]. \t  -2.1211369056358635 \t -1.9078690836840042\n",
            "25     \t [ 6.77920456  9.70681397 10.          0.57464446  8.          0.44257905]. \t  -1.9643382948642434 \t -1.9078690836840042\n",
            "26     \t [8.97724042 2.45771723 7.         0.8512854  6.         0.30764744]. \t  -2.05540425148707 \t -1.9078690836840042\n",
            "27     \t [ 2.94497588  1.06436103  6.          0.79530993 17.          0.30986228]. \t  -2.055850561898443 \t -1.9078690836840042\n",
            "28     \t [ 4.91141977  1.12730433 12.          0.87585679  5.          0.3620304 ]. \t  -2.060500437247096 \t -1.9078690836840042\n",
            "29     \t [ 1.94632061  9.43492022 13.          0.88086778  9.          0.9176475 ]. \t  -1.9129854224948086 \t -1.9078690836840042\n",
            "30     \t [ 4.74313986  7.31454387  5.          0.5        20.          0.1       ]. \t  -2.122258942325229 \t -1.9078690836840042\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "61351.93418054509"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xk0IPTSTbIl3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce0c2d96-37f1-463b-eab0-87dd4f9ea467"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'stp' Acquisition Function run number = 8 \n",
        "\n",
        "np.random.seed(run_num_8)\n",
        "surrogate_stp_8 = tStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train8, X_test8, y_train8, y_test8 = train_test_split(X, y, test_size=test_perc, random_state=run_num_8)\n",
        "\n",
        "def f_syn_polarity8(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_8, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train8, y=y_train8).mean())\n",
        "    return operator * score\n",
        "\n",
        "stp_8 = GPGO(surrogate_stp_8, Acquisition_new(util_stp), f_syn_polarity8, param, n_jobs = -1) # Define BayesOpt\n",
        "stp_8.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_stp_8 = stp_8.getResult()[0]\n",
        "params_stp_8['max_depth'] = int(params_stp_8['max_depth'])\n",
        "params_stp_8['min_child_weight'] = int(params_stp_8['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_stp_train8 = xgb.DMatrix(X_train8, y_train8)\n",
        "dX_stp_test8 = xgb.DMatrix(X_test8, y_test8)\n",
        "model_stp_8 = xgb.train(params_stp_8, dX_stp_train8)\n",
        "pred_stp_8 = model_stp_8.predict(dX_stp_test8)\n",
        "\n",
        "rmse_stp_8 = np.sqrt(mean_squared_error(pred_stp_8, y_test8))\n",
        "rmse_stp_8"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 8.73429403  9.68540663 10.          0.68875849  9.          0.48011572]. \t  -1.9120326417702995 \t -1.8978279741265411\n",
            "init   \t [ 6.12033333  7.66062926  8.          0.76133734 13.          0.93379456]. \t  -1.8978279741265411 \t -1.8978279741265411\n",
            "init   \t [ 1.46524679  7.01527914  7.          0.90913299 10.          0.36016753]. \t  -1.9465178144863287 \t -1.8978279741265411\n",
            "init   \t [ 9.73855241  3.33774046 14.          0.53290419  7.          0.7088681 ]. \t  -1.921087044254333 \t -1.8978279741265411\n",
            "init   \t [ 3.00618018  1.82702795 11.          0.75681389 14.          0.98627449]. \t  -1.8997134238136284 \t -1.8978279741265411\n",
            "1      \t [4.42022545 5.48487111 9.         0.97165909 3.         0.63617522]. \t  \u001b[92m-1.8908646806075349\u001b[0m \t -1.8908646806075349\n",
            "2      \t [ 9.3432851   3.80536023 13.          0.82203895 19.          0.99569116]. \t  -1.89272590205946 \t -1.8908646806075349\n",
            "3      \t [ 2.52429836  9.02824683 14.          0.59641093 17.          0.61934886]. \t  -1.914756151644013 \t -1.8908646806075349\n",
            "4      \t [ 9.53473907  5.08424998 11.          0.50652828 18.          0.67121466]. \t  -1.9209643461279284 \t -1.8908646806075349\n",
            "5      \t [6.89072012 1.88822945 5.         0.9252956  8.         0.40577637]. \t  -1.8995533704461902 \t -1.8908646806075349\n",
            "6      \t [ 2.42575645  9.87357367  5.          0.61143882 19.          0.11833201]. \t  -2.0343401141761657 \t -1.8908646806075349\n",
            "7      \t [ 0.9931658   1.40870497 14.          0.50614818  6.          0.71944448]. \t  -1.9248486024276654 \t -1.8908646806075349\n",
            "8      \t [ 9.09148899  1.42093493  5.          0.88801001 17.          0.53231573]. \t  -1.8993681151521848 \t -1.8908646806075349\n",
            "9      \t [9.69554908 3.70013633 5.         0.72727157 1.         0.49530336]. \t  -1.9105998731253515 \t -1.8908646806075349\n",
            "10     \t [ 2.66410938  9.83743919 13.          0.58899688  8.          0.29675269]. \t  -1.9726396266176844 \t -1.8908646806075349\n",
            "11     \t [1.66316873 0.47469495 7.         0.60820298 1.         0.50689458]. \t  -1.9104457631445986 \t -1.8908646806075349\n",
            "12     \t [ 1.2277143   1.05411485  5.          0.50198686 13.          0.89258454]. \t  -1.9265050432816568 \t -1.8908646806075349\n",
            "13     \t [5.63420638 9.7026496  5.         0.64869539 8.         0.22475566]. \t  -2.041476906060752 \t -1.8908646806075349\n",
            "14     \t [ 0.63194856  9.08760061 12.          0.51277257  1.          0.85579144]. \t  -1.925679764332541 \t -1.8908646806075349\n",
            "15     \t [ 8.35277365  5.17929354 14.          0.67305838  1.          0.70101595]. \t  -1.9117870268337829 \t -1.8908646806075349\n",
            "16     \t [ 8.62413803  1.63568526 10.          0.78670071 12.          0.5099252 ]. \t  -1.9026291638149861 \t -1.8908646806075349\n",
            "17     \t [ 3.5121134   5.24088616  9.          0.68973249 19.          0.78159968]. \t  -1.906037076413386 \t -1.8908646806075349\n",
            "18     \t [5.83203328 9.4812958  5.         0.60479193 1.         0.24995758]. \t  -2.03809958053387 \t -1.8908646806075349\n",
            "19     \t [ 4.57796249  0.39278383  9.          0.9579464  12.          0.65503241]. \t  -1.8926058579251066 \t -1.8908646806075349\n",
            "20     \t [ 5.53354207  3.63748442 10.          0.843546    5.          0.10685433]. \t  -2.0315680215452563 \t -1.8908646806075349\n",
            "21     \t [10.          0.89704739 10.61090306  0.5         1.          0.1       ]. \t  -2.0437261825168154 \t -1.8908646806075349\n",
            "22     \t [1.88906258 2.399107   9.         0.73879582 6.         0.6970214 ]. \t  -1.9100577809209855 \t -1.8908646806075349\n",
            "23     \t [ 5.88952232  5.36083784 12.          0.76230976 10.          0.77008819]. \t  -1.9013743621574597 \t -1.8908646806075349\n",
            "24     \t [1.43710423e-02 4.76269342e-02 7.00000000e+00 5.26967851e-01\n",
            " 1.90000000e+01 9.00776830e-01]. \t  -1.9181964373339357 \t -1.8908646806075349\n",
            "25     \t [ 0.54777791  3.09782342 14.          0.64396842 19.          0.55122597]. \t  -1.9135040332946247 \t -1.8908646806075349\n",
            "26     \t [ 9.52773829  9.74841019  7.          0.53250812 18.          0.59000663]. \t  -1.9174523318961256 \t -1.8908646806075349\n",
            "27     \t [ 3.69662439  9.66714727 14.          0.96143213  3.          0.46448042]. \t  -1.9007419041636133 \t -1.8908646806075349\n",
            "28     \t [0.10033663 9.40183052 7.         0.87595922 4.         0.70368524]. \t  -1.8982324001116126 \t -1.8908646806075349\n",
            "29     \t [ 8.95175191  0.44446962 10.          0.69407016 15.          0.57756567]. \t  -1.9082842096811248 \t -1.8908646806075349\n",
            "30     \t [ 0.06827449  3.46801888 14.          0.74856114  1.          0.47083066]. \t  -1.9136050520547951 \t -1.8908646806075349\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60822.98185938519"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UroEj_RbLSb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cdd44e9b-1068-480a-9ac8-2a3698d99623"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'stp' Acquisition Function run number = 9 \n",
        "\n",
        "np.random.seed(run_num_9)\n",
        "surrogate_stp_9 = tStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train9, X_test9, y_train9, y_test9 = train_test_split(X, y, test_size=test_perc, random_state=run_num_9)\n",
        "\n",
        "def f_syn_polarity9(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_9, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train9, y=y_train9).mean())\n",
        "    return operator * score\n",
        "\n",
        "stp_9 = GPGO(surrogate_stp_9, Acquisition_new(util_stp), f_syn_polarity9, param, n_jobs = -1) # Define BayesOpt\n",
        "stp_9.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_stp_9 = stp_9.getResult()[0]\n",
        "params_stp_9['max_depth'] = int(params_stp_9['max_depth'])\n",
        "params_stp_9['min_child_weight'] = int(params_stp_9['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_stp_train9 = xgb.DMatrix(X_train9, y_train9)\n",
        "dX_stp_test9 = xgb.DMatrix(X_test9, y_test9)\n",
        "model_stp_9 = xgb.train(params_stp_9, dX_stp_train9)\n",
        "pred_stp_9 = model_stp_9.predict(dX_stp_test9)\n",
        "\n",
        "rmse_stp_9 = np.sqrt(mean_squared_error(pred_stp_9, y_test9))\n",
        "rmse_stp_9"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 0.10374154  5.01874592 11.          0.50377155  2.          0.29670281]. \t  -2.165522561386585 \t -1.963183361033061\n",
            "init   \t [ 4.18508181  2.48101168 13.          0.69794293  2.          0.25009871]. \t  -2.1585464315559983 \t -1.963183361033061\n",
            "init   \t [ 8.78559086  9.50964032 13.          0.98395204 11.          0.90820641]. \t  -1.963183361033061 \t -1.963183361033061\n",
            "init   \t [ 6.66898973  5.47837783  6.          0.97165345 12.          0.72499481]. \t  -2.0332026844846673 \t -1.963183361033061\n",
            "init   \t [ 8.24870465  4.65668475 13.          0.68760467  9.          0.98502332]. \t  -1.990093015638481 \t -1.963183361033061\n",
            "1      \t [6.73714319 2.39608167 5.         0.58130302 3.         0.163077  ]. \t  -2.141000706961993 \t -1.963183361033061\n",
            "2      \t [ 1.89773665  4.24398106 11.          0.60135502  9.          0.22312501]. \t  -2.1420691289307263 \t -1.963183361033061\n",
            "3      \t [ 3.60566534  9.79805332 11.          0.62032576 16.          0.3578496 ]. \t  -2.1523125446424403 \t -1.963183361033061\n",
            "4      \t [ 4.86601509  0.61279594  8.          0.72162785 18.          0.68911833]. \t  -2.0367494366398486 \t -1.963183361033061\n",
            "5      \t [9.39353565 9.93046622 5.         0.57188784 4.         0.83501032]. \t  -2.0407674386690404 \t -1.963183361033061\n",
            "6      \t [1.13863488 5.86180669 5.         0.9953054  3.         0.88639082]. \t  -1.9733707814909445 \t -1.963183361033061\n",
            "7      \t [4.58728604 0.17361597 5.         0.87465126 8.         0.75024655]. \t  -2.0191440000719005 \t -1.963183361033061\n",
            "8      \t [ 7.07313313  8.94084339  5.          0.99439529 19.          0.33798274]. \t  -2.1423980804760943 \t -1.963183361033061\n",
            "9      \t [ 9.5805444   7.83819543 12.          0.79715932  3.          0.61699162]. \t  -2.041877784583074 \t -1.963183361033061\n",
            "10     \t [ 9.89680111  6.16985579 13.          0.58428363 17.          0.77251451]. \t  -2.030413459145069 \t -1.963183361033061\n",
            "11     \t [ 8.41810681  0.28363289 14.          0.70665052 14.          0.98883394]. \t  -1.9880347834610952 \t -1.963183361033061\n",
            "12     \t [ 1.960699    0.55073612 14.          0.55131138 15.          0.12137879]. \t  -2.1431732006298994 \t -1.963183361033061\n",
            "13     \t [ 1.98261944  9.85597834 14.          0.56925415  7.          0.93739664]. \t  -1.9938845051252645 \t -1.963183361033061\n",
            "14     \t [ 0.80844375  8.9121894   5.          0.56134557 18.          0.84901701]. \t  -2.0399284199132373 \t -1.963183361033061\n",
            "15     \t [ 1.35070076  4.39734883 12.          0.79332071 17.          0.52113501]. \t  -2.0357272044337495 \t -1.963183361033061\n",
            "16     \t [2.44116814 2.00097769 8.         0.88240959 5.         0.83295612]. \t  -2.0108373590033417 \t -1.963183361033061\n",
            "17     \t [ 4.42438935  7.48165688 13.          0.98976248  9.          0.66129639]. \t  -2.0172969759871995 \t -1.963183361033061\n",
            "18     \t [ 9.9650824   0.70561372  5.          0.81536816 14.          0.22588839]. \t  -2.1421772905723664 \t -1.963183361033061\n",
            "19     \t [1.13714057 9.27625406 8.         0.71061991 7.         0.91130482]. \t  -1.987672837593535 \t -1.963183361033061\n",
            "20     \t [ 4.50567014  9.37436132 10.          0.7400357   1.          0.87968259]. \t  -1.9912788022336065 \t -1.963183361033061\n",
            "21     \t [0.97579948 1.44644999 7.         0.50191057 8.         0.85357213]. \t  -2.0483870635269774 \t -1.963183361033061\n",
            "22     \t [ 1.57716579  4.21950462  6.          0.5445041  15.          0.49949298]. \t  -2.073347178960136 \t -1.963183361033061\n",
            "23     \t [9.09546853 4.87309943 8.         0.64897007 5.         0.81947612]. \t  -2.0269043866011898 \t -1.963183361033061\n",
            "24     \t [9.0223237  0.52522072 9.         0.65667592 8.         0.49977193]. \t  -2.0798861610447408 \t -1.963183361033061\n",
            "25     \t [ 5.8438709   6.22193244 10.          0.62194189 19.          0.74449288]. \t  -2.045170702064853 \t -1.963183361033061\n",
            "26     \t [ 4.59866707  1.51696625  9.          0.86264971 12.          0.40546822]. \t  -2.073851233326944 \t -1.963183361033061\n",
            "27     \t [ 9.1527712   3.38393353  5.          0.71966892 19.          0.77992325]. \t  -2.0298339861539416 \t -1.963183361033061\n",
            "28     \t [ 7.879138    1.55050577 12.          0.69502042 19.          0.2853965 ]. \t  -2.1540973749507697 \t -1.963183361033061\n",
            "29     \t [ 6.42812692  9.78921072  5.          0.51106874 14.09488875  1.        ]. \t  -2.0082822192841894 \t -1.963183361033061\n",
            "30     \t [4.75349257 0.80284538 6.         0.96119826 4.         0.35448796]. \t  -2.1431523981033527 \t -1.963183361033061\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60590.73520973802"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VgaJOoJbOIE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "651182a0-18b9-4771-f0ae-40e030c66cde"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'stp' Acquisition Function run number = 10 \n",
        "\n",
        "np.random.seed(run_num_10)\n",
        "surrogate_stp_10 = tStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train10, X_test10, y_train10, y_test10 = train_test_split(X, y, test_size=test_perc, random_state=run_num_10)\n",
        "\n",
        "def f_syn_polarity10(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_10, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train10, y=y_train10).mean())\n",
        "    return operator * score\n",
        "\n",
        "stp_10 = GPGO(surrogate_stp_10, Acquisition_new(util_stp), f_syn_polarity10, param, n_jobs = -1) # Define BayesOpt\n",
        "stp_10.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_stp_10 = stp_10.getResult()[0]\n",
        "params_stp_10['max_depth'] = int(params_stp_10['max_depth'])\n",
        "params_stp_10['min_child_weight'] = int(params_stp_10['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_stp_train10 = xgb.DMatrix(X_train10, y_train10)\n",
        "dX_stp_test10 = xgb.DMatrix(X_test10, y_test10)\n",
        "model_stp_10 = xgb.train(params_stp_10, dX_stp_train10)\n",
        "pred_stp_10 = model_stp_10.predict(dX_stp_test10)\n",
        "\n",
        "rmse_stp_10 = np.sqrt(mean_squared_error(pred_stp_10, y_test10))\n",
        "rmse_stp_10"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 7.71320643  0.20751949  5.          0.72150747 17.          0.12265456]. \t  -2.120578178283629 \t -1.940587000655573\n",
            "init   \t [ 7.0920801   2.65566127 13.          0.57518893 17.          0.83494165]. \t  -1.9492101131384572 \t -1.940587000655573\n",
            "init   \t [ 3.36071584  8.90816531  6.          0.86087766 15.          0.75469196]. \t  -1.940587000655573 \t -1.940587000655573\n",
            "init   \t [ 5.40880931  1.31458152  8.          0.57108502 14.          0.62551123]. \t  -1.9531076777438756 \t -1.940587000655573\n",
            "init   \t [1.82631436 8.26082248 6.         0.80888349 5.         0.15900694]. \t  -2.117914211014308 \t -1.940587000655573\n",
            "1      \t [8.31989768 3.09778055 7.         0.64798085 3.         0.98471878]. \t  -1.9418208809914852 \t -1.940587000655573\n",
            "2      \t [ 1.51483713  6.46720195 14.          0.87676044  8.          0.10934204]. \t  -2.1137891529220116 \t -1.940587000655573\n",
            "3      \t [ 1.40638864  6.36994003 14.          0.94554832 18.          0.42624162]. \t  -1.9877536819272958 \t -1.940587000655573\n",
            "4      \t [ 6.23532773  8.31439809 13.          0.65134225  1.          0.75774237]. \t  -1.944930422519724 \t -1.940587000655573\n",
            "5      \t [ 9.32103763  8.04997374 14.          0.76165598 11.          0.58576369]. \t  -1.94715310296014 \t -1.940587000655573\n",
            "6      \t [ 2.70513667  1.83577987 12.          0.56122064  1.          0.15848231]. \t  -2.1245795979640434 \t -1.940587000655573\n",
            "7      \t [ 9.16520307  0.72602801 12.          0.91999471  9.          0.54336218]. \t  -1.942906357007064 \t -1.940587000655573\n",
            "8      \t [ 0.13114685  2.69967978  5.          0.89490476 19.          0.55706236]. \t  -1.9467516181423725 \t -1.940587000655573\n",
            "9      \t [ 9.57603828  8.81375557  5.          0.56495862 19.          0.45710368]. \t  -1.9933028759284936 \t -1.940587000655573\n",
            "10     \t [ 9.82501514  7.31311253  5.          0.75029053 12.          0.39735105]. \t  -1.9923385444831923 \t -1.940587000655573\n",
            "11     \t [0.40833691 2.05040396 5.         0.83675528 2.         0.93839002]. \t  \u001b[92m-1.9377831200331728\u001b[0m \t -1.9377831200331728\n",
            "12     \t [ 0.06083858  0.83347778 13.          0.60208867 14.          0.81102115]. \t  \u001b[92m-1.937448474670023\u001b[0m \t -1.937448474670023\n",
            "13     \t [ 3.87733745  1.80097513 10.          0.87276131  7.          0.20829771]. \t  -2.113777158554646 \t -1.937448474670023\n",
            "14     \t [ 0.42759101  9.94526216 13.          0.83538077 13.          0.34479326]. \t  -2.0441178672932465 \t -1.937448474670023\n",
            "15     \t [ 5.01422237  2.7485076   5.          0.70272741 18.          0.63900816]. \t  -1.9437945365334919 \t -1.937448474670023\n",
            "16     \t [ 0.15165059  8.17402613 14.          0.57436172  4.          0.83812492]. \t  -1.9542257478285112 \t -1.937448474670023\n",
            "17     \t [ 4.07487199  1.00167604 14.          0.71526642  9.          0.78428439]. \t  -1.9438934382587916 \t -1.937448474670023\n",
            "18     \t [7.60796195 7.8170794  5.         0.85145938 8.         0.57832563]. \t  -1.9457808537343264 \t -1.937448474670023\n",
            "19     \t [ 9.09859843  3.19427966 13.          0.59321479  2.          0.92093381]. \t  -1.9488772035328452 \t -1.937448474670023\n",
            "20     \t [6.46081033 9.19989249 5.         0.99579878 1.         0.40331905]. \t  -1.9863703355681792 \t -1.937448474670023\n",
            "21     \t [ 5.43710564  7.15852561  7.          0.68540235 15.          0.95785607]. \t  -1.9418787378606726 \t -1.937448474670023\n",
            "22     \t [ 9.47787147  0.28850754  5.          0.93373452 11.          0.64656012]. \t  -1.9488858282487946 \t -1.937448474670023\n",
            "23     \t [ 4.46663911  9.72978769 11.          0.89200199 18.          0.28748604]. \t  -2.0440436052138997 \t -1.937448474670023\n",
            "24     \t [0.1599249  0.39741746 6.         0.60317609 6.         0.15585329]. \t  -2.1188800417603253 \t -1.937448474670023\n",
            "25     \t [ 1.03344423  5.00833607  6.          0.61596167 11.          0.46437664]. \t  -1.9872990349067616 \t -1.937448474670023\n",
            "26     \t [7.87976227 8.52619142 9.         0.83336259 3.         0.37794579]. \t  -1.9927431277929764 \t -1.937448474670023\n",
            "27     \t [ 2.00203905  0.39549986 10.          0.62317733 19.          0.49551446]. \t  -1.9904775719925254 \t -1.937448474670023\n",
            "28     \t [ 8.96844948  7.57871569 12.          0.65088231 18.          0.90772934]. \t  \u001b[92m-1.9324436088888934\u001b[0m \t -1.9324436088888934\n",
            "29     \t [ 0.25978885  9.59245044  8.          0.6861086  11.          0.9425771 ]. \t  -1.937662940141402 \t -1.9324436088888934\n",
            "30     \t [8.33517528 6.12539597 6.         0.7706296  2.         0.87665637]. \t  -1.9455277296070375 \t -1.9324436088888934\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "61024.24492923078"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51z87uHWbRGr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7537f02a-0999-40ac-c4e1-642eeed818b8"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'stp' Acquisition Function run number = 11 \n",
        "\n",
        "np.random.seed(run_num_11)\n",
        "surrogate_stp_11 = tStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train11, X_test11, y_train11, y_test11 = train_test_split(X, y, test_size=test_perc, random_state=run_num_11)\n",
        "\n",
        "def f_syn_polarity11(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_11, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train11, y=y_train11).mean())\n",
        "    return operator * score\n",
        "\n",
        "stp_11 = GPGO(surrogate_stp_11, Acquisition_new(util_stp), f_syn_polarity11, param, n_jobs = -1) # Define BayesOpt\n",
        "stp_11.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_stp_11 = stp_11.getResult()[0]\n",
        "params_stp_11['max_depth'] = int(params_stp_11['max_depth'])\n",
        "params_stp_11['min_child_weight'] = int(params_stp_11['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_stp_train11 = xgb.DMatrix(X_train11, y_train11)\n",
        "dX_stp_test11 = xgb.DMatrix(X_test11, y_test11)\n",
        "model_stp_11 = xgb.train(params_stp_11, dX_stp_train11)\n",
        "pred_stp_11 = model_stp_11.predict(dX_stp_test11)\n",
        "\n",
        "rmse_stp_11 = np.sqrt(mean_squared_error(pred_stp_11, y_test11))\n",
        "rmse_stp_11"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 1.80269689  0.19475241  6.          0.59705781 13.          0.47818324]. \t  -1.9015016338784072 \t -1.8483088481664438\n",
            "init   \t [ 4.85427098  0.12780815  5.          0.91309068 14.          0.86571558]. \t  -1.8541246115708696 \t -1.8483088481664438\n",
            "init   \t [ 7.2996447   1.08736072 10.          0.92857712 18.          0.66910061]. \t  -1.8532385782615584 \t -1.8483088481664438\n",
            "init   \t [ 0.20483613  1.16737269  7.          0.57895615 16.          0.83644782]. \t  -1.8483088481664438 \t -1.8483088481664438\n",
            "init   \t [ 3.44624491  3.18798797 14.          0.54197657 15.          0.63958906]. \t  -1.8544028395211494 \t -1.8483088481664438\n",
            "1      \t [9.77136617 6.6548802  7.         0.51036649 9.         0.81011527]. \t  -1.857805309121489 \t -1.8483088481664438\n",
            "2      \t [0.5279662  8.15331655 5.         0.83127487 9.         0.53242685]. \t  -1.8583090737384367 \t -1.8483088481664438\n",
            "3      \t [8.62555756 1.5478147  8.         0.99964468 2.         0.74874718]. \t  -1.8519845859133308 \t -1.8483088481664438\n",
            "4      \t [ 0.90299561  9.42808632 14.          0.71344248  9.          0.5250902 ]. \t  -1.8560986061392328 \t -1.8483088481664438\n",
            "5      \t [ 0.07122179  2.9458437  13.          0.89742149  2.          0.63052749]. \t  -1.8559044305734542 \t -1.8483088481664438\n",
            "6      \t [ 8.80621297  1.41648139 14.          0.58742169  8.          0.82618778]. \t  -1.8573035206957946 \t -1.8483088481664438\n",
            "7      \t [ 8.68943806  9.29354072 13.          0.58241565  2.          0.90282292]. \t  \u001b[92m-1.8428237838756616\u001b[0m \t -1.8428237838756616\n",
            "8      \t [0.47065357 6.80536856 5.         0.94482943 1.         0.93677618]. \t  \u001b[92m-1.8404628329061805\u001b[0m \t -1.8404628329061805\n",
            "9      \t [ 9.7975974   8.60326626  5.          0.83535605 19.          0.47008667]. \t  -1.8910632154003886 \t -1.8404628329061805\n",
            "10     \t [ 0.731097    9.22001741 10.          0.740611   19.          0.69778336]. \t  -1.8529617219679229 \t -1.8404628329061805\n",
            "11     \t [ 8.61765552  0.94349031 10.          0.85641829  4.          0.91576259]. \t  \u001b[92m-1.8381433785201957\u001b[0m \t -1.8381433785201957\n",
            "12     \t [9.1689709  8.67069462 6.         0.8799734  8.         0.25184132]. \t  -1.9989977691412277 \t -1.8381433785201957\n",
            "13     \t [ 8.32040378  7.9243385  14.          0.97104566 12.          0.2674345 ]. \t  -2.0037940735544373 \t -1.8381433785201957\n",
            "14     \t [ 8.40730244  5.3235921  14.          0.57824885  9.          0.96689527]. \t  -1.8413325855281535 \t -1.8381433785201957\n",
            "15     \t [ 6.43479335  7.34424748 13.          0.50651226 19.          0.72120005]. \t  -1.8528022514083715 \t -1.8381433785201957\n",
            "16     \t [ 1.62679665  9.41000757 13.          0.73103911  2.          0.19462364]. \t  -2.0353042010418547 \t -1.8381433785201957\n",
            "17     \t [7.21149356 9.11091404 7.         0.99215908 1.         0.48569583]. \t  -1.9021458924879262 \t -1.8381433785201957\n",
            "18     \t [ 6.19006075  3.41925871 11.          0.95286331  6.          0.39133224]. \t  -1.9088899501060776 \t -1.8381433785201957\n",
            "19     \t [0.77256475 1.22732493 7.         0.97692145 7.         0.9071396 ]. \t  \u001b[92m-1.834153229976279\u001b[0m \t -1.834153229976279\n",
            "20     \t [ 7.57663538  0.21163728  6.          0.88846447 14.          0.7520692 ]. \t  -1.855069280334827 \t -1.834153229976279\n",
            "21     \t [ 4.50397896  5.47611458  7.          0.69081282 14.          0.56035386]. \t  -1.8599000847840537 \t -1.834153229976279\n",
            "22     \t [ 3.18349223  8.74823637 11.          0.77393568 13.          0.73768421]. \t  -1.854805356379711 \t -1.834153229976279\n",
            "23     \t [8.50800557 6.99487065 5.         0.66195901 2.         0.63696231]. \t  -1.8506008705116712 \t -1.834153229976279\n",
            "24     \t [9.27619589 0.78753966 6.         0.96256618 8.         0.7409797 ]. \t  -1.8506140373865207 \t -1.834153229976279\n",
            "25     \t [ 0.19423991  3.67893916 12.          0.71860106  9.          0.48088001]. \t  -1.896430250744371 \t -1.834153229976279\n",
            "26     \t [2.75419674 8.71692748 8.         0.92739161 1.         0.40026048]. \t  -1.9115417838103717 \t -1.834153229976279\n",
            "27     \t [0.96956571 0.16256086 8.         0.8766109  1.         0.88289087]. \t  -1.8378612108365218 \t -1.834153229976279\n",
            "28     \t [ 5.59910258  1.26423688 14.          0.97318774  1.          0.54144173]. \t  -1.8599961869387194 \t -1.834153229976279\n",
            "29     \t [ 7.36190993  8.79630973  5.          0.82949201 12.          0.64478292]. \t  -1.8524055616314634 \t -1.834153229976279\n",
            "30     \t [ 1.1917216   2.1425571   9.          0.8043315  13.          0.32406453]. \t  -2.001456417055954 \t -1.834153229976279\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "61781.81920935658"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8jZUeoWbTvn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "868c4a8c-2888-4931-e89e-af202b141ff1"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'stp' Acquisition Function run number = 12\n",
        "\n",
        "np.random.seed(run_num_12)\n",
        "surrogate_stp_12 = tStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train12, X_test12, y_train12, y_test12 = train_test_split(X, y, test_size=test_perc, random_state=run_num_12)\n",
        "\n",
        "def f_syn_polarity12(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_12, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train12, y=y_train12).mean())\n",
        "    return operator * score\n",
        "\n",
        "stp_12 = GPGO(surrogate_stp_12, Acquisition_new(util_stp), f_syn_polarity12, param, n_jobs = -1) # Define BayesOpt\n",
        "stp_12.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_stp_12 = stp_12.getResult()[0]\n",
        "params_stp_12['max_depth'] = int(params_stp_12['max_depth'])\n",
        "params_stp_12['min_child_weight'] = int(params_stp_12['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_stp_train12 = xgb.DMatrix(X_train12, y_train12)\n",
        "dX_stp_test12 = xgb.DMatrix(X_test12, y_test12)\n",
        "model_stp_12 = xgb.train(params_stp_12, dX_stp_train12)\n",
        "pred_stp_12 = model_stp_12.predict(dX_stp_test12)\n",
        "\n",
        "rmse_stp_12 = np.sqrt(mean_squared_error(pred_stp_12, y_test12))\n",
        "rmse_stp_12"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [1.54162842 7.40049697 6.         0.54321714 4.         0.11311747]. \t  -2.1334526770789597 \t -2.024051333725814\n",
            "init   \t [ 9.18747008  9.00714854 14.          0.97847467 11.          0.35544552]. \t  -2.1193628264859967 \t -2.024051333725814\n",
            "init   \t [ 6.06083184  9.44225136 14.          0.95626942  5.          0.56910342]. \t  -2.0441668248397766 \t -2.024051333725814\n",
            "init   \t [ 5.52037633  4.85377414  7.          0.97886436 17.          0.78810441]. \t  -2.024051333725814 \t -2.024051333725814\n",
            "init   \t [ 0.20809798  1.35210178  5.          0.65494879 16.          0.36062811]. \t  -2.1361168864432996 \t -2.024051333725814\n",
            "1      \t [7.9625576  2.91107495 9.         0.77382625 8.         0.70200131]. \t  \u001b[92m-2.014848171131292\u001b[0m \t -2.014848171131292\n",
            "2      \t [9.04256367 2.61736915 8.         0.66026854 8.         0.14510453]. \t  -2.131446620940571 \t -2.014848171131292\n",
            "3      \t [ 0.19302366  0.02327751 14.          0.56718888  5.          0.47502069]. \t  -2.131782321448441 \t -2.014848171131292\n",
            "4      \t [ 0.24796255  2.18203944 14.          0.56497025 17.          0.63132662]. \t  -2.0348905948964817 \t -2.014848171131292\n",
            "5      \t [9.4784156  9.00325816 7.         0.60328721 3.         0.24203563]. \t  -2.132806951723957 \t -2.014848171131292\n",
            "6      \t [ 6.12519689  9.03489206 14.          0.50242809 19.          0.36351298]. \t  -2.1454654454188167 \t -2.014848171131292\n",
            "7      \t [ 2.32173395  7.65213511 12.          0.64373085 13.          0.55474003]. \t  -2.065465443061359 \t -2.014848171131292\n",
            "8      \t [4.67891619 0.11615049 8.         0.7429617  1.         0.12932336]. \t  -2.127388392597063 \t -2.014848171131292\n",
            "9      \t [ 8.22133096  1.6482771  13.          0.89645528 16.          0.24914004]. \t  -2.1183349004532745 \t -2.014848171131292\n",
            "10     \t [1.93389684 1.14657818 7.         0.75614655 7.         0.68854615]. \t  -2.0187436356338964 \t -2.014848171131292\n",
            "11     \t [ 7.47997525  1.61646627 14.          0.55587442  3.          0.40322882]. \t  -2.1410961833108537 \t -2.014848171131292\n",
            "12     \t [ 1.77596586  6.40303748  5.          0.61072248 10.          0.62396354]. \t  -2.0854625626469856 \t -2.014848171131292\n",
            "13     \t [ 8.78320366  8.79913444  6.          0.99071139 11.          0.95942355]. \t  \u001b[92m-2.0082218142008337\u001b[0m \t -2.0082218142008337\n",
            "14     \t [ 0.2922362   7.26869686 11.          0.72426969 19.          0.65842849]. \t  -2.025740977628988 \t -2.0082218142008337\n",
            "15     \t [ 0.01587639  8.40095083 11.          0.97399373  7.          0.45731894]. \t  -2.1331602894842234 \t -2.0082218142008337\n",
            "16     \t [ 8.33925252  9.93812036  6.          0.82854794 19.          0.41239927]. \t  -2.1251659590112206 \t -2.0082218142008337\n",
            "17     \t [ 0.96920037  6.62909386 14.          0.51410819  2.          0.40605393]. \t  -2.147011199293055 \t -2.0082218142008337\n",
            "18     \t [3.37218761 1.70646487 6.         0.91511592 7.         0.29782176]. \t  -2.1181977257134084 \t -2.0082218142008337\n",
            "19     \t [ 9.56103036  2.69189352  5.          0.51874789 13.          0.83592686]. \t  -2.0458840126261664 \t -2.0082218142008337\n",
            "20     \t [ 3.98144058  1.51634117 13.          0.74704606 10.          0.82620713]. \t  -2.0200021362846314 \t -2.0082218142008337\n",
            "21     \t [ 5.85814474  5.85241394 10.          0.73962752  2.          0.14060026]. \t  -2.1300669532611645 \t -2.0082218142008337\n",
            "22     \t [ 7.82284706  5.68501929 11.          0.60127334 18.          0.21365323]. \t  -2.135292836875354 \t -2.0082218142008337\n",
            "23     \t [8.08722347 4.03121272 5.10490653 0.86452494 1.96474159 0.35174434]. \t  -2.1288688387485917 \t -2.0082218142008337\n",
            "24     \t [ 3.58874616  9.89133335  5.          0.63118978 16.          0.10056118]. \t  -2.1331309724713847 \t -2.0082218142008337\n",
            "25     \t [ 4.81161298  0.45782675  8.          0.89123573 13.          0.47720533]. \t  -2.1244782799004414 \t -2.0082218142008337\n",
            "26     \t [ 0.43684061  3.55859976  9.          0.98657827 12.          0.37831286]. \t  -2.1240746036064757 \t -2.0082218142008337\n",
            "27     \t [10.          1.31905156  5.22925509  0.5        20.          1.        ]. \t  -2.0112193026709093 \t -2.0082218142008337\n",
            "28     \t [ 1.32332772  2.89632575  9.          0.78031968 18.          0.20160474]. \t  -2.1253367968730883 \t -2.0082218142008337\n",
            "29     \t [ 8.08515539  2.89814129 14.          0.83662502  8.          0.83132625]. \t  -2.0167162195322703 \t -2.0082218142008337\n",
            "30     \t [ 0.         10.          6.08203033  0.5        20.          1.        ]. \t  -2.0113285784990116 \t -2.0082218142008337\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "62601.861330284526"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "snTrqE2RbWbe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c10684c0-915f-4f9d-e02d-7047dbb914fb"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'stp' Acquisition Function run number = 13 \n",
        "\n",
        "np.random.seed(run_num_13)\n",
        "surrogate_stp_13 = tStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train13, X_test13, y_train13, y_test13 = train_test_split(X, y, test_size=test_perc, random_state=run_num_13)\n",
        "\n",
        "def f_syn_polarity13(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_13, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train13, y=y_train13).mean())\n",
        "    return operator * score\n",
        "\n",
        "stp_13 = GPGO(surrogate_stp_13, Acquisition_new(util_stp), f_syn_polarity13, param, n_jobs = -1) # Define BayesOpt\n",
        "stp_13.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_stp_13 = stp_13.getResult()[0]\n",
        "params_stp_13['max_depth'] = int(params_stp_13['max_depth'])\n",
        "params_stp_13['min_child_weight'] = int(params_stp_13['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_stp_train13 = xgb.DMatrix(X_train13, y_train13)\n",
        "dX_stp_test13 = xgb.DMatrix(X_test13, y_test13)\n",
        "model_stp_13 = xgb.train(params_stp_13, dX_stp_train13)\n",
        "pred_stp_13 = model_stp_13.predict(dX_stp_test13)\n",
        "\n",
        "rmse_stp_13 = np.sqrt(mean_squared_error(pred_stp_13, y_test13))\n",
        "rmse_stp_13"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 7.77702411  2.3754122  11.          0.94649135 13.          0.7827256 ]. \t  -1.9378879688573776 \t -1.9378879688573776\n",
            "init   \t [ 7.51661514  6.07343344 11.          0.69402149 11.          0.13153287]. \t  -2.1281814260438034 \t -1.9378879688573776\n",
            "init   \t [ 2.98449471  0.58512492 10.          0.73579614 12.          0.33065195]. \t  -2.035439141741416 \t -1.9378879688573776\n",
            "init   \t [ 3.47581215  0.0941277  11.          0.86143432  8.          0.58454932]. \t  -1.9849077466482243 \t -1.9378879688573776\n",
            "init   \t [ 4.70137857  6.24432527 10.          0.8149145  18.          0.10784416]. \t  -2.129754084431454 \t -1.9378879688573776\n",
            "1      \t [1.51786663 9.25994479 9.         0.99792981 2.         0.61199673]. \t  -1.9877621530540666 \t -1.9378879688573776\n",
            "2      \t [ 8.98888343  8.3187307  12.          0.8674744   2.          0.79321204]. \t  -1.9449521808507277 \t -1.9378879688573776\n",
            "3      \t [ 2.15576965  9.94171254  5.          0.86819662 11.          0.93589556]. \t  -1.9399105675953052 \t -1.9378879688573776\n",
            "4      \t [9.56183168 0.58146885 8.         0.70816908 2.         0.91494753]. \t  -1.9528094176941089 \t -1.9378879688573776\n",
            "5      \t [ 0.06338612  1.25078283  6.          0.89144883 18.          0.43402566]. \t  -1.9917740920889266 \t -1.9378879688573776\n",
            "6      \t [0.75135379 4.33666257 5.         0.52792906 6.         0.30010782]. \t  -2.0324954030649804 \t -1.9378879688573776\n",
            "7      \t [ 9.14713824  0.07484253  6.          0.59644494 18.          0.23277246]. \t  -2.1303726688090716 \t -1.9378879688573776\n",
            "8      \t [ 1.31863824  8.38888205 14.          0.95097909  8.          0.13910651]. \t  -2.129026813194881 \t -1.9378879688573776\n",
            "9      \t [8.85934669 7.20257433 5.         0.6906114  7.         0.88958995]. \t  -1.944466760904125 \t -1.9378879688573776\n",
            "10     \t [ 8.39231109  0.32510731 14.          0.5902879  19.          0.62232309]. \t  -1.9957846881275045 \t -1.9378879688573776\n",
            "11     \t [ 8.95958255  8.68558585  7.          0.83565872 16.          0.19670804]. \t  -2.1314765258067823 \t -1.9378879688573776\n",
            "12     \t [ 3.29983413  0.94019517 14.          0.95545191  1.          0.90508732]. \t  -1.9479412475792763 \t -1.9378879688573776\n",
            "13     \t [ 0.21953253  3.99186433 14.          0.58641005 17.          0.5656381 ]. \t  -1.995917210822471 \t -1.9378879688573776\n",
            "14     \t [5.15880003 5.0230589  5.         0.52962923 1.         0.65578751]. \t  -1.948733977474307 \t -1.9378879688573776\n",
            "15     \t [ 2.05966685  9.6653479  14.          0.93596851 16.          0.35673509]. \t  -2.030444004492692 \t -1.9378879688573776\n",
            "16     \t [ 8.65567215  6.08076461  8.          0.91292835 18.          0.79314709]. \t  \u001b[92m-1.9348697805500472\u001b[0m \t -1.9348697805500472\n",
            "17     \t [ 5.99108127  5.7450543  10.          0.85866764  5.          0.5640336 ]. \t  -1.9935659090259619 \t -1.9348697805500472\n",
            "18     \t [ 7.14553626  1.23155981 14.          0.66739229 19.          0.6965719 ]. \t  -1.9425468217166184 \t -1.9348697805500472\n",
            "19     \t [ 7.77731865  0.46886504  6.          0.89516882 10.          0.67837617]. \t  -1.9516673783729204 \t -1.9348697805500472\n",
            "20     \t [ 0.23802705  6.98954431 10.          0.83200081 12.          0.11124925]. \t  -2.130873482600896 \t -1.9348697805500472\n",
            "21     \t [ 4.11631647  8.93314349 11.          0.93514193  8.          0.77537084]. \t  -1.938061178199682 \t -1.9348697805500472\n",
            "22     \t [ 8.44321164  0.812026   13.          0.88050192  6.          0.95533043]. \t  -1.9429231098027313 \t -1.9348697805500472\n",
            "23     \t [ 4.04714754  9.15175014  5.          0.902405   19.          0.56336372]. \t  -1.9856503849968654 \t -1.9348697805500472\n",
            "24     \t [4.85684542 3.85119664 7.         0.7765889  5.         0.58703964]. \t  -1.9950780408990418 \t -1.9348697805500472\n",
            "25     \t [0.14854021 0.01080693 8.         0.6500909  1.         0.71671091]. \t  -1.9506491459577888 \t -1.9348697805500472\n",
            "26     \t [ 5.15987851  6.3821279   5.          0.51471163 14.          0.79893666]. \t  -1.9461127233060829 \t -1.9348697805500472\n",
            "27     \t [ 1.0415082   5.66630881 14.          0.96867531  2.          0.71476094]. \t  -1.9464088436922584 \t -1.9348697805500472\n",
            "28     \t [ 7.69738953  8.55847352 14.          0.5678416  16.          0.88672119]. \t  -1.935436614212722 \t -1.9348697805500472\n",
            "29     \t [10.          0.         15.          1.         11.94513221  1.        ]. \t  \u001b[92m-1.926705033810108\u001b[0m \t -1.926705033810108\n",
            "30     \t [ 8.63153223  3.27586736 14.          0.55827322  1.          0.47866172]. \t  -1.9997698864695905 \t -1.926705033810108\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "58655.65989889668"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAuEsXYbtOnC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57c227f0-0400-4f28-cfbb-75dd7fe70c2b"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'stp' Acquisition Function run number = 14 \n",
        "\n",
        "np.random.seed(run_num_14)\n",
        "surrogate_stp_14 = tStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train14, X_test14, y_train14, y_test14 = train_test_split(X, y, test_size=test_perc, random_state=run_num_14)\n",
        "\n",
        "def f_syn_polarity14(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_14, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train14, y=y_train14).mean())\n",
        "    return operator * score\n",
        "\n",
        "stp_14 = GPGO(surrogate_stp_14, Acquisition_new(util_stp), f_syn_polarity14, param, n_jobs = -1) # Define BayesOpt\n",
        "stp_14.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_stp_14 = stp_14.getResult()[0]\n",
        "params_stp_14['max_depth'] = int(params_stp_14['max_depth'])\n",
        "params_stp_14['min_child_weight'] = int(params_stp_14['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_stp_train14 = xgb.DMatrix(X_train14, y_train14)\n",
        "dX_stp_test14 = xgb.DMatrix(X_test14, y_test14)\n",
        "model_stp_14 = xgb.train(params_stp_14, dX_stp_train14)\n",
        "pred_stp_14 = model_stp_14.predict(dX_stp_test14)\n",
        "\n",
        "rmse_stp_14 = np.sqrt(mean_squared_error(pred_stp_14, y_test14))\n",
        "rmse_stp_14"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 5.13943344  7.73165052 12.          0.6831412  11.          0.37876233]. \t  -2.0164943249949188 \t -1.9500125911148154\n",
            "init   \t [ 9.57603739  5.13116712 14.          0.76959997 12.          0.71328228]. \t  -1.9699703337255101 \t -1.9500125911148154\n",
            "init   \t [5.34950319 2.47493539 5.         0.50293689 6.         0.29706373]. \t  -2.0377420945059783 \t -1.9500125911148154\n",
            "init   \t [ 2.94506579  3.45329697  8.          0.87620946 14.          0.9783044 ]. \t  -1.9500125911148154 \t -1.9500125911148154\n",
            "init   \t [ 1.11811929  1.73004086  5.          0.73745288 12.          0.20586008]. \t  -2.0557846580952273 \t -1.9500125911148154\n",
            "1      \t [ 6.50637223  2.67617722 14.          0.53562507  1.          0.16862152]. \t  -2.065483651943695 \t -1.9500125911148154\n",
            "2      \t [ 9.22243919  0.59642165  6.          0.72537748 19.          0.46639325]. \t  -2.0211824238378755 \t -1.9500125911148154\n",
            "3      \t [ 5.79577795  1.8570688  14.          0.83128935 19.          0.71549729]. \t  -1.974511320981101 \t -1.9500125911148154\n",
            "4      \t [9.32373648 9.05676215 9.         0.53064322 3.         0.70657534]. \t  -1.9867881195553743 \t -1.9500125911148154\n",
            "5      \t [ 9.52454394  8.82757271  9.          0.90064956 19.          0.16022914]. \t  -2.052682286285491 \t -1.9500125911148154\n",
            "6      \t [ 3.61508571  7.70718733 10.          0.62042707  5.          0.12186292]. \t  -2.054423315700128 \t -1.9500125911148154\n",
            "7      \t [ 0.05037086  7.50461284  5.          0.70076046 19.          0.10543546]. \t  -2.051384439295456 \t -1.9500125911148154\n",
            "8      \t [ 9.40430013  0.15700131  7.          0.99940272 12.          0.43771306]. \t  -2.013853982401966 \t -1.9500125911148154\n",
            "9      \t [ 0.40405522  2.81796516 11.          0.8908648   1.          0.54002187]. \t  -1.9742051884562268 \t -1.9500125911148154\n",
            "10     \t [ 2.08494663  9.70581169 14.          0.64307382  3.          0.10613693]. \t  -2.0525265381353774 \t -1.9500125911148154\n",
            "11     \t [ 1.55781918  0.46142569 10.          0.80240433 16.          0.22604037]. \t  -2.0517106112449888 \t -1.9500125911148154\n",
            "12     \t [ 8.32471637  8.64868248  5.          0.80719895 12.          0.64183859]. \t  -1.9814066722728896 \t -1.9500125911148154\n",
            "13     \t [ 1.63603408  9.08540306 13.          0.75743361 17.          0.35594014]. \t  -2.0172876609396297 \t -1.9500125911148154\n",
            "14     \t [ 2.19312776  1.39765821 13.          0.6652195   7.          0.63762954]. \t  -1.9757937384712718 \t -1.9500125911148154\n",
            "15     \t [9.46744067 0.0339838  9.         0.74305504 6.         0.26947831]. \t  -2.0127786392667426 \t -1.9500125911148154\n",
            "16     \t [0.0435652  8.78739493 5.         0.77065126 4.         0.67815602]. \t  -1.9787670813279328 \t -1.9500125911148154\n",
            "17     \t [ 3.43075392  3.21961062 14.          0.99813107 13.          0.94340707]. \t  \u001b[92m-1.9460711839509812\u001b[0m \t -1.9460711839509812\n",
            "18     \t [ 2.97507046  9.85127832  5.          0.75729568 12.          0.23402253]. \t  -2.0517743294083326 \t -1.9460711839509812\n",
            "19     \t [ 9.95126131  9.64022555 11.          0.74273384  9.          0.68757519]. \t  -1.9740277193497149 \t -1.9460711839509812\n",
            "20     \t [3.49244872 7.62920524 6.         0.74139713 3.         0.75714686]. \t  -1.959882174977824 \t -1.9460711839509812\n",
            "21     \t [1.39020966 3.68389758 8.         0.82157631 8.         0.77314746]. \t  -1.9489611010994288 \t -1.9460711839509812\n",
            "22     \t [ 6.56068402  3.85427912  9.          0.82435782 13.          0.74543409]. \t  -1.967158139131082 \t -1.9460711839509812\n",
            "23     \t [4.75581533 1.81641826 7.         0.54457543 7.         0.42549744]. \t  -2.0326322211146364 \t -1.9460711839509812\n",
            "24     \t [ 5.51708302  2.33519561 14.          0.61732112  6.          0.65273214]. \t  -1.9765434762296614 \t -1.9460711839509812\n",
            "25     \t [ 9.00670023  9.99970555 14.          0.96205059 15.          0.60286575]. \t  -1.9628906042724847 \t -1.9460711839509812\n",
            "26     \t [4.98125015 9.32607017 6.         0.79018295 8.         0.37250842]. \t  -2.0161974447240953 \t -1.9460711839509812\n",
            "27     \t [0.         2.20814859 5.         0.5        3.06720162 1.        ]. \t  -1.9747759635974436 \t -1.9460711839509812\n",
            "28     \t [ 2.74266123  7.05787468 14.          0.61105672  5.          0.17080638]. \t  -2.0554048363059882 \t -1.9460711839509812\n",
            "29     \t [8.43113725 9.51621399 6.         0.9100291  9.         0.49381473]. \t  -2.0218983660794656 \t -1.9460711839509812\n",
            "30     \t [7.63967259 1.75314197 6.         0.83632371 1.         0.52048938]. \t  -1.9792583676201239 \t -1.9460711839509812\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "61531.47771017445"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgxvE7Irbbj_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de9b074d-eb76-4959-9b16-6b767a91c21f"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'stp' Acquisition Function run number = 15 \n",
        "\n",
        "np.random.seed(run_num_15)\n",
        "surrogate_stp_15 = tStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train15, X_test15, y_train15, y_test15 = train_test_split(X, y, test_size=test_perc, random_state=run_num_15)\n",
        "\n",
        "def f_syn_polarity15(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_15, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train15, y=y_train15).mean())\n",
        "    return operator * score\n",
        "\n",
        "stp_15 = GPGO(surrogate_stp_15, Acquisition_new(util_stp), f_syn_polarity15, param, n_jobs = -1) # Define BayesOpt\n",
        "stp_15.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_stp_15 = stp_15.getResult()[0]\n",
        "params_stp_15['max_depth'] = int(params_stp_15['max_depth'])\n",
        "params_stp_15['min_child_weight'] = int(params_stp_15['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_stp_train15 = xgb.DMatrix(X_train15, y_train15)\n",
        "dX_stp_test15 = xgb.DMatrix(X_test15, y_test15)\n",
        "model_stp_15 = xgb.train(params_stp_15, dX_stp_train15)\n",
        "pred_stp_15 = model_stp_15.predict(dX_stp_test15)\n",
        "\n",
        "rmse_stp_15 = np.sqrt(mean_squared_error(pred_stp_15, y_test15))\n",
        "rmse_stp_15"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 8.48817697  1.78895925 12.          0.55549316  8.          0.93397854]. \t  -1.9771020004296471 \t -1.9771020004296471\n",
            "init   \t [ 0.24953032  8.22298097 12.          0.62494951 11.          0.12924598]. \t  -2.039987754752231 \t -1.9771020004296471\n",
            "init   \t [ 5.02017228  5.50882771 11.          0.85295832 19.          0.13548008]. \t  -2.0342163062344127 \t -1.9771020004296471\n",
            "init   \t [2.0023081  9.98543403 7.         0.6295772  2.         0.526127  ]. \t  -1.9991206593771125 \t -1.9771020004296471\n",
            "init   \t [ 5.09715306  9.45038417 11.          0.7388277  16.          0.22739973]. \t  -2.0362669401948086 \t -1.9771020004296471\n",
            "1      \t [ 0.29158961  4.9949242  12.          0.89124583  3.          0.67554049]. \t  -1.9851996507567322 \t -1.9771020004296471\n",
            "2      \t [ 0.67158936  0.34278237  6.          0.51048023 11.          0.77715736]. \t  -2.003673551363784 \t -1.9771020004296471\n",
            "3      \t [9.75991344 6.15203198 6.         0.65490407 1.         0.73816291]. \t  -1.9902880644776384 \t -1.9771020004296471\n",
            "4      \t [ 9.51793103  9.55070381  6.          0.93315157 11.          0.40416985]. \t  -2.0266063382197212 \t -1.9771020004296471\n",
            "5      \t [ 9.6441781   0.22441753 11.          0.68756428 18.          0.60531707]. \t  -1.9919153360569464 \t -1.9771020004296471\n",
            "6      \t [1.13261559 9.28349969 7.         0.98964629 7.         0.37032959]. \t  -2.0254340467583893 \t -1.9771020004296471\n",
            "7      \t [ 6.26289557  9.29064244 14.          0.75267974  4.          0.19589403]. \t  -2.0412565123469837 \t -1.9771020004296471\n",
            "8      \t [3.08968857 1.08940277 5.         0.75575035 2.         0.4049356 ]. \t  -2.0295630153651567 \t -1.9771020004296471\n",
            "9      \t [ 0.53269319  3.10786722 14.          0.59617872 16.          0.1338107 ]. \t  -2.042364057019339 \t -1.9771020004296471\n",
            "10     \t [ 8.93696009  0.85767079 13.          0.81270336  5.          0.91231878]. \t  \u001b[92m-1.9536298328565667\u001b[0m \t -1.9536298328565667\n",
            "11     \t [ 2.97928851  7.73905112  6.          0.87870551 18.          0.36796416]. \t  -2.02573754736145 \t -1.9536298328565667\n",
            "12     \t [ 3.91025291  0.94746935  6.          0.83827135 18.          0.68489482]. \t  -1.9853689755005886 \t -1.9536298328565667\n",
            "13     \t [ 1.41127451  0.02455301 14.          0.99438541  9.          0.56009967]. \t  -1.9824591808375935 \t -1.9536298328565667\n",
            "14     \t [9.71973947 0.88964704 5.         0.66866463 8.         0.65465923]. \t  -1.995490169303702 \t -1.9536298328565667\n",
            "15     \t [ 7.70971055  5.9598343  10.          0.83735899 18.          0.36826156]. \t  -2.027111574813945 \t -1.9536298328565667\n",
            "16     \t [ 0.7652639  10.         15.          0.5        15.99999455  1.        ]. \t  \u001b[92m-1.9523774173955595\u001b[0m \t -1.9523774173955595\n",
            "17     \t [ 9.37517193  1.1819082  10.          0.8214404  11.          0.63983914]. \t  -1.9823480496953692 \t -1.9523774173955595\n",
            "18     \t [ 8.77636678  8.74391722 14.          0.79691628 11.          0.9639423 ]. \t  \u001b[92m-1.9508206940717965\u001b[0m \t -1.9508206940717965\n",
            "19     \t [4.93471288 5.72012849 9.         0.64180271 5.         0.60720791]. \t  -1.9934067692694355 \t -1.9508206940717965\n",
            "20     \t [ 6.98072388  2.07135083 14.          0.54090106 14.          0.42460351]. \t  -2.031516509429137 \t -1.9508206940717965\n",
            "21     \t [ 3.42135923  4.98287529  7.          0.71818773 13.          0.89062209]. \t  -1.9565185543816945 \t -1.9508206940717965\n",
            "22     \t [ 9.62142849  1.52309765  6.          0.56506114 19.          0.2885673 ]. \t  -2.0350474491058743 \t -1.9508206940717965\n",
            "23     \t [4.93569774 0.38285768 6.         0.68402372 5.         0.88995938]. \t  -1.9641484511572596 \t -1.9508206940717965\n",
            "24     \t [ 4.11758599  1.74847556 10.          0.8903118  14.          0.95295029]. \t  \u001b[92m-1.9482490720272676\u001b[0m \t -1.9482490720272676\n",
            "25     \t [ 9.43729682  8.97263958 11.          0.74950823  1.          0.15807049]. \t  -2.0404583338079245 \t -1.9482490720272676\n",
            "26     \t [ 3.69916467  4.8966226  13.          0.98398682 10.          0.9978567 ]. \t  \u001b[92m-1.940788145427129\u001b[0m \t -1.940788145427129\n",
            "27     \t [ 8.91523665  9.83677871 10.          0.83513023  7.          0.10082017]. \t  -2.0348557801551865 \t -1.940788145427129\n",
            "28     \t [ 5.32045246  0.29028992 14.          0.86818346  1.          0.97681612]. \t  -1.9566824794699158 \t -1.940788145427129\n",
            "29     \t [ 4.95789928  1.28528383  6.          0.72382182 19.          0.95905174]. \t  -1.957690958562328 \t -1.940788145427129\n",
            "30     \t [ 8.47232258  7.03217508  5.          0.5        15.9428986   1.        ]. \t  -1.9543982266567077 \t -1.940788145427129\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60946.715003188256"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TaP6RoGuiNT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d25fe04a-8964-4da0-b661-87b10224035f"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'stp' Acquisition Function run number = 16 \n",
        "\n",
        "np.random.seed(run_num_16)\n",
        "surrogate_stp_16 = tStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train16, X_test16, y_train16, y_test16 = train_test_split(X, y, test_size=test_perc, random_state=run_num_16)\n",
        "\n",
        "def f_syn_polarity16(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_16, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train16, y=y_train16).mean())\n",
        "    return operator * score\n",
        "\n",
        "stp_16 = GPGO(surrogate_stp_16, Acquisition_new(util_stp), f_syn_polarity16, param, n_jobs = -1) # Define BayesOpt\n",
        "stp_16.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_stp_16 = stp_16.getResult()[0]\n",
        "params_stp_16['max_depth'] = int(params_stp_16['max_depth'])\n",
        "params_stp_16['min_child_weight'] = int(params_stp_16['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_stp_train16 = xgb.DMatrix(X_train16, y_train16)\n",
        "dX_stp_test16 = xgb.DMatrix(X_test16, y_test16)\n",
        "model_stp_16 = xgb.train(params_stp_16, dX_stp_train16)\n",
        "pred_stp_16 = model_stp_16.predict(dX_stp_test16)\n",
        "\n",
        "rmse_stp_16 = np.sqrt(mean_squared_error(pred_stp_16, y_test16))\n",
        "rmse_stp_16"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [2.23291079 5.23163341 6.         0.65430839 5.         0.30077285]. \t  -2.0565156149305297 \t -2.035211151920518\n",
            "init   \t [6.88726162 1.63731425 7.         0.97050543 2.         0.25392012]. \t  -2.055048050691712 \t -2.035211151920518\n",
            "init   \t [ 5.94328983  5.6393473   5.          0.67602695 19.          0.42538144]. \t  -2.035211151920518 \t -2.035211151920518\n",
            "init   \t [ 0.88741148  3.08148142 14.          0.56043938  9.          0.27515386]. \t  -2.0784041797925226 \t -2.035211151920518\n",
            "init   \t [ 2.74631586  1.30996118 11.          0.52160786  8.          0.27956463]. \t  -2.070688794097313 \t -2.035211151920518\n",
            "1      \t [ 7.8937256   1.5972923  14.          0.61610774 17.          0.78739284]. \t  \u001b[92m-1.9211628477361509\u001b[0m \t -1.9211628477361509\n",
            "2      \t [ 9.01655783  8.21383177  9.          0.60772965 10.          0.9401803 ]. \t  \u001b[92m-1.8833303967241242\u001b[0m \t -1.8833303967241242\n",
            "3      \t [ 4.35132073  9.89698316 12.          0.94137984 16.          0.57741056]. \t  -1.97819725226882 \t -1.8833303967241242\n",
            "4      \t [ 9.99266675  2.3482113  14.          0.65036483  2.          0.18233953]. \t  -2.063280175992589 \t -1.8833303967241242\n",
            "5      \t [ 0.02157337  9.97534925  5.          0.75404051 13.          0.40760752]. \t  -2.0247293958409025 \t -1.8833303967241242\n",
            "6      \t [ 0.19317903  0.6596816   6.          0.86233301 15.          0.41906313]. \t  -2.0192307301965045 \t -1.8833303967241242\n",
            "7      \t [ 3.4112379   7.22921505 12.          0.51794009  1.          0.9590442 ]. \t  -1.8988148247327985 \t -1.8833303967241242\n",
            "8      \t [ 1.22130867  0.64008351 12.          0.59515137 19.          0.65193522]. \t  -1.9820463830680937 \t -1.8833303967241242\n",
            "9      \t [8.31596139 8.08775071 5.         0.5698323  1.         0.11769544]. \t  -2.0667662116388583 \t -1.8833303967241242\n",
            "10     \t [ 9.39421065  1.15238895 10.          0.86257926 10.          0.82976642]. \t  -1.9154020559223555 \t -1.8833303967241242\n",
            "11     \t [ 8.63952355  8.87914214 14.          0.57943185  3.          0.83429859]. \t  -1.9367981595012502 \t -1.8833303967241242\n",
            "12     \t [ 4.93583282  3.95579207  5.          0.78393748 11.          0.19828753]. \t  -2.0507830298087946 \t -1.8833303967241242\n",
            "13     \t [ 0.31878638  7.7064847   9.          0.53908047 19.          0.69534532]. \t  -1.9877741315823578 \t -1.8833303967241242\n",
            "14     \t [2.43756281e-03 1.86203502e-01 1.10000000e+01 5.84519618e-01\n",
            " 1.30000000e+01 2.30149841e-01]. \t  -2.0641995781036115 \t -1.8833303967241242\n",
            "15     \t [ 3.22380477  8.8210053  12.          0.91827732  7.          0.1365336 ]. \t  -2.049645314312633 \t -1.8833303967241242\n",
            "16     \t [ 1.87615966  0.2032349  10.          0.89545954  2.          0.86993332]. \t  -1.9348315060565047 \t -1.8833303967241242\n",
            "17     \t [ 0.27313091  7.4504504  11.          0.83119788 12.          0.13163591]. \t  -2.0516424308774184 \t -1.8833303967241242\n",
            "18     \t [ 6.86779017  4.50453048 14.          0.571211    7.          0.9988365 ]. \t  -1.8835902734915937 \t -1.8833303967241242\n",
            "19     \t [ 8.62230754  6.2585252   7.          0.51058047 14.          0.43325928]. \t  -2.0407280397872287 \t -1.8833303967241242\n",
            "20     \t [ 4.77306317  4.41011512 11.          0.84776341 14.          0.81171734]. \t  -1.919767559692652 \t -1.8833303967241242\n",
            "21     \t [6.24960154 8.55385116 5.         0.5        6.83904924 1.        ]. \t  -1.8941828251350281 \t -1.8833303967241242\n",
            "22     \t [ 8.45172576  0.5262772   5.          0.63044843 14.          0.25167537]. \t  -2.0594791913277706 \t -1.8833303967241242\n",
            "23     \t [ 9.09657207  2.91442102  8.          0.70314474 18.          0.93425216]. \t  \u001b[92m-1.8815318653688191\u001b[0m \t -1.8815318653688191\n",
            "24     \t [ 9.32791107  8.26216826 14.          0.84053349 12.          0.21556049]. \t  -2.0522712137304984 \t -1.8815318653688191\n",
            "25     \t [9.84387962 2.26306199 5.         0.9933513  9.         0.7496543 ]. \t  -1.9666804511348026 \t -1.8815318653688191\n",
            "26     \t [ 0.4412441   4.59795849 13.          0.69951646  4.          0.51137503]. \t  -2.0030904429522947 \t -1.8815318653688191\n",
            "27     \t [ 5.51954089  0.67514983 14.          0.56532869  4.          0.54553004]. \t  -2.016125293054148 \t -1.8815318653688191\n",
            "28     \t [ 4.49747313  7.7487808   5.          0.54890424 12.          0.86613014]. \t  -1.9373802146985633 \t -1.8815318653688191\n",
            "29     \t [0.65695569 0.30127043 5.         0.56436611 9.         0.10012212]. \t  -2.0666994830749843 \t -1.8815318653688191\n",
            "30     \t [9.76566402 1.35277955 7.         0.85921975 5.         0.56345918]. \t  -1.9831840086160626 \t -1.8815318653688191\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60435.893875961425"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NiOaMUmgulbx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8bb22b5-4704-40c1-837b-133cfa329ad7"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'stp' Acquisition Function run number = 17 \n",
        "\n",
        "np.random.seed(run_num_17)\n",
        "surrogate_stp_17 = tStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train17, X_test17, y_train17, y_test17 = train_test_split(X, y, test_size=test_perc, random_state=run_num_17)\n",
        "\n",
        "def f_syn_polarity17(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_17, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train17, y=y_train17).mean())\n",
        "    return operator * score\n",
        "\n",
        "stp_17 = GPGO(surrogate_stp_17, Acquisition_new(util_stp), f_syn_polarity17, param, n_jobs = -1) # Define BayesOpt\n",
        "stp_17.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_stp_17 = stp_17.getResult()[0]\n",
        "params_stp_17['max_depth'] = int(params_stp_17['max_depth'])\n",
        "params_stp_17['min_child_weight'] = int(params_stp_17['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_stp_train17 = xgb.DMatrix(X_train17, y_train17)\n",
        "dX_stp_test17 = xgb.DMatrix(X_test17, y_test17)\n",
        "model_stp_17 = xgb.train(params_stp_17, dX_stp_train17)\n",
        "pred_stp_17 = model_stp_17.predict(dX_stp_test17)\n",
        "\n",
        "rmse_stp_17 = np.sqrt(mean_squared_error(pred_stp_17, y_test17))\n",
        "rmse_stp_17"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 2.94665003  5.30586756 11.          0.94443241 14.          0.80828691]. \t  -2.0339055477365475 \t -2.0339055477365475\n",
            "init   \t [ 6.56333522  6.37520896 12.          0.81487881 18.          0.42203224]. \t  -2.0931879884342264 \t -2.0339055477365475\n",
            "init   \t [ 9.45683187  0.6004468  11.          0.5171566  10.          0.53881211]. \t  -2.0781263774021443 \t -2.0339055477365475\n",
            "init   \t [2.72705857 1.19063434 6.         0.74176431 6.         0.10101151]. \t  -2.1016571617786393 \t -2.0339055477365475\n",
            "init   \t [ 4.77631812  5.24671297 13.          0.66254476 19.          0.36708086]. \t  -2.0994481639151874 \t -2.0339055477365475\n",
            "1      \t [ 0.65702322  5.79284078 13.          0.75136902  1.          0.30306068]. \t  -2.1101246565070526 \t -2.0339055477365475\n",
            "2      \t [ 6.93446178  8.68032298 13.          0.78195789  7.          0.91906958]. \t  \u001b[92m-1.9718672938390385\u001b[0m \t -1.9718672938390385\n",
            "3      \t [9.72843652 3.88893279 9.         0.6901555  1.         0.31608219]. \t  -2.107188511168377 \t -1.9718672938390385\n",
            "4      \t [ 8.68206795  9.15744586  6.          0.68749659 13.          0.68423941]. \t  -2.0757960311482555 \t -1.9718672938390385\n",
            "5      \t [ 4.97204887  2.40072226  5.          0.54268748 19.          0.30995407]. \t  -2.1050552165746326 \t -1.9718672938390385\n",
            "6      \t [0.12174033 8.73496008 5.         0.89827646 5.         0.85354798]. \t  -2.0440226052468478 \t -1.9718672938390385\n",
            "7      \t [ 2.91443079  0.16723755 13.          0.598201    6.          0.91729605]. \t  -1.975547562855126 \t -1.9718672938390385\n",
            "8      \t [ 8.38209371  1.79436187  5.          0.95610423 10.          0.10723534]. \t  -2.0988212957478756 \t -1.9718672938390385\n",
            "9      \t [9.15321707 8.76513753 7.         0.80257874 5.         0.36550444]. \t  -2.09664514499322 \t -1.9718672938390385\n",
            "10     \t [ 0.          5.5917824   5.          0.5        12.71788687  0.1       ]. \t  -2.1057848473579206 \t -1.9718672938390385\n",
            "11     \t [ 0.12410542  7.60180472 13.          0.97425003  8.          0.76245421]. \t  -2.0241362397717504 \t -1.9718672938390385\n",
            "12     \t [ 2.44282715  9.71851747  7.          0.86792183 17.          0.93015556]. \t  \u001b[92m-1.9587190471635343\u001b[0m \t -1.9587190471635343\n",
            "13     \t [3.34695797 5.34548011 7.         0.57512217 1.         0.35650988]. \t  -2.106963591296494 \t -1.9587190471635343\n",
            "14     \t [ 9.06002681  9.03779351 14.          0.60614154  1.          0.16421461]. \t  -2.1030373412955305 \t -1.9587190471635343\n",
            "15     \t [ 0.59590325  0.30071901  8.          0.9148403  16.          0.62633871]. \t  -2.0739873895509007 \t -1.9587190471635343\n",
            "16     \t [ 9.42476917  0.82445581 10.          0.69152972 18.          0.6513959 ]. \t  -2.0702441248170564 \t -1.9587190471635343\n",
            "17     \t [ 5.5997101   2.80089542 11.          0.91397635  4.          0.58148876]. \t  -2.063555181444724 \t -1.9587190471635343\n",
            "18     \t [ 8.19688222  5.098902   12.          0.73989726 13.          0.77383077]. \t  -2.0389545773257685 \t -1.9587190471635343\n",
            "19     \t [ 8.34933229  9.44839603 12.          0.7237677   1.          0.61392301]. \t  -2.085908672599236 \t -1.9587190471635343\n",
            "20     \t [ 7.9169136   6.25989639 14.          0.56885759 17.          0.23393138]. \t  -2.1010863609084574 \t -1.9587190471635343\n",
            "21     \t [ 8.28485694  8.99532858  7.          0.60431477 19.          0.2404873 ]. \t  -2.100701747553335 \t -1.9587190471635343\n",
            "22     \t [ 3.45521931  9.78963512 10.          0.71985214  3.          0.38449583]. \t  -2.10731358956697 \t -1.9587190471635343\n",
            "23     \t [0.55999373 9.11405418 9.         0.80740872 9.         0.37432076]. \t  -2.0947964787908466 \t -1.9587190471635343\n",
            "24     \t [ 0.         10.         11.30396548  1.         14.2840811   1.        ]. \t  \u001b[92m-1.9445359714829926\u001b[0m \t -1.9445359714829926\n",
            "25     \t [ 0.17278073  0.04498009 14.          0.7905257  14.          0.72677309]. \t  -2.075505699973587 \t -1.9445359714829926\n",
            "26     \t [ 7.95504097  1.26105641 14.          0.97412785 16.          0.7974695 ]. \t  -2.023170181345951 \t -1.9445359714829926\n",
            "27     \t [ 1.00872007  1.35729156 10.          0.54659624  1.          0.56088869]. \t  -2.0837206269353996 \t -1.9445359714829926\n",
            "28     \t [ 0.          1.37395905  9.03417914  1.         10.43880198  1.        ]. \t  -1.9468139192447225 \t -1.9445359714829926\n",
            "29     \t [ 0.   0.  15.   1.  20.   0.1]. \t  -2.0886134392612616 \t -1.9445359714829926\n",
            "30     \t [ 9.32807666  0.         15.          0.5         1.          0.1       ]. \t  -2.107084633703324 \t -1.9445359714829926\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "59921.71717760397"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5H4MWSXFcZjO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "241e2231-8eb3-4d90-d380-95f8c062b3f4"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'stp' Acquisition Function run number = 18 \n",
        "\n",
        "np.random.seed(run_num_18)\n",
        "surrogate_stp_18 = tStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train18, X_test18, y_train18, y_test18 = train_test_split(X, y, test_size=test_perc, random_state=run_num_18)\n",
        "\n",
        "def f_syn_polarity18(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_18, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train18, y=y_train18).mean())\n",
        "    return operator * score\n",
        "\n",
        "stp_18 = GPGO(surrogate_stp_18, Acquisition_new(util_stp), f_syn_polarity18, param, n_jobs = -1) # Define BayesOpt\n",
        "stp_18.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_stp_18 = stp_18.getResult()[0]\n",
        "params_stp_18['max_depth'] = int(params_stp_18['max_depth'])\n",
        "params_stp_18['min_child_weight'] = int(params_stp_18['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_stp_train18 = xgb.DMatrix(X_train18, y_train18)\n",
        "dX_stp_test18 = xgb.DMatrix(X_test18, y_test18)\n",
        "model_stp_18 = xgb.train(params_stp_18, dX_stp_train18)\n",
        "pred_stp_18 = model_stp_18.predict(dX_stp_test18)\n",
        "\n",
        "rmse_stp_18 = np.sqrt(mean_squared_error(pred_stp_18, y_test18))\n",
        "rmse_stp_18"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [6.50374242 5.05453374 6.         0.59092011 3.         0.28357516]. \t  -2.1139887892273643 \t -2.0192613200573843\n",
            "init   \t [0.11506734 4.26891483 9.         0.81785956 5.         0.63489043]. \t  -2.021964437155906 \t -2.0192613200573843\n",
            "init   \t [ 2.8861259   6.35547834 11.          0.64267955 14.          0.27877092]. \t  -2.109484039844671 \t -2.0192613200573843\n",
            "init   \t [6.57189031 6.99655629 8.         0.63235896 4.         0.52894035]. \t  -2.030485631652704 \t -2.0192613200573843\n",
            "init   \t [ 6.66600348  2.11312037 14.          0.74363461  4.          0.73174558]. \t  -2.0192613200573843 \t -2.0192613200573843\n",
            "1      \t [ 8.67093232  0.11649132  5.          0.92962202 15.          0.53672863]. \t  \u001b[92m-2.0164730733659684\u001b[0m \t -2.0164730733659684\n",
            "2      \t [ 8.43851229  2.41114508 13.          0.75771586 19.          0.86905071]. \t  \u001b[92m-1.9696197573755676\u001b[0m \t -1.9696197573755676\n",
            "3      \t [ 9.44281001  9.01534322  7.          0.99142432 16.          0.37631199]. \t  -2.0820868604419425 \t -1.9696197573755676\n",
            "4      \t [ 3.19538294  9.91737336 14.          0.7976317   5.          0.25704487]. \t  -2.1103974327134365 \t -1.9696197573755676\n",
            "5      \t [ 0.21200191  9.95034596  6.          0.77719285 19.          0.61346381]. \t  -2.0144419210740105 \t -1.9696197573755676\n",
            "6      \t [ 1.26601315  0.31299408  6.          0.95296222 16.          0.13649883]. \t  -2.1052900828522505 \t -1.9696197573755676\n",
            "7      \t [ 1.2588084   9.80413977  5.          0.75618546 12.          0.53020258]. \t  -2.019403423453722 \t -1.9696197573755676\n",
            "8      \t [ 6.63763513  1.21594617 14.          0.92753462 12.          0.25002233]. \t  -2.1049809529578947 \t -1.9696197573755676\n",
            "9      \t [ 7.49192948  9.60283663 14.          0.93718151 19.          0.24625933]. \t  -2.1079043952870204 \t -1.9696197573755676\n",
            "10     \t [ 0.45900242  1.30431521 14.          0.64901358 15.          0.91762916]. \t  \u001b[92m-1.9553584001512683\u001b[0m \t -1.9553584001512683\n",
            "11     \t [9.98653758 8.80568206 9.         0.86984433 9.         0.78984159]. \t  -1.971249941301663 \t -1.9553584001512683\n",
            "12     \t [4.77329541 1.13129133 5.         0.67932546 9.         0.50909066]. \t  -2.027763760903764 \t -1.9553584001512683\n",
            "13     \t [0.58655573 8.89860432 5.         0.62593909 1.         0.46819727]. \t  -2.100295123540829 \t -1.9553584001512683\n",
            "14     \t [ 4.25762222  4.02301922  9.          0.6129246  19.          0.59981465]. \t  -2.0334594914581703 \t -1.9553584001512683\n",
            "15     \t [9.66555931 0.03278214 7.         0.65118318 6.         0.28697131]. \t  -2.1071723632151538 \t -1.9553584001512683\n",
            "16     \t [ 6.80131964  5.61100356  5.          0.60827701 12.          0.4103298 ]. \t  -2.09465788810513 \t -1.9553584001512683\n",
            "17     \t [4.62904808 8.17796855 8.         0.7827474  9.         0.73274763]. \t  -2.0136623540254646 \t -1.9553584001512683\n",
            "18     \t [ 9.56072091  9.1368036  14.          0.68050527  1.          0.47597207]. \t  -2.1073491859568416 \t -1.9553584001512683\n",
            "19     \t [ 4.00053444  5.91661585 10.          0.89776515 11.          0.44950258]. \t  -2.085956131655061 \t -1.9553584001512683\n",
            "20     \t [ 0.71757549  1.10909841 12.          0.74563843  9.          0.40273808]. \t  -2.0869129638122113 \t -1.9553584001512683\n",
            "21     \t [ 2.07208012  1.48825717  9.          0.81554889 11.          0.70539991]. \t  -2.016291870656276 \t -1.9553584001512683\n",
            "22     \t [ 6.99215684  5.0752615   6.          0.8313862  19.          0.43806959]. \t  -2.087126168292577 \t -1.9553584001512683\n",
            "23     \t [5.8651125  6.95720403 5.         0.56056787 7.         0.5685839 ]. \t  -2.031551902008703 \t -1.9553584001512683\n",
            "24     \t [9.78152027 0.75275159 9.         0.84702061 1.         0.21494752]. \t  -2.108937917604126 \t -1.9553584001512683\n",
            "25     \t [ 8.72640117  6.23036694 13.          0.73164781 18.          0.80623945]. \t  -1.9799986639138418 \t -1.9553584001512683\n",
            "26     \t [ 3.01028032  2.6806302  12.          0.67746669  7.          0.99064833]. \t  -1.962282367554117 \t -1.9553584001512683\n",
            "27     \t [ 5.78379623  2.32827768 12.          0.89134178  9.          0.95885752]. \t  \u001b[92m-1.9450303362088412\u001b[0m \t -1.9450303362088412\n",
            "28     \t [ 9.50685675  6.18023099 13.          0.91822576  7.          0.43374917]. \t  -2.0830503728285708 \t -1.9450303362088412\n",
            "29     \t [ 1.15280786  1.57121363 13.          0.94824381  1.          0.67894475]. \t  -2.019690866797508 \t -1.9450303362088412\n",
            "30     \t [ 5.3794144   5.36928469 11.          0.52216935  1.          0.14998606]. \t  -2.113094027889619 \t -1.9450303362088412\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "61211.63548152184"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-zaPbk2uuzH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f9cbe3e-73a7-47ca-e505-621a4e01a521"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'stp' Acquisition Function run number = 19 \n",
        "\n",
        "np.random.seed(run_num_19)\n",
        "surrogate_stp_19 = tStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train19, X_test19, y_train19, y_test19 = train_test_split(X, y, test_size=test_perc, random_state=run_num_19)\n",
        "\n",
        "def f_syn_polarity19(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_19, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train19, y=y_train19).mean())\n",
        "    return operator * score\n",
        "\n",
        "stp_19 = GPGO(surrogate_stp_19, Acquisition_new(util_stp), f_syn_polarity19, param, n_jobs = -1) # Define BayesOpt\n",
        "stp_19.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_stp_19 = stp_19.getResult()[0]\n",
        "params_stp_19['max_depth'] = int(params_stp_19['max_depth'])\n",
        "params_stp_19['min_child_weight'] = int(params_stp_19['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_stp_train19 = xgb.DMatrix(X_train19, y_train19)\n",
        "dX_stp_test19 = xgb.DMatrix(X_test19, y_test19)\n",
        "model_stp_19 = xgb.train(params_stp_19, dX_stp_train19)\n",
        "pred_stp_19 = model_stp_19.predict(dX_stp_test19)\n",
        "\n",
        "rmse_stp_19 = np.sqrt(mean_squared_error(pred_stp_19, y_test19))\n",
        "rmse_stp_19"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 0.97533602  7.61249717 13.          0.85765469 11.          0.39830191]. \t  -2.1125055225907645 \t -2.0304436386765667\n",
            "init   \t [ 0.82999565  6.71977081  6.          0.50407413 19.          0.67209466]. \t  -2.1089329254044453 \t -2.0304436386765667\n",
            "init   \t [ 2.15923256  5.49027432 12.          0.52588686 10.          0.20235326]. \t  -2.2159557105709857 \t -2.0304436386765667\n",
            "init   \t [4.99659267 1.52108422 6.         0.73481085 4.         0.71949465]. \t  -2.0952304096019114 \t -2.0304436386765667\n",
            "init   \t [ 3.72927156  9.46160045  5.          0.80554614 18.          0.97708466]. \t  -2.0304436386765667 \t -2.0304436386765667\n",
            "1      \t [ 3.75019371  2.78533043 14.          0.97471706  2.          0.68741144]. \t  -2.100501937390617 \t -2.0304436386765667\n",
            "2      \t [ 7.89674065  9.31460122 11.          0.96158687  5.          0.67754853]. \t  -2.094659803224844 \t -2.0304436386765667\n",
            "3      \t [ 8.97857647  2.41265761 14.          0.90058112 15.          0.81986861]. \t  \u001b[92m-2.01276824348674\u001b[0m \t -2.01276824348674\n",
            "4      \t [ 7.93352861  1.21613749  5.          0.73869628 14.          0.41779112]. \t  -2.110394999641106 \t -2.01276824348674\n",
            "5      \t [0.25768796 8.33414072 6.         0.99948369 4.         0.66680619]. \t  -2.079171320001423 \t -2.01276824348674\n",
            "6      \t [ 1.10650842  9.77537077 14.          0.83431584  1.          0.5884296 ]. \t  -2.11757293741839 \t -2.01276824348674\n",
            "7      \t [ 3.36932774  0.57742335 11.          0.51495691 19.          0.2088797 ]. \t  -2.2127129608171137 \t -2.01276824348674\n",
            "8      \t [ 9.38912369  9.90171967 12.          0.61591012 19.          0.76327492]. \t  -2.037964443247069 \t -2.01276824348674\n",
            "9      \t [7.08488952 8.05904216 5.         0.93088713 1.         0.30662699]. \t  -2.1202385141076285 \t -2.01276824348674\n",
            "10     \t [ 9.81457301  8.66419485 11.          0.75732484 12.          0.78456883]. \t  -2.038657929069152 \t -2.01276824348674\n",
            "11     \t [ 8.47165413  3.80540877 14.          0.97366473  8.          0.28918689]. \t  -2.119272189028089 \t -2.01276824348674\n",
            "12     \t [ 9.46853542  3.17467139 10.          0.82370493  3.          0.10263671]. \t  -2.2114440261483166 \t -2.01276824348674\n",
            "13     \t [ 2.37824388  4.47272578  5.          0.97943263 10.          0.125395  ]. \t  -2.2030647191031965 \t -2.01276824348674\n",
            "14     \t [9.64210186 7.83231909 5.         0.82425794 9.         0.37767184]. \t  -2.1072632080720535 \t -2.01276824348674\n",
            "15     \t [ 2.45146849  8.32898472 14.          0.63227537 18.          0.3341326 ]. \t  -2.1338982173393233 \t -2.01276824348674\n",
            "16     \t [ 7.35292167  9.31070018  5.          0.61182479 14.          0.93954189]. \t  -2.035699208274957 \t -2.01276824348674\n",
            "17     \t [ 1.9120179   0.52119504 12.          0.71043482  7.          0.33341372]. \t  -2.1373004771263746 \t -2.01276824348674\n",
            "18     \t [ 5.58873618  5.05559533  9.          0.74428471 15.          0.4314805 ]. \t  -2.1101065306002047 \t -2.01276824348674\n",
            "19     \t [ 5.02254815  8.45315995 13.          0.52448693 12.          0.67787954]. \t  -2.1050900956065526 \t -2.01276824348674\n",
            "20     \t [ 1.48099584  7.99555342  9.          0.76325911 10.          0.82131089]. \t  -2.035698222843441 \t -2.01276824348674\n",
            "21     \t [ 9.66162199  4.75730099  7.          0.78582304 12.          0.61363074]. \t  -2.0955559154763774 \t -2.01276824348674\n",
            "22     \t [ 0.71647145  1.27051081 13.          0.91306303 14.          0.15632235]. \t  -2.2052286508583263 \t -2.01276824348674\n",
            "23     \t [ 2.07609396  6.30478088 11.          0.69245157  4.          0.8237956 ]. \t  -2.0402113650755083 \t -2.01276824348674\n",
            "24     \t [ 1.2058118   1.26347336  7.          0.78194028 14.          0.53763047]. \t  -2.0889168464991563 \t -2.01276824348674\n",
            "25     \t [0.14886079 3.10947104 7.         0.52818873 1.         0.88078996]. \t  -2.0431935427374084 \t -2.01276824348674\n",
            "26     \t [ 2.33225003  7.36284504 13.          0.50079514 16.          0.49115927]. \t  -2.1214434125742834 \t -2.01276824348674\n",
            "27     \t [ 7.59038656  5.8345378   8.          0.85246945 12.          0.1130244 ]. \t  -2.206617858544531 \t -2.01276824348674\n",
            "28     \t [ 7.81350913  9.17939329 10.          0.69108106  9.          0.81949429]. \t  -2.0397936319295864 \t -2.01276824348674\n",
            "29     \t [ 0.04332693  3.83181893 10.          0.67809295  9.          0.69301409]. \t  -2.096507534179233 \t -2.01276824348674\n",
            "30     \t [10.          0.          9.40298462  1.         10.69072643  0.1       ]. \t  -2.197912984558449 \t -2.01276824348674\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60318.205645702714"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NvkuHKlQuxRy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "529254e3-5949-4afb-9d02-e9f606393cfa"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'stp' Acquisition Function run number = 20 \n",
        "\n",
        "np.random.seed(run_num_20)\n",
        "surrogate_stp_20 = tStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train20, X_test20, y_train20, y_test20 = train_test_split(X, y, test_size=test_perc, random_state=run_num_20)\n",
        "\n",
        "def f_syn_polarity20(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_20, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train20, y=y_train20).mean())\n",
        "    return operator * score\n",
        "\n",
        "stp_20 = GPGO(surrogate_stp_20, Acquisition_new(util_stp), f_syn_polarity20, param, n_jobs = -1) # Define BayesOpt\n",
        "stp_20.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_stp_20 = stp_20.getResult()[0]\n",
        "params_stp_20['max_depth'] = int(params_stp_20['max_depth'])\n",
        "params_stp_20['min_child_weight'] = int(params_stp_20['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_stp_train20 = xgb.DMatrix(X_train20, y_train20)\n",
        "dX_stp_test20 = xgb.DMatrix(X_test20, y_test20)\n",
        "model_stp_20 = xgb.train(params_stp_20, dX_stp_train20)\n",
        "pred_stp_20 = model_stp_20.predict(dX_stp_test20)\n",
        "\n",
        "rmse_stp_20 = np.sqrt(mean_squared_error(pred_stp_20, y_test20))\n",
        "rmse_stp_20"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 5.88130801  8.97713728 14.          0.81074445  8.          0.95540649]. \t  -1.909363007310379 \t -1.909363007310379\n",
            "init   \t [6.72865655 0.41173329 8.         0.6361582  7.         0.76174061]. \t  -1.945489761868388 \t -1.909363007310379\n",
            "init   \t [ 4.77387703  8.66202323 10.          0.51833215  7.          0.10123387]. \t  -2.0538318450351323 \t -1.909363007310379\n",
            "init   \t [ 5.75489985  4.74524381  8.          0.78084343 15.          0.26643049]. \t  -2.019385891619828 \t -1.909363007310379\n",
            "init   \t [ 4.53444     4.47342833  8.          0.91974896 18.          0.35997552]. \t  -2.0147074022409646 \t -1.909363007310379\n",
            "1      \t [ 7.96566073  7.15509535  7.          0.79906691 11.          0.34132075]. \t  -2.0240306652522984 \t -1.909363007310379\n",
            "2      \t [ 1.98667885  1.35773177 13.          0.57199118  2.          0.39498908]. \t  -2.0408843487652284 \t -1.909363007310379\n",
            "3      \t [ 0.05406024  0.42106765 14.          0.6066366  16.          0.86098378]. \t  -1.9411782541304745 \t -1.909363007310379\n",
            "4      \t [ 9.3606342   3.21248061 14.          0.65614013 17.          0.10926152]. \t  -2.0468162361461912 \t -1.909363007310379\n",
            "5      \t [8.0846212  5.99993376 6.         0.83941375 1.         0.46362124]. \t  -2.023086361344062 \t -1.909363007310379\n",
            "6      \t [0.61316554 1.36115087 5.         0.87944956 1.         0.21740227]. \t  -2.051987483090283 \t -1.909363007310379\n",
            "7      \t [ 0.72788527  2.26655356 10.          0.97273032 15.          0.85843758]. \t  -1.933940076934298 \t -1.909363007310379\n",
            "8      \t [ 7.29847873  0.61439441  5.          0.60353619 15.          0.628184  ]. \t  -1.9768480879829973 \t -1.909363007310379\n",
            "9      \t [ 4.64103339  9.2844785  14.          0.59589216 16.          0.96162706]. \t  -1.9228766934228059 \t -1.909363007310379\n",
            "10     \t [ 4.90806168  2.69843832 13.          0.67916837 11.          0.40124283]. \t  -2.020788314981995 \t -1.909363007310379\n",
            "11     \t [ 1.25677459  5.28407296 10.          0.60004946  4.          0.56610318]. \t  -2.0312666659764664 \t -1.909363007310379\n",
            "12     \t [ 9.62878188  0.47045758 13.          0.73408624  1.          0.43054124]. \t  -2.030327991812984 \t -1.909363007310379\n",
            "13     \t [7.12982753 6.84003365 7.         0.76458922 2.         0.82832765]. \t  -1.9405374900554668 \t -1.909363007310379\n",
            "14     \t [ 0.94401465  8.52695367 11.          0.55068347 12.          0.44800952]. \t  -2.03447855074187 \t -1.909363007310379\n",
            "15     \t [ 5.37444991  0.3056877   9.          0.99777328 15.          0.5903115 ]. \t  -2.0148906213566007 \t -1.909363007310379\n",
            "16     \t [ 0.03685635  8.99252991  7.          0.68273443 17.          0.92978046]. \t  -1.9103412054375848 \t -1.909363007310379\n",
            "17     \t [ 9.44977056  8.08706416 10.          0.57562031 19.          0.10040302]. \t  -2.050740110403435 \t -1.909363007310379\n",
            "18     \t [0.12661394 7.44623666 6.         0.78474136 2.         0.7832835 ]. \t  -1.9348659138632975 \t -1.909363007310379\n",
            "19     \t [9.1583509  6.64261308 7.         0.61935796 6.         0.66637309]. \t  -1.983157470329422 \t -1.909363007310379\n",
            "20     \t [ 2.87962423  9.8363639  12.          0.65618476  1.          0.9142099 ]. \t  -1.9312348470361962 \t -1.909363007310379\n",
            "21     \t [ 2.0749172   5.19886505  6.          0.75632955 10.          0.70984332]. \t  -1.963763546357199 \t -1.909363007310379\n",
            "22     \t [8.32364611 9.09619953 5.         0.94202726 3.         0.73593282]. \t  -1.969243794199723 \t -1.909363007310379\n",
            "23     \t [4.55589936 8.75643381 6.         0.98026412 1.         0.85391714]. \t  -1.9327092382321531 \t -1.909363007310379\n",
            "24     \t [ 0.51858465  5.79677664  5.          0.89220249 18.          0.95415664]. \t  -1.9131760920258223 \t -1.909363007310379\n",
            "25     \t [ 8.40148618  7.51466635 14.          0.59782191  1.          0.74448504]. \t  -1.9895479565559726 \t -1.909363007310379\n",
            "26     \t [ 9.14711333  3.65983271 10.          0.73619351 19.          0.70116669]. \t  -1.9750610471891523 \t -1.909363007310379\n",
            "27     \t [ 9.95161506  3.4326104  13.          0.6110053   8.          0.43299301]. \t  -2.0332084961171737 \t -1.909363007310379\n",
            "28     \t [ 4.88662748  3.02002377 14.          0.74992868  6.          0.18968798]. \t  -2.0510497798312146 \t -1.909363007310379\n",
            "29     \t [ 0.32486498  6.23816646 12.          0.52277042 19.          0.22531709]. \t  -2.0524047001832324 \t -1.909363007310379\n",
            "30     \t [ 0.21888051  0.35132818  6.          0.77703308 19.          0.35680372]. \t  -2.0225138607678073 \t -1.909363007310379\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "59312.96896149271"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFKuwvS3uzrs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83b7f678-1815-436d-f74c-43423f7cef88"
      },
      "source": [
        "end_stp = time.time()\n",
        "end_stp\n",
        "\n",
        "time_stp = end_stp - start_stp\n",
        "time_stp"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "977.0188040733337"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CU2FlhY4vHUk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83145862-69a0-4670-b08c-783651f2261e"
      },
      "source": [
        "rmse_gp = [rmse_gp_1,\n",
        "rmse_gp_2,\n",
        "rmse_gp_3,\n",
        "rmse_gp_4,\n",
        "rmse_gp_5,\n",
        "rmse_gp_6,\n",
        "rmse_gp_7,\n",
        "rmse_gp_8,\n",
        "rmse_gp_9,\n",
        "rmse_gp_10,\n",
        "rmse_gp_11,\n",
        "rmse_gp_12,\n",
        "rmse_gp_13,\n",
        "rmse_gp_14,\n",
        "rmse_gp_15,\n",
        "rmse_gp_16,\n",
        "rmse_gp_17,\n",
        "rmse_gp_18,\n",
        "rmse_gp_19,\n",
        "rmse_gp_20]\n",
        "\n",
        "np.mean(rmse_gp)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "61064.03349347403"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZ53FsWXu3J1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9f910ae-00d9-4871-d667-0d40aca81ba2"
      },
      "source": [
        "rmse_stp = [rmse_stp_1,\n",
        "rmse_stp_2,\n",
        "rmse_stp_3,\n",
        "rmse_stp_4,\n",
        "rmse_stp_5,\n",
        "rmse_stp_6,\n",
        "rmse_stp_7,\n",
        "rmse_stp_8,\n",
        "rmse_stp_9,\n",
        "rmse_stp_10,\n",
        "rmse_stp_11,\n",
        "rmse_stp_12,\n",
        "rmse_stp_13,\n",
        "rmse_stp_14,\n",
        "rmse_stp_15,\n",
        "rmse_stp_16,\n",
        "rmse_stp_17,\n",
        "rmse_stp_18,\n",
        "rmse_stp_19,\n",
        "rmse_stp_20]\n",
        "\n",
        "np.mean(rmse_stp)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60835.66984266051"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9FOyoH8u5Wx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1088533f-9ff8-4377-8305-3ddfca9f6d3a"
      },
      "source": [
        "min_rmse_gp = min_max_array(rmse_gp)\n",
        "min_rmse_gp, len(min_rmse_gp)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([60754.16307826351,\n",
              "  60754.16307826351,\n",
              "  59850.95807424735,\n",
              "  59850.95807424735,\n",
              "  59850.95807424735,\n",
              "  59850.95807424735,\n",
              "  59850.95807424735,\n",
              "  59850.95807424735,\n",
              "  59850.95807424735,\n",
              "  59850.95807424735,\n",
              "  59850.95807424735,\n",
              "  59850.95807424735,\n",
              "  59850.95807424735,\n",
              "  59850.95807424735,\n",
              "  59850.95807424735,\n",
              "  59850.95807424735,\n",
              "  59850.95807424735,\n",
              "  59850.95807424735,\n",
              "  59850.95807424735,\n",
              "  59194.599001987306],\n",
              " 20)"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unXOpKHcvO15",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d1d27fe-eb5c-4b1c-feee-4da139cdad3e"
      },
      "source": [
        "min_rmse_stp = min_max_array(rmse_stp)\n",
        "min_rmse_stp, len(min_rmse_stp)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([61032.19618864838,\n",
              "  60928.26805906831,\n",
              "  60928.26805906831,\n",
              "  60684.47557007898,\n",
              "  60684.47557007898,\n",
              "  59866.06285748848,\n",
              "  59866.06285748848,\n",
              "  59866.06285748848,\n",
              "  59866.06285748848,\n",
              "  59866.06285748848,\n",
              "  59866.06285748848,\n",
              "  59866.06285748848,\n",
              "  58655.65989889668,\n",
              "  58655.65989889668,\n",
              "  58655.65989889668,\n",
              "  58655.65989889668,\n",
              "  58655.65989889668,\n",
              "  58655.65989889668,\n",
              "  58655.65989889668,\n",
              "  58655.65989889668],\n",
              " 20)"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yxo85-HEvRPi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 291
        },
        "outputId": "f47862ab-8e99-4b45-9ade-2915d8af4b39"
      },
      "source": [
        "### Visualise!\n",
        "\n",
        "title = obj_func\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(min_rmse_gp, color = 'Yellow', label='RMSE: GP CBM')\n",
        "plt.plot(min_rmse_stp, color = 'Green', ls='--', label='RMSE: STP CBM ' r'($\\nu$' ' = {})'.format(df))\n",
        "\n",
        "plt.title(title, weight = 'bold')\n",
        "plt.xlabel('Experiment(s)', weight = 'bold') # x-axis label\n",
        "plt.ylabel('RMSE (US Dollars $)', weight = 'bold') # y-axis label\n",
        "plt.legend(loc=0) # add plot legend\n",
        "\n",
        "### Make the x-ticks integers, not floats:\n",
        "count = len(min_rmse_gp)\n",
        "plt.xticks(np.arange(count), np.arange(1, count + 1))\n",
        "plt.grid(b=None)\n",
        "plt.show() #visualise!\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwyO7_iZvT7a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1458cfd-2fc6-4eb1-990b-1a56878e5a02"
      },
      "source": [
        "time_gp, time_stp\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1097.0747191905975, 977.0188040733337)"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHLA-0DnVXxD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40c9da39-c8ff-4792-e960-a2774ba2ddc2"
      },
      "source": [
        "min(min_rmse_stp), min(min_rmse_gp)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(58655.65989889668, 59194.599001987306)"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iUNBRy3W0GY"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}