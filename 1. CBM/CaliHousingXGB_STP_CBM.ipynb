{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9wHutsqZUcn"
      },
      "source": [
        "XGBoost Regression - 'real-world' example: Californian Housing Dataset\n",
        "\n",
        "https://scikit-learn.org/stable/datasets/real_world.html#california-housing-dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-0Pe1i4Z2R_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a36fc268-27c2-4e32-88fd-c0f85583dfc7"
      },
      "source": [
        "!pip install pyGPGO"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyGPGO in /usr/local/lib/python3.7/dist-packages (0.5.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from pyGPGO) (1.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from pyGPGO) (1.7.3)\n",
            "Requirement already satisfied: Theano-PyMC in /usr/local/lib/python3.7/dist-packages (from pyGPGO) (1.1.2)\n",
            "Requirement already satisfied: mkl in /usr/local/lib/python3.7/dist-packages (from pyGPGO) (2019.0)\n",
            "Requirement already satisfied: pyMC3 in /usr/local/lib/python3.7/dist-packages (from pyGPGO) (3.11.5)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from pyGPGO) (1.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pyGPGO) (1.21.6)\n",
            "Requirement already satisfied: intel-openmp in /usr/local/lib/python3.7/dist-packages (from mkl->pyGPGO) (2022.1.0)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from pyMC3->pyGPGO) (1.3.5)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from pyMC3->pyGPGO) (0.3.5.1)\n",
            "Requirement already satisfied: cachetools>=4.2.1 in /usr/local/lib/python3.7/dist-packages (from pyMC3->pyGPGO) (4.2.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from pyMC3->pyGPGO) (4.1.1)\n",
            "Requirement already satisfied: arviz>=0.11.0 in /usr/local/lib/python3.7/dist-packages (from pyMC3->pyGPGO) (0.12.1)\n",
            "Requirement already satisfied: fastprogress>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from pyMC3->pyGPGO) (1.0.3)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.7/dist-packages (from pyMC3->pyGPGO) (0.5.2)\n",
            "Requirement already satisfied: semver>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from pyMC3->pyGPGO) (2.13.0)\n",
            "Requirement already satisfied: deprecat in /usr/local/lib/python3.7/dist-packages (from pyMC3->pyGPGO) (2.1.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from Theano-PyMC->pyGPGO) (3.8.0)\n",
            "Requirement already satisfied: setuptools>=38.4 in /usr/local/lib/python3.7/dist-packages (from arviz>=0.11.0->pyMC3->pyGPGO) (57.4.0)\n",
            "Requirement already satisfied: matplotlib>=3.0 in /usr/local/lib/python3.7/dist-packages (from arviz>=0.11.0->pyMC3->pyGPGO) (3.2.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from arviz>=0.11.0->pyMC3->pyGPGO) (21.3)\n",
            "Requirement already satisfied: xarray>=0.16.1 in /usr/local/lib/python3.7/dist-packages (from arviz>=0.11.0->pyMC3->pyGPGO) (0.20.2)\n",
            "Requirement already satisfied: netcdf4 in /usr/local/lib/python3.7/dist-packages (from arviz>=0.11.0->pyMC3->pyGPGO) (1.6.0)\n",
            "Requirement already satisfied: xarray-einstats>=0.2 in /usr/local/lib/python3.7/dist-packages (from arviz>=0.11.0->pyMC3->pyGPGO) (0.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0->arviz>=0.11.0->pyMC3->pyGPGO) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0->arviz>=0.11.0->pyMC3->pyGPGO) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0->arviz>=0.11.0->pyMC3->pyGPGO) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0->arviz>=0.11.0->pyMC3->pyGPGO) (1.4.4)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->pyMC3->pyGPGO) (2022.2.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from patsy>=0.5.1->pyMC3->pyGPGO) (1.15.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from xarray>=0.16.1->arviz>=0.11.0->pyMC3->pyGPGO) (4.12.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from deprecat->pyMC3->pyGPGO) (1.14.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->xarray>=0.16.1->arviz>=0.11.0->pyMC3->pyGPGO) (3.8.1)\n",
            "Requirement already satisfied: cftime in /usr/local/lib/python3.7/dist-packages (from netcdf4->arviz>=0.11.0->pyMC3->pyGPGO) (1.6.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pyGPGO) (3.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7zDTf1naBsH"
      },
      "source": [
        "# Load some default Python modules:\n",
        "\n",
        "import numpy as np\n",
        "import scipy as sp\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import xgboost as xgb\n",
        "import time\n",
        "\n",
        "from matplotlib.pyplot import rc\n",
        "rc('font',**{'family':'sans-serif','sans-serif':['Helvetica']})\n",
        "rc('text', usetex=False)\n",
        "import seaborn as sns\n",
        "plt.style.use('seaborn-whitegrid')\n",
        "\n",
        "from collections import OrderedDict\n",
        "from joblib import Parallel, delayed\n",
        "from numpy.linalg import slogdet, inv, cholesky, solve\n",
        "from scipy.optimize import minimize\n",
        "from scipy.spatial.distance import cdist\n",
        "from scipy.special import gamma\n",
        "from scipy.stats import norm, t\n",
        "from joblib import Parallel, delayed\n",
        "import itertools\n",
        "\n",
        "from pyGPGO.logger import EventLogger\n",
        "from pyGPGO.GPGO import GPGO\n",
        "from pyGPGO.surrogates.GaussianProcess import GaussianProcess\n",
        "from pyGPGO.surrogates.tStudentProcess import tStudentProcess\n",
        "from pyGPGO.acquisition import Acquisition\n",
        "from pyGPGO.covfunc import squaredExponential\n",
        "from sklearn.model_selection import cross_val_score, train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from xgboost import XGBRegressor\n",
        "from pandas_datareader import data\n",
        "\n",
        "import warnings\n",
        "import random\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXicekJhaE0P"
      },
      "source": [
        "# Read data in pandas dataframe:\n",
        "df_train =  pd.read_csv('/content/sample_data/california_housing_train.csv')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQ0mDzt_cBmw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "outputId": "57102041-eae0-43de-ceb9-120a6446b499"
      },
      "source": [
        "# List first rows:\n",
        "\n",
        "df_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
              "0    -114.31     34.19                15.0       5612.0          1283.0   \n",
              "1    -114.47     34.40                19.0       7650.0          1901.0   \n",
              "2    -114.56     33.69                17.0        720.0           174.0   \n",
              "3    -114.57     33.64                14.0       1501.0           337.0   \n",
              "4    -114.57     33.57                20.0       1454.0           326.0   \n",
              "\n",
              "   population  households  median_income  median_house_value  \n",
              "0      1015.0       472.0         1.4936             66900.0  \n",
              "1      1129.0       463.0         1.8200             80100.0  \n",
              "2       333.0       117.0         1.6509             85700.0  \n",
              "3       515.0       226.0         3.1917             73400.0  \n",
              "4       624.0       262.0         1.9250             65500.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-62df5a98-b851-4924-8640-30bd03819925\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>longitude</th>\n",
              "      <th>latitude</th>\n",
              "      <th>housing_median_age</th>\n",
              "      <th>total_rooms</th>\n",
              "      <th>total_bedrooms</th>\n",
              "      <th>population</th>\n",
              "      <th>households</th>\n",
              "      <th>median_income</th>\n",
              "      <th>median_house_value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-114.31</td>\n",
              "      <td>34.19</td>\n",
              "      <td>15.0</td>\n",
              "      <td>5612.0</td>\n",
              "      <td>1283.0</td>\n",
              "      <td>1015.0</td>\n",
              "      <td>472.0</td>\n",
              "      <td>1.4936</td>\n",
              "      <td>66900.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-114.47</td>\n",
              "      <td>34.40</td>\n",
              "      <td>19.0</td>\n",
              "      <td>7650.0</td>\n",
              "      <td>1901.0</td>\n",
              "      <td>1129.0</td>\n",
              "      <td>463.0</td>\n",
              "      <td>1.8200</td>\n",
              "      <td>80100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-114.56</td>\n",
              "      <td>33.69</td>\n",
              "      <td>17.0</td>\n",
              "      <td>720.0</td>\n",
              "      <td>174.0</td>\n",
              "      <td>333.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>1.6509</td>\n",
              "      <td>85700.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-114.57</td>\n",
              "      <td>33.64</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1501.0</td>\n",
              "      <td>337.0</td>\n",
              "      <td>515.0</td>\n",
              "      <td>226.0</td>\n",
              "      <td>3.1917</td>\n",
              "      <td>73400.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-114.57</td>\n",
              "      <td>33.57</td>\n",
              "      <td>20.0</td>\n",
              "      <td>1454.0</td>\n",
              "      <td>326.0</td>\n",
              "      <td>624.0</td>\n",
              "      <td>262.0</td>\n",
              "      <td>1.9250</td>\n",
              "      <td>65500.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-62df5a98-b851-4924-8640-30bd03819925')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-62df5a98-b851-4924-8640-30bd03819925 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-62df5a98-b851-4924-8640-30bd03819925');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTVDAD2KchTv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e6a470b-33ff-4d2e-ad69-f3e0372aabca"
      },
      "source": [
        "# Remove missing data:\n",
        "\n",
        "df_train = df_train.dropna(how = 'any', axis = 'rows')\n",
        "print('New size: %d' % len(df_train))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New size: 17000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXgSHPyYcnuv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "outputId": "90b9d6f9-46d2-4cad-f71d-430d2991e8a6"
      },
      "source": [
        "# Histogram fare plot:\n",
        "\n",
        "df_train.median_house_value.hist(bins=100, figsize=(16,5), color = \"red\")\n",
        "plt.xlabel('$ US Dollars', weight = 'bold', family = 'Arial')\n",
        "plt.title('Median Californian House Price', weight = 'bold')\n",
        "plt.grid(b=None)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.font_manager:findfont: Font family ['Arial'] not found. Falling back to DejaVu Sans.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1152x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9TMSdAAjcr4o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46b62641-6905-408b-e585-6ae5d5b448e1"
      },
      "source": [
        "y = df_train.median_house_value.values + 1e-10\n",
        "y ### for supervised learning: output vector y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 66900.,  80100.,  85700., ..., 103600.,  85800.,  94600.])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FOeHvi3cu1n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "outputId": "da3235d5-08ff-4d2a-aecb-7fb643191071"
      },
      "source": [
        "# List first rows (post-cleaning):\n",
        "\n",
        "df_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
              "0    -114.31     34.19                15.0       5612.0          1283.0   \n",
              "1    -114.47     34.40                19.0       7650.0          1901.0   \n",
              "2    -114.56     33.69                17.0        720.0           174.0   \n",
              "3    -114.57     33.64                14.0       1501.0           337.0   \n",
              "4    -114.57     33.57                20.0       1454.0           326.0   \n",
              "\n",
              "   population  households  median_income  median_house_value  \n",
              "0      1015.0       472.0         1.4936             66900.0  \n",
              "1      1129.0       463.0         1.8200             80100.0  \n",
              "2       333.0       117.0         1.6509             85700.0  \n",
              "3       515.0       226.0         3.1917             73400.0  \n",
              "4       624.0       262.0         1.9250             65500.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-515d5b4a-bc92-4046-ab5f-6a5695b6f986\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>longitude</th>\n",
              "      <th>latitude</th>\n",
              "      <th>housing_median_age</th>\n",
              "      <th>total_rooms</th>\n",
              "      <th>total_bedrooms</th>\n",
              "      <th>population</th>\n",
              "      <th>households</th>\n",
              "      <th>median_income</th>\n",
              "      <th>median_house_value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-114.31</td>\n",
              "      <td>34.19</td>\n",
              "      <td>15.0</td>\n",
              "      <td>5612.0</td>\n",
              "      <td>1283.0</td>\n",
              "      <td>1015.0</td>\n",
              "      <td>472.0</td>\n",
              "      <td>1.4936</td>\n",
              "      <td>66900.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-114.47</td>\n",
              "      <td>34.40</td>\n",
              "      <td>19.0</td>\n",
              "      <td>7650.0</td>\n",
              "      <td>1901.0</td>\n",
              "      <td>1129.0</td>\n",
              "      <td>463.0</td>\n",
              "      <td>1.8200</td>\n",
              "      <td>80100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-114.56</td>\n",
              "      <td>33.69</td>\n",
              "      <td>17.0</td>\n",
              "      <td>720.0</td>\n",
              "      <td>174.0</td>\n",
              "      <td>333.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>1.6509</td>\n",
              "      <td>85700.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-114.57</td>\n",
              "      <td>33.64</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1501.0</td>\n",
              "      <td>337.0</td>\n",
              "      <td>515.0</td>\n",
              "      <td>226.0</td>\n",
              "      <td>3.1917</td>\n",
              "      <td>73400.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-114.57</td>\n",
              "      <td>33.57</td>\n",
              "      <td>20.0</td>\n",
              "      <td>1454.0</td>\n",
              "      <td>326.0</td>\n",
              "      <td>624.0</td>\n",
              "      <td>262.0</td>\n",
              "      <td>1.9250</td>\n",
              "      <td>65500.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-515d5b4a-bc92-4046-ab5f-6a5695b6f986')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-515d5b4a-bc92-4046-ab5f-6a5695b6f986 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-515d5b4a-bc92-4046-ab5f-6a5695b6f986');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-lT9BBicw4P",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "a0af0fd1-a129-43a8-bf85-28ab3ab0fe9c"
      },
      "source": [
        "X = df_train.drop(['median_house_value'], axis = 1)\n",
        "X.head() ### for supervised learning: input matrix X"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
              "0    -114.31     34.19                15.0       5612.0          1283.0   \n",
              "1    -114.47     34.40                19.0       7650.0          1901.0   \n",
              "2    -114.56     33.69                17.0        720.0           174.0   \n",
              "3    -114.57     33.64                14.0       1501.0           337.0   \n",
              "4    -114.57     33.57                20.0       1454.0           326.0   \n",
              "\n",
              "   population  households  median_income  \n",
              "0      1015.0       472.0         1.4936  \n",
              "1      1129.0       463.0         1.8200  \n",
              "2       333.0       117.0         1.6509  \n",
              "3       515.0       226.0         3.1917  \n",
              "4       624.0       262.0         1.9250  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3ecc8e3a-9db4-4834-b72f-3d2ed2f609ac\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>longitude</th>\n",
              "      <th>latitude</th>\n",
              "      <th>housing_median_age</th>\n",
              "      <th>total_rooms</th>\n",
              "      <th>total_bedrooms</th>\n",
              "      <th>population</th>\n",
              "      <th>households</th>\n",
              "      <th>median_income</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-114.31</td>\n",
              "      <td>34.19</td>\n",
              "      <td>15.0</td>\n",
              "      <td>5612.0</td>\n",
              "      <td>1283.0</td>\n",
              "      <td>1015.0</td>\n",
              "      <td>472.0</td>\n",
              "      <td>1.4936</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-114.47</td>\n",
              "      <td>34.40</td>\n",
              "      <td>19.0</td>\n",
              "      <td>7650.0</td>\n",
              "      <td>1901.0</td>\n",
              "      <td>1129.0</td>\n",
              "      <td>463.0</td>\n",
              "      <td>1.8200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-114.56</td>\n",
              "      <td>33.69</td>\n",
              "      <td>17.0</td>\n",
              "      <td>720.0</td>\n",
              "      <td>174.0</td>\n",
              "      <td>333.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>1.6509</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-114.57</td>\n",
              "      <td>33.64</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1501.0</td>\n",
              "      <td>337.0</td>\n",
              "      <td>515.0</td>\n",
              "      <td>226.0</td>\n",
              "      <td>3.1917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-114.57</td>\n",
              "      <td>33.57</td>\n",
              "      <td>20.0</td>\n",
              "      <td>1454.0</td>\n",
              "      <td>326.0</td>\n",
              "      <td>624.0</td>\n",
              "      <td>262.0</td>\n",
              "      <td>1.9250</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3ecc8e3a-9db4-4834-b72f-3d2ed2f609ac')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3ecc8e3a-9db4-4834-b72f-3d2ed2f609ac button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3ecc8e3a-9db4-4834-b72f-3d2ed2f609ac');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eC8SDPzczNY"
      },
      "source": [
        "### Optimum rmse: regression model objective function is Root Mean Square Error (RMSE); \n",
        "### Should be minimized (as close to zero as possible):\n",
        "\n",
        "y_global_orig = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GoTmWEhSc1qQ"
      },
      "source": [
        "### Bayesian Optimization - inputs:\n",
        "\n",
        "obj_func = 'XGBoost'\n",
        "n_test = 500 # test points\n",
        "\n",
        "util_gp = 'CBMinimized'\n",
        "util_stp = 'tCBMinimized'\n",
        "n_init = 5 # random initialisations\n",
        "opt = True\n",
        "\n",
        "test_perc = 0.1\n",
        "train_perc = 1 - test_perc\n",
        "\n",
        "n_test = int(len(df_train) * test_perc)\n",
        "n_train = int(len(df_train) - n_test)\n",
        "\n",
        "eps = 1e-08\n",
        "\n",
        "df = 3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2ngnRxbc7cg"
      },
      "source": [
        "### Objective function:\n",
        "\n",
        "if obj_func == 'XGBoost': # 6-D\n",
        "            \n",
        "    # Constraints:\n",
        "    param_lb_alpha = 0\n",
        "    param_ub_alpha = 10\n",
        "    \n",
        "    param_lb_gamma = 0\n",
        "    param_ub_gamma = 10\n",
        "    \n",
        "    param_lb_max_depth = 5\n",
        "    param_ub_max_depth = 15\n",
        "    \n",
        "    param_lb_min_child_weight = 1\n",
        "    param_ub_min_child_weight = 20\n",
        "    \n",
        "    param_lb_subsample = .5\n",
        "    param_ub_subsample = 1\n",
        "    \n",
        "    param_lb_colsample = .1\n",
        "    param_ub_colsample = 1\n",
        "    \n",
        "    # 6-D inputs' parameter bounds:\n",
        "    param = { 'alpha':  ('cont', (param_lb_alpha, param_ub_alpha)),\n",
        "         'gamma':  ('cont', (param_lb_gamma, param_ub_gamma)),     \n",
        "         'max_depth':  ('int', (param_lb_max_depth, param_ub_max_depth)),\n",
        "         'subsample':  ('cont', (param_lb_subsample, param_ub_subsample)),\n",
        "          'min_child_weight':  ('int', (param_lb_min_child_weight, param_ub_min_child_weight)),\n",
        "            'colsample': ('cont', (param_lb_colsample, param_ub_colsample))\n",
        "        }\n",
        "       \n",
        "    # True y bounds:\n",
        "    dim = 6\n",
        "    \n",
        "    max_iter = 30  # iterations of Bayesian optimization\n",
        "    \n",
        "    operator = 1 \n",
        "    \n",
        "    n_est = 3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3pmZYhVl9Hb"
      },
      "source": [
        "n_start_AcqFunc = max_iter\n",
        "cov_func = squaredExponential()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9ZuEB2VdE0W"
      },
      "source": [
        "### Set-seeds:\n",
        "\n",
        "run_num_1 = 1\n",
        "run_num_2 = 2\n",
        "run_num_3 = 3\n",
        "run_num_4 = 4\n",
        "run_num_5 = 5\n",
        "run_num_6 = 6\n",
        "run_num_7 = 7\n",
        "run_num_8 = 8\n",
        "run_num_9 = 9\n",
        "run_num_10 = 10\n",
        "run_num_11 = 11\n",
        "run_num_12 = 12\n",
        "run_num_13 = 13\n",
        "run_num_14 = 14\n",
        "run_num_15 = 15\n",
        "run_num_16 = 16\n",
        "run_num_17 = 17\n",
        "run_num_18 = 18\n",
        "run_num_19 = 19\n",
        "run_num_20 = 20\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XgHMFEyPdCk4"
      },
      "source": [
        "### Cumulative Regret Calculator:\n",
        "\n",
        "def min_max_array(x):\n",
        "    new_list = []\n",
        "    for i, num in enumerate(x):\n",
        "            new_list.append(np.min(x[0:i+1]))\n",
        "    return new_list\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Add exact acquisition function gradient as attribute:\n",
        "\n",
        "Beta_CBM = 1.5 #dim\n",
        "\n",
        "class Acquisition_new(Acquisition):    \n",
        "    def __init__(self, mode, eps=1e-06, **params):\n",
        "        \n",
        "        self.params = params\n",
        "        self.eps = eps\n",
        "\n",
        "        mode_dict = {\n",
        "            'CBMinimized': self.CBMinimized,\n",
        "            'tCBMinimized': self.tCBMinimized\n",
        "        }\n",
        "\n",
        "        self.f = mode_dict[mode]\n",
        "   \n",
        "    def CBMinimized(self, tau, mean, std):\n",
        "        \n",
        "        gamma = (mean - y_global_orig - self.eps) / (std + self.eps)\n",
        "        return (std + self.eps) * (gamma + np.sqrt(Beta_CBM))\n",
        "    \n",
        "    def tCBMinimized(self, tau, mean, std, nu=3.0):\n",
        "        \n",
        "        gamma = (mean - y_global_orig - self.eps) / (std + self.eps)\n",
        "        return (std + self.eps) * (gamma + np.sqrt(Beta_CBM))\n"
      ],
      "metadata": {
        "id": "ZIh5RYGkwBUZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlilveEgdIR_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db634080-af23-49a5-ca2a-1e53f65b97a5"
      },
      "source": [
        "start_gp = time.time()\n",
        "start_gp"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1663844807.0193772"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wlzDSHbUG-c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "337549bd-cdef-4645-e04a-4398a473ae7c"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'gp' Acquisition Function run number = 1\n",
        "\n",
        "np.random.seed(run_num_1)\n",
        "surrogate_gp_1 = GaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train1, X_test1, y_train1, y_test1 = train_test_split(X, y, test_size=test_perc, random_state=run_num_1)\n",
        "\n",
        "def f_syn_polarity1(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_1, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train1, y=y_train1).mean())\n",
        "    return operator * score\n",
        "\n",
        "gp_1 = GPGO(surrogate_gp_1, Acquisition_new(util_gp), f_syn_polarity1, param, n_jobs = -1) # define BayesOpt\n",
        "gp_1.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_gp_1 = gp_1.getResult()[0]\n",
        "params_gp_1['max_depth'] = int(params_gp_1['max_depth'])\n",
        "params_gp_1['min_child_weight'] = int(params_gp_1['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_gp_train1 = xgb.DMatrix(X_train1, y_train1)\n",
        "dX_gp_test1 = xgb.DMatrix(X_test1, y_test1)\n",
        "model_gp_1 = xgb.train(params_gp_1, dX_gp_train1)\n",
        "pred_gp_1 = model_gp_1.predict(dX_gp_test1)\n",
        "\n",
        "rmse_gp_1 = np.sqrt(mean_squared_error(pred_gp_1, y_test1))\n",
        "rmse_gp_1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 4.17022005  7.20324493 14.          0.65116629 16.          0.31248008]. \t  -1.6139329892980396 \t -1.3678797200853317\n",
            "init   \t [ 3.96580727  3.87910741 11.          0.96776954  6.          0.71669755]. \t  -1.4460566998267423 \t -1.3678797200853317\n",
            "init   \t [ 2.0445225   8.78117436  7.          0.95698101 10.          0.48762871]. \t  -1.5755054668571844 \t -1.3678797200853317\n",
            "init   \t [ 9.39127789  7.78389236 14.          0.98413079  2.          0.87851823]. \t  -1.3678797200853317 \t -1.3678797200853317\n",
            "init   \t [8.29146907 8.29603359 8.         0.58491521 9.         0.18851215]. \t  -1.6515361212564685 \t -1.3678797200853317\n",
            "1      \t [ 7.86951474  0.6406733  11.          0.78919481 19.          0.44182296]. \t  -1.5598734918230905 \t -1.3678797200853317\n",
            "2      \t [ 1.53213416  0.0254654   5.          0.89591052 19.          0.80006363]. \t  -1.4345643510991433 \t -1.3678797200853317\n",
            "3      \t [ 1.50183822  8.58761638 10.          0.99635044  4.          0.82916307]. \t  -1.3996258462682616 \t -1.3678797200853317\n",
            "4      \t [ 5.65732147  9.08808032  6.          0.69595029 18.          0.83818222]. \t  -1.4285184283194432 \t -1.3678797200853317\n",
            "5      \t [9.98806418 1.50440675 6.         0.54760374 1.         0.41555547]. \t  -1.586246485916007 \t -1.3678797200853317\n",
            "6      \t [ 6.24179723  2.64836655 10.          0.81947391  1.          0.33673458]. \t  -1.6145197451691538 \t -1.3678797200853317\n",
            "7      \t [8.6650221  9.45569726 5.         0.8687539  2.         0.61530184]. \t  -1.5322061877126625 \t -1.3678797200853317\n",
            "8      \t [7.97575021 5.80400652 6.         0.87295046 5.         0.38399845]. \t  -1.5836075710279964 \t -1.3678797200853317\n",
            "9      \t [ 9.36604818  1.94992428 14.          0.76772352  6.          0.21757078]. \t  -1.6503086764937163 \t -1.3678797200853317\n",
            "10     \t [ 6.90531581  0.79289494  5.          0.9449601  15.          0.87962791]. \t  -1.4247418774620022 \t -1.3678797200853317\n",
            "11     \t [0.00729349 0.2106352  5.         0.83783904 2.         0.22549491]. \t  -1.6541036852200945 \t -1.3678797200853317\n",
            "12     \t [ 0.45906059  0.26611017  8.          0.58032353 12.          0.22425355]. \t  -1.6520299291139036 \t -1.3678797200853317\n",
            "13     \t [ 0.18852046  4.72346213  9.          0.50650796 17.          0.38993772]. \t  -1.5696076533584669 \t -1.3678797200853317\n",
            "14     \t [ 7.52390886  2.64954422 11.          0.6015     12.          0.85038067]. \t  -1.4059827776794123 \t -1.3678797200853317\n",
            "15     \t [ 9.86204333  8.60405361 11.          0.80139835 15.          0.34648534]. \t  -1.612487470274953 \t -1.3678797200853317\n",
            "16     \t [3.27513171 5.82385842 5.         0.75636223 1.         0.61631619]. \t  -1.5326233413720243 \t -1.3678797200853317\n",
            "17     \t [ 1.02343527  0.5518211  13.          0.59111056 19.          0.5850565 ]. \t  -1.506486849915985 \t -1.3678797200853317\n",
            "18     \t [8.64050344 1.82173909 5.         0.83164376 9.         0.64260402]. \t  -1.4951909789662494 \t -1.3678797200853317\n",
            "19     \t [ 1.60277226  4.47727324 12.          0.85573582 11.          0.44008307]. \t  -1.5597631696194434 \t -1.3678797200853317\n",
            "20     \t [ 6.86004863  8.41027685 14.          0.56621165  6.93764832  0.73494511]. \t  -1.4557066975183344 \t -1.3678797200853317\n",
            "21     \t [ 7.26077517  6.12663875  5.          0.88530553 13.          0.85587133]. \t  -1.4356084923494852 \t -1.3678797200853317\n",
            "22     \t [ 0.09257908  4.29655963 12.          0.98972055  1.          0.90266783]. \t  -1.3687669027835168 \t -1.3678797200853317\n",
            "23     \t [0.         8.73833586 5.         0.69288878 4.7781157  1.        ]. \t  -1.429713618440168 \t -1.3678797200853317\n",
            "24     \t [10.          6.22999677  8.760246    1.          1.          0.1       ]. \t  -1.6554586328110594 \t -1.3678797200853317\n",
            "25     \t [ 0.18256843  9.80114086 11.          0.99093287 18.          0.37632134]. \t  -1.5582545255021636 \t -1.3678797200853317\n",
            "26     \t [ 0.45997981  0.06225002 14.          0.83843842  5.          0.61806168]. \t  -1.5118267120599522 \t -1.3678797200853317\n",
            "27     \t [ 3.29954726  8.04138761 14.          0.78387363  1.          0.45823253]. \t  -1.5716984080931646 \t -1.3678797200853317\n",
            "28     \t [8.88745872 1.7155124  9.         0.56955413 5.         0.81074564]. \t  -1.408649807316293 \t -1.3678797200853317\n",
            "29     \t [ 7.28587864  2.24783242 14.          0.73021029 12.          0.81296805]. \t  -1.4022025838970784 \t -1.3678797200853317\n",
            "30     \t [ 1.18252266 10.         11.59090557  1.         12.64249483  1.        ]. \t  -1.3682228046809972 \t -1.3678797200853317\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "48973.66312746987"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClJ9rN2KUJzy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1866bca5-c99b-4208-d4c3-d1daffbbac78"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'gp' Acquisition Function run number = 2\n",
        "\n",
        "np.random.seed(run_num_2)\n",
        "surrogate_gp_2 = GaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(X, y, test_size=test_perc, random_state=run_num_2)\n",
        "\n",
        "def f_syn_polarity2(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_2, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train2, y=y_train2).mean())\n",
        "    return operator * score\n",
        "\n",
        "gp_2 = GPGO(surrogate_gp_2, Acquisition_new(util_gp), f_syn_polarity2, param, n_jobs = -1) # define BayesOpt\n",
        "gp_2.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_gp_2 = gp_2.getResult()[0]\n",
        "params_gp_2['max_depth'] = int(params_gp_2['max_depth'])\n",
        "params_gp_2['min_child_weight'] = int(params_gp_2['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_gp_train2 = xgb.DMatrix(X_train2, y_train2)\n",
        "dX_gp_test2 = xgb.DMatrix(X_test2, y_test2)\n",
        "model_gp_2 = xgb.train(params_gp_2, dX_gp_train2)\n",
        "pred_gp_2 = model_gp_2.predict(dX_gp_test2)\n",
        "\n",
        "rmse_gp_2 = np.sqrt(mean_squared_error(pred_gp_2, y_test2))\n",
        "rmse_gp_2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 4.35994902  0.25926232 11.          0.97386531 12.          0.47833102]. \t  -1.4860127799448324 \t -1.4169097144768446\n",
            "init   \t [ 3.30334821  2.04648634 10.          0.55997527  6.          0.71472339]. \t  -1.4169097144768446 \t -1.4169097144768446\n",
            "init   \t [ 4.9856117   5.86796978  8.          0.89266757 11.          0.59158659]. \t  -1.4327785108491773 \t -1.4169097144768446\n",
            "init   \t [ 4.07307832  1.76984624 13.          0.75262305  7.          0.35908193]. \t  -1.5060418558860291 \t -1.4169097144768446\n",
            "init   \t [ 1.16193318  1.81727038  9.          0.79837265 19.          0.29965165]. \t  -1.5035568847025498 \t -1.4169097144768446\n",
            "1      \t [9.68290573 5.74953535 8.         0.93445831 2.         0.81872709]. \t  \u001b[92m-1.410960072516526\u001b[0m \t -1.410960072516526\n",
            "2      \t [ 8.78180153  6.61060882 12.          0.91523653 18.          0.29687212]. \t  -1.5013572260649615 \t -1.410960072516526\n",
            "3      \t [ 0.66591974  9.26661294 14.          0.96342421 18.          0.94909068]. \t  \u001b[92m-1.390328162245039\u001b[0m \t -1.390328162245039\n",
            "4      \t [0.53023554 8.79041977 6.         0.85342606 1.         0.93968064]. \t  -1.4201040141226167 \t -1.390328162245039\n",
            "5      \t [ 2.90965473  9.60484926 14.          0.96745917  2.          0.76388947]. \t  -1.4076008242378815 \t -1.390328162245039\n",
            "6      \t [ 8.57602235  9.83360074 12.          0.99133635  7.          0.25584574]. \t  -1.500520260093468 \t -1.390328162245039\n",
            "7      \t [ 9.77744834  2.26597384  5.          0.98618685 19.          0.58642903]. \t  -1.4646927872213165 \t -1.390328162245039\n",
            "8      \t [ 1.82124551  9.97992306  7.          0.66460563 15.          0.68270076]. \t  -1.4240667703875103 \t -1.390328162245039\n",
            "9      \t [ 5.76886466  6.30636441 11.          0.85075313  6.          0.94564556]. \t  -1.394084837946688 \t -1.390328162245039\n",
            "10     \t [ 0.92680624  0.80829442  5.          0.99163751 10.          0.48273491]. \t  -1.5007102989702947 \t -1.390328162245039\n",
            "11     \t [ 8.66397635  9.94226364  5.          0.61754568 19.          0.46861962]. \t  -1.5035673307420439 \t -1.390328162245039\n",
            "12     \t [ 0.03855324  8.9930469  12.          0.98249334  8.          0.88557845]. \t  \u001b[92m-1.390252227653465\u001b[0m \t -1.390252227653465\n",
            "13     \t [ 9.78109337  2.52726344  5.          0.62902817 11.          0.70291169]. \t  -1.441326058232906 \t -1.390252227653465\n",
            "14     \t [ 2.61078484  8.48438058 14.          0.79784401 12.          0.37480602]. \t  -1.5047091743524688 \t -1.390252227653465\n",
            "15     \t [ 8.35914343  2.39349698 13.          0.9820231   1.          0.65048694]. \t  -1.4140715095141794 \t -1.390252227653465\n",
            "16     \t [9.62212538 0.02188724 6.         0.71871951 5.         0.99422834]. \t  -1.4220547117497682 \t -1.390252227653465\n",
            "17     \t [1.70838606 1.7073017  5.         0.64676695 1.         0.90384668]. \t  -1.4360013522947241 \t -1.390252227653465\n",
            "18     \t [ 8.08580133  4.76452432 13.          0.87438829 11.          0.13864055]. \t  -1.506691281547808 \t -1.390252227653465\n",
            "19     \t [5.71127179 8.62909383 6.         0.9145048  4.         0.23844251]. \t  -1.5085145831548314 \t -1.390252227653465\n",
            "20     \t [ 0.40164348  1.66439141 14.          0.96476321  1.          0.14148109]. \t  -1.5053383318864 \t -1.390252227653465\n",
            "21     \t [ 9.65372179  0.75820772 11.          0.87845932  8.          0.76871909]. \t  -1.4081514304897453 \t -1.390252227653465\n",
            "22     \t [ 9.82502828  9.60705161  7.          0.82204279 10.          0.53606301]. \t  -1.4430713311807182 \t -1.390252227653465\n",
            "23     \t [ 8.20282777  1.10989571 14.          0.76173732 19.          0.96560411]. \t  -1.396141109696305 \t -1.390252227653465\n",
            "24     \t [ 9.52708013  8.87907405 14.          0.61965333  2.          0.85399372]. \t  -1.4143808966092173 \t -1.390252227653465\n",
            "25     \t [ 0.          3.90857795 12.85656044  0.5        10.47726396  1.        ]. \t  -1.3943815991323991 \t -1.390252227653465\n",
            "26     \t [ 1.76132165  0.         15.          1.         19.05432821  0.1       ]. \t  -1.5636768137654127 \t -1.390252227653465\n",
            "27     \t [ 2.36111081 10.          6.48376022  0.5         8.42854931  0.65023182]. \t  -1.433608597173365 \t -1.390252227653465\n",
            "28     \t [ 3.59503153  3.0430168   6.          0.69422875 15.          0.61511341]. \t  -1.4546410386319057 \t -1.390252227653465\n",
            "29     \t [ 4.50289646  9.52028371 10.          0.92016613 19.          0.98574835]. \t  -1.395192733428693 \t -1.390252227653465\n",
            "30     \t [ 4.44907567  5.42728735 15.          0.5        15.96912287  0.1       ]. \t  -1.5078732515968956 \t -1.390252227653465\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "48495.7639648715"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-45l3NU4UNiI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f35fbb6d-1d80-4af1-c4f9-0e94125e266a"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'gp' Acquisition Function run number = 3\n",
        "\n",
        "np.random.seed(run_num_3)\n",
        "surrogate_gp_3 = GaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train3, X_test3, y_train3, y_test3 = train_test_split(X, y, test_size=test_perc, random_state=run_num_3)\n",
        "\n",
        "def f_syn_polarity3(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_3, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train3, y=y_train3).mean())\n",
        "    return operator * score\n",
        "\n",
        "gp_3 = GPGO(surrogate_gp_3, Acquisition_new(util_gp), f_syn_polarity3, param, n_jobs = -1) # define BayesOpt\n",
        "gp_3.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_gp_3 = gp_3.getResult()[0]\n",
        "params_gp_3['max_depth'] = int(params_gp_3['max_depth'])\n",
        "params_gp_3['min_child_weight'] = int(params_gp_3['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_gp_train3 = xgb.DMatrix(X_train3, y_train3)\n",
        "dX_gp_test3 = xgb.DMatrix(X_test3, y_test3)\n",
        "model_gp_3 = xgb.train(params_gp_3, dX_gp_train3)\n",
        "pred_gp_3 = model_gp_3.predict(dX_gp_test3)\n",
        "\n",
        "rmse_gp_3 = np.sqrt(mean_squared_error(pred_gp_3, y_test3))\n",
        "rmse_gp_3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 5.50797903  7.08147823 13.          0.56066429 11.          0.11687321]. \t  -1.658976916292621 \t -1.5210450722954243\n",
            "init   \t [ 0.40630737  2.47888297 11.          0.72040492 13.          0.23083313]. \t  -1.6618243503452674 \t -1.5210450722954243\n",
            "init   \t [ 4.53172301  2.15577008 11.          0.74631796  2.          0.60296868]. \t  -1.5210450722954243 \t -1.5210450722954243\n",
            "init   \t [ 2.59252447  4.15101197 13.          0.79330998  8.          0.24118096]. \t  -1.6631154838515818 \t -1.5210450722954243\n",
            "init   \t [ 5.44649018  7.80314765 10.          0.62879264 18.          0.44917413]. \t  -1.5829020757643195 \t -1.5210450722954243\n",
            "1      \t [4.88873245 9.27936348 6.         0.94344906 8.         0.25949204]. \t  -1.6501981990436252 \t -1.5210450722954243\n",
            "2      \t [ 8.93142368  1.52910591 13.          0.84039318 17.          0.60846833]. \t  \u001b[92m-1.5092574325498493\u001b[0m \t -1.5092574325498493\n",
            "3      \t [ 6.38594331  1.19109066  5.          0.81189053 13.          0.59164768]. \t  -1.5410004357692944 \t -1.5092574325498493\n",
            "4      \t [ 1.02918863  9.32189805 13.          0.88333707  1.          0.86998588]. \t  \u001b[92m-1.439706732811691\u001b[0m \t -1.439706732811691\n",
            "5      \t [ 9.74929058  1.51205926 11.          0.50025602  8.          0.46132437]. \t  -1.59016257705781 \t -1.439706732811691\n",
            "6      \t [ 9.45052852  8.62641484  7.          0.79615518 14.          0.32790361]. \t  -1.6501290215812254 \t -1.439706732811691\n",
            "7      \t [ 8.92744991  9.09956287 12.          0.74944313  3.          0.11030352]. \t  -1.6643689223331695 \t -1.439706732811691\n",
            "8      \t [0.28002919 1.86471402 5.         0.90893429 3.         0.44808833]. \t  -1.5972277209590486 \t -1.439706732811691\n",
            "9      \t [ 2.50233267  5.65022453 13.          0.972061   12.          0.65081115]. \t  -1.4662483354999793 \t -1.439706732811691\n",
            "10     \t [9.43215663 9.14652183 5.         0.95117899 1.         0.516629  ]. \t  -1.5404665240025386 \t -1.439706732811691\n",
            "11     \t [ 2.84857043  0.57472701  5.          0.53705172 19.          0.51858228]. \t  -1.5388327686383294 \t -1.439706732811691\n",
            "12     \t [ 0.63346059  9.87550877  6.          0.74382195 14.          0.39340576]. \t  -1.5920660091084768 \t -1.439706732811691\n",
            "13     \t [2.99254427 2.69228882 7.         0.63915731 9.         0.21678027]. \t  -1.6628491561530567 \t -1.439706732811691\n",
            "14     \t [8.8237369  0.04240955 5.         0.7158964  1.         0.99950517]. \t  \u001b[92m-1.4386279807964175\u001b[0m \t -1.4386279807964175\n",
            "15     \t [ 5.16407823  0.21306793  9.          0.64072128 15.          0.97949486]. \t  \u001b[92m-1.408906333951487\u001b[0m \t -1.408906333951487\n",
            "16     \t [9.25339855 3.80341124 5.         0.92679998 9.         0.56391072]. \t  -1.5412797015838162 \t -1.408906333951487\n",
            "17     \t [ 0.94336997  1.29293405 12.          0.62917786 19.          0.81056172]. \t  -1.432235043083774 \t -1.408906333951487\n",
            "18     \t [0.6517745  8.4352119  5.         0.65405414 2.         0.41089997]. \t  -1.5972466187187164 \t -1.408906333951487\n",
            "19     \t [ 9.8542409   3.34207335 14.          0.75035548  3.          0.6035725 ]. \t  -1.5233046302364048 \t -1.408906333951487\n",
            "20     \t [ 3.60954441  5.81173439  5.          0.60415615 17.          0.56274483]. \t  -1.5367842962083376 \t -1.408906333951487\n",
            "21     \t [ 6.40272995  1.06358237 14.          0.62818522 12.          0.41787453]. \t  -1.5855193401996872 \t -1.408906333951487\n",
            "22     \t [ 8.39294544  7.99689894 15.          0.9894595  16.75547096  0.48893707]. \t  -1.5784116475184824 \t -1.408906333951487\n",
            "23     \t [ 9.78167745  1.27204532  5.          0.70251342 19.          0.96277306]. \t  -1.4398248105458875 \t -1.408906333951487\n",
            "24     \t [1.52170238 5.56235877 9.         0.83783695 5.         0.52222813]. \t  -1.5157437069758977 \t -1.408906333951487\n",
            "25     \t [ 0.2751438   0.01326429 12.          0.57681507  4.          0.18289652]. \t  -1.6606586644279537 \t -1.408906333951487\n",
            "26     \t [ 9.57846798  5.67492818 11.          0.9450323  15.          0.64577167]. \t  -1.461678563063694 \t -1.408906333951487\n",
            "27     \t [ 9.8165296   6.20631181  7.          0.5503895  19.          0.99977881]. \t  -1.4211742765510988 \t -1.408906333951487\n",
            "28     \t [ 1.49730247  0.83144325 14.          0.60476723  9.          0.25549349]. \t  -1.6530168191774848 \t -1.408906333951487\n",
            "29     \t [5.8694186  4.60882741 5.         1.         4.08937257 0.1       ]. \t  -1.662419469891855 \t -1.408906333951487\n",
            "30     \t [ 1.39598812  9.90188838 13.          0.61873715  9.          0.19633416]. \t  -1.6602629591139597 \t -1.408906333951487\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49855.66398330986"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "voPfk1UDUQU0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9543218c-c824-44b7-cc64-534d2bba99da"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'gp' Acquisition Function run number = 4\n",
        "\n",
        "np.random.seed(run_num_4)\n",
        "surrogate_gp_4 = GaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train4, X_test4, y_train4, y_test4 = train_test_split(X, y, test_size=test_perc, random_state=run_num_4)\n",
        "\n",
        "def f_syn_polarity4(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_4, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train4, y=y_train4).mean())\n",
        "    return operator * score\n",
        "\n",
        "gp_4 = GPGO(surrogate_gp_4, Acquisition_new(util_gp), f_syn_polarity4, param, n_jobs = -1) # define BayesOpt\n",
        "gp_4.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_gp_4 = gp_4.getResult()[0]\n",
        "params_gp_4['max_depth'] = int(params_gp_4['max_depth'])\n",
        "params_gp_4['min_child_weight'] = int(params_gp_4['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_gp_train4 = xgb.DMatrix(X_train4, y_train4)\n",
        "dX_gp_test4 = xgb.DMatrix(X_test4, y_test4)\n",
        "model_gp_4 = xgb.train(params_gp_4, dX_gp_train4)\n",
        "pred_gp_4 = model_gp_4.predict(dX_gp_test4)\n",
        "\n",
        "rmse_gp_4 = np.sqrt(mean_squared_error(pred_gp_4, y_test4))\n",
        "rmse_gp_4"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [9.67029839 5.47232249 6.         0.92781047 9.         0.72795594]. \t  -1.4430569076610322 \t -1.38492629511548\n",
            "init   \t [ 2.16089496  9.76274455 12.          0.62649118  9.          0.66966679]. \t  -1.4187070295885058 \t -1.38492629511548\n",
            "init   \t [ 0.05159149  5.72356491  9.          0.99170034 10.          0.10808749]. \t  -1.6911169704550582 \t -1.38492629511548\n",
            "init   \t [ 3.86571283  0.44160058 10.          0.90553105 18.          0.95407958]. \t  -1.38492629511548 \t -1.38492629511548\n",
            "init   \t [ 7.86305986  8.66289299  6.          0.53285477 14.          0.25117497]. \t  -1.557078690359533 \t -1.38492629511548\n",
            "1      \t [ 8.45443649  8.61014312 11.          0.83475494  1.          0.14018305]. \t  -1.6919233052610914 \t -1.38492629511548\n",
            "2      \t [ 9.55101363  6.99634383 11.          0.90625635 13.          0.71296594]. \t  -1.410715515363325 \t -1.38492629511548\n",
            "3      \t [0.6226627  4.92286423 6.         0.98206698 1.         0.51413802]. \t  -1.464510330325681 \t -1.38492629511548\n",
            "4      \t [ 4.4716856   2.9455437  14.          0.69787049  4.          0.17791454]. \t  -1.6927142453134727 \t -1.38492629511548\n",
            "5      \t [ 1.88634477  6.88806857 14.          0.85788793 18.          0.9393565 ]. \t  \u001b[92m-1.3831439580282818\u001b[0m \t -1.3831439580282818\n",
            "6      \t [ 1.90363379  0.17398374 14.          0.70399728 12.          0.8996527 ]. \t  -1.3847872876333995 \t -1.3831439580282818\n",
            "7      \t [ 0.79250634  6.36332745  6.          0.84703891 17.          0.8628914 ]. \t  -1.4448878111930763 \t -1.3831439580282818\n",
            "8      \t [9.26767626 0.09691703 5.         0.59554562 3.         0.95249041]. \t  -1.4324314656379458 \t -1.3831439580282818\n",
            "9      \t [ 8.9794725   0.03075938 11.          0.54769472  8.          0.98530081]. \t  -1.395793879521598 \t -1.3831439580282818\n",
            "10     \t [3.43076773 0.51115291 6.         0.80398076 7.         0.163561  ]. \t  -1.6908218618918773 \t -1.3831439580282818\n",
            "11     \t [ 9.49700512  3.76022933  5.          0.67589324 19.          0.87143471]. \t  -1.4674125011286119 \t -1.3831439580282818\n",
            "12     \t [ 6.03647398  5.02077859  7.          0.51964174 12.          0.90396407]. \t  -1.4052934473455991 \t -1.3831439580282818\n",
            "13     \t [9.08552417 8.21603276 5.         0.9484502  3.         0.34767457]. \t  -1.5560902612428715 \t -1.3831439580282818\n",
            "14     \t [ 9.29091353  0.24848851 14.          0.65742606 17.          0.33836791]. \t  -1.5593858693380156 \t -1.3831439580282818\n",
            "15     \t [ 8.60378966  6.96017126 14.          0.52818131 19.          0.40796127]. \t  -1.509131199008714 \t -1.3831439580282818\n",
            "16     \t [ 2.02212851  9.9407933  10.          0.71009222  3.          0.59925198]. \t  -1.438966807510655 \t -1.3831439580282818\n",
            "17     \t [ 7.85427932  8.81949282 14.          0.936894    6.          0.6768425 ]. \t  -1.4146429889777234 \t -1.3831439580282818\n",
            "18     \t [ 6.65760625  2.35253217 11.          0.58483338 14.          0.21088543]. \t  -1.6903944266354756 \t -1.3831439580282818\n",
            "19     \t [2.49881659 8.67542232 6.         0.73013729 7.         0.53552532]. \t  -1.4664389892749103 \t -1.3831439580282818\n",
            "20     \t [ 0.65787882  1.52536753  7.          0.582989   13.          0.8348692 ]. \t  -1.4332539296790092 \t -1.3831439580282818\n",
            "21     \t [3.55038264e-03 5.28840138e-01 1.20000000e+01 6.40411100e-01\n",
            " 2.00000000e+00 4.44593025e-01]. \t  -1.5135040626039693 \t -1.3831439580282818\n",
            "22     \t [ 4.87796269  9.76915883  8.          0.70370432 19.          0.96700567]. \t  -1.395278077009085 \t -1.3831439580282818\n",
            "23     \t [ 9.81651939  0.09554533 12.          0.83243918  2.          0.50892162]. \t  -1.4356022494971612 \t -1.3831439580282818\n",
            "24     \t [ 8.58299287  0.          6.93840764  1.         12.00489631  0.1       ]. \t  -1.6905433611007084 \t -1.3831439580282818\n",
            "25     \t [ 4.21831435  8.61967339 11.          0.89773152 14.          0.74417938]. \t  -1.411590470443056 \t -1.3831439580282818\n",
            "26     \t [ 0.          4.76706818 12.8721721   0.5        13.43249698  0.1       ]. \t  -1.6934684402959035 \t -1.3831439580282818\n",
            "27     \t [ 5.73131934  4.91766705 11.          0.79884772  8.          0.85361293]. \t  -1.4162174195326234 \t -1.3831439580282818\n",
            "28     \t [ 3.44214135  8.32661064 14.65302955  1.          2.5534425   1.        ]. \t  \u001b[92m-1.3675752594143014\u001b[0m \t -1.3675752594143014\n",
            "29     \t [ 3.47524976  9.27226861 12.          0.90347022 15.          0.17738131]. \t  -1.690727456238977 \t -1.3675752594143014\n",
            "30     \t [10.          4.57078575 15.          1.          9.6401462   0.1       ]. \t  -1.6914269972652722 \t -1.3675752594143014\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "51302.62836089506"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kEnTd7MUdlv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61477dde-4f6a-488d-8b1e-89043377045f"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'gp' Acquisition Function run number = 5\n",
        "\n",
        "np.random.seed(run_num_5)\n",
        "surrogate_gp_5 = GaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train5, X_test5, y_train5, y_test5 = train_test_split(X, y, test_size=test_perc, random_state=run_num_5)\n",
        "\n",
        "def f_syn_polarity5(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_5, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train5, y=y_train5).mean())\n",
        "    return operator * score\n",
        "\n",
        "gp_5 = GPGO(surrogate_gp_5, Acquisition_new(util_gp), f_syn_polarity5, param, n_jobs = -1) # define BayesOpt\n",
        "gp_5.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_gp_5 = gp_5.getResult()[0]\n",
        "params_gp_5['max_depth'] = int(params_gp_5['max_depth'])\n",
        "params_gp_5['min_child_weight'] = int(params_gp_5['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_gp_train5 = xgb.DMatrix(X_train5, y_train5)\n",
        "dX_gp_test5 = xgb.DMatrix(X_test5, y_test5)\n",
        "model_gp_5 = xgb.train(params_gp_5, dX_gp_train5)\n",
        "pred_gp_5 = model_gp_5.predict(dX_gp_test5)\n",
        "\n",
        "rmse_gp_5 = np.sqrt(mean_squared_error(pred_gp_5, y_test5))\n",
        "rmse_gp_5"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 2.21993171  8.70732306 11.          0.68186845 10.          0.53957007]. \t  -1.437240644949997 \t -1.4314427524402045\n",
            "init   \t [ 6.11743863  7.65907856  5.          0.64840025 16.          0.82745351]. \t  -1.4314427524402045 \t -1.4314427524402045\n",
            "init   \t [ 6.49458883  8.19472793  6.          0.93996852 19.          0.36647194]. \t  -1.5681212058087062 \t -1.4314427524402045\n",
            "init   \t [ 6.28787909  5.7983781   6.          0.63290956 17.          0.18402673]. \t  -1.571097153432666 \t -1.4314427524402045\n",
            "init   \t [8.26554249 8.33492742 9.         0.97900675 3.         0.26957319]. \t  -1.5587909137089784 \t -1.4314427524402045\n",
            "1      \t [1.95474956 1.21548467 5.         0.65548996 6.         0.3261206 ]. \t  -1.5743532080703466 \t -1.4314427524402045\n",
            "2      \t [ 0.09956678  5.3014067  14.          0.6298658  17.          0.94976952]. \t  \u001b[92m-1.3952193294969657\u001b[0m \t -1.3952193294969657\n",
            "3      \t [ 8.96005069  0.40158558 13.          0.99993231  1.          0.57714848]. \t  -1.4354830630513837 \t -1.3952193294969657\n",
            "4      \t [ 9.87326458  3.08165071 13.          0.89537491 17.          0.48678657]. \t  -1.4780743495369868 \t -1.3952193294969657\n",
            "5      \t [ 0.42801231  0.53056997 14.          0.88001393  3.          0.60870677]. \t  -1.437822937474437 \t -1.3952193294969657\n",
            "6      \t [ 9.41789049  5.24678791 11.          0.78426601 10.          0.31189288]. \t  -1.5613050777466426 \t -1.3952193294969657\n",
            "7      \t [ 0.15773168  2.32643207  7.          0.74406654 13.          0.24500907]. \t  -1.5672014346319914 \t -1.3952193294969657\n",
            "8      \t [ 0.5259471   9.7567347  14.          0.91097263  1.          0.64281486]. \t  -1.3958511727899978 \t -1.3952193294969657\n",
            "9      \t [ 7.68019847  0.14272251  5.          0.84271757 13.          0.46064437]. \t  -1.5068069699486835 \t -1.3952193294969657\n",
            "10     \t [1.24717977 9.40645683 5.         0.65383928 3.         0.68852908]. \t  -1.4316511120811846 \t -1.3952193294969657\n",
            "11     \t [8.5765283  1.77730566 7.         0.63994635 4.         0.42153661]. \t  -1.491819528735433 \t -1.3952193294969657\n",
            "12     \t [7.9980796  9.13466128 6.         0.81085598 9.         0.18640376]. \t  -1.5735984894720563 \t -1.3952193294969657\n",
            "13     \t [ 5.39228464  0.17784539 13.          0.57001227  9.          0.60313835]. \t  -1.4407452364616864 \t -1.3952193294969657\n",
            "14     \t [ 3.9042494   1.34731655 10.          0.83969498 18.          0.52845925]. \t  -1.4355450531766754 \t -1.3952193294969657\n",
            "15     \t [ 0.         10.          5.          1.         10.02904528  1.        ]. \t  -1.420492729531722 \t -1.3952193294969657\n",
            "16     \t [ 7.87772257  8.71340044 12.          0.8589136  15.          0.7305315 ]. \t  \u001b[92m-1.3895543192412831\u001b[0m \t -1.3895543192412831\n",
            "17     \t [ 2.69799571  4.11635768 10.          0.52379148  1.          0.50396624]. \t  -1.4470155770157886 \t -1.3895543192412831\n",
            "18     \t [ 7.17986799  9.26077659 14.          0.86343845  7.          0.73398847]. \t  -1.391733996303619 \t -1.3895543192412831\n",
            "19     \t [ 3.67285876  4.02281152 12.          0.74204243 13.          0.68426689]. \t  -1.3932528770859998 \t -1.3895543192412831\n",
            "20     \t [5.04402526 4.31256329 8.         0.99408623 8.         0.14099051]. \t  -1.563088428761723 \t -1.3895543192412831\n",
            "21     \t [0.  0.  5.  0.5 1.  1. ]. \t  -1.4206263401916293 \t -1.3895543192412831\n",
            "22     \t [ 0.60794936  9.70046112  9.          0.6774471  17.          0.19815335]. \t  -1.5623918621840538 \t -1.3895543192412831\n",
            "23     \t [ 5.90196834  7.02558993 13.0830812   0.5        20.          1.        ]. \t  \u001b[92m-1.381381766269247\u001b[0m \t -1.381381766269247\n",
            "24     \t [ 0.          9.71391937 10.25197958  1.          4.96215694  0.1       ]. \t  -1.5923497157168716 \t -1.381381766269247\n",
            "25     \t [ 0.09378584  0.46225465  6.          0.94133859 19.          0.52002331]. \t  -1.463000157761675 \t -1.381381766269247\n",
            "26     \t [10.          9.16735408 14.17860986  0.57303202  1.          0.29033196]. \t  -1.5726553333039561 \t -1.381381766269247\n",
            "27     \t [ 3.27568033 10.         15.          0.5        14.99997163  0.1       ]. \t  -1.5623236835944918 \t -1.381381766269247\n",
            "28     \t [ 8.43934599  0.8447506   5.          0.83249299 19.          0.31289567]. \t  -1.5742085459806785 \t -1.381381766269247\n",
            "29     \t [ 0.503779    6.02389217  5.          0.5        20.          1.        ]. \t  -1.420441771577347 \t -1.381381766269247\n",
            "30     \t [ 3.07114412  0.         15.          0.5        17.          1.        ]. \t  \u001b[92m-1.3812469390414557\u001b[0m \t -1.3812469390414557\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "52341.20396827942"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjVSH6caUgyy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "128ceef7-002b-43f2-a65e-3e5291a7d32b"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'gp' Acquisition Function run number = 6\n",
        "\n",
        "np.random.seed(run_num_6)\n",
        "surrogate_gp_6 = GaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train6, X_test6, y_train6, y_test6 = train_test_split(X, y, test_size=test_perc, random_state=run_num_6)\n",
        "\n",
        "def f_syn_polarity6(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_6, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train6, y=y_train6).mean())\n",
        "    return operator * score\n",
        "\n",
        "gp_6 = GPGO(surrogate_gp_6, Acquisition_new(util_gp), f_syn_polarity6, param, n_jobs = -1) # define BayesOpt\n",
        "gp_6.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_gp_6 = gp_6.getResult()[0]\n",
        "params_gp_6['max_depth'] = int(params_gp_6['max_depth'])\n",
        "params_gp_6['min_child_weight'] = int(params_gp_6['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_gp_train6 = xgb.DMatrix(X_train6, y_train6)\n",
        "dX_gp_test6 = xgb.DMatrix(X_test6, y_test6)\n",
        "model_gp_6 = xgb.train(params_gp_6, dX_gp_train6)\n",
        "pred_gp_6 = model_gp_6.predict(dX_gp_test6)\n",
        "\n",
        "rmse_gp_6 = np.sqrt(mean_squared_error(pred_gp_6, y_test6))\n",
        "rmse_gp_6"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [8.92860151 3.31979805 5.         0.99251441 2.         0.57683563]. \t  -1.5190535184382172 \t -1.467261064668007\n",
            "init   \t [4.18807429 3.35407849 9.         0.87750649 3.         0.56623277]. \t  -1.5046102560432295 \t -1.467261064668007\n",
            "init   \t [ 5.788586    6.45355096 14.          0.70660047 12.          0.82154882]. \t  -1.467261064668007 \t -1.467261064668007\n",
            "init   \t [4.58184578 6.73834679 5.         0.90108528 3.         0.65482895]. \t  -1.5215270866416617 \t -1.467261064668007\n",
            "init   \t [ 4.42510505  5.75952352 14.          0.97882365 15.          0.29525604]. \t  -1.664748595544141 \t -1.467261064668007\n",
            "1      \t [ 2.61343239  0.80193947  5.          0.83898129 13.          0.84644718]. \t  -1.503282313171498 \t -1.467261064668007\n",
            "2      \t [ 9.72322443  9.21177696  5.          0.87917074 11.          0.86681736]. \t  -1.5025549146464172 \t -1.467261064668007\n",
            "3      \t [ 5.94160899  0.75325837 13.          0.80313713  9.          0.38465378]. \t  -1.6229119422918337 \t -1.467261064668007\n",
            "4      \t [ 2.98453858  8.8700865   6.          0.73955182 19.          0.28620498]. \t  -1.6585576125101582 \t -1.467261064668007\n",
            "5      \t [ 9.98276075  2.51129284  8.          0.78524028 18.          0.90705498]. \t  \u001b[92m-1.4090769719454428\u001b[0m \t -1.4090769719454428\n",
            "6      \t [ 0.58299146  9.62458538  9.          0.94830232 11.          0.21492907]. \t  -1.6930001706622346 \t -1.4090769719454428\n",
            "7      \t [ 9.32984285  9.13994472 13.          0.80971831  3.          0.95492455]. \t  \u001b[92m-1.4037534194516463\u001b[0m \t -1.4037534194516463\n",
            "8      \t [ 9.32420466  6.39616005 13.          0.93300527 17.          0.34904443]. \t  -1.6629223928531551 \t -1.4037534194516463\n",
            "9      \t [ 2.3330023   9.76264059 12.          0.88161689  4.          0.98638718]. \t  \u001b[92m-1.4010082389964054\u001b[0m \t -1.4010082389964054\n",
            "10     \t [ 9.18133243  4.09376148 10.          0.96038921  5.          0.75655401]. \t  -1.4644877108201928 \t -1.4010082389964054\n",
            "11     \t [0.50322511 5.36549123 5.         0.63452016 9.         0.79019916]. \t  -1.5078986088443043 \t -1.4010082389964054\n",
            "12     \t [ 1.90877122  0.88669904 11.          0.72802974 19.          0.27519153]. \t  -1.6626099836759345 \t -1.4010082389964054\n",
            "13     \t [ 8.84415462  2.89803683  6.          0.75669789 10.          0.66428199]. \t  -1.5130684787900361 \t -1.4010082389964054\n",
            "14     \t [ 0.47139237  0.24747681 14.          0.53291734 14.          0.24490793]. \t  -1.693497902927448 \t -1.4010082389964054\n",
            "15     \t [ 4.08585896  5.34099618  8.          0.80348872 14.          0.82390552]. \t  -1.474075457159221 \t -1.4010082389964054\n",
            "16     \t [ 0.1193966   4.00087708 11.          0.63402737  8.          0.19613602]. \t  -1.6931122373774463 \t -1.4010082389964054\n",
            "17     \t [6.81400827 9.89935465 8.         0.72740578 7.         0.33091033]. \t  -1.6612988818305836 \t -1.4010082389964054\n",
            "18     \t [ 5.96087465  0.         15.          0.5        19.04147885  1.        ]. \t  \u001b[92m-1.3849579254836586\u001b[0m \t -1.3849579254836586\n",
            "19     \t [ 0.17525712  4.19183624 13.          0.93093846  1.          0.77496282]. \t  -1.4770408140616145 \t -1.3849579254836586\n",
            "20     \t [ 1.59392983  0.4187331   5.          0.53325118 19.          0.2829738 ]. \t  -1.6633922967741952 \t -1.3849579254836586\n",
            "21     \t [ 9.45838821  8.43771394  5.          0.837519   19.          0.66803955]. \t  -1.5217487782042345 \t -1.3849579254836586\n",
            "22     \t [9.35356053 9.20533358 5.         0.79175179 4.         0.44565956]. \t  -1.6363264613190132 \t -1.3849579254836586\n",
            "23     \t [0.21801428 3.91749792 5.         0.82365963 1.         0.87015731]. \t  -1.5034031679495272 \t -1.3849579254836586\n",
            "24     \t [ 1.26205935  9.99749922 12.          0.77151435 18.          0.65232396]. \t  -1.4960778012146236 \t -1.3849579254836586\n",
            "25     \t [0.         0.         8.65006086 1.         4.99001507 0.96063119]. \t  -1.4174604738459866 \t -1.3849579254836586\n",
            "26     \t [ 6.78501766  0.03433927 14.          0.61227345  3.          0.98696086]. \t  -1.4133341759445888 \t -1.3849579254836586\n",
            "27     \t [ 9.32769379  0.59894614 11.          0.56174421 13.          0.92492634]. \t  -1.4096775225369842 \t -1.3849579254836586\n",
            "28     \t [ 0.          0.         14.86962348  1.          7.92931894  0.1       ]. \t  -1.6962676599036608 \t -1.3849579254836586\n",
            "29     \t [ 5.86054887  4.74834199 13.93654987  1.          1.          0.1       ]. \t  -1.6971539610324722 \t -1.3849579254836586\n",
            "30     \t [10.          5.66960081 11.23940714  1.         10.17354381  0.1       ]. \t  -1.6956270733658207 \t -1.3849579254836586\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "48488.50555803437"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1WsphKSUj19",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f7a447e-1fd0-4af3-df84-0aa11d39179e"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'gp' Acquisition Function run number = 7\n",
        "\n",
        "np.random.seed(run_num_7)\n",
        "surrogate_gp_7 = GaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train7, X_test7, y_train7, y_test7 = train_test_split(X, y, test_size=test_perc, random_state=run_num_7)\n",
        "\n",
        "def f_syn_polarity7(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_7, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train7, y=y_train7).mean())\n",
        "    return operator * score\n",
        "\n",
        "gp_7 = GPGO(surrogate_gp_7, Acquisition_new(util_gp), f_syn_polarity7, param, n_jobs = -1) # define BayesOpt\n",
        "gp_7.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_gp_7 = gp_7.getResult()[0]\n",
        "params_gp_7['max_depth'] = int(params_gp_7['max_depth'])\n",
        "params_gp_7['min_child_weight'] = int(params_gp_7['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_gp_train7 = xgb.DMatrix(X_train7, y_train7)\n",
        "dX_gp_test7 = xgb.DMatrix(X_test7, y_test7)\n",
        "model_gp_7 = xgb.train(params_gp_7, dX_gp_train7)\n",
        "pred_gp_7 = model_gp_7.predict(dX_gp_test7)\n",
        "\n",
        "rmse_gp_7 = np.sqrt(mean_squared_error(pred_gp_7, y_test7))\n",
        "rmse_gp_7"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.76308289 7.79918792 8.         0.98911145 8.         0.98019056]. \t  -1.3766913184499914 \t -1.3716193029156287\n",
            "init   \t [ 5.3849587   5.01120464 13.          0.74994125  5.          0.88192131]. \t  -1.3716193029156287 \t -1.3716193029156287\n",
            "init   \t [ 3.30839249  3.9294231  12.          0.6440728  13.          0.41137564]. \t  -1.4844760060500033 \t -1.3716193029156287\n",
            "init   \t [9.29528191 2.6258377  5.         0.80027446 1.         0.86616513]. \t  -1.4553420696682378 \t -1.3716193029156287\n",
            "init   \t [ 1.74052764  7.90763512 14.          0.7244129   4.          0.77536887]. \t  -1.4144357133522163 \t -1.3716193029156287\n",
            "1      \t [3.70351083 4.59092978 6.         0.70937861 6.         0.814213  ]. \t  -1.438878549232204 \t -1.3716193029156287\n",
            "2      \t [ 0.03374059  5.72098042  5.          0.61235924 18.          0.8711559 ]. \t  -1.4545666235159225 \t -1.3716193029156287\n",
            "3      \t [ 9.12127254  9.64651695 14.          0.53624962  1.          0.38247449]. \t  -1.50441276662484 \t -1.3716193029156287\n",
            "4      \t [ 8.15448719  3.4710932   7.          0.61547067 18.          0.53291628]. \t  -1.4373733025375093 \t -1.3716193029156287\n",
            "5      \t [ 9.19979425  8.97441441 13.          0.88387282 19.          0.6456674 ]. \t  -1.4142697325004108 \t -1.3716193029156287\n",
            "6      \t [9.43260743 8.53539628 9.         0.68880888 9.         0.5954756 ]. \t  -1.4252808407490185 \t -1.3716193029156287\n",
            "7      \t [ 7.73252727  0.7079457   5.          0.93170437 11.          0.47373855]. \t  -1.5019969299464655 \t -1.3716193029156287\n",
            "8      \t [ 0.04434682  1.14105742 10.          0.89864231  2.          0.82027014]. \t  -1.4083920739677098 \t -1.3716193029156287\n",
            "9      \t [ 1.29932493  8.0055142  14.          0.51325501 19.          0.83654101]. \t  -1.4172515575270401 \t -1.3716193029156287\n",
            "10     \t [ 7.58520897  0.92332909 14.          0.64294573 18.          0.55530663]. \t  -1.4191001053874044 \t -1.3716193029156287\n",
            "11     \t [ 5.67407045  9.94967311  6.          0.75213901 15.          0.78517579]. \t  -1.4404275557086703 \t -1.3716193029156287\n",
            "12     \t [ 9.94824081  0.39149062 12.          0.59113076  1.          0.49709751]. \t  -1.5007161735692889 \t -1.3716193029156287\n",
            "13     \t [ 9.50485243  0.62770054 13.          0.93971373  9.          0.8838596 ]. \t  \u001b[92m-1.363806994811626\u001b[0m \t -1.363806994811626\n",
            "14     \t [9.78412355 9.15542954 6.         0.58671092 3.         0.40397987]. \t  -1.4987444891931392 \t -1.363806994811626\n",
            "15     \t [ 2.46176728  0.50526411  8.          0.70541011 10.          0.67627912]. \t  -1.4283999689301698 \t -1.363806994811626\n",
            "16     \t [2.55619498 9.35193462 5.         0.90124769 1.         0.7192924 ]. \t  -1.4699097084123944 \t -1.363806994811626\n",
            "17     \t [ 5.07215524  9.54440855 14.          0.82673842 10.          0.75906001]. \t  -1.4093681088023804 \t -1.363806994811626\n",
            "18     \t [ 9.90342616  9.00177359 13.          0.74202782 13.          0.95569351]. \t  -1.3697360438035369 \t -1.363806994811626\n",
            "19     \t [ 0.65002247  1.37990605 13.          0.58702251 19.          0.24436942]. \t  -1.627366680977902 \t -1.363806994811626\n",
            "20     \t [ 5.96104682  5.36781706 13.          0.90782508  8.          0.4137887 ]. \t  -1.4847846180118622 \t -1.363806994811626\n",
            "21     \t [ 0.11818298  8.16975133  9.          0.52445152 14.          0.81513004]. \t  -1.419706919451531 \t -1.363806994811626\n",
            "22     \t [ 5.08446652  8.91354164 10.          0.78618996  1.          0.52971559]. \t  -1.4212154260901577 \t -1.363806994811626\n",
            "23     \t [ 1.74680493  0.         14.04932474  0.5         6.33243272  1.        ]. \t  -1.3731297554553419 \t -1.363806994811626\n",
            "24     \t [ 3.38620018  0.63587877  7.          0.78058815 16.          0.30878239]. \t  -1.5459662593835468 \t -1.363806994811626\n",
            "25     \t [ 9.70956164  8.2897435   5.          0.7557001  12.          0.6921717 ]. \t  -1.4705807756988738 \t -1.363806994811626\n",
            "26     \t [8.97724042 2.45771723 7.         0.8512854  6.         0.30764744]. \t  -1.5459500781869888 \t -1.363806994811626\n",
            "27     \t [ 0.         8.5825784 15.         1.        13.         1.       ]. \t  \u001b[92m-1.3567803140147916\u001b[0m \t -1.3567803140147916\n",
            "28     \t [10.          5.96979767 10.73483117  1.          3.37321266  1.        ]. \t  -1.361248846383889 \t -1.3567803140147916\n",
            "29     \t [ 3.9309628   9.15233826  6.00840627  0.61833841 19.87508927  0.1       ]. \t  -1.6292095927783727 \t -1.3567803140147916\n",
            "30     \t [ 5.62404001 10.          5.          1.          6.36606739  0.1       ]. \t  -1.5876108237245212 \t -1.3567803140147916\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50286.939981704614"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hI8sFP4ZUmOs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5ea71bc-3b64-4e74-ab05-296d8893ac3e"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'gp' Acquisition Function run number = 8\n",
        "\n",
        "np.random.seed(run_num_8)\n",
        "surrogate_gp_8 = GaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train8, X_test8, y_train8, y_test8 = train_test_split(X, y, test_size=test_perc, random_state=run_num_8)\n",
        "\n",
        "def f_syn_polarity8(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_8, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train8, y=y_train8).mean())\n",
        "    return operator * score\n",
        "\n",
        "gp_8 = GPGO(surrogate_gp_8, Acquisition_new(util_gp), f_syn_polarity8, param, n_jobs = -1) # define BayesOpt\n",
        "gp_8.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_gp_8 = gp_8.getResult()[0]\n",
        "params_gp_8['max_depth'] = int(params_gp_8['max_depth'])\n",
        "params_gp_8['min_child_weight'] = int(params_gp_8['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_gp_train8 = xgb.DMatrix(X_train8, y_train8)\n",
        "dX_gp_test8 = xgb.DMatrix(X_test8, y_test8)\n",
        "model_gp_8 = xgb.train(params_gp_8, dX_gp_train8)\n",
        "pred_gp_8 = model_gp_8.predict(dX_gp_test8)\n",
        "\n",
        "rmse_gp_8 = np.sqrt(mean_squared_error(pred_gp_8, y_test8))\n",
        "rmse_gp_8"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 8.73429403  9.68540663 10.          0.68875849  9.          0.48011572]. \t  -1.4345420020169601 \t -1.380205361584031\n",
            "init   \t [ 6.12033333  7.66062926  8.          0.76133734 13.          0.93379456]. \t  -1.389083518296823 \t -1.380205361584031\n",
            "init   \t [ 1.46524679  7.01527914  7.          0.90913299 10.          0.36016753]. \t  -1.4546623776895313 \t -1.380205361584031\n",
            "init   \t [ 9.73855241  3.33774046 14.          0.53290419  7.          0.7088681 ]. \t  -1.400955898397293 \t -1.380205361584031\n",
            "init   \t [ 3.00618018  1.82702795 11.          0.75681389 14.          0.98627449]. \t  -1.380205361584031 \t -1.380205361584031\n",
            "1      \t [4.42022545 5.48487111 9.         0.97165909 3.         0.63617522]. \t  -1.392033230213678 \t -1.380205361584031\n",
            "2      \t [ 9.3432851   3.80536023 13.          0.82203895 19.          0.99569116]. \t  -1.3810003759019789 \t -1.380205361584031\n",
            "3      \t [ 2.52429836  9.02824683 14.          0.59641093 17.          0.61934886]. \t  -1.4189890610685807 \t -1.380205361584031\n",
            "4      \t [ 9.53473907  5.08424998 11.          0.50652828 18.          0.67121466]. \t  -1.3995921109500755 \t -1.380205361584031\n",
            "5      \t [6.89072012 1.88822945 5.         0.9252956  8.         0.40577637]. \t  -1.4671872329107825 \t -1.380205361584031\n",
            "6      \t [ 2.42575645  9.87357367  5.          0.61143882 19.          0.11833201]. \t  -1.5217192808835498 \t -1.380205361584031\n",
            "7      \t [ 0.9931658   1.40870497 14.          0.50614818  6.          0.71944448]. \t  -1.3993577222957068 \t -1.380205361584031\n",
            "8      \t [ 9.09148899  1.42093493  5.          0.88801001 17.          0.53231573]. \t  -1.4612253332966916 \t -1.380205361584031\n",
            "9      \t [9.69554908 3.70013633 5.         0.72727157 1.         0.49530336]. \t  -1.4660245850133664 \t -1.380205361584031\n",
            "10     \t [ 2.66410938  9.83743919 13.          0.58899688  8.          0.29675269]. \t  -1.4559646932762471 \t -1.380205361584031\n",
            "11     \t [1.66316873 0.47469495 7.         0.60820298 1.         0.50689458]. \t  -1.4305575307333285 \t -1.380205361584031\n",
            "12     \t [ 1.2277143   1.05411485  5.          0.50198686 13.          0.89258454]. \t  -1.4252760814462118 \t -1.380205361584031\n",
            "13     \t [ 6.53366965  0.44467545 13.          0.98765404  1.          0.73688157]. \t  -1.3930878262516195 \t -1.380205361584031\n",
            "14     \t [9.03940661 8.93111188 5.         0.98342695 5.         0.13222435]. \t  -1.5211622616600005 \t -1.380205361584031\n",
            "15     \t [10.         10.         10.64577823  1.          1.          0.1       ]. \t  -1.6347839089780383 \t -1.380205361584031\n",
            "16     \t [ 8.62413803  1.63568526 10.          0.78670071 12.          0.5099252 ]. \t  -1.4157220359031473 \t -1.380205361584031\n",
            "17     \t [ 3.5121134   5.24088616  9.          0.68973249 19.          0.78159968]. \t  -1.39634939916643 \t -1.380205361584031\n",
            "18     \t [ 8.31774559  9.86409044  5.          0.5896951  17.          0.89174436]. \t  -1.4240962371845975 \t -1.380205361584031\n",
            "19     \t [0.71956405 9.27388815 5.         0.63252089 3.         0.24230104]. \t  -1.5230143316996865 \t -1.380205361584031\n",
            "20     \t [10.          0.          8.51784684  0.5         5.45378964  0.1       ]. \t  -1.5132089975114629 \t -1.380205361584031\n",
            "21     \t [ 0.          7.66861191 14.64159671  0.5         3.00357659  1.        ]. \t  \u001b[92m-1.3792864691621858\u001b[0m \t -1.3792864691621858\n",
            "22     \t [ 4.9352833   5.03320453 14.66090363  1.          4.62539697  0.1       ]. \t  -1.6343839761421044 \t -1.3792864691621858\n",
            "23     \t [10.          4.04182423 10.46097259  1.          1.          0.1       ]. \t  -1.6347839089780383 \t -1.3792864691621858\n",
            "24     \t [1.43710423e-02 4.76269342e-02 7.00000000e+00 5.26967851e-01\n",
            " 1.90000000e+01 9.00776830e-01]. \t  -1.3986535157014168 \t -1.3792864691621858\n",
            "25     \t [ 0.54777791  3.09782342 14.          0.64396842 19.          0.55122597]. \t  -1.416575389962748 \t -1.3792864691621858\n",
            "26     \t [0.         1.56735361 8.31851258 1.         5.95459208 0.96162702]. \t  \u001b[92m-1.375110051160012\u001b[0m \t -1.375110051160012\n",
            "27     \t [ 8.80780334  8.13019048 14.          0.72995412 15.          0.51529349]. \t  -1.4172383713248544 \t -1.375110051160012\n",
            "28     \t [ 8.94857541  9.04896271 14.13991549  0.63279507  5.62253027  0.44941387]. \t  -1.4372449895561663 \t -1.375110051160012\n",
            "29     \t [ 5.71118477  0.         15.          0.76767178 13.99999998  0.1       ]. \t  -1.513929961730931 \t -1.375110051160012\n",
            "30     \t [ 4.58684964  5.51484251 14.32745956  0.5        11.31798197  0.1       ]. \t  -1.5124282033451726 \t -1.375110051160012\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "52888.34499546752"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vw5IYus6UpAn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4248f7b-8499-4c8b-affc-82d2782d1ec7"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'gp' Acquisition Function run number = 9\n",
        "\n",
        "np.random.seed(run_num_9)\n",
        "surrogate_gp_9 = GaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train9, X_test9, y_train9, y_test9 = train_test_split(X, y, test_size=test_perc, random_state=run_num_9)\n",
        "\n",
        "def f_syn_polarity9(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_9, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train9, y=y_train9).mean())\n",
        "    return operator * score\n",
        "\n",
        "gp_9 = GPGO(surrogate_gp_9, Acquisition_new(util_gp), f_syn_polarity9, param, n_jobs = -1) # define BayesOpt\n",
        "gp_9.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_gp_9 = gp_9.getResult()[0]\n",
        "params_gp_9['max_depth'] = int(params_gp_9['max_depth'])\n",
        "params_gp_9['min_child_weight'] = int(params_gp_9['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_gp_train9 = xgb.DMatrix(X_train9, y_train9)\n",
        "dX_gp_test9 = xgb.DMatrix(X_test9, y_test9)\n",
        "model_gp_9 = xgb.train(params_gp_9, dX_gp_train9)\n",
        "pred_gp_9 = model_gp_9.predict(dX_gp_test9)\n",
        "\n",
        "rmse_gp_9 = np.sqrt(mean_squared_error(pred_gp_9, y_test9))\n",
        "rmse_gp_9"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 0.10374154  5.01874592 11.          0.50377155  2.          0.29670281]. \t  -1.5577132784573362 \t -1.3722986758568372\n",
            "init   \t [ 4.18508181  2.48101168 13.          0.69794293  2.          0.25009871]. \t  -1.557988294847283 \t -1.3722986758568372\n",
            "init   \t [ 8.78559086  9.50964032 13.          0.98395204 11.          0.90820641]. \t  -1.3722986758568372 \t -1.3722986758568372\n",
            "init   \t [ 6.66898973  5.47837783  6.          0.97165345 12.          0.72499481]. \t  -1.4672635070842577 \t -1.3722986758568372\n",
            "init   \t [ 8.24870465  4.65668475 13.          0.68760467  9.          0.98502332]. \t  -1.3809301169879382 \t -1.3722986758568372\n",
            "1      \t [6.73714319 2.39608167 5.         0.58130302 3.         0.163077  ]. \t  -1.685094312684032 \t -1.3722986758568372\n",
            "2      \t [ 1.89773665  4.24398106 11.          0.60135502  9.          0.22312501]. \t  -1.6853446147658802 \t -1.3722986758568372\n",
            "3      \t [ 3.60566534  9.79805332 11.          0.62032576 16.          0.3578496 ]. \t  -1.5497427912361297 \t -1.3722986758568372\n",
            "4      \t [ 6.08573587  9.31882131 12.          0.78209013  2.          0.32135533]. \t  -1.5566260274199373 \t -1.3722986758568372\n",
            "5      \t [ 5.22023219  1.10001946  7.          0.73373378 19.          0.6897111 ]. \t  -1.4580594251715395 \t -1.3722986758568372\n",
            "6      \t [ 3.86796235  4.27805985 10.          0.53963329 10.          0.97039142]. \t  -1.390325785644111 \t -1.3722986758568372\n",
            "7      \t [ 2.44734743  2.02559893 14.          0.92018065 17.          0.63484374]. \t  -1.4356103653195027 \t -1.3722986758568372\n",
            "8      \t [ 7.07313313  8.94084339  5.          0.99439529 19.          0.33798274]. \t  -1.554418754580938 \t -1.3722986758568372\n",
            "9      \t [2.73711767 8.77804998 5.         0.98905949 4.         0.33321969]. \t  -1.5549484255817796 \t -1.3722986758568372\n",
            "10     \t [ 0.33325568  9.91557366  5.          0.68177057 13.          0.10400948]. \t  -1.6867857091186174 \t -1.3722986758568372\n",
            "11     \t [ 8.41810681  0.28363289 14.          0.70665052 14.          0.98883394]. \t  -1.3814999486957347 \t -1.3722986758568372\n",
            "12     \t [ 9.52610365  6.73753702 11.          0.58325203 16.          0.91335778]. \t  -1.387737931709514 \t -1.3722986758568372\n",
            "13     \t [9.40250417 9.33715302 5.         0.70325406 3.         0.25654671]. \t  -1.5556661058733117 \t -1.3722986758568372\n",
            "14     \t [ 1.5822225   4.71560548  5.          0.51218922 16.          0.7972216 ]. \t  -1.4381373009936254 \t -1.3722986758568372\n",
            "15     \t [ 9.54820008  5.17222391 14.          0.98104009  3.          0.97784428]. \t  -1.3732323980317689 \t -1.3722986758568372\n",
            "16     \t [1.23196188 2.06578212 5.         0.98486218 7.         0.57472002]. \t  -1.4869815938710977 \t -1.3722986758568372\n",
            "17     \t [ 4.38000801  0.43341145  5.          0.89363197 12.          0.78884071]. \t  -1.4403135303890342 \t -1.3722986758568372\n",
            "18     \t [ 1.5415602   9.46604854 14.          0.65637186  6.          0.8350241 ]. \t  -1.3926508074336286 \t -1.3722986758568372\n",
            "19     \t [ 0.47436291  1.70628393  9.          0.76945327 14.          0.88694933]. \t  -1.387865649756329 \t -1.3722986758568372\n",
            "20     \t [8.68002052 0.29618424 6.         0.93279865 8.         0.39922875]. \t  -1.5028026470664622 \t -1.3722986758568372\n",
            "21     \t [ 2.45004823  7.25341111 15.          1.         13.20191042  0.1       ]. \t  -1.6471436503233243 \t -1.3722986758568372\n",
            "22     \t [10.          0.         12.65350214  0.5        20.          0.1       ]. \t  -1.687303138309192 \t -1.3722986758568372\n",
            "23     \t [ 0.         10.          8.65803541  1.         20.          0.1       ]. \t  -1.6469746012578814 \t -1.3722986758568372\n",
            "24     \t [ 9.28478482  1.11902119  6.          0.54613225 15.          0.48308121]. \t  -1.507987233590719 \t -1.3722986758568372\n",
            "25     \t [ 3.75980644  9.87621224  9.21381088  1.         10.5994785   0.1       ]. \t  -1.6468257191198377 \t -1.3722986758568372\n",
            "26     \t [0.23292219 3.86003066 5.         0.55791089 2.         0.17888483]. \t  -1.686560297585811 \t -1.3722986758568372\n",
            "27     \t [ 7.26118809 10.         15.          0.5        19.81380561  1.        ]. \t  -1.3841199756353482 \t -1.3722986758568372\n",
            "28     \t [6.77162904 6.0335373  8.         0.52340245 6.         0.94735199]. \t  -1.3999072779404529 \t -1.3722986758568372\n",
            "29     \t [ 2.7526456   0.         15.          1.          7.65291081  1.        ]. \t  \u001b[92m-1.3697187002715348\u001b[0m \t -1.3697187002715348\n",
            "30     \t [ 8.94291108  0.         15.          0.5         1.          1.        ]. \t  -1.3925658036528108 \t -1.3697187002715348\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "48920.748353885465"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YD494io_Ur7V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3acf5aa-4ca8-45c1-870e-fff073cbaf3e"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'gp' Acquisition Function run number = 10\n",
        "\n",
        "np.random.seed(run_num_10)\n",
        "surrogate_gp_10 = GaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train10, X_test10, y_train10, y_test10 = train_test_split(X, y, test_size=test_perc, random_state=run_num_10)\n",
        "\n",
        "def f_syn_polarity10(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_10, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train10, y=y_train10).mean())\n",
        "    return operator * score\n",
        "\n",
        "gp_10 = GPGO(surrogate_gp_10, Acquisition_new(util_gp), f_syn_polarity10, param, n_jobs = -1) # define BayesOpt\n",
        "gp_10.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_gp_10 = gp_10.getResult()[0]\n",
        "params_gp_10['max_depth'] = int(params_gp_10['max_depth'])\n",
        "params_gp_10['min_child_weight'] = int(params_gp_10['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_gp_train10 = xgb.DMatrix(X_train10, y_train10)\n",
        "dX_gp_test10 = xgb.DMatrix(X_test10, y_test10)\n",
        "model_gp_10 = xgb.train(params_gp_10, dX_gp_train10)\n",
        "pred_gp_10 = model_gp_10.predict(dX_gp_test10)\n",
        "\n",
        "rmse_gp_10 = np.sqrt(mean_squared_error(pred_gp_10, y_test10))\n",
        "rmse_gp_10"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 7.71320643  0.20751949  5.          0.72150747 17.          0.12265456]. \t  -1.5966621860966772 \t -1.3816576901725537\n",
            "init   \t [ 7.0920801   2.65566127 13.          0.57518893 17.          0.83494165]. \t  -1.3816576901725537 \t -1.3816576901725537\n",
            "init   \t [ 3.36071584  8.90816531  6.          0.86087766 15.          0.75469196]. \t  -1.4046956914996547 \t -1.3816576901725537\n",
            "init   \t [ 5.40880931  1.31458152  8.          0.57108502 14.          0.62551123]. \t  -1.4201195466728969 \t -1.3816576901725537\n",
            "init   \t [1.82631436 8.26082248 6.         0.80888349 5.         0.15900694]. \t  -1.5985040415985665 \t -1.3816576901725537\n",
            "1      \t [8.31989768 3.09778055 7.         0.64798085 3.         0.98471878]. \t  -1.3861520034074002 \t -1.3816576901725537\n",
            "2      \t [ 1.51483713  6.46720195 14.          0.87676044  8.          0.10934204]. \t  -1.6003439345483486 \t -1.3816576901725537\n",
            "3      \t [ 1.40638864  6.36994003 14.          0.94554832 18.          0.42624162]. \t  -1.4382374839869 \t -1.3816576901725537\n",
            "4      \t [ 6.23532773  8.31439809 13.          0.65134225  1.          0.75774237]. \t  -1.385366563936203 \t -1.3816576901725537\n",
            "5      \t [ 9.32103763  8.04997374 14.          0.76165598 11.          0.58576369]. \t  -1.428324678040395 \t -1.3816576901725537\n",
            "6      \t [ 2.70513667  1.83577987 12.          0.56122064  1.          0.15848231]. \t  -1.602579832216111 \t -1.3816576901725537\n",
            "7      \t [ 9.16520307  0.72602801 12.          0.91999471  9.          0.54336218]. \t  -1.426094761499742 \t -1.3816576901725537\n",
            "8      \t [ 0.13114685  2.69967978  5.          0.89490476 19.          0.55706236]. \t  -1.441014468615035 \t -1.3816576901725537\n",
            "9      \t [ 9.57603828  8.81375557  5.          0.56495862 19.          0.45710368]. \t  -1.4509053625704245 \t -1.3816576901725537\n",
            "10     \t [ 9.82501514  7.31311253  5.          0.75029053 12.          0.39735105]. \t  -1.4509928730738761 \t -1.3816576901725537\n",
            "11     \t [0.40833691 2.05040396 5.         0.83675528 2.         0.93839002]. \t  -1.4153000784199807 \t -1.3816576901725537\n",
            "12     \t [ 0.06083858  0.83347778 13.          0.60208867 14.          0.81102115]. \t  \u001b[92m-1.3802194987068834\u001b[0m \t -1.3802194987068834\n",
            "13     \t [0.58859866 0.67354665 6.         0.58048837 8.         0.52032775]. \t  -1.437184275266924 \t -1.3802194987068834\n",
            "14     \t [ 0.42759101  9.94526216 13.          0.83538077 13.          0.34479326]. \t  -1.5463634920895817 \t -1.3802194987068834\n",
            "15     \t [9.80244061 9.59221257 6.         0.81318958 4.         0.96637387]. \t  -1.3975977207172405 \t -1.3802194987068834\n",
            "16     \t [ 9.42421731  1.45800675  5.          0.89810349 11.          0.91467377]. \t  -1.4133279568815276 \t -1.3802194987068834\n",
            "17     \t [ 9.71047899  2.77697649 13.          0.98225484  2.          0.32725448]. \t  -1.5514962457207713 \t -1.3802194987068834\n",
            "18     \t [ 2.98907775  0.26115088 11.          0.70419286 18.          0.69826817]. \t  -1.4157936210555349 \t -1.3802194987068834\n",
            "19     \t [ 8.10151611  9.78827602 14.          0.68048433 19.          0.19392154]. \t  -1.6002801665184923 \t -1.3802194987068834\n",
            "20     \t [5.06471065 8.34537352 9.         0.63051058 9.         0.69636185]. \t  -1.4170370299663966 \t -1.3802194987068834\n",
            "21     \t [6.93720357 6.92840877 6.         0.54212343 9.         0.84245085]. \t  -1.4081316581893781 \t -1.3802194987068834\n",
            "22     \t [ 3.37500695  9.43359873  8.51903549  0.66203305 20.          0.83898049]. \t  -1.3891434736871324 \t -1.3802194987068834\n",
            "23     \t [5.0726005  7.07984277 5.         0.91834936 1.         0.44352868]. \t  -1.4500831383436341 \t -1.3802194987068834\n",
            "24     \t [ 1.03522207  8.69814288 11.          0.7029143   3.          0.33992678]. \t  -1.5509970208209647 \t -1.3802194987068834\n",
            "25     \t [ 0.06471143  5.84723895  9.          0.53454904 15.          0.38988458]. \t  -1.4428091313556053 \t -1.3802194987068834\n",
            "26     \t [ 1.12747219  5.27248187  5.          0.5        10.91430873  0.1       ]. \t  -1.5996906143614171 \t -1.3802194987068834\n",
            "27     \t [ 3.7207087   1.30311582 11.          0.70106414  7.          0.99156498]. \t  \u001b[92m-1.365513957888989\u001b[0m \t -1.365513957888989\n",
            "28     \t [0.54364673 4.87088415 9.         0.90325879 8.         0.88625433]. \t  \u001b[92m-1.3615280112715997\u001b[0m \t -1.3615280112715997\n",
            "29     \t [ 8.02638704  6.6707952  12.          0.69569342  6.          0.98018482]. \t  -1.3643161620169562 \t -1.3615280112715997\n",
            "30     \t [5.22573422 0.65980959 5.         0.73641403 1.         0.11802776]. \t  -1.5975351442715646 \t -1.3615280112715997\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49872.96102464079"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N03Sq0TvUuhp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4455b5b-f0ef-4549-8e53-e2c9e7ef390c"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'gp' Acquisition Function run number = 11\n",
        "\n",
        "np.random.seed(run_num_11)\n",
        "surrogate_gp_11 = GaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train11, X_test11, y_train11, y_test11 = train_test_split(X, y, test_size=test_perc, random_state=run_num_11)\n",
        "\n",
        "def f_syn_polarity11(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_11, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train11, y=y_train11).mean())\n",
        "    return operator * score\n",
        "\n",
        "gp_11 = GPGO(surrogate_gp_11, Acquisition_new(util_gp), f_syn_polarity11, param, n_jobs = -1) # define BayesOpt\n",
        "gp_11.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_gp_11 = gp_11.getResult()[0]\n",
        "params_gp_11['max_depth'] = int(params_gp_11['max_depth'])\n",
        "params_gp_11['min_child_weight'] = int(params_gp_11['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_gp_train11 = xgb.DMatrix(X_train11, y_train11)\n",
        "dX_gp_test11 = xgb.DMatrix(X_test11, y_test11)\n",
        "model_gp_11 = xgb.train(params_gp_11, dX_gp_train11)\n",
        "pred_gp_11 = model_gp_11.predict(dX_gp_test11)\n",
        "\n",
        "rmse_gp_11 = np.sqrt(mean_squared_error(pred_gp_11, y_test11))\n",
        "rmse_gp_11"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 1.80269689  0.19475241  6.          0.59705781 13.          0.47818324]. \t  -1.4816591577946832 \t -1.4105425145194488\n",
            "init   \t [ 4.85427098  0.12780815  5.          0.91309068 14.          0.86571558]. \t  -1.426706936764755 \t -1.4105425145194488\n",
            "init   \t [ 7.2996447   1.08736072 10.          0.92857712 18.          0.66910061]. \t  -1.4105425145194488 \t -1.4105425145194488\n",
            "init   \t [ 0.20483613  1.16737269  7.          0.57895615 16.          0.83644782]. \t  -1.4183397861714337 \t -1.4105425145194488\n",
            "init   \t [ 3.44624491  3.18798797 14.          0.54197657 15.          0.63958906]. \t  -1.4201459936126652 \t -1.4105425145194488\n",
            "1      \t [9.77136617 6.6548802  7.         0.51036649 9.         0.81011527]. \t  -1.4198592349317078 \t -1.4105425145194488\n",
            "2      \t [0.5279662  8.15331655 5.         0.83127487 9.         0.53242685]. \t  -1.4775633373451906 \t -1.4105425145194488\n",
            "3      \t [8.62555756 1.5478147  8.         0.99964468 2.         0.74874718]. \t  -1.4123297977539668 \t -1.4105425145194488\n",
            "4      \t [ 0.90299561  9.42808632 14.          0.71344248  9.          0.5250902 ]. \t  -1.4659195951888304 \t -1.4105425145194488\n",
            "5      \t [ 0.07122179  2.9458437  13.          0.89742149  2.          0.63052749]. \t  -1.4165796433495284 \t -1.4105425145194488\n",
            "6      \t [ 2.80563958  8.51387637  8.          0.72474118 19.          0.16647242]. \t  -1.5954888498474655 \t -1.4105425145194488\n",
            "7      \t [ 8.68943806  9.29354072 13.          0.58241565  2.          0.90282292]. \t  \u001b[92m-1.3827383913835647\u001b[0m \t -1.3827383913835647\n",
            "8      \t [0.47065357 6.80536856 5.         0.94482943 1.         0.93677618]. \t  -1.4135866309918552 \t -1.3827383913835647\n",
            "9      \t [ 8.74582539  1.09960491 14.          0.69981761  9.          0.73083826]. \t  -1.4174999872552454 \t -1.3827383913835647\n",
            "10     \t [ 9.62795963  5.53773092  5.          0.74613073 18.          0.44845649]. \t  -1.482748052716914 \t -1.3827383913835647\n",
            "11     \t [ 8.61765552  0.94349031 10.          0.85641829  4.          0.91576259]. \t  \u001b[92m-1.3748287643146533\u001b[0m \t -1.3748287643146533\n",
            "12     \t [4.51634165 2.99534228 6.         0.60005383 7.         0.33729133]. \t  -1.5463963481365885 \t -1.3748287643146533\n",
            "13     \t [ 8.32040378  7.9243385  14.          0.97104566 12.          0.2674345 ]. \t  -1.5432512311988016 \t -1.3748287643146533\n",
            "14     \t [ 8.40730244  5.3235921  14.          0.57824885  9.          0.96689527]. \t  -1.37819978697588 \t -1.3748287643146533\n",
            "15     \t [6.75392728 7.91761012 7.         0.70633705 1.         0.25915429]. \t  -1.5451513657965883 \t -1.3748287643146533\n",
            "16     \t [ 1.62679665  9.41000757 13.          0.73103911  2.          0.19462364]. \t  -1.596482119016073 \t -1.3748287643146533\n",
            "17     \t [ 8.54318912  8.37398397 11.          0.93167688 18.          0.44938036]. \t  -1.4705328668006143 \t -1.3748287643146533\n",
            "18     \t [ 6.19006075  3.41925871 11.          0.95286331  6.          0.39133224]. \t  -1.4758685740249062 \t -1.3748287643146533\n",
            "19     \t [ 2.81778167  9.0813261  14.          0.72293262 17.          0.23686204]. \t  -1.595561680467761 \t -1.3748287643146533\n",
            "20     \t [ 3.78244012  9.06799134  7.          0.53176719 13.          0.73242639]. \t  -1.4234289068136747 \t -1.3748287643146533\n",
            "21     \t [ 1.08214001  0.68881265 10.          0.59348453  7.          0.38320657]. \t  -1.4797598502200402 \t -1.3748287643146533\n",
            "22     \t [ 3.30514816  0.35103582 13.09088826  0.7660938  20.          1.        ]. \t  \u001b[92m-1.361494424849931\u001b[0m \t -1.361494424849931\n",
            "23     \t [1.00000000e+01 4.44089210e-16 5.10513729e+00 1.00000000e+00\n",
            " 6.93642453e+00 1.00000000e-01]. \t  -1.593907457156904 \t -1.361494424849931\n",
            "24     \t [ 6.00387651 10.          5.          1.          6.47161819  1.        ]. \t  -1.4104150484663525 \t -1.361494424849931\n",
            "25     \t [10.          1.20637475 15.          0.5        20.          1.        ]. \t  -1.373374303009109 \t -1.361494424849931\n",
            "26     \t [10.          3.7939101  10.54884814  0.8552672  13.24752021  0.1       ]. \t  -1.5958715432152886 \t -1.361494424849931\n",
            "27     \t [0.96956571 0.16256086 8.         0.8766109  1.         0.88289087]. \t  -1.3837881529349936 \t -1.361494424849931\n",
            "28     \t [ 5.59910258  1.26423688 14.          0.97318774  1.          0.54144173]. \t  -1.474546950627062 \t -1.361494424849931\n",
            "29     \t [0.68654828 9.91106907 7.         0.5834958  5.         0.88066674]. \t  -1.393190335830753 \t -1.361494424849931\n",
            "30     \t [ 0.          0.         15.          1.         12.42796068  1.        ]. \t  \u001b[92m-1.3583041804482074\u001b[0m \t -1.3583041804482074\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50666.79216264356"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_nP9lQjUztV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ddbe939-5811-44ee-fedb-b006d95ac7e8"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'gp' Acquisition Function run number = 12\n",
        "\n",
        "np.random.seed(run_num_12)\n",
        "surrogate_gp_12 = GaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train12, X_test12, y_train12, y_test12 = train_test_split(X, y, test_size=test_perc, random_state=run_num_12)\n",
        "\n",
        "def f_syn_polarity12(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_12, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train12, y=y_train12).mean())\n",
        "    return operator * score\n",
        "\n",
        "gp_12 = GPGO(surrogate_gp_12, Acquisition_new(util_gp), f_syn_polarity12, param, n_jobs = -1) # define BayesOpt\n",
        "gp_12.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_gp_12 = gp_12.getResult()[0]\n",
        "params_gp_12['max_depth'] = int(params_gp_12['max_depth'])\n",
        "params_gp_12['min_child_weight'] = int(params_gp_12['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_gp_train12 = xgb.DMatrix(X_train12, y_train12)\n",
        "dX_gp_test12 = xgb.DMatrix(X_test12, y_test12)\n",
        "model_gp_12 = xgb.train(params_gp_12, dX_gp_train12)\n",
        "pred_gp_12 = model_gp_12.predict(dX_gp_test12)\n",
        "\n",
        "rmse_gp_12 = np.sqrt(mean_squared_error(pred_gp_12, y_test12))\n",
        "rmse_gp_12"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [1.54162842 7.40049697 6.         0.54321714 4.         0.11311747]. \t  -1.6495881989170076 \t -1.4161885061290391\n",
            "init   \t [ 9.18747008  9.00714854 14.          0.97847467 11.          0.35544552]. \t  -1.5149964971320231 \t -1.4161885061290391\n",
            "init   \t [ 6.06083184  9.44225136 14.          0.95626942  5.          0.56910342]. \t  -1.4459275331997625 \t -1.4161885061290391\n",
            "init   \t [ 5.52037633  4.85377414  7.          0.97886436 17.          0.78810441]. \t  -1.4161885061290391 \t -1.4161885061290391\n",
            "init   \t [ 0.20809798  1.35210178  5.          0.65494879 16.          0.36062811]. \t  -1.527260055706503 \t -1.4161885061290391\n",
            "1      \t [8.63751826 0.13862581 5.         0.68795787 5.         0.56136101]. \t  -1.4887973872171105 \t -1.4161885061290391\n",
            "2      \t [9.04256367 2.61736915 8.         0.66026854 8.         0.14510453]. \t  -1.6475213437726843 \t -1.4161885061290391\n",
            "3      \t [ 6.53994588  2.3076831  14.          0.85412016 14.          0.68100975]. \t  \u001b[92m-1.4056026672175623\u001b[0m \t -1.4056026672175623\n",
            "4      \t [ 0.80213572  3.81577068 14.          0.79504785  3.          0.9667177 ]. \t  \u001b[92m-1.4030296413704064\u001b[0m \t -1.4030296413704064\n",
            "5      \t [ 1.93384153  7.13950146  8.          0.85480597 18.          0.33734734]. \t  -1.5145617058584957 \t -1.4030296413704064\n",
            "6      \t [ 0.40359854  2.22527636 10.          0.60258213 10.          0.38255809]. \t  -1.5093017035694707 \t -1.4030296413704064\n",
            "7      \t [ 7.78419215  2.89852776 10.          0.89344175  1.          0.77103302]. \t  -1.409936397896555 \t -1.4030296413704064\n",
            "8      \t [ 1.77450628  1.48504026 14.          0.51849896 19.          0.12332361]. \t  -1.6478391153104617 \t -1.4030296413704064\n",
            "9      \t [0.31974577 0.28426423 5.         0.59429506 1.         0.19680364]. \t  -1.6516747969976298 \t -1.4030296413704064\n",
            "10     \t [9.84794037 9.82021004 7.         0.66665474 2.         0.55288414]. \t  -1.4628204039885015 \t -1.4030296413704064\n",
            "11     \t [ 4.46941345  8.83889784  8.          0.9945161  12.          0.25955004]. \t  -1.5141389187823509 \t -1.4030296413704064\n",
            "12     \t [ 1.73522493  9.43858502 13.          0.55982395 15.          0.59746886]. \t  -1.4534626570454727 \t -1.4030296413704064\n",
            "13     \t [ 3.95801979  3.60127695  5.          0.58247512 11.          0.33687332]. \t  -1.52686146152081 \t -1.4030296413704064\n",
            "14     \t [ 9.68766688  1.03665973  9.          0.58395515 19.          0.19787312]. \t  -1.6464069839816518 \t -1.4030296413704064\n",
            "15     \t [ 9.28517101  9.6064307  11.          0.55718143 17.          0.68781329]. \t  -1.4124964428939424 \t -1.4030296413704064\n",
            "16     \t [5.99294447 7.0114806  5.         0.86352024 2.         0.47030879]. \t  -1.5238701446854095 \t -1.4030296413704064\n",
            "17     \t [ 5.96286708  3.01360223 14.          0.85746882  8.          0.80215192]. \t  -1.406166963471523 \t -1.4030296413704064\n",
            "18     \t [ 9.5438775   8.73969671  5.          0.92582953 11.          0.88100187]. \t  -1.4342735169294625 \t -1.4030296413704064\n",
            "19     \t [ 9.56103036  2.69189352  5.          0.51874789 13.          0.83592686]. \t  -1.4504182267045986 \t -1.4030296413704064\n",
            "20     \t [ 0.49442426  9.20422434 11.          0.70522852  1.          0.50168224]. \t  -1.4557755515879731 \t -1.4030296413704064\n",
            "21     \t [ 5.2902047   7.0524146  14.          0.62689476 19.          0.19028095]. \t  -1.647509707108453 \t -1.4030296413704064\n",
            "22     \t [ 7.72221885  5.46205222  9.91842427  0.5        12.57927317  1.        ]. \t  \u001b[92m-1.393033754470601\u001b[0m \t -1.393033754470601\n",
            "23     \t [3.05924396 2.6241273  9.         0.65095111 4.         0.78376796]. \t  -1.4142198358325353 \t -1.393033754470601\n",
            "24     \t [10.          7.59185896 15.          0.5         1.          0.1       ]. \t  -1.6498632462828293 \t -1.393033754470601\n",
            "25     \t [ 8.5762454  10.          5.          0.5        17.17873532  1.        ]. \t  -1.4291383920717036 \t -1.393033754470601\n",
            "26     \t [ 1.07676697  8.61574113 12.          0.68395859  7.          0.90374399]. \t  -1.4044057527860676 \t -1.393033754470601\n",
            "27     \t [10.          4.40909357 12.84387106  1.         17.70042725  1.        ]. \t  \u001b[92m-1.3707737138455962\u001b[0m \t -1.3707737138455962\n",
            "28     \t [ 4.85930535  0.          8.00506327  1.         20.          1.        ]. \t  -1.3847285441397665 \t -1.3707737138455962\n",
            "29     \t [ 6.44329728  6.62134943 11.          0.5043606   8.          0.94472304]. \t  -1.4143895716741408 \t -1.3707737138455962\n",
            "30     \t [ 4.81543201  6.7988661  10.          0.96470416  2.          0.45284728]. \t  -1.5077121899933685 \t -1.3707737138455962\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50465.03889580665"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDI2Bi9vU05U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93a0438d-95ae-49dd-de04-bc570b80808f"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'gp' Acquisition Function run number = 13\n",
        "\n",
        "np.random.seed(run_num_13)\n",
        "surrogate_gp_13 = GaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train13, X_test13, y_train13, y_test13 = train_test_split(X, y, test_size=test_perc, random_state=run_num_13)\n",
        "\n",
        "def f_syn_polarity13(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_13, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train13, y=y_train13).mean())\n",
        "    return operator * score\n",
        "\n",
        "gp_13 = GPGO(surrogate_gp_13, Acquisition_new(util_gp), f_syn_polarity13, param, n_jobs = -1) # define BayesOpt\n",
        "gp_13.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_gp_13 = gp_13.getResult()[0]\n",
        "params_gp_13['max_depth'] = int(params_gp_13['max_depth'])\n",
        "params_gp_13['min_child_weight'] = int(params_gp_13['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_gp_train13 = xgb.DMatrix(X_train13, y_train13)\n",
        "dX_gp_test13 = xgb.DMatrix(X_test13, y_test13)\n",
        "model_gp_13 = xgb.train(params_gp_13, dX_gp_train13)\n",
        "pred_gp_13 = model_gp_13.predict(dX_gp_test13)\n",
        "\n",
        "rmse_gp_13 = np.sqrt(mean_squared_error(pred_gp_13, y_test13))\n",
        "rmse_gp_13"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 7.77702411  2.3754122  11.          0.94649135 13.          0.7827256 ]. \t  -1.3814631927491285 \t -1.3814631927491285\n",
            "init   \t [ 7.51661514  6.07343344 11.          0.69402149 11.          0.13153287]. \t  -1.6959297564173816 \t -1.3814631927491285\n",
            "init   \t [ 2.98449471  0.58512492 10.          0.73579614 12.          0.33065195]. \t  -1.5246886192220386 \t -1.3814631927491285\n",
            "init   \t [ 3.47581215  0.0941277  11.          0.86143432  8.          0.58454932]. \t  -1.4185759644827896 \t -1.3814631927491285\n",
            "init   \t [ 4.70137857  6.24432527 10.          0.8149145  18.          0.10784416]. \t  -1.6944183605438403 \t -1.3814631927491285\n",
            "1      \t [1.51786663 9.25994479 9.         0.99792981 2.         0.61199673]. \t  -1.4182805465760875 \t -1.3814631927491285\n",
            "2      \t [ 8.98888343  8.3187307  12.          0.8674744   2.          0.79321204]. \t  -1.3887986537394084 \t -1.3814631927491285\n",
            "3      \t [8.39231279 2.68541099 7.         0.57298175 6.         0.49020579]. \t  -1.4776526601111564 \t -1.3814631927491285\n",
            "4      \t [ 3.74996446  2.55146251 14.          0.66084872  1.          0.77825432]. \t  -1.3958421889249872 \t -1.3814631927491285\n",
            "5      \t [ 1.38431049  2.01198974  5.          0.99962019 19.          0.43410173]. \t  -1.4812282668358374 \t -1.3814631927491285\n",
            "6      \t [ 0.24849923  8.89894441 12.          0.55765506 12.          0.24110321]. \t  -1.6960625707011168 \t -1.3814631927491285\n",
            "7      \t [ 9.14713824  0.07484253  6.          0.59644494 18.          0.23277246]. \t  -1.6955072679167311 \t -1.3814631927491285\n",
            "8      \t [2.60467387 1.69759745 7.         0.66029575 2.         0.33596206]. \t  -1.5242955464700683 \t -1.3814631927491285\n",
            "9      \t [ 3.21523099  9.01411529  5.          0.71759952 10.          0.55614635]. \t  -1.4576099118722177 \t -1.3814631927491285\n",
            "10     \t [9.03865737 8.3609218  5.         0.67278271 3.         0.94732904]. \t  -1.4363334391982163 \t -1.3814631927491285\n",
            "11     \t [ 8.95958255  8.68558585  7.          0.83565872 16.          0.19670804]. \t  -1.6944002607106452 \t -1.3814631927491285\n",
            "12     \t [ 0.25014222  1.63131458 14.          0.76511372 18.          0.34115868]. \t  -1.525866997083546 \t -1.3814631927491285\n",
            "13     \t [ 9.8386932   0.06427629 14.          0.90521004  4.          0.3283497 ]. \t  -1.5258385027616264 \t -1.3814631927491285\n",
            "14     \t [ 0.53168452  6.22780986 14.          0.60501546  6.          0.86794467]. \t  -1.3935958988363564 \t -1.3814631927491285\n",
            "15     \t [ 2.48128047  9.70146472  6.          0.59664322 19.          0.9781653 ]. \t  -1.4115942567427784 \t -1.3814631927491285\n",
            "16     \t [ 0.45887278  2.85056326  5.          0.74071653 10.          0.59169802]. \t  -1.456518593617855 \t -1.3814631927491285\n",
            "17     \t [ 7.13034425  5.06408202  5.          0.68138745 11.          0.35508943]. \t  -1.5234111731990247 \t -1.3814631927491285\n",
            "18     \t [ 7.14553626  1.23155981 14.          0.66739229 19.          0.6965719 ]. \t  -1.4067956272209592 \t -1.3814631927491285\n",
            "19     \t [ 7.96608258  7.94548372 14.          0.73851386 17.          0.8059717 ]. \t  -1.3873071539547066 \t -1.3814631927491285\n",
            "20     \t [ 5.21101553  9.67647733 14.          0.62080142  7.          0.61297287]. \t  -1.4261281081690989 \t -1.3814631927491285\n",
            "21     \t [ 3.95033192  3.33060238 14.          0.94774536 15.          0.9379921 ]. \t  \u001b[92m-1.3761181111167455\u001b[0m \t -1.3761181111167455\n",
            "22     \t [ 0.05328809  6.59440794  5.          0.5        15.08777473  1.        ]. \t  -1.4302941405224914 \t -1.3761181111167455\n",
            "23     \t [7.45031435 0.09330355 9.39697447 0.79637454 1.         0.76490414]. \t  -1.3921707386092401 \t -1.3761181111167455\n",
            "24     \t [5.82122745 6.12272363 9.         0.98593278 4.         0.73696219]. \t  -1.4025659489306581 \t -1.3761181111167455\n",
            "25     \t [ 8.15054467  1.02897349 14.          0.91391062  9.          0.45468598]. \t  -1.480034979659725 \t -1.3761181111167455\n",
            "26     \t [8.85653809 9.85136423 6.         0.62679211 8.         0.32810376]. \t  -1.522877497837814 \t -1.3761181111167455\n",
            "27     \t [ 9.63349954  0.          6.59642491  1.         10.84907699  1.        ]. \t  -1.4049134568513615 \t -1.3761181111167455\n",
            "28     \t [ 0.          0.         11.33936993  1.          2.86407601  1.        ]. \t  \u001b[92m-1.3739682913937652\u001b[0m \t -1.3739682913937652\n",
            "29     \t [ 3.2569353   3.18728918 11.          0.75726487 14.          0.49398999]. \t  -1.4791786224496222 \t -1.3739682913937652\n",
            "30     \t [0.02795003 4.81524904 8.59248409 0.5        5.71361364 0.1       ]. \t  -1.6949638568627041 \t -1.3739682913937652\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49865.06963765026"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2F_Q194U3uu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63fc01df-fb8f-402f-c6a2-0fbbfb2ab9fc"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'gp' Acquisition Function run number = 14\n",
        "\n",
        "np.random.seed(run_num_14)\n",
        "surrogate_gp_14 = GaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train14, X_test14, y_train14, y_test14 = train_test_split(X, y, test_size=test_perc, random_state=run_num_14)\n",
        "\n",
        "def f_syn_polarity14(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_14, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train14, y=y_train14).mean())\n",
        "    return operator * score\n",
        "\n",
        "gp_14 = GPGO(surrogate_gp_14, Acquisition_new(util_gp), f_syn_polarity14, param, n_jobs = -1) # define BayesOpt\n",
        "gp_14.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_gp_14 = gp_14.getResult()[0]\n",
        "params_gp_14['max_depth'] = int(params_gp_14['max_depth'])\n",
        "params_gp_14['min_child_weight'] = int(params_gp_14['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_gp_train14 = xgb.DMatrix(X_train14, y_train14)\n",
        "dX_gp_test14 = xgb.DMatrix(X_test14, y_test14)\n",
        "model_gp_14 = xgb.train(params_gp_14, dX_gp_train14)\n",
        "pred_gp_14 = model_gp_14.predict(dX_gp_test14)\n",
        "\n",
        "rmse_gp_14 = np.sqrt(mean_squared_error(pred_gp_14, y_test14))\n",
        "rmse_gp_14"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 5.13943344  7.73165052 12.          0.6831412  11.          0.37876233]. \t  -1.5555798623190729 \t -1.4024696810470139\n",
            "init   \t [ 9.57603739  5.13116712 14.          0.76959997 12.          0.71328228]. \t  -1.4192714165556448 \t -1.4024696810470139\n",
            "init   \t [5.34950319 2.47493539 5.         0.50293689 6.         0.29706373]. \t  -1.6043764718675084 \t -1.4024696810470139\n",
            "init   \t [ 2.94506579  3.45329697  8.          0.87620946 14.          0.9783044 ]. \t  -1.4024696810470139 \t -1.4024696810470139\n",
            "init   \t [ 1.11811929  1.73004086  5.          0.73745288 12.          0.20586008]. \t  -1.6112248980856712 \t -1.4024696810470139\n",
            "1      \t [ 6.50637223  2.67617722 14.          0.53562507  1.          0.16862152]. \t  -1.6022414457029215 \t -1.4024696810470139\n",
            "2      \t [ 9.22243919  0.59642165  6.          0.72537748 19.          0.46639325]. \t  -1.564344837026232 \t -1.4024696810470139\n",
            "3      \t [ 5.79577795  1.8570688  14.          0.83128935 19.          0.71549729]. \t  -1.4169867499577495 \t -1.4024696810470139\n",
            "4      \t [9.32373648 9.05676215 9.         0.53064322 3.         0.70657534]. \t  -1.42733721626933 \t -1.4024696810470139\n",
            "5      \t [ 9.52454394  8.82757271  9.          0.90064956 19.          0.16022914]. \t  -1.6022845508632764 \t -1.4024696810470139\n",
            "6      \t [ 3.61508571  7.70718733 10.          0.62042707  5.          0.12186292]. \t  -1.602233101109481 \t -1.4024696810470139\n",
            "7      \t [ 0.05037086  7.50461284  5.          0.70076046 19.          0.10543546]. \t  -1.6116524740300122 \t -1.4024696810470139\n",
            "8      \t [ 9.40430013  0.15700131  7.          0.99940272 12.          0.43771306]. \t  -1.5573888104973324 \t -1.4024696810470139\n",
            "9      \t [ 0.40405522  2.81796516 11.          0.8908648   1.          0.54002187]. \t  -1.4639850559345085 \t -1.4024696810470139\n",
            "10     \t [ 2.08494663  9.70581169 14.          0.64307382  3.          0.10613693]. \t  -1.6030119269054786 \t -1.4024696810470139\n",
            "11     \t [ 1.55781918  0.46142569 10.          0.80240433 16.          0.22604037]. \t  -1.60177102977272 \t -1.4024696810470139\n",
            "12     \t [ 8.32471637  8.64868248  5.          0.80719895 12.          0.64183859]. \t  -1.4404446830987008 \t -1.4024696810470139\n",
            "13     \t [ 1.63603408  9.08540306 13.          0.75743361 17.          0.35594014]. \t  -1.587913089307395 \t -1.4024696810470139\n",
            "14     \t [ 2.19312776  1.39765821 13.          0.6652195   7.          0.63762954]. \t  -1.4222324219911133 \t -1.4024696810470139\n",
            "15     \t [9.46744067 0.0339838  9.         0.74305504 6.         0.26947831]. \t  -1.5881306431931612 \t -1.4024696810470139\n",
            "16     \t [0.0435652  8.78739493 5.         0.77065126 4.         0.67815602]. \t  -1.4394328305576434 \t -1.4024696810470139\n",
            "17     \t [ 3.43075392  3.21961062 14.          0.99813107 13.          0.94340707]. \t  \u001b[92m-1.3964001881391521\u001b[0m \t -1.3964001881391521\n",
            "18     \t [ 2.97507046  9.85127832  5.          0.75729568 12.          0.23402253]. \t  -1.611298267555469 \t -1.3964001881391521\n",
            "19     \t [ 9.95126131  9.64022555 11.          0.74273384  9.          0.68757519]. \t  -1.4199186833049537 \t -1.3964001881391521\n",
            "20     \t [ 7.50974882  6.12589601 14.          0.77913808  6.          0.27444251]. \t  -1.5891726948933933 \t -1.3964001881391521\n",
            "21     \t [4.01077079 4.87438744 7.         0.96137822 1.         0.27391463]. \t  -1.5927161505995344 \t -1.3964001881391521\n",
            "22     \t [ 0.98687002  0.46451547  5.          0.53593171 19.          0.17227232]. \t  -1.6100345677772712 \t -1.3964001881391521\n",
            "23     \t [ 5.32421952 10.          5.          1.         19.          1.        ]. \t  -1.4242100933902138 \t -1.3964001881391521\n",
            "24     \t [ 0.68728119  6.88874322 14.          0.56925497  8.          0.98569942]. \t  -1.405810115680569 \t -1.3964001881391521\n",
            "25     \t [ 0.   0.  15.   0.5 20.   1. ]. \t  \u001b[92m-1.3848610984735081\u001b[0m \t -1.3848610984735081\n",
            "26     \t [4.98125015 9.32607017 6.         0.79018295 8.         0.37250842]. \t  -1.5974622816849782 \t -1.3848610984735081\n",
            "27     \t [ 8.70162135  0.29353067 12.          0.52032166 14.          0.17293308]. \t  -1.6011070386808484 \t -1.3848610984735081\n",
            "28     \t [ 8.27686849  4.09226404 11.          0.93221919  8.          0.64340763]. \t  -1.4164920078002272 \t -1.3848610984735081\n",
            "29     \t [0.30844082 1.68294033 6.         0.62646826 5.         0.88330573]. \t  -1.4193442087588626 \t -1.3848610984735081\n",
            "30     \t [9.67199856 3.0463468  9.43414972 0.5        1.         0.1       ]. \t  -1.6020215763823606 \t -1.3848610984735081\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "52311.56793669759"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Po5wImJaU6VC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "632b8730-6636-4f87-bf92-8df194619c90"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'gp' Acquisition Function run number = 15\n",
        "\n",
        "np.random.seed(run_num_15)\n",
        "surrogate_gp_15 = GaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train15, X_test15, y_train15, y_test15 = train_test_split(X, y, test_size=test_perc, random_state=run_num_15)\n",
        "\n",
        "def f_syn_polarity15(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_15, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train15, y=y_train15).mean())\n",
        "    return operator * score\n",
        "\n",
        "gp_15 = GPGO(surrogate_gp_15, Acquisition_new(util_gp), f_syn_polarity15, param, n_jobs = -1) # define BayesOpt\n",
        "gp_15.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_gp_15 = gp_15.getResult()[0]\n",
        "params_gp_15['max_depth'] = int(params_gp_15['max_depth'])\n",
        "params_gp_15['min_child_weight'] = int(params_gp_15['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_gp_train15 = xgb.DMatrix(X_train15, y_train15)\n",
        "dX_gp_test15 = xgb.DMatrix(X_test15, y_test15)\n",
        "model_gp_15 = xgb.train(params_gp_15, dX_gp_train15)\n",
        "pred_gp_15 = model_gp_15.predict(dX_gp_test15)\n",
        "\n",
        "rmse_gp_15 = np.sqrt(mean_squared_error(pred_gp_15, y_test15))\n",
        "rmse_gp_15"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 8.48817697  1.78895925 12.          0.55549316  8.          0.93397854]. \t  -1.376451715987612 \t -1.376451715987612\n",
            "init   \t [ 0.24953032  8.22298097 12.          0.62494951 11.          0.12924598]. \t  -1.5659547455717522 \t -1.376451715987612\n",
            "init   \t [ 5.02017228  5.50882771 11.          0.85295832 19.          0.13548008]. \t  -1.5651600836199522 \t -1.376451715987612\n",
            "init   \t [2.0023081  9.98543403 7.         0.6295772  2.         0.526127  ]. \t  -1.4164354656135685 \t -1.376451715987612\n",
            "init   \t [ 5.09715306  9.45038417 11.          0.7388277  16.          0.22739973]. \t  -1.5662872595805275 \t -1.376451715987612\n",
            "1      \t [ 0.29158961  4.9949242  12.          0.89124583  3.          0.67554049]. \t  -1.3814014024038652 \t -1.376451715987612\n",
            "2      \t [3.68214008 4.55748717 6.         0.60488381 8.         0.88973248]. \t  -1.409417039109656 \t -1.376451715987612\n",
            "3      \t [9.75991344 6.15203198 6.         0.65490407 1.         0.73816291]. \t  -1.434052604843357 \t -1.376451715987612\n",
            "4      \t [ 0.04347405  0.16019908 11.          0.96902942  9.          0.40185268]. \t  -1.4912886214882008 \t -1.376451715987612\n",
            "5      \t [ 6.65116837  8.16324548 14.          0.95750787  1.          0.74925927]. \t  -1.3835754605277415 \t -1.376451715987612\n",
            "6      \t [1.13261559 9.28349969 7.         0.98964629 7.         0.37032959]. \t  -1.5321752314839754 \t -1.376451715987612\n",
            "7      \t [ 5.30770728  0.52044454  5.          0.75000665 15.          0.36204331]. \t  -1.5405533309916828 \t -1.376451715987612\n",
            "8      \t [ 9.99655383  8.39499737  6.          0.67304848 18.          0.73483896]. \t  -1.4333260183385295 \t -1.376451715987612\n",
            "9      \t [ 0.53269319  3.10786722 14.          0.59617872 16.          0.1338107 ]. \t  -1.5676411414124878 \t -1.376451715987612\n",
            "10     \t [ 8.93696009  0.85767079 13.          0.81270336  5.          0.91231878]. \t  \u001b[92m-1.367567800306326\u001b[0m \t -1.367567800306326\n",
            "11     \t [ 2.97928851  7.73905112  6.          0.87870551 18.          0.36796416]. \t  -1.5362986940304182 \t -1.367567800306326\n",
            "12     \t [3.02150875 0.49910736 5.         0.91633249 1.         0.11262301]. \t  -1.5698220321275584 \t -1.367567800306326\n",
            "13     \t [ 9.52301108  9.56759639  5.          0.87397797 11.          0.23091707]. \t  -1.569385681404325 \t -1.367567800306326\n",
            "14     \t [ 7.09557213  0.02461437 14.          0.76122797 15.          0.64719348]. \t  -1.3849435816230813 \t -1.367567800306326\n",
            "15     \t [ 9.71215516  9.31848438 12.          0.64520711  3.          0.99268325]. \t  -1.3740671813415748 \t -1.367567800306326\n",
            "16     \t [ 5.50024874  9.43132458 14.          0.7989196   9.          0.98009911]. \t  -1.367674954509086 \t -1.367567800306326\n",
            "17     \t [ 0.11138125  2.32868485  8.          0.89421542 19.          0.22148224]. \t  -1.5638657083878622 \t -1.367567800306326\n",
            "18     \t [10.         10.         13.06691057  0.5        20.          1.        ]. \t  -1.384089785935408 \t -1.367567800306326\n",
            "19     \t [ 2.27839391  3.48085254  9.          0.82265329 13.          0.31218776]. \t  -1.5308323963166444 \t -1.367567800306326\n",
            "20     \t [ 9.25728564  5.26038256 11.          0.59019992 14.          0.7451302 ]. \t  -1.3942932454421542 \t -1.367567800306326\n",
            "21     \t [8.5494149  1.73174988 6.         0.87711027 5.         0.60256102]. \t  -1.4314601830042388 \t -1.367567800306326\n",
            "22     \t [ 9.62142849  1.52309765  6.          0.56506114 19.          0.2885673 ]. \t  -1.5380478896564154 \t -1.367567800306326\n",
            "23     \t [ 9.99496189  2.0757972   7.          0.84610912 11.          0.26906844]. \t  -1.5338290523587796 \t -1.367567800306326\n",
            "24     \t [ 0.         10.          6.06796224  1.         13.50582032  0.1       ]. \t  -1.5306111201115846 \t -1.367567800306326\n",
            "25     \t [ 0.50551835  0.14826145 12.          0.5         1.          0.1       ]. \t  -1.567877421897687 \t -1.367567800306326\n",
            "26     \t [6.72036499 9.58584789 7.         0.87733607 7.         0.17836235]. \t  -1.5662037854996131 \t -1.367567800306326\n",
            "27     \t [ 1.72891896 10.         14.00216329  0.5         1.          1.        ]. \t  -1.388398374745078 \t -1.367567800306326\n",
            "28     \t [ 0.09538892 10.         13.34723119  0.5        20.          1.        ]. \t  -1.3840886835729567 \t -1.367567800306326\n",
            "29     \t [ 3.73383719  3.48941963 15.          1.         10.94676488  1.        ]. \t  -1.3682800897169791 \t -1.367567800306326\n",
            "30     \t [ 3.67159606  4.37479925 11.29248355  0.5         7.2124537   0.1       ]. \t  -1.5667709364747016 \t -1.367567800306326\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49910.28580714552"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HrAQN-pU9Qo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9c93e43-7ed2-4c9d-d8c2-cd6b8a86a824"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'gp' Acquisition Function run number = 16\n",
        "\n",
        "np.random.seed(run_num_16)\n",
        "surrogate_gp_16 = GaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train16, X_test16, y_train16, y_test16 = train_test_split(X, y, test_size=test_perc, random_state=run_num_16)\n",
        "\n",
        "def f_syn_polarity16(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_16, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train16, y=y_train16).mean())\n",
        "    return operator * score\n",
        "\n",
        "gp_16 = GPGO(surrogate_gp_16, Acquisition_new(util_gp), f_syn_polarity16, param, n_jobs = -1) # define BayesOpt\n",
        "gp_16.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_gp_16 = gp_16.getResult()[0]\n",
        "params_gp_16['max_depth'] = int(params_gp_16['max_depth'])\n",
        "params_gp_16['min_child_weight'] = int(params_gp_16['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_gp_train16 = xgb.DMatrix(X_train16, y_train16)\n",
        "dX_gp_test16 = xgb.DMatrix(X_test16, y_test16)\n",
        "model_gp_16 = xgb.train(params_gp_16, dX_gp_train16)\n",
        "pred_gp_16 = model_gp_16.predict(dX_gp_test16)\n",
        "\n",
        "rmse_gp_16 = np.sqrt(mean_squared_error(pred_gp_16, y_test16))\n",
        "rmse_gp_16"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [2.23291079 5.23163341 6.         0.65430839 5.         0.30077285]. \t  -1.5445131891906443 \t -1.5311877282940682\n",
            "init   \t [6.88726162 1.63731425 7.         0.97050543 2.         0.25392012]. \t  -1.5397173057708042 \t -1.5311877282940682\n",
            "init   \t [ 5.94328983  5.6393473   5.          0.67602695 19.          0.42538144]. \t  -1.5311877282940682 \t -1.5311877282940682\n",
            "init   \t [ 0.88741148  3.08148142 14.          0.56043938  9.          0.27515386]. \t  -1.545084837896393 \t -1.5311877282940682\n",
            "init   \t [ 2.74631586  1.30996118 11.          0.52160786  8.          0.27956463]. \t  -1.5455911570787226 \t -1.5311877282940682\n",
            "1      \t [ 7.8937256   1.5972923  14.          0.61610774 17.          0.78739284]. \t  \u001b[92m-1.416411889040415\u001b[0m \t -1.416411889040415\n",
            "2      \t [ 9.01655783  8.21383177  9.          0.60772965 10.          0.9401803 ]. \t  \u001b[92m-1.3918448667936738\u001b[0m \t -1.3918448667936738\n",
            "3      \t [ 4.35132073  9.89698316 12.          0.94137984 16.          0.57741056]. \t  -1.4703780749414233 \t -1.3918448667936738\n",
            "4      \t [ 9.99266675  2.3482113  14.          0.65036483  2.          0.18233953]. \t  -1.5584826301317314 \t -1.3918448667936738\n",
            "5      \t [ 6.10466162  9.7407612  14.          0.94272754  1.          0.44776149]. \t  -1.5261434245626113 \t -1.3918448667936738\n",
            "6      \t [ 0.85309637  3.25044751 10.          0.72917812 19.          0.59717282]. \t  -1.4714651475001548 \t -1.3918448667936738\n",
            "7      \t [ 4.26860043  3.42752897  5.          0.50941556 12.          0.6715708 ]. \t  -1.4743462549929636 \t -1.3918448667936738\n",
            "8      \t [8.94430486 7.20655808 9.         0.72124353 2.         0.50974082]. \t  -1.4730433653031816 \t -1.3918448667936738\n",
            "9      \t [ 1.27230763  4.23505107 12.          0.83635418  2.          0.68972104]. \t  -1.4295645741908234 \t -1.3918448667936738\n",
            "10     \t [ 9.39421065  1.15238895 10.          0.86257926 10.          0.82976642]. \t  -1.4125632140700126 \t -1.3918448667936738\n",
            "11     \t [ 1.24722194  8.61098711  7.          0.8332647  13.          0.95770358]. \t  -1.4048333824782346 \t -1.3918448667936738\n",
            "12     \t [ 0.56085252  9.28952868 12.90538594  0.5         7.14042589  1.        ]. \t  \u001b[92m-1.3864693550159657\u001b[0m \t -1.3864693550159657\n",
            "13     \t [ 9.12869134  9.21110573  6.          0.97189779 15.          0.84522104]. \t  -1.4500711132190474 \t -1.3864693550159657\n",
            "14     \t [2.43756281e-03 1.86203502e-01 1.10000000e+01 5.84519618e-01\n",
            " 1.30000000e+01 2.30149841e-01]. \t  -1.5578200935879836 \t -1.3864693550159657\n",
            "15     \t [ 9.04508355  2.79238236  6.          0.57508185 15.          0.81346745]. \t  -1.4477677098626835 \t -1.3864693550159657\n",
            "16     \t [ 9.80203814  5.08834263 14.          0.60567693  8.          0.92815593]. \t  -1.3910801221532587 \t -1.3864693550159657\n",
            "17     \t [ 9.28048782  8.68448405 12.          0.88207994 19.          0.89868617]. \t  -1.387256933592076 \t -1.3864693550159657\n",
            "18     \t [ 0.06909596  9.96923496  8.          0.86088515 19.          0.34694652]. \t  -1.539105177155323 \t -1.3864693550159657\n",
            "19     \t [ 3.92480099  5.40964322 12.          0.71365949 13.          0.24890557]. \t  -1.556566889337666 \t -1.3864693550159657\n",
            "20     \t [ 9.8049394   5.64638797 12.          0.54117047 14.          0.36652185]. \t  -1.545201254225955 \t -1.3864693550159657\n",
            "21     \t [0.66157836 9.34435957 8.         0.77097926 1.         0.98953743]. \t  -1.3964918521130474 \t -1.3864693550159657\n",
            "22     \t [7.93549203 3.33469655 5.         0.69861256 8.         0.82745681]. \t  -1.4637450863581072 \t -1.3864693550159657\n",
            "23     \t [0.63596114 0.36601256 8.         0.62063923 2.         0.75529163]. \t  -1.4263829834960373 \t -1.3864693550159657\n",
            "24     \t [ 3.51469751  4.61304636 14.49292419  1.         18.41578213  0.1       ]. \t  -1.5581268703358184 \t -1.3864693550159657\n",
            "25     \t [7.3758468  9.27269285 6.         0.56233653 6.         0.21830906]. \t  -1.561176827477611 \t -1.3864693550159657\n",
            "26     \t [ 3.81239939  0.35246626  5.          0.52554366 18.          0.33210519]. \t  -1.5476870461075118 \t -1.3864693550159657\n",
            "27     \t [ 5.51954089  0.67514983 14.          0.56532869  4.          0.54553004]. \t  -1.4823560068635029 \t -1.3864693550159657\n",
            "28     \t [5.07379039 7.85907939 5.         0.52936986 1.         0.84442911]. \t  -1.462175258335442 \t -1.3864693550159657\n",
            "29     \t [0.65695569 0.30127043 5.         0.56436611 9.         0.10012212]. \t  -1.5621840706568417 \t -1.3864693550159657\n",
            "30     \t [ 0.03397719  5.49302385  9.          0.60805313 10.          0.11343875]. \t  -1.5574590476911718 \t -1.3864693550159657\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "51006.58259788701"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXelbcAVVCqO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2d07c6e-87a5-43aa-89df-eca900864624"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'gp' Acquisition Function run number = 17\n",
        "\n",
        "np.random.seed(run_num_17)\n",
        "surrogate_gp_17 = GaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train17, X_test17, y_train17, y_test17 = train_test_split(X, y, test_size=test_perc, random_state=run_num_17)\n",
        "\n",
        "def f_syn_polarity17(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_17, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train17, y=y_train17).mean())\n",
        "    return operator * score\n",
        "\n",
        "gp_17 = GPGO(surrogate_gp_17, Acquisition_new(util_gp), f_syn_polarity17, param, n_jobs = -1) # define BayesOpt\n",
        "gp_17.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_gp_17 = gp_17.getResult()[0]\n",
        "params_gp_17['max_depth'] = int(params_gp_17['max_depth'])\n",
        "params_gp_17['min_child_weight'] = int(params_gp_17['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_gp_train17 = xgb.DMatrix(X_train17, y_train17)\n",
        "dX_gp_test17 = xgb.DMatrix(X_test17, y_test17)\n",
        "model_gp_17 = xgb.train(params_gp_17, dX_gp_train17)\n",
        "pred_gp_17 = model_gp_17.predict(dX_gp_test17)\n",
        "\n",
        "rmse_gp_17 = np.sqrt(mean_squared_error(pred_gp_17, y_test17))\n",
        "rmse_gp_17"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 2.94665003  5.30586756 11.          0.94443241 14.          0.80828691]. \t  -1.432187192078573 \t -1.432187192078573\n",
            "init   \t [ 6.56333522  6.37520896 12.          0.81487881 18.          0.42203224]. \t  -1.4945483449196877 \t -1.432187192078573\n",
            "init   \t [ 9.45683187  0.6004468  11.          0.5171566  10.          0.53881211]. \t  -1.4548205565954722 \t -1.432187192078573\n",
            "init   \t [2.72705857 1.19063434 6.         0.74176431 6.         0.10101151]. \t  -1.6432713945852762 \t -1.432187192078573\n",
            "init   \t [ 4.77631812  5.24671297 13.          0.66254476 19.          0.36708086]. \t  -1.5567864797674738 \t -1.432187192078573\n",
            "1      \t [ 0.65702322  5.79284078 13.          0.75136902  1.          0.30306068]. \t  -1.5652619856245054 \t -1.432187192078573\n",
            "2      \t [ 6.93446178  8.68032298 13.          0.78195789  7.          0.91906958]. \t  \u001b[92m-1.38003104553365\u001b[0m \t -1.38003104553365\n",
            "3      \t [9.72843652 3.88893279 9.         0.6901555  1.         0.31608219]. \t  -1.5608607576489912 \t -1.38003104553365\n",
            "4      \t [ 9.65057736  8.52725784  5.          0.68420234 13.          0.40008732]. \t  -1.5175779886624106 \t -1.38003104553365\n",
            "5      \t [ 4.97204887  2.40072226  5.          0.54268748 19.          0.30995407]. \t  -1.5702611271060207 \t -1.38003104553365\n",
            "6      \t [0.12174033 8.73496008 5.         0.89827646 5.         0.85354798]. \t  -1.4615526201092108 \t -1.38003104553365\n",
            "7      \t [ 2.91443079  0.16723755 13.          0.598201    6.          0.91729605]. \t  -1.389287224690272 \t -1.38003104553365\n",
            "8      \t [7.20615247 9.36901627 6.         0.85465034 7.         0.6878262 ]. \t  -1.4551474523018149 \t -1.38003104553365\n",
            "9      \t [ 9.02586164  0.59354638 10.          0.86038693 18.          0.90794111]. \t  -1.3802009359113299 \t -1.38003104553365\n",
            "10     \t [ 0.          5.55153736  5.          0.5        12.82446281  0.1       ]. \t  -1.6485580055021984 \t -1.38003104553365\n",
            "11     \t [ 0.12410542  7.60180472 13.          0.97425003  8.          0.76245421]. \t  -1.432887901007922 \t -1.38003104553365\n",
            "12     \t [ 2.44282715  9.71851747  7.          0.86792183 17.          0.93015556]. \t  -1.3970181930296728 \t -1.38003104553365\n",
            "13     \t [9.59190042 1.26233772 5.         0.55398722 6.         0.46259714]. \t  -1.5201208467499083 \t -1.38003104553365\n",
            "14     \t [10.  10.   5.   0.5 20.   0.1]. \t  -1.6484981212268068 \t -1.38003104553365\n",
            "15     \t [ 0.59590325  0.30071901  8.          0.9148403  16.          0.62633871]. \t  -1.4373113896623342 \t -1.38003104553365\n",
            "16     \t [ 8.69529605  0.27226865 14.          0.90636352  1.          0.39638219]. \t  -1.5046635673583721 \t -1.38003104553365\n",
            "17     \t [ 5.5997101   2.80089542 11.          0.91397635  4.          0.58148876]. \t  -1.4494302633410614 \t -1.38003104553365\n",
            "18     \t [0.80821954 3.92969474 5.         0.76246697 1.         0.44850699]. \t  -1.5174417372376876 \t -1.38003104553365\n",
            "19     \t [ 8.34933229  9.44839603 12.          0.7237677   1.          0.61392301]. \t  -1.4568845318807093 \t -1.38003104553365\n",
            "20     \t [ 7.9822505   0.1930237   5.          0.88184327 12.          0.30139498]. \t  -1.5670334372887373 \t -1.38003104553365\n",
            "21     \t [5.87263712 6.8450002  5.         0.7215051  1.         0.7571289 ]. \t  -1.4615803239773477 \t -1.38003104553365\n",
            "22     \t [4.75219772 4.87503255 8.45725083 0.5        9.27138775 1.        ]. \t  -1.3935095860770759 \t -1.38003104553365\n",
            "23     \t [ 0.          1.26400272 11.11375571  0.5        10.90818108  0.1       ]. \t  -1.6468479273927652 \t -1.38003104553365\n",
            "24     \t [ 0.         10.          8.37705939  0.5        10.86957076  0.97532522]. \t  -1.4005686486899205 \t -1.38003104553365\n",
            "25     \t [4.87734487 0.64350127 7.         0.63026204 1.         0.82731867]. \t  -1.446123608470477 \t -1.38003104553365\n",
            "26     \t [1.41729765e-03 8.21631165e+00 1.50000000e+01 5.95539694e-01\n",
            " 1.66579439e+01 3.12348673e-01]. \t  -1.5593353631818125 \t -1.38003104553365\n",
            "27     \t [ 9.74261362  9.42398989 13.          0.72114466 14.          0.32286083]. \t  -1.5564980156871067 \t -1.38003104553365\n",
            "28     \t [2.44311729 9.62067961 9.40741272 1.         1.         0.67837812]. \t  -1.486744358680933 \t -1.38003104553365\n",
            "29     \t [ 0.05259888  5.3518091   8.34924339  1.         19.9366114   0.1       ]. \t  -1.638380304471329 \t -1.38003104553365\n",
            "30     \t [ 9.6296564   4.05482725 14.          0.85993848  6.          0.44197287]. \t  -1.499442491325177 \t -1.38003104553365\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49701.87282233635"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJG2fAtAVFDZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca595152-16de-4738-a07c-441ed686b80b"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'gp' Acquisition Function run number = 18\n",
        "\n",
        "np.random.seed(run_num_18)\n",
        "surrogate_gp_18 = GaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train18, X_test18, y_train18, y_test18 = train_test_split(X, y, test_size=test_perc, random_state=run_num_18)\n",
        "\n",
        "def f_syn_polarity18(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_11, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train18, y=y_train18).mean())\n",
        "    return operator * score\n",
        "\n",
        "gp_18 = GPGO(surrogate_gp_18, Acquisition_new(util_gp), f_syn_polarity18, param, n_jobs = -1) # define BayesOpt\n",
        "gp_18.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_gp_18 = gp_18.getResult()[0]\n",
        "params_gp_18['max_depth'] = int(params_gp_18['max_depth'])\n",
        "params_gp_18['min_child_weight'] = int(params_gp_18['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_gp_train18 = xgb.DMatrix(X_train18, y_train18)\n",
        "dX_gp_test18 = xgb.DMatrix(X_test18, y_test18)\n",
        "model_gp_18 = xgb.train(params_gp_18, dX_gp_train18)\n",
        "pred_gp_18 = model_gp_18.predict(dX_gp_test18)\n",
        "\n",
        "rmse_gp_18 = np.sqrt(mean_squared_error(pred_gp_18, y_test18))\n",
        "rmse_gp_18"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [6.50374242 5.05453374 6.         0.59092011 3.         0.28357516]. \t  -1.554201920032415 \t -1.4181769530522108\n",
            "init   \t [0.11506734 4.26891483 9.         0.81785956 5.         0.63489043]. \t  -1.4181769530522108 \t -1.4181769530522108\n",
            "init   \t [ 2.8861259   6.35547834 11.          0.64267955 14.          0.27877092]. \t  -1.5553172299320928 \t -1.4181769530522108\n",
            "init   \t [6.57189031 6.99655629 8.         0.63235896 4.         0.52894035]. \t  -1.4757071646006859 \t -1.4181769530522108\n",
            "init   \t [ 6.66600348  2.11312037 14.          0.74363461  4.          0.73174558]. \t  -1.4231733496037333 \t -1.4181769530522108\n",
            "1      \t [ 8.67093232  0.11649132  5.          0.92962202 15.          0.53672863]. \t  -1.4839064811956693 \t -1.4181769530522108\n",
            "2      \t [ 8.43851229  2.41114508 13.          0.75771586 19.          0.86905071]. \t  \u001b[92m-1.4170388469543282\u001b[0m \t -1.4170388469543282\n",
            "3      \t [ 9.44281001  9.01534322  7.          0.99142432 16.          0.37631199]. \t  -1.4817355854839138 \t -1.4170388469543282\n",
            "4      \t [ 3.19538294  9.91737336 14.          0.7976317   5.          0.25704487]. \t  -1.556808253849707 \t -1.4170388469543282\n",
            "5      \t [ 0.21200191  9.95034596  6.          0.77719285 19.          0.61346381]. \t  -1.4769477292513715 \t -1.4170388469543282\n",
            "6      \t [ 1.26601315  0.31299408  6.          0.95296222 16.          0.13649883]. \t  -1.5994083421933591 \t -1.4170388469543282\n",
            "7      \t [ 1.2588084   9.80413977  5.          0.75618546 12.          0.53020258]. \t  -1.4864755539001755 \t -1.4170388469543282\n",
            "8      \t [ 6.63763513  1.21594617 14.          0.92753462 12.          0.25002233]. \t  -1.5497531337346515 \t -1.4170388469543282\n",
            "9      \t [ 7.49192948  9.60283663 14.          0.93718151 19.          0.24625933]. \t  -1.6000990236826755 \t -1.4170388469543282\n",
            "10     \t [ 4.47885244  2.43320277  7.          0.94199375 10.          0.18110335]. \t  -1.6001091393531823 \t -1.4170388469543282\n",
            "11     \t [9.98653758 8.80568206 9.         0.86984433 9.         0.78984159]. \t  \u001b[92m-1.4153730810920688\u001b[0m \t -1.4153730810920688\n",
            "12     \t [ 1.68019344  0.20490035 13.          0.89332378 19.          0.17761947]. \t  -1.6017551704266366 \t -1.4153730810920688\n",
            "13     \t [0.58655573 8.89860432 5.         0.62593909 1.         0.46819727]. \t  -1.4919070358164288 \t -1.4153730810920688\n",
            "14     \t [ 4.25762222  4.02301922  9.          0.6129246  19.          0.59981465]. \t  -1.4722561560272687 \t -1.4153730810920688\n",
            "15     \t [ 0.         10.         15.          1.         19.05529788  0.1       ]. \t  -1.6001165193533002 \t -1.4153730810920688\n",
            "16     \t [ 5.19698908  7.3359847  15.          0.55236124  9.79168501  0.7136993 ]. \t  -1.425296334097221 \t -1.4153730810920688\n",
            "17     \t [ 0.40313625  2.99614021 14.          0.85649477 11.          0.77047003]. \t  -1.4157193536165775 \t -1.4153730810920688\n",
            "18     \t [ 9.56072091  9.1368036  14.          0.68050527  1.          0.47597207]. \t  -1.4980138659295537 \t -1.4153730810920688\n",
            "19     \t [0.99924333 0.         6.68651107 0.7716238  2.68651107 0.46981663]. \t  -1.4845815153260271 \t -1.4153730810920688\n",
            "20     \t [ 1.47346798  3.42280397 13.          0.87173303  1.          0.71719115]. \t  -1.4287338891758996 \t -1.4153730810920688\n",
            "21     \t [ 3.44515297  9.88839832 10.          0.9177246   1.          0.9409372 ]. \t  \u001b[92m-1.3769562579809285\u001b[0m \t -1.3769562579809285\n",
            "22     \t [ 9.49894385  0.77810151 10.          0.58753678  8.          0.98856388]. \t  -1.3826987171957712 \t -1.3769562579809285\n",
            "23     \t [ 9.74561971  4.04943837  5.          0.5        20.          1.        ]. \t  -1.4218864689875872 \t -1.3769562579809285\n",
            "24     \t [9.78152027 0.75275159 9.         0.84702061 1.         0.21494752]. \t  -1.602311922418087 \t -1.3769562579809285\n",
            "25     \t [ 8.59573283  4.42214943 10.          0.58523007 14.          0.18190609]. \t  -1.601803779574866 \t -1.3769562579809285\n",
            "26     \t [ 4.58131525  4.34231136  5.07781169  0.5        14.86002263  0.1       ]. \t  -1.5998591320589202 \t -1.3769562579809285\n",
            "27     \t [ 0.         0.        15.         0.5        4.6884172  0.1      ]. \t  -1.6016049484918835 \t -1.3769562579809285\n",
            "28     \t [10.          3.69499731  5.          0.5         9.26691542  1.        ]. \t  -1.4217326748069212 \t -1.3769562579809285\n",
            "29     \t [10.          8.21814993 15.          1.         12.40702911  0.1       ]. \t  -1.6001398804415765 \t -1.3769562579809285\n",
            "30     \t [10.          0.          5.          1.          5.18820539  1.        ]. \t  -1.4154624751088907 \t -1.3769562579809285\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "48907.311549394726"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHidSEGcVHvG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d02e51a1-7faa-4bc9-8b03-100736aa593f"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'gp' Acquisition Function run number = 19\n",
        "\n",
        "np.random.seed(run_num_19)\n",
        "surrogate_gp_19 = GaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train19, X_test19, y_train19, y_test19 = train_test_split(X, y, test_size=test_perc, random_state=run_num_19)\n",
        "\n",
        "def f_syn_polarity19(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_19, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train19, y=y_train19).mean())\n",
        "    return operator * score\n",
        "\n",
        "gp_19 = GPGO(surrogate_gp_19, Acquisition_new(util_gp), f_syn_polarity19, param, n_jobs = -1) # define BayesOpt\n",
        "gp_19.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_gp_19 = gp_19.getResult()[0]\n",
        "params_gp_19['max_depth'] = int(params_gp_19['max_depth'])\n",
        "params_gp_19['min_child_weight'] = int(params_gp_19['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_gp_train19 = xgb.DMatrix(X_train19, y_train19)\n",
        "dX_gp_test19 = xgb.DMatrix(X_test19, y_test19)\n",
        "model_gp_19 = xgb.train(params_gp_19, dX_gp_train19)\n",
        "pred_gp_19 = model_gp_19.predict(dX_gp_test19)\n",
        "\n",
        "rmse_gp_19 = np.sqrt(mean_squared_error(pred_gp_19, y_test19))\n",
        "rmse_gp_19"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 0.97533602  7.61249717 13.          0.85765469 11.          0.39830191]. \t  -1.4075337339770704 \t -1.4075337339770704\n",
            "init   \t [ 0.82999565  6.71977081  6.          0.50407413 19.          0.67209466]. \t  -1.4228132434714993 \t -1.4075337339770704\n",
            "init   \t [ 2.15923256  5.49027432 12.          0.52588686 10.          0.20235326]. \t  -1.6084741621894145 \t -1.4075337339770704\n",
            "init   \t [4.99659267 1.52108422 6.         0.73481085 4.         0.71949465]. \t  -1.4198106118164695 \t -1.4075337339770704\n",
            "init   \t [ 3.72927156  9.46160045  5.          0.80554614 18.          0.97708466]. \t  -1.4218628552782113 \t -1.4075337339770704\n",
            "1      \t [ 8.33060043  1.42030563  8.          0.92863724 14.          0.78606141]. \t  \u001b[92m-1.3842780004279849\u001b[0m \t -1.3842780004279849\n",
            "2      \t [ 4.70068371  4.9755295  14.          0.98901029  1.          0.96039614]. \t  \u001b[92m-1.372031481989105\u001b[0m \t -1.372031481989105\n",
            "3      \t [9.07948237 9.55063617 7.         0.80962147 4.         0.34142584]. \t  -1.472070120000281 \t -1.372031481989105\n",
            "4      \t [ 3.65000245  2.90359952 13.          0.98940034 19.          0.29019455]. \t  -1.4708108340180257 \t -1.372031481989105\n",
            "5      \t [0.25768796 8.33414072 6.         0.99948369 4.         0.66680619]. \t  -1.4172691326632303 \t -1.372031481989105\n",
            "6      \t [ 8.89243569  4.2136102  10.          0.88870164  8.          0.77683659]. \t  -1.3727429340394495 \t -1.372031481989105\n",
            "7      \t [ 7.9630536   9.9112732  14.          0.53823001 14.          0.26777722]. \t  -1.473086995627504 \t -1.372031481989105\n",
            "8      \t [1.60895472e-01 8.27074864e-03 1.30000000e+01 6.91893018e-01\n",
            " 5.00000000e+00 4.60327119e-01]. \t  -1.412265762362551 \t -1.372031481989105\n",
            "9      \t [ 0.32873959  7.7155114   5.          0.56871173 11.          0.34471029]. \t  -1.4765632459324078 \t -1.372031481989105\n",
            "10     \t [ 6.55489773  0.06438745 14.          0.53351105 11.          0.76391016]. \t  -1.3809975751973738 \t -1.372031481989105\n",
            "11     \t [ 9.32390837  9.51845123 14.          0.71072327  2.          0.55726506]. \t  -1.3894225887477218 \t -1.372031481989105\n",
            "12     \t [ 4.31405249  0.92741236  7.          0.67333637 19.          0.97097788]. \t  -1.3981247907535166 \t -1.372031481989105\n",
            "13     \t [ 0.07353347  8.4040255  13.          0.8931152   4.          0.37840671]. \t  -1.4090516400471915 \t -1.372031481989105\n",
            "14     \t [10.          1.81934613 14.17377026  1.          2.29796158  1.        ]. \t  \u001b[92m-1.3706297612140912\u001b[0m \t -1.3706297612140912\n",
            "15     \t [0.22611985 0.1170465  7.         0.55795985 9.         0.86758401]. \t  -1.399675395140902 \t -1.3706297612140912\n",
            "16     \t [ 9.0780433   8.49155787  5.          0.8925855  13.          0.38273904]. \t  -1.44700455519301 \t -1.3706297612140912\n",
            "17     \t [ 2.66360123  9.86349513 14.          0.64775009 19.          0.29460461]. \t  -1.471057474761123 \t -1.3706297612140912\n",
            "18     \t [ 5.27081379  9.69565951  9.          0.57130727 12.          0.81546981]. \t  -1.3846958512286693 \t -1.3706297612140912\n",
            "19     \t [10.          9.71834805 12.43220434  1.          8.11402915  1.        ]. \t  \u001b[92m-1.3692601393285162\u001b[0m \t -1.3692601393285162\n",
            "20     \t [ 0.          3.27443329 13.89150916  0.5        14.22417302  0.43588923]. \t  -1.413719516990898 \t -1.3692601393285162\n",
            "21     \t [ 9.63925033  0.21213822 12.          0.67633014 18.          0.33271761]. \t  -1.4702920453950845 \t -1.3692601393285162\n",
            "22     \t [10.          4.38757266  7.33498052  0.5         1.          0.1       ]. \t  -1.6083402580778572 \t -1.3692601393285162\n",
            "23     \t [ 9.92956349  7.77258705 12.          0.55312411 19.          0.68798636]. \t  -1.3929948827249123 \t -1.3692601393285162\n",
            "24     \t [5.29135345 7.81521949 5.         0.90273467 1.         0.30567834]. \t  -1.4782948733885863 \t -1.3692601393285162\n",
            "25     \t [0.14886079 3.10947104 7.         0.52818873 1.         0.88078996]. \t  -1.3998190079256125 \t -1.3692601393285162\n",
            "26     \t [ 9.64351854  5.42661113  7.          0.68638573 18.          0.54416589]. \t  -1.4060589173664737 \t -1.3692601393285162\n",
            "27     \t [9.54369369 1.08133324 5.         0.81823057 8.         0.81568043]. \t  -1.4340678502540898 \t -1.3692601393285162\n",
            "28     \t [ 6.03837287  7.14777444 14.          0.87499142  6.          0.38618348]. \t  -1.4094851376450346 \t -1.3692601393285162\n",
            "29     \t [5.11767722 6.2213831  5.         0.95037427 9.         0.35220717]. \t  -1.4769066201474979 \t -1.3692601393285162\n",
            "30     \t [ 7.09183177  3.72662154 14.58994253  0.5        15.1251915   0.1       ]. \t  -1.6072226308497986 \t -1.3692601393285162\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50524.39339298682"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWGPYRJhVKsO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67c1abde-3d35-499b-aed6-d5dec19e4a42"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'gp' Acquisition Function run number = 20\n",
        "\n",
        "np.random.seed(run_num_20)\n",
        "surrogate_gp_20 = GaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train20, X_test20, y_train20, y_test20 = train_test_split(X, y, test_size=test_perc, random_state=run_num_20)\n",
        "\n",
        "def f_syn_polarity20(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_20, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train20, y=y_train20).mean())\n",
        "    return operator * score\n",
        "\n",
        "gp_20 = GPGO(surrogate_gp_20, Acquisition_new(util_gp), f_syn_polarity20, param, n_jobs = -1) # define BayesOpt\n",
        "gp_20.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_gp_20 = gp_20.getResult()[0]\n",
        "params_gp_20['max_depth'] = int(params_gp_20['max_depth'])\n",
        "params_gp_20['min_child_weight'] = int(params_gp_20['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_gp_train20 = xgb.DMatrix(X_train20, y_train20)\n",
        "dX_gp_test20 = xgb.DMatrix(X_test20, y_test20)\n",
        "model_gp_20 = xgb.train(params_gp_20, dX_gp_train20)\n",
        "pred_gp_20 = model_gp_20.predict(dX_gp_test20)\n",
        "\n",
        "rmse_gp_20 = np.sqrt(mean_squared_error(pred_gp_20, y_test20))\n",
        "rmse_gp_20"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 5.88130801  8.97713728 14.          0.81074445  8.          0.95540649]. \t  -1.3748447855907977 \t -1.3748447855907977\n",
            "init   \t [6.72865655 0.41173329 8.         0.6361582  7.         0.76174061]. \t  -1.4185133726703796 \t -1.3748447855907977\n",
            "init   \t [ 4.77387703  8.66202323 10.          0.51833215  7.          0.10123387]. \t  -1.6439786774737961 \t -1.3748447855907977\n",
            "init   \t [ 5.75489985  4.74524381  8.          0.78084343 15.          0.26643049]. \t  -1.534878770114387 \t -1.3748447855907977\n",
            "init   \t [ 4.53444     4.47342833  8.          0.91974896 18.          0.35997552]. \t  -1.5336412960522285 \t -1.3748447855907977\n",
            "1      \t [ 7.96566073  7.15509535  7.          0.79906691 11.          0.34132075]. \t  -1.536147862834937 \t -1.3748447855907977\n",
            "2      \t [ 1.98667885  1.35773177 13.          0.57199118  2.          0.39498908]. \t  -1.5177654419926867 \t -1.3748447855907977\n",
            "3      \t [ 0.05406024  0.42106765 14.          0.6066366  16.          0.86098378]. \t  -1.4186471151892663 \t -1.3748447855907977\n",
            "4      \t [ 9.3606342   3.21248061 14.          0.65614013 17.          0.10926152]. \t  -1.6425026081238112 \t -1.3748447855907977\n",
            "5      \t [8.0846212  5.99993376 6.         0.83941375 1.         0.46362124]. \t  -1.5160706218749516 \t -1.3748447855907977\n",
            "6      \t [0.61316554 1.36115087 5.         0.87944956 1.         0.21740227]. \t  -1.647069572593536 \t -1.3748447855907977\n",
            "7      \t [ 0.72788527  2.26655356 10.          0.97273032 15.          0.85843758]. \t  -1.4077391596162414 \t -1.3748447855907977\n",
            "8      \t [ 7.29847873  0.61439441  5.          0.60353619 15.          0.628184  ]. \t  -1.4345096580234407 \t -1.3748447855907977\n",
            "9      \t [ 4.64103339  9.2844785  14.          0.59589216 16.          0.96162706]. \t  -1.383883729168391 \t -1.3748447855907977\n",
            "10     \t [ 1.01814405  9.81807131 14.          0.52908047  1.          0.89345697]. \t  -1.3962993664603363 \t -1.3748447855907977\n",
            "11     \t [ 1.25677459  5.28407296 10.          0.60004946  4.          0.56610318]. \t  -1.4919500521860947 \t -1.3748447855907977\n",
            "12     \t [ 9.62878188  0.47045758 13.          0.73408624  1.          0.43054124]. \t  -1.513483497598801 \t -1.3748447855907977\n",
            "13     \t [ 8.98143836  8.7693897  12.          0.89468403 12.          0.66552576]. \t  -1.4130024878196525 \t -1.3748447855907977\n",
            "14     \t [ 6.6950957   0.         14.27209554  1.          7.21178157  0.1       ]. \t  -1.6338068683133682 \t -1.3748447855907977\n",
            "15     \t [ 5.37444991  0.3056877   9.          0.99777328 15.          0.5903115 ]. \t  -1.4795657647949234 \t -1.3748447855907977\n",
            "16     \t [ 0.03685635  8.99252991  7.          0.68273443 17.          0.92978046]. \t  -1.395430580686903 \t -1.3748447855907977\n",
            "17     \t [ 0.0269108   5.63927067 14.          0.80391219 10.          0.28928667]. \t  -1.5365227742755958 \t -1.3748447855907977\n",
            "18     \t [ 0. 10.  5.  1. 11.  1.]. \t  -1.412785980362323 \t -1.3748447855907977\n",
            "19     \t [ 8.64250146  8.29138679 14.          0.77039694  1.          0.68995319]. \t  -1.4250949839080236 \t -1.3748447855907977\n",
            "20     \t [ 1.39513001  1.37149056  5.          0.56200696 12.          0.29219492]. \t  -1.546785171195434 \t -1.3748447855907977\n",
            "21     \t [0.15149846 9.88823869 5.         0.95867301 2.         0.16840843]. \t  -1.6467680774651914 \t -1.3748447855907977\n",
            "22     \t [ 8.10941441  9.74874115  6.          0.52082796 19.          0.22723491]. \t  -1.6477856724991806 \t -1.3748447855907977\n",
            "23     \t [ 0.6445059   6.33509243 13.          0.62492289 19.          0.63091816]. \t  -1.4166142966677415 \t -1.3748447855907977\n",
            "24     \t [ 1.28253914  0.15341453 13.          0.85438017  9.          0.20001708]. \t  -1.640937864466003 \t -1.3748447855907977\n",
            "25     \t [2.37069593 4.9707475  5.         0.7881524  7.         0.58748019]. \t  -1.516090785163389 \t -1.3748447855907977\n",
            "26     \t [ 9.47612957  0.28973582 11.          0.50295675 11.          0.23442852]. \t  -1.6446161338379912 \t -1.3748447855907977\n",
            "27     \t [10.          5.61191789 10.04071369  1.          5.87900255  1.        ]. \t  \u001b[92m-1.3625294649715864\u001b[0m \t -1.3625294649715864\n",
            "28     \t [10.          8.99468211 11.47679529  0.5        19.05041644  0.1       ]. \t  -1.6452232654295103 \t -1.3625294649715864\n",
            "29     \t [8.72687752 0.12971134 5.         0.79754502 3.         0.55895681]. \t  -1.5149065002483704 \t -1.3625294649715864\n",
            "30     \t [ 0.21888051  0.35132818  6.          0.77703308 19.          0.35680372]. \t  -1.539156201026812 \t -1.3625294649715864\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50290.85149919465"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1d_1LyydIfe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de6ffae6-102d-4bcc-847d-726244c18799"
      },
      "source": [
        "end_gp = time.time()\n",
        "end_gp\n",
        "\n",
        "time_gp = end_gp - start_gp\n",
        "time_gp\n",
        "\n",
        "start_stp = time.time()\n",
        "start_stp"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1663845832.805419"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAyOw7XYVwAf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3673da3d-5f0b-4c24-830e-5b73b6b09801"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'stp' Acquisition Function run number = 1 \n",
        "\n",
        "np.random.seed(run_num_1)\n",
        "surrogate_stp_1 = tStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train1, X_test1, y_train1, y_test1 = train_test_split(X, y, test_size=test_perc, random_state=run_num_1)\n",
        "\n",
        "def f_syn_polarity1(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_1, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train1, y=y_train1).mean())\n",
        "    return operator * score\n",
        "\n",
        "stp_1 = GPGO(surrogate_stp_1, Acquisition_new(util_stp), f_syn_polarity1, param, n_jobs = -1) # Define BayesOpt\n",
        "stp_1.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_stp_1 = stp_1.getResult()[0]\n",
        "params_stp_1['max_depth'] = int(params_stp_1['max_depth'])\n",
        "params_stp_1['min_child_weight'] = int(params_stp_1['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_stp_train1 = xgb.DMatrix(X_train1, y_train1)\n",
        "dX_stp_test1 = xgb.DMatrix(X_test1, y_test1)\n",
        "model_stp_1 = xgb.train(params_stp_1, dX_stp_train1)\n",
        "pred_stp_1 = model_stp_1.predict(dX_stp_test1)\n",
        "\n",
        "rmse_stp_1 = np.sqrt(mean_squared_error(pred_stp_1, y_test1))\n",
        "rmse_stp_1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 4.17022005  7.20324493 14.          0.65116629 16.          0.31248008]. \t  -1.6139329892980396 \t -1.3678797200853317\n",
            "init   \t [ 3.96580727  3.87910741 11.          0.96776954  6.          0.71669755]. \t  -1.4460566998267423 \t -1.3678797200853317\n",
            "init   \t [ 2.0445225   8.78117436  7.          0.95698101 10.          0.48762871]. \t  -1.5755054668571844 \t -1.3678797200853317\n",
            "init   \t [ 9.39127789  7.78389236 14.          0.98413079  2.          0.87851823]. \t  -1.3678797200853317 \t -1.3678797200853317\n",
            "init   \t [8.29146907 8.29603359 8.         0.58491521 9.         0.18851215]. \t  -1.6515361212564685 \t -1.3678797200853317\n",
            "1      \t [ 7.86951474  0.6406733  11.          0.78919481 19.          0.44182296]. \t  -1.5598734918230905 \t -1.3678797200853317\n",
            "2      \t [ 1.53213416  0.0254654   5.          0.89591052 19.          0.80006363]. \t  -1.4345643510991433 \t -1.3678797200853317\n",
            "3      \t [ 1.50183822  8.58761638 10.          0.99635044  4.          0.82916307]. \t  -1.3996258462682616 \t -1.3678797200853317\n",
            "4      \t [ 5.65732147  9.08808032  6.          0.69595029 18.          0.83818222]. \t  -1.4285184283194432 \t -1.3678797200853317\n",
            "5      \t [9.98806418 1.50440675 6.         0.54760374 1.         0.41555547]. \t  -1.586246485916007 \t -1.3678797200853317\n",
            "6      \t [ 6.24179723  2.64836655 10.          0.81947391  1.          0.33673458]. \t  -1.6145197451691538 \t -1.3678797200853317\n",
            "7      \t [8.6650221  9.45569726 5.         0.8687539  2.         0.61530184]. \t  -1.5322061877126625 \t -1.3678797200853317\n",
            "8      \t [7.48628498 1.51155622 6.         0.85807268 7.         0.37628775]. \t  -1.5846217231295427 \t -1.3678797200853317\n",
            "9      \t [ 4.47599616  8.44385041 11.          0.94031085  7.          0.96918513]. \t  -1.3689885623771654 \t -1.3678797200853317\n",
            "10     \t [ 8.11464609  2.0146632   6.          0.91144529 14.          0.40214185]. \t  -1.582653932611899 \t -1.3678797200853317\n",
            "11     \t [0.00729349 0.2106352  5.         0.83783904 2.         0.22549491]. \t  -1.6541036852200945 \t -1.3678797200853317\n",
            "12     \t [ 0.45906059  0.26611017  8.          0.58032353 12.          0.22425355]. \t  -1.6520299291139036 \t -1.3678797200853317\n",
            "13     \t [ 9.06758413  3.01418741 14.          0.72551833 11.          0.41081156]. \t  -1.5601780240310545 \t -1.3678797200853317\n",
            "14     \t [ 1.3841305   9.86132121 12.          0.92142521  6.          0.35236045]. \t  -1.6139267753013598 \t -1.3678797200853317\n",
            "15     \t [ 9.86204333  8.60405361 11.          0.80139835 15.          0.34648534]. \t  -1.612487470274953 \t -1.3678797200853317\n",
            "16     \t [ 6.15640361  8.42319415  6.          0.63476806 14.          0.78301957]. \t  -1.4257166856763481 \t -1.3678797200853317\n",
            "17     \t [ 1.02343527  0.5518211  13.          0.59111056 19.          0.5850565 ]. \t  -1.506486849915985 \t -1.3678797200853317\n",
            "18     \t [ 5.76113528  3.02448571 12.          0.93856444 16.          0.76020545]. \t  -1.3975024985659985 \t -1.3678797200853317\n",
            "19     \t [ 6.61442417  2.82391077  8.          0.61329489 10.          0.39224918]. \t  -1.569287025686101 \t -1.3678797200853317\n",
            "20     \t [ 1.50144707  5.14920288  9.          0.7661634  16.          0.23702425]. \t  -1.6492131198961644 \t -1.3678797200853317\n",
            "21     \t [0.12629976 7.95651056 5.         0.86964613 1.         0.83818748]. \t  -1.4338741866674867 \t -1.3678797200853317\n",
            "22     \t [ 0.09257908  4.29655963 12.          0.98972055  1.          0.90266783]. \t  -1.3687669027835168 \t -1.3678797200853317\n",
            "23     \t [ 9.23992453  0.05133941 14.          0.88443663  5.          0.65530002]. \t  -1.450938383925194 \t -1.3678797200853317\n",
            "24     \t [4.403566   6.43675047 6.         0.5484318  5.         0.9988694 ]. \t  -1.4140823578615263 \t -1.3678797200853317\n",
            "25     \t [ 0.18256843  9.80114086 11.          0.99093287 18.          0.37632134]. \t  -1.5582545255021636 \t -1.3678797200853317\n",
            "26     \t [9.23021756 6.74716448 9.         0.8274377  5.         0.17491533]. \t  -1.6495843232358094 \t -1.3678797200853317\n",
            "27     \t [ 0.59270101  6.0604431   5.          0.72276441 12.          0.91740607]. \t  -1.4273371140140854 \t -1.3678797200853317\n",
            "28     \t [9.080485   8.82058008 7.         0.69137115 5.         0.61799713]. \t  -1.5183592209940744 \t -1.3678797200853317\n",
            "29     \t [ 1.71913478  1.19069953 14.          0.98073618 12.          0.63106632]. \t  -1.4446858902406146 \t -1.3678797200853317\n",
            "30     \t [ 0.18385951  4.94552467  5.          0.72039973 19.          0.65748155]. \t  -1.494770244291408 \t -1.3678797200853317\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "48973.66312746987"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrDQbChpZ48F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e599e681-7b76-417c-db6f-f59dfb599d24"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'stp' Acquisition Function run number = 2 \n",
        "\n",
        "np.random.seed(run_num_2)\n",
        "surrogate_stp_2 = tStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(X, y, test_size=test_perc, random_state=run_num_2)\n",
        "\n",
        "def f_syn_polarity2(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_2, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train2, y=y_train2).mean())\n",
        "    return operator * score\n",
        "\n",
        "stp_2 = GPGO(surrogate_stp_2, Acquisition_new(util_stp), f_syn_polarity2, param, n_jobs = -1) # Define BayesOpt\n",
        "stp_2.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_stp_2 = stp_2.getResult()[0]\n",
        "params_stp_2['max_depth'] = int(params_stp_2['max_depth'])\n",
        "params_stp_2['min_child_weight'] = int(params_stp_2['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_stp_train2 = xgb.DMatrix(X_train2, y_train2)\n",
        "dX_stp_test2 = xgb.DMatrix(X_test2, y_test2)\n",
        "model_stp_2 = xgb.train(params_stp_2, dX_stp_train2)\n",
        "pred_stp_2 = model_stp_2.predict(dX_stp_test2)\n",
        "\n",
        "rmse_stp_2 = np.sqrt(mean_squared_error(pred_stp_2, y_test2))\n",
        "rmse_stp_2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 4.35994902  0.25926232 11.          0.97386531 12.          0.47833102]. \t  -1.4860127799448324 \t -1.4169097144768446\n",
            "init   \t [ 3.30334821  2.04648634 10.          0.55997527  6.          0.71472339]. \t  -1.4169097144768446 \t -1.4169097144768446\n",
            "init   \t [ 4.9856117   5.86796978  8.          0.89266757 11.          0.59158659]. \t  -1.4327785108491773 \t -1.4169097144768446\n",
            "init   \t [ 4.07307832  1.76984624 13.          0.75262305  7.          0.35908193]. \t  -1.5060418558860291 \t -1.4169097144768446\n",
            "init   \t [ 1.16193318  1.81727038  9.          0.79837265 19.          0.29965165]. \t  -1.5035568847025498 \t -1.4169097144768446\n",
            "1      \t [ 9.41115874  8.16019152 11.          0.70945365  2.          0.28765225]. \t  -1.5068099343324377 \t -1.4169097144768446\n",
            "2      \t [ 8.78180153  6.61060882 12.          0.91523653 18.          0.29687212]. \t  -1.5013572260649615 \t -1.4169097144768446\n",
            "3      \t [ 0.66591974  9.26661294 14.          0.96342421 18.          0.94909068]. \t  \u001b[92m-1.390328162245039\u001b[0m \t -1.390328162245039\n",
            "4      \t [9.43471272 1.33765191 5.         0.65986314 3.         0.80610967]. \t  -1.439200754043505 \t -1.390328162245039\n",
            "5      \t [1.59581768 7.00478001 5.         0.69739252 1.         0.78795203]. \t  -1.44189593702372 \t -1.390328162245039\n",
            "6      \t [ 2.29390808  9.72620131 13.          0.87738596  7.          0.2041919 ]. \t  -1.5071424533319249 \t -1.390328162245039\n",
            "7      \t [ 9.77744834  2.26597384  5.          0.98618685 19.          0.58642903]. \t  -1.4646927872213165 \t -1.390328162245039\n",
            "8      \t [ 1.82124551  9.97992306  7.          0.66460563 15.          0.68270076]. \t  -1.4240667703875103 \t -1.390328162245039\n",
            "9      \t [ 5.76886466  6.30636441 11.          0.85075313  6.          0.94564556]. \t  -1.394084837946688 \t -1.390328162245039\n",
            "10     \t [ 0.92680624  0.80829442  5.          0.99163751 10.          0.48273491]. \t  -1.5007102989702947 \t -1.390328162245039\n",
            "11     \t [ 8.66397635  9.94226364  5.          0.61754568 19.          0.46861962]. \t  -1.5035673307420439 \t -1.390328162245039\n",
            "12     \t [ 6.86168313  6.90043916 14.          0.78811364 12.          0.80689433]. \t  -1.409738797675001 \t -1.390328162245039\n",
            "13     \t [ 9.78109337  2.52726344  5.          0.62902817 11.          0.70291169]. \t  -1.441326058232906 \t -1.390328162245039\n",
            "14     \t [ 2.61078484  8.48438058 14.          0.79784401 12.          0.37480602]. \t  -1.5047091743524688 \t -1.390328162245039\n",
            "15     \t [9.48863669 8.35692203 6.         0.96369308 8.         0.31460767]. \t  -1.5017588323106756 \t -1.390328162245039\n",
            "16     \t [ 9.16837918  2.32035478 14.          0.50291805  1.          0.25746282]. \t  -1.5128204451867133 \t -1.390328162245039\n",
            "17     \t [ 1.36729794  4.89791321 13.          0.50996816  1.          0.64172429]. \t  -1.4261510165681064 \t -1.390328162245039\n",
            "18     \t [ 5.60637572  9.049847    5.          0.8061539  14.          0.24568718]. \t  -1.5112314760821572 \t -1.390328162245039\n",
            "19     \t [ 1.33742818  3.5146468  11.          0.8409387  12.          0.885211  ]. \t  -1.3957654942151698 \t -1.390328162245039\n",
            "20     \t [3.40850589 1.14636785 5.         0.86701245 1.         0.2864602 ]. \t  -1.5074944734729399 \t -1.390328162245039\n",
            "21     \t [ 9.65372179  0.75820772 11.          0.87845932  8.          0.76871909]. \t  -1.4081514304897453 \t -1.390328162245039\n",
            "22     \t [ 3.48144242  3.07395364 14.          0.91708598 18.          0.75997466]. \t  -1.4051077710244413 \t -1.390328162245039\n",
            "23     \t [ 5.5034428   0.25076678  6.          0.92417725 15.          0.48298202]. \t  -1.4973490207865274 \t -1.390328162245039\n",
            "24     \t [ 9.92497277  5.66371343  6.          0.94976894 15.          0.29571725]. \t  -1.5025922034451766 \t -1.390328162245039\n",
            "25     \t [7.9287711  9.29326427 6.         0.61920697 2.         0.41295855]. \t  -1.5004906943659613 \t -1.390328162245039\n",
            "26     \t [ 0.          4.66958376 15.          1.          6.32038981  1.        ]. \t  \u001b[92m-1.379375385095416\u001b[0m \t -1.379375385095416\n",
            "27     \t [ 7.38118595  1.4640181  10.          0.93209373 18.          0.28531178]. \t  -1.4999652293180774 \t -1.379375385095416\n",
            "28     \t [0.3625226  8.883305   8.         0.89857457 5.         0.88967443]. \t  -1.4024798276549248 \t -1.379375385095416\n",
            "29     \t [ 9.28214506  0.62575135 14.          0.7797226  13.          0.14775188]. \t  -1.50798894272367 \t -1.379375385095416\n",
            "30     \t [ 6.9743181   4.08164347 11.          0.67599958 15.          0.69542659]. \t  -1.4150201127017472 \t -1.379375385095416\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49040.24717192535"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpUPyXRfZ95Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f8574a4-91f8-473d-ef30-a6240fc1559d"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'stp' Acquisition Function run number = 3 \n",
        "\n",
        "np.random.seed(run_num_3)\n",
        "surrogate_stp_3 = tStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train3, X_test3, y_train3, y_test3 = train_test_split(X, y, test_size=test_perc, random_state=run_num_3)\n",
        "\n",
        "def f_syn_polarity3(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_3, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train3, y=y_train3).mean())\n",
        "    return operator * score\n",
        "\n",
        "stp_3 = GPGO(surrogate_stp_3, Acquisition_new(util_stp), f_syn_polarity3, param, n_jobs = -1) # Define BayesOpt\n",
        "stp_3.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_stp_3 = stp_3.getResult()[0]\n",
        "params_stp_3['max_depth'] = int(params_stp_3['max_depth'])\n",
        "params_stp_3['min_child_weight'] = int(params_stp_3['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_stp_train3 = xgb.DMatrix(X_train3, y_train3)\n",
        "dX_stp_test3 = xgb.DMatrix(X_test3, y_test3)\n",
        "model_stp_3 = xgb.train(params_stp_3, dX_stp_train3)\n",
        "pred_stp_3 = model_stp_3.predict(dX_stp_test3)\n",
        "\n",
        "rmse_stp_3 = np.sqrt(mean_squared_error(pred_stp_3, y_test3))\n",
        "rmse_stp_3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 5.50797903  7.08147823 13.          0.56066429 11.          0.11687321]. \t  -1.658976916292621 \t -1.5210450722954243\n",
            "init   \t [ 0.40630737  2.47888297 11.          0.72040492 13.          0.23083313]. \t  -1.6618243503452674 \t -1.5210450722954243\n",
            "init   \t [ 4.53172301  2.15577008 11.          0.74631796  2.          0.60296868]. \t  -1.5210450722954243 \t -1.5210450722954243\n",
            "init   \t [ 2.59252447  4.15101197 13.          0.79330998  8.          0.24118096]. \t  -1.6631154838515818 \t -1.5210450722954243\n",
            "init   \t [ 5.44649018  7.80314765 10.          0.62879264 18.          0.44917413]. \t  -1.5829020757643195 \t -1.5210450722954243\n",
            "1      \t [1.56262424 9.7795241  5.         0.91450054 5.         0.53102391]. \t  -1.5403180511194614 \t -1.5210450722954243\n",
            "2      \t [ 8.93142368  1.52910591 13.          0.84039318 17.          0.60846833]. \t  \u001b[92m-1.5092574325498493\u001b[0m \t -1.5092574325498493\n",
            "3      \t [8.41995405 9.27364382 8.         0.68446211 1.         0.99788466]. \t  \u001b[92m-1.4118423886164195\u001b[0m \t -1.4118423886164195\n",
            "4      \t [8.47261306 6.81509107 5.         0.93648192 9.         0.53187869]. \t  -1.5415592650900953 \t -1.4118423886164195\n",
            "5      \t [8.06707125 1.78809757 7.         0.93970888 2.         0.58519626]. \t  -1.5231776805100854 \t -1.4118423886164195\n",
            "6      \t [ 9.45052852  8.62641484  7.          0.79615518 14.          0.32790361]. \t  -1.6501290215812254 \t -1.4118423886164195\n",
            "7      \t [ 2.45193347  9.55190019 12.          0.92827182  3.          0.50558919]. \t  -1.5163445192779554 \t -1.4118423886164195\n",
            "8      \t [0.28002919 1.86471402 5.         0.90893429 3.         0.44808833]. \t  -1.5972277209590486 \t -1.4118423886164195\n",
            "9      \t [ 7.28641305  8.33932692 13.          0.7940189  15.          0.72843882]. \t  -1.4684469537955505 \t -1.4118423886164195\n",
            "10     \t [ 6.35239499  0.96053771  6.          0.98590601 17.          0.89384662]. \t  -1.427676024937613 \t -1.4118423886164195\n",
            "11     \t [ 1.69036107  9.02210895  8.          0.55873434 17.          0.80600268]. \t  -1.438130487952789 \t -1.4118423886164195\n",
            "12     \t [ 3.17822574  0.11455113  5.          0.70667634 10.          0.58577441]. \t  -1.5406870923871583 \t -1.4118423886164195\n",
            "13     \t [ 0.63366318  7.00411349 14.          0.89817768 18.          0.82387154]. \t  -1.4296476273903451 \t -1.4118423886164195\n",
            "14     \t [ 0.80651555  9.5561147   5.          0.83412306 17.          0.31360754]. \t  -1.6533952091306534 \t -1.4118423886164195\n",
            "15     \t [ 5.7586577   1.42812945 10.          0.74022438  8.          0.79053147]. \t  -1.4337203225971753 \t -1.4118423886164195\n",
            "16     \t [ 0.56385055  1.58792803 11.          0.96778339 10.          0.4958124 ]. \t  -1.5791363563172909 \t -1.4118423886164195\n",
            "17     \t [ 0.03931856  2.64974551  5.          0.57733556 16.          0.50165871]. \t  -1.5395115822454435 \t -1.4118423886164195\n",
            "18     \t [0.83814341 5.71403476 9.         0.54345391 1.         0.77347681]. \t  -1.4382764712128153 \t -1.4118423886164195\n",
            "19     \t [ 2.32690039  0.         13.21019478  1.         18.73276559  1.        ]. \t  \u001b[92m-1.3783857415857463\u001b[0m \t -1.3783857415857463\n",
            "20     \t [ 1.11444394  7.06530999  8.          0.77345153 10.          0.93594567]. \t  -1.4118770089113988 \t -1.3783857415857463\n",
            "21     \t [ 9.56946612  1.40277927  6.          0.97658228 10.          0.57276632]. \t  -1.5293613603968084 \t -1.3783857415857463\n",
            "22     \t [ 9.19400319  7.26150003 13.          0.85195954  5.          0.91138712]. \t  -1.4040696455776156 \t -1.3783857415857463\n",
            "23     \t [ 1.09978763  9.06043976 11.          0.8830514  19.          0.28872071]. \t  -1.6496862949307194 \t -1.3783857415857463\n",
            "24     \t [ 9.74524986  8.05873588 11.          0.80751649 10.          0.89010727]. \t  -1.4036522726718421 \t -1.3783857415857463\n",
            "25     \t [ 0.          3.08501636  8.44234203  1.         20.          1.        ]. \t  -1.3943773008008804 \t -1.3783857415857463\n",
            "26     \t [ 9.6685917   1.75247163 14.          0.6319706   3.          0.62105866]. \t  -1.5276555997678307 \t -1.3783857415857463\n",
            "27     \t [ 9.6553331   0.78950956  5.          0.88539267 13.          0.42518008]. \t  -1.5964769411071456 \t -1.3783857415857463\n",
            "28     \t [10.          1.8836985  12.29527739  0.5        10.96003969  0.1       ]. \t  -1.6594333941245831 \t -1.3783857415857463\n",
            "29     \t [ 7.82426466  7.10592631  5.          0.5        19.25987119  0.83196113]. \t  -1.4520269264183752 \t -1.3783857415857463\n",
            "30     \t [4.54734625 5.45348327 5.         0.5        1.         1.        ]. \t  -1.434044047713482 \t -1.3783857415857463\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "47648.10643318531"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKX_nfEaaAwm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e083f882-4fd5-4b9a-abbe-f8bd6f38e603"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'stp' Acquisition Function run number = 4 \n",
        "\n",
        "np.random.seed(run_num_4)\n",
        "surrogate_stp_4 = tStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train4, X_test4, y_train4, y_test4 = train_test_split(X, y, test_size=test_perc, random_state=run_num_4)\n",
        "\n",
        "def f_syn_polarity4(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_4, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train4, y=y_train4).mean())\n",
        "    return operator * score\n",
        "\n",
        "stp_4 = GPGO(surrogate_stp_4, Acquisition_new(util_stp), f_syn_polarity4, param, n_jobs = -1) # Define BayesOpt\n",
        "stp_4.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_stp_4 = stp_4.getResult()[0]\n",
        "params_stp_4['max_depth'] = int(params_stp_4['max_depth'])\n",
        "params_stp_4['min_child_weight'] = int(params_stp_4['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_stp_train4 = xgb.DMatrix(X_train4, y_train4)\n",
        "dX_stp_test4 = xgb.DMatrix(X_test4, y_test4)\n",
        "model_stp_4 = xgb.train(params_stp_4, dX_stp_train4)\n",
        "pred_stp_4 = model_stp_4.predict(dX_stp_test4)\n",
        "\n",
        "rmse_stp_4 = np.sqrt(mean_squared_error(pred_stp_4, y_test4))\n",
        "rmse_stp_4"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [9.67029839 5.47232249 6.         0.92781047 9.         0.72795594]. \t  -1.4430569076610322 \t -1.38492629511548\n",
            "init   \t [ 2.16089496  9.76274455 12.          0.62649118  9.          0.66966679]. \t  -1.4187070295885058 \t -1.38492629511548\n",
            "init   \t [ 0.05159149  5.72356491  9.          0.99170034 10.          0.10808749]. \t  -1.6911169704550582 \t -1.38492629511548\n",
            "init   \t [ 3.86571283  0.44160058 10.          0.90553105 18.          0.95407958]. \t  -1.38492629511548 \t -1.38492629511548\n",
            "init   \t [ 7.86305986  8.66289299  6.          0.53285477 14.          0.25117497]. \t  -1.557078690359533 \t -1.38492629511548\n",
            "1      \t [ 8.45443649  8.61014312 11.          0.83475494  1.          0.14018305]. \t  -1.6919233052610914 \t -1.38492629511548\n",
            "2      \t [ 9.55101363  6.99634383 11.          0.90625635 13.          0.71296594]. \t  -1.410715515363325 \t -1.38492629511548\n",
            "3      \t [0.6226627  4.92286423 6.         0.98206698 1.         0.51413802]. \t  -1.464510330325681 \t -1.38492629511548\n",
            "4      \t [ 4.4716856   2.9455437  14.          0.69787049  4.          0.17791454]. \t  -1.6927142453134727 \t -1.38492629511548\n",
            "5      \t [ 1.88634477  6.88806857 14.          0.85788793 18.          0.9393565 ]. \t  \u001b[92m-1.3831439580282818\u001b[0m \t -1.3831439580282818\n",
            "6      \t [ 6.46481407  7.76140156 13.          0.58767591  7.          0.80424891]. \t  -1.4222289018642091 \t -1.3831439580282818\n",
            "7      \t [ 0.79250634  6.36332745  6.          0.84703891 17.          0.8628914 ]. \t  -1.4448878111930763 \t -1.3831439580282818\n",
            "8      \t [9.26767626 0.09691703 5.         0.59554562 3.         0.95249041]. \t  -1.4324314656379458 \t -1.3831439580282818\n",
            "9      \t [ 8.9794725   0.03075938 11.          0.54769472  8.          0.98530081]. \t  -1.395793879521598 \t -1.3831439580282818\n",
            "10     \t [3.43076773 0.51115291 6.         0.80398076 7.         0.163561  ]. \t  -1.6908218618918773 \t -1.3831439580282818\n",
            "11     \t [ 6.71217542  4.64325058 14.          0.8178406  17.          0.28246892]. \t  -1.5555165110270497 \t -1.3831439580282818\n",
            "12     \t [ 6.03647398  5.02077859  7.          0.51964174 12.          0.90396407]. \t  -1.4052934473455991 \t -1.3831439580282818\n",
            "13     \t [4.46413576 9.74013874 9.         0.81676013 8.         0.18225082]. \t  -1.692202080120584 \t -1.3831439580282818\n",
            "14     \t [ 0.44275841  5.34607842 13.          0.76183897  1.          0.10740906]. \t  -1.6947345728474605 \t -1.3831439580282818\n",
            "15     \t [ 8.61120595  1.15607694  7.          0.67864711 15.          0.6375813 ]. \t  -1.4327271750756299 \t -1.3831439580282818\n",
            "16     \t [ 5.99047436  2.37202156  9.          0.99159406 15.          0.91638188]. \t  -1.383742071300851 \t -1.3831439580282818\n",
            "17     \t [8.23276762 9.05963655 5.         0.99512262 3.         0.70759498]. \t  -1.461741004420105 \t -1.3831439580282818\n",
            "18     \t [ 0.84701744  1.60683479 14.          0.52191349  9.          0.13284287]. \t  -1.694102268115941 \t -1.3831439580282818\n",
            "19     \t [ 0.16868492  1.45547778 15.          1.         20.          0.1       ]. \t  -1.6906260821469963 \t -1.3831439580282818\n",
            "20     \t [ 8.80208976  1.51962351 12.          0.89266186 10.          0.91980928]. \t  \u001b[92m-1.3827153139356407\u001b[0m \t -1.3827153139356407\n",
            "21     \t [3.70467295 0.42865714 5.         0.65772579 1.         0.52937485]. \t  -1.4846495203659666 \t -1.3827153139356407\n",
            "22     \t [9.92585707 6.89853334 9.         0.64013349 8.         0.74868649]. \t  -1.4221148098681797 \t -1.3827153139356407\n",
            "23     \t [ 9.81651939  0.09554533 12.          0.83243918  2.          0.50892162]. \t  -1.4356022494971612 \t -1.3827153139356407\n",
            "24     \t [10.  10.  15.   0.5 20.   1. ]. \t  \u001b[92m-1.3781170740916278\u001b[0m \t -1.3781170740916278\n",
            "25     \t [ 6.11542971  4.73500754  5.          0.71416589 19.          0.49348915]. \t  -1.533595477037884 \t -1.3781170740916278\n",
            "26     \t [0.28463957 9.94093696 9.         0.85139789 3.         0.22455873]. \t  -1.6921197443161788 \t -1.3781170740916278\n",
            "27     \t [ 1.89521122  0.32319771  5.          0.58478896 16.          0.77456858]. \t  -1.4674571089353527 \t -1.3781170740916278\n",
            "28     \t [1.00000000e+01 9.23149339e-03 5.00000000e+00 5.00000000e-01\n",
            " 9.11814071e+00 1.00000000e-01]. \t  -1.691562250045315 \t -1.3781170740916278\n",
            "29     \t [ 4.57170252  8.94909137 10.          0.53029442 16.          0.95602552]. \t  -1.3954614171322428 \t -1.3781170740916278\n",
            "30     \t [0.05073688 9.52784774 5.         0.54923801 7.         0.20792694]. \t  -1.6908763595479346 \t -1.3781170740916278\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "53204.964210687205"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJmI9saAaEG1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afd6b749-f6d4-4570-ac32-ff7e5dd40baa"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'stp' Acquisition Function run number = 5 \n",
        "\n",
        "np.random.seed(run_num_5)\n",
        "surrogate_stp_5 = tStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train5, X_test5, y_train5, y_test5 = train_test_split(X, y, test_size=test_perc, random_state=run_num_5)\n",
        "\n",
        "def f_syn_polarity5(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_5, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train5, y=y_train5).mean())\n",
        "    return operator * score\n",
        "\n",
        "stp_5 = GPGO(surrogate_stp_5, Acquisition_new(util_stp), f_syn_polarity5, param, n_jobs = -1) # Define BayesOpt\n",
        "stp_5.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_stp_5 = stp_5.getResult()[0]\n",
        "params_stp_5['max_depth'] = int(params_stp_5['max_depth'])\n",
        "params_stp_5['min_child_weight'] = int(params_stp_5['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_stp_train5 = xgb.DMatrix(X_train5, y_train5)\n",
        "dX_stp_test5 = xgb.DMatrix(X_test5, y_test5)\n",
        "model_stp_5 = xgb.train(params_stp_5, dX_stp_train5)\n",
        "pred_stp_5 = model_stp_5.predict(dX_stp_test5)\n",
        "\n",
        "rmse_stp_5 = np.sqrt(mean_squared_error(pred_stp_5, y_test5))\n",
        "rmse_stp_5"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 2.21993171  8.70732306 11.          0.68186845 10.          0.53957007]. \t  -1.437240644949997 \t -1.4314427524402045\n",
            "init   \t [ 6.11743863  7.65907856  5.          0.64840025 16.          0.82745351]. \t  -1.4314427524402045 \t -1.4314427524402045\n",
            "init   \t [ 6.49458883  8.19472793  6.          0.93996852 19.          0.36647194]. \t  -1.5681212058087062 \t -1.4314427524402045\n",
            "init   \t [ 6.28787909  5.7983781   6.          0.63290956 17.          0.18402673]. \t  -1.571097153432666 \t -1.4314427524402045\n",
            "init   \t [8.26554249 8.33492742 9.         0.97900675 3.         0.26957319]. \t  -1.5587909137089784 \t -1.4314427524402045\n",
            "1      \t [1.95474956 1.21548467 5.         0.65548996 6.         0.3261206 ]. \t  -1.5743532080703466 \t -1.4314427524402045\n",
            "2      \t [ 0.09956678  5.3014067  14.          0.6298658  17.          0.94976952]. \t  \u001b[92m-1.3952193294969657\u001b[0m \t -1.3952193294969657\n",
            "3      \t [ 8.96005069  0.40158558 13.          0.99993231  1.          0.57714848]. \t  -1.4354830630513837 \t -1.3952193294969657\n",
            "4      \t [ 9.87326458  3.08165071 13.          0.89537491 17.          0.48678657]. \t  -1.4780743495369868 \t -1.3952193294969657\n",
            "5      \t [ 0.42801231  0.53056997 14.          0.88001393  3.          0.60870677]. \t  -1.437822937474437 \t -1.3952193294969657\n",
            "6      \t [ 9.41789049  5.24678791 11.          0.78426601 10.          0.31189288]. \t  -1.5613050777466426 \t -1.3952193294969657\n",
            "7      \t [ 0.15773168  2.32643207  7.          0.74406654 13.          0.24500907]. \t  -1.5672014346319914 \t -1.3952193294969657\n",
            "8      \t [ 0.5259471   9.7567347  14.          0.91097263  1.          0.64281486]. \t  -1.3958511727899978 \t -1.3952193294969657\n",
            "9      \t [ 7.68019847  0.14272251  5.          0.84271757 13.          0.46064437]. \t  -1.5068069699486835 \t -1.3952193294969657\n",
            "10     \t [1.24717977 9.40645683 5.         0.65383928 3.         0.68852908]. \t  -1.4316511120811846 \t -1.3952193294969657\n",
            "11     \t [8.5765283  1.77730566 7.         0.63994635 4.         0.42153661]. \t  -1.491819528735433 \t -1.3952193294969657\n",
            "12     \t [7.9980796  9.13466128 6.         0.81085598 9.         0.18640376]. \t  -1.5735984894720563 \t -1.3952193294969657\n",
            "13     \t [ 5.39228464  0.17784539 13.          0.57001227  9.          0.60313835]. \t  -1.4407452364616864 \t -1.3952193294969657\n",
            "14     \t [ 3.9042494   1.34731655 10.          0.83969498 18.          0.52845925]. \t  -1.4355450531766754 \t -1.3952193294969657\n",
            "15     \t [2.03762865 4.34961943 8.         0.53797581 1.         0.36410352]. \t  -1.565767439244981 \t -1.3952193294969657\n",
            "16     \t [ 7.87772257  8.71340044 12.          0.8589136  15.          0.7305315 ]. \t  \u001b[92m-1.3895543192412831\u001b[0m \t -1.3895543192412831\n",
            "17     \t [ 6.80615583  6.45556443 14.          0.61036314  1.          0.8555849 ]. \t  -1.4035853189282244 \t -1.3895543192412831\n",
            "18     \t [ 0.39655743  9.88537948  7.          0.8395494  15.          0.83639512]. \t  -1.406404229652473 \t -1.3895543192412831\n",
            "19     \t [0.86243549 8.92584837 5.         0.6740487  9.         0.55305648]. \t  -1.480070993593469 \t -1.3895543192412831\n",
            "20     \t [ 0.75013773  4.67656983 14.87195577  0.83668978 11.27370711  0.56221585]. \t  -1.4315467214916349 \t -1.3895543192412831\n",
            "21     \t [ 0.          0.         11.38407188  0.5        14.48028781  0.1       ]. \t  -1.5623509798382973 \t -1.3895543192412831\n",
            "22     \t [3.8251056  4.70693202 9.         0.557829   7.         0.19729257]. \t  -1.5646463069352003 \t -1.3895543192412831\n",
            "23     \t [ 6.81691807  8.87161629 14.          0.87860353  9.          0.18458297]. \t  -1.564718625989378 \t -1.3895543192412831\n",
            "24     \t [10.          0.5562416  15.          0.5        12.14542698  0.1       ]. \t  -1.5623371002930027 \t -1.3895543192412831\n",
            "25     \t [ 0.09378584  0.46225465  6.          0.94133859 19.          0.52002331]. \t  -1.463000157761675 \t -1.3895543192412831\n",
            "26     \t [ 2.57424953 10.         11.92159727  0.5        19.18283351  1.        ]. \t  \u001b[92m-1.3815672009828912\u001b[0m \t -1.3815672009828912\n",
            "27     \t [ 2.63916471 10.         15.          0.5        15.00019572  0.1       ]. \t  -1.5622390355352238 \t -1.3815672009828912\n",
            "28     \t [ 8.43934599  0.8447506   5.          0.83249299 19.          0.31289567]. \t  -1.5742085459806785 \t -1.3815672009828912\n",
            "29     \t [ 0.22970977  1.05448095 11.86301427  0.52667539  7.69177834  0.77530462]. \t  -1.3996453809400182 \t -1.3815672009828912\n",
            "30     \t [ 3.55992574  0.         15.          0.5        19.50618208  1.        ]. \t  \u001b[92m-1.3814462820759146\u001b[0m \t -1.3814462820759146\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50602.29200977843"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulhEolsxaG4k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b23fce5e-d636-441a-e52b-a636d9d01fcc"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'stp' Acquisition Function run number = 6 \n",
        "\n",
        "np.random.seed(run_num_6)\n",
        "surrogate_stp_6 = tStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train6, X_test6, y_train6, y_test6 = train_test_split(X, y, test_size=test_perc, random_state=run_num_6)\n",
        "\n",
        "def f_syn_polarity6(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=int(min_child_weight),\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_6, objective = 'reg:squarederror', eval_metric = 'rmse')\n",
        "    score = np.array(cross_val_score(reg, X=X_train6, y=y_train6).mean())\n",
        "    return operator * score\n",
        "\n",
        "stp_6 = GPGO(surrogate_stp_6, Acquisition_new(util_stp), f_syn_polarity6, param, n_jobs = -1) # Define BayesOpt\n",
        "stp_6.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_stp_6 = stp_6.getResult()[0]\n",
        "params_stp_6['max_depth'] = int(params_stp_6['max_depth'])\n",
        "params_stp_6['min_child_weight'] = int(params_stp_6['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_stp_train6 = xgb.DMatrix(X_train6, y_train6)\n",
        "dX_stp_test6 = xgb.DMatrix(X_test6, y_test6)\n",
        "model_stp_6 = xgb.train(params_stp_6, dX_stp_train6)\n",
        "pred_stp_6 = model_stp_6.predict(dX_stp_test6)\n",
        "\n",
        "rmse_stp_6 = np.sqrt(mean_squared_error(pred_stp_6, y_test6))\n",
        "rmse_stp_6"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [8.92860151 3.31979805 5.         0.99251441 2.         0.57683563]. \t  -1.5190535184382172 \t -1.467261064668007\n",
            "init   \t [4.18807429 3.35407849 9.         0.87750649 3.         0.56623277]. \t  -1.5046102560432295 \t -1.467261064668007\n",
            "init   \t [ 5.788586    6.45355096 14.          0.70660047 12.          0.82154882]. \t  -1.467261064668007 \t -1.467261064668007\n",
            "init   \t [4.58184578 6.73834679 5.         0.90108528 3.         0.65482895]. \t  -1.5215270866416617 \t -1.467261064668007\n",
            "init   \t [ 4.42510505  5.75952352 14.          0.97882365 15.          0.29525604]. \t  -1.664748595544141 \t -1.467261064668007\n",
            "1      \t [ 2.61343239  0.80193947  5.          0.83898129 13.          0.84644718]. \t  -1.503282313171498 \t -1.467261064668007\n",
            "2      \t [ 9.72322443  9.21177696  5.          0.87917074 11.          0.86681736]. \t  -1.5025549146464172 \t -1.467261064668007\n",
            "3      \t [ 0.5654966   9.52584762 14.          0.82016688  4.          0.10717254]. \t  -1.6925731527242012 \t -1.467261064668007\n",
            "4      \t [ 2.98453858  8.8700865   6.          0.73955182 19.          0.28620498]. \t  -1.6585576125101582 \t -1.467261064668007\n",
            "5      \t [ 9.78497949  3.70554688  8.          0.72818063 17.          0.66380896]. \t  -1.5015349278197097 \t -1.467261064668007\n",
            "6      \t [ 0.58299146  9.62458538  9.          0.94830232 11.          0.21492907]. \t  -1.6930001706622346 \t -1.467261064668007\n",
            "7      \t [ 9.32984285  9.13994472 13.          0.80971831  3.          0.95492455]. \t  \u001b[92m-1.4037534194516463\u001b[0m \t -1.4037534194516463\n",
            "8      \t [ 9.32420466  6.39616005 13.          0.93300527 17.          0.34904443]. \t  -1.6629223928531551 \t -1.4037534194516463\n",
            "9      \t [ 5.79804816  0.18524154 13.          0.91373451 12.          0.1336305 ]. \t  -1.6936455440800635 \t -1.4037534194516463\n",
            "10     \t [ 9.18133243  4.09376148 10.          0.96038921  5.          0.75655401]. \t  -1.4644877108201928 \t -1.4037534194516463\n",
            "11     \t [0.50322511 5.36549123 5.         0.63452016 9.         0.79019916]. \t  -1.5078986088443043 \t -1.4037534194516463\n",
            "12     \t [ 1.90877122  0.88669904 11.          0.72802974 19.          0.27519153]. \t  -1.6626099836759345 \t -1.4037534194516463\n",
            "13     \t [ 8.84415462  2.89803683  6.          0.75669789 10.          0.66428199]. \t  -1.5130684787900361 \t -1.4037534194516463\n",
            "14     \t [ 4.4133116   1.55939325 14.          0.77762123  6.          0.86802935]. \t  -1.469041841877573 \t -1.4037534194516463\n",
            "15     \t [ 7.27176358  4.99393483  8.          0.92639524 14.          0.49037849]. \t  -1.6188867909126767 \t -1.4037534194516463\n",
            "16     \t [ 0.1193966   4.00087708 11.          0.63402737  8.          0.19613602]. \t  -1.6931122373774463 \t -1.4037534194516463\n",
            "17     \t [ 8.23412741  6.52581345 14.          0.83873301  7.          0.59923199]. \t  -1.506472933995673 \t -1.4037534194516463\n",
            "18     \t [ 4.70831246  5.31862206 13.          0.78784252  5.          0.59183181]. \t  -1.5104983871357243 \t -1.4037534194516463\n",
            "19     \t [ 0.17525712  4.19183624 13.          0.93093846  1.          0.77496282]. \t  -1.4770408140616145 \t -1.4037534194516463\n",
            "20     \t [ 4.81384656  2.93779689 11.          0.77304449 13.          0.48782362]. \t  -1.6207530282314764 \t -1.4037534194516463\n",
            "21     \t [ 1.96438538  2.93800461  5.          0.78368424 19.          0.63390012]. \t  -1.5217031446983547 \t -1.4037534194516463\n",
            "22     \t [ 0.50073585  2.52813513 13.          0.75574888 14.          0.36976835]. \t  -1.6646202258012757 \t -1.4037534194516463\n",
            "23     \t [8.85658963 1.07861601 8.         0.84497915 4.         0.67749442]. \t  -1.5007751693735443 \t -1.4037534194516463\n",
            "24     \t [ 1.26205935  9.99749922 12.          0.77151435 18.          0.65232396]. \t  -1.4960778012146236 \t -1.4037534194516463\n",
            "25     \t [ 8.79078586  9.8288488   6.          0.52132456 18.          0.18316089]. \t  -1.6926543733513018 \t -1.4037534194516463\n",
            "26     \t [ 7.26154915  0.75751462  8.          0.73283489 19.          0.51570742]. \t  -1.506457971976914 \t -1.4037534194516463\n",
            "27     \t [9.43692546 8.17023379 7.         0.75468215 2.         0.38712207]. \t  -1.623772959254302 \t -1.4037534194516463\n",
            "28     \t [10.          3.37184433 15.          0.5         1.          0.1       ]. \t  -1.6939894442776045 \t -1.4037534194516463\n",
            "29     \t [ 0.          7.64618561 14.45376841  0.5        10.95337877  1.        ]. \t  \u001b[92m-1.38400999479489\u001b[0m \t -1.38400999479489\n",
            "30     \t [ 2.735623    7.87687419 11.          0.92836598  7.          0.52601118]. \t  -1.5036631290670688 \t -1.38400999479489\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "48670.76624712112"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYebx3RVaJ1w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0828d1fc-09a3-4897-d98d-bf172277e43e"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'stp' Acquisition Function run number = 7 \n",
        "\n",
        "np.random.seed(run_num_7)\n",
        "surrogate_stp_7 = tStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train7, X_test7, y_train7, y_test7 = train_test_split(X, y, test_size=test_perc, random_state=run_num_7)\n",
        "\n",
        "def f_syn_polarity7(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_7, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train7, y=y_train7).mean())\n",
        "    return operator * score\n",
        "\n",
        "stp_7 = GPGO(surrogate_stp_7, Acquisition_new(util_stp), f_syn_polarity7, param, n_jobs = -1) # Define BayesOpt\n",
        "stp_7.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_stp_7 = stp_7.getResult()[0]\n",
        "params_stp_7['max_depth'] = int(params_stp_7['max_depth'])\n",
        "params_stp_7['min_child_weight'] = int(params_stp_7['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_stp_train7 = xgb.DMatrix(X_train7, y_train7)\n",
        "dX_stp_test7 = xgb.DMatrix(X_test7, y_test7)\n",
        "model_stp_7 = xgb.train(params_stp_7, dX_stp_train7)\n",
        "pred_stp_7 = model_stp_7.predict(dX_stp_test7)\n",
        "\n",
        "rmse_stp_7 = np.sqrt(mean_squared_error(pred_stp_7, y_test7))\n",
        "rmse_stp_7"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.76308289 7.79918792 8.         0.98911145 8.         0.98019056]. \t  -1.3766913184499914 \t -1.3716193029156287\n",
            "init   \t [ 5.3849587   5.01120464 13.          0.74994125  5.          0.88192131]. \t  -1.3716193029156287 \t -1.3716193029156287\n",
            "init   \t [ 3.30839249  3.9294231  12.          0.6440728  13.          0.41137564]. \t  -1.4844760060500033 \t -1.3716193029156287\n",
            "init   \t [9.29528191 2.6258377  5.         0.80027446 1.         0.86616513]. \t  -1.4553420696682378 \t -1.3716193029156287\n",
            "init   \t [ 1.74052764  7.90763512 14.          0.7244129   4.          0.77536887]. \t  -1.4144357133522163 \t -1.3716193029156287\n",
            "1      \t [3.43305102 3.00339076 8.         0.71322679 4.         0.33322219]. \t  -1.5452875922440117 \t -1.3716193029156287\n",
            "2      \t [ 7.6343627   1.31181598  5.          0.5769645  12.          0.84874959]. \t  -1.4551213921481168 \t -1.3716193029156287\n",
            "3      \t [ 9.12127254  9.64651695 14.          0.53624962  1.          0.38247449]. \t  -1.50441276662484 \t -1.3716193029156287\n",
            "4      \t [ 4.51243396  9.79601217  8.          0.69773915 19.          0.69687222]. \t  -1.4287808048470285 \t -1.3716193029156287\n",
            "5      \t [ 8.06748781  9.6311716   5.          0.89165168 11.          0.90769253]. \t  -1.4257160663203758 \t -1.3716193029156287\n",
            "6      \t [ 9.84853722  9.76587477 12.          0.66808012 15.          0.83895675]. \t  -1.4120477636464197 \t -1.3716193029156287\n",
            "7      \t [6.4915356  8.69600226 5.         0.66481282 2.         0.54976375]. \t  -1.471811121647584 \t -1.3716193029156287\n",
            "8      \t [ 0.86712134  2.53401598  5.          0.75823741 18.          0.7884932 ]. \t  -1.4568408302380156 \t -1.3716193029156287\n",
            "9      \t [ 1.29932493  8.0055142  14.          0.51325501 19.          0.83654101]. \t  -1.4172515575270401 \t -1.3716193029156287\n",
            "10     \t [1.34376539 6.51152091 7.         0.79389881 2.         0.97428464]. \t  -1.393401499670094 \t -1.3716193029156287\n",
            "11     \t [ 9.18418284  4.20360033 12.          0.59367506 19.          0.17440889]. \t  -1.6275641043033833 \t -1.3716193029156287\n",
            "12     \t [ 9.94824081  0.39149062 12.          0.59113076  1.          0.49709751]. \t  -1.5007161735692889 \t -1.3716193029156287\n",
            "13     \t [ 6.10581063  8.36866303 10.          0.7848773  10.          0.82571765]. \t  -1.4125006263647732 \t -1.3716193029156287\n",
            "14     \t [ 3.34596156  0.67230605 11.          0.7366642  19.          0.29949997]. \t  -1.5431674100399762 \t -1.3716193029156287\n",
            "15     \t [ 2.28086985  0.05850709  5.          0.90922938 11.          0.53631831]. \t  -1.4698264876273437 \t -1.3716193029156287\n",
            "16     \t [ 0.54101623  0.39016798 11.          0.92560048 17.          0.838304  ]. \t  -1.4048858198319796 \t -1.3716193029156287\n",
            "17     \t [ 9.45137179  0.74358028 14.          0.78939199  9.          0.47186777]. \t  -1.4850171205893612 \t -1.3716193029156287\n",
            "18     \t [ 9.71411962  1.71380043  5.          0.50726337 19.          0.71982498]. \t  -1.4732591929152012 \t -1.3716193029156287\n",
            "19     \t [3.72773018 4.44555607 7.         0.83964318 4.         0.80247824]. \t  -1.4252061838992058 \t -1.3716193029156287\n",
            "20     \t [ 1.77048754  9.0838881   6.          0.98375355 14.          0.13025417]. \t  -1.6301111208584214 \t -1.3716193029156287\n",
            "21     \t [9.92931813 4.94961117 7.         0.63712516 8.         0.80063535]. \t  -1.4301046948493812 \t -1.3716193029156287\n",
            "22     \t [ 0.36223704  1.06802481 10.          0.97825678  9.          0.58731601]. \t  -1.4146012991312247 \t -1.3716193029156287\n",
            "23     \t [ 1.76253367 10.         14.38482331  1.          9.21810325  0.1       ]. \t  -1.5891082742572695 \t -1.3716193029156287\n",
            "24     \t [ 9.63151594  7.41103965  5.          0.61709228 19.          0.17785178]. \t  -1.6308142818585338 \t -1.3716193029156287\n",
            "25     \t [ 7.95896155  0.55053524 12.          0.56160055 15.          0.90994804]. \t  -1.3787005008553694 \t -1.3716193029156287\n",
            "26     \t [6.88772798 0.         5.         0.5        6.6650878  0.1       ]. \t  -1.630751830616433 \t -1.3716193029156287\n",
            "27     \t [ 1.66321151  0.2606512  14.          0.78233211  3.          0.71720551]. \t  -1.4233894430537086 \t -1.3716193029156287\n",
            "28     \t [ 0.          0.         14.8375915   0.5        11.44159258  1.        ]. \t  -1.3733613745269424 \t -1.3716193029156287\n",
            "29     \t [10.          5.96086533 12.97170341  0.5         9.32478752  0.5958602 ]. \t  -1.430494093537363 \t -1.3716193029156287\n",
            "30     \t [4.81866756 9.1233297  5.         0.83229967 7.         0.84758799]. \t  -1.4563215345742702 \t -1.3716193029156287\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "52543.48673799942"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xk0IPTSTbIl3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c309b57-d3c1-481e-96da-c953e18e201f"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'stp' Acquisition Function run number = 8 \n",
        "\n",
        "np.random.seed(run_num_8)\n",
        "surrogate_stp_8 = tStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train8, X_test8, y_train8, y_test8 = train_test_split(X, y, test_size=test_perc, random_state=run_num_8)\n",
        "\n",
        "def f_syn_polarity8(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_8, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train8, y=y_train8).mean())\n",
        "    return operator * score\n",
        "\n",
        "stp_8 = GPGO(surrogate_stp_8, Acquisition_new(util_stp), f_syn_polarity8, param, n_jobs = -1) # Define BayesOpt\n",
        "stp_8.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_stp_8 = stp_8.getResult()[0]\n",
        "params_stp_8['max_depth'] = int(params_stp_8['max_depth'])\n",
        "params_stp_8['min_child_weight'] = int(params_stp_8['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_stp_train8 = xgb.DMatrix(X_train8, y_train8)\n",
        "dX_stp_test8 = xgb.DMatrix(X_test8, y_test8)\n",
        "model_stp_8 = xgb.train(params_stp_8, dX_stp_train8)\n",
        "pred_stp_8 = model_stp_8.predict(dX_stp_test8)\n",
        "\n",
        "rmse_stp_8 = np.sqrt(mean_squared_error(pred_stp_8, y_test8))\n",
        "rmse_stp_8"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 8.73429403  9.68540663 10.          0.68875849  9.          0.48011572]. \t  -1.4345420020169601 \t -1.380205361584031\n",
            "init   \t [ 6.12033333  7.66062926  8.          0.76133734 13.          0.93379456]. \t  -1.389083518296823 \t -1.380205361584031\n",
            "init   \t [ 1.46524679  7.01527914  7.          0.90913299 10.          0.36016753]. \t  -1.4546623776895313 \t -1.380205361584031\n",
            "init   \t [ 9.73855241  3.33774046 14.          0.53290419  7.          0.7088681 ]. \t  -1.400955898397293 \t -1.380205361584031\n",
            "init   \t [ 3.00618018  1.82702795 11.          0.75681389 14.          0.98627449]. \t  -1.380205361584031 \t -1.380205361584031\n",
            "1      \t [4.42022545 5.48487111 9.         0.97165909 3.         0.63617522]. \t  -1.392033230213678 \t -1.380205361584031\n",
            "2      \t [ 9.3432851   3.80536023 13.          0.82203895 19.          0.99569116]. \t  -1.3810003759019789 \t -1.380205361584031\n",
            "3      \t [ 2.52429836  9.02824683 14.          0.59641093 17.          0.61934886]. \t  -1.4189890610685807 \t -1.380205361584031\n",
            "4      \t [ 9.53473907  5.08424998 11.          0.50652828 18.          0.67121466]. \t  -1.3995921109500755 \t -1.380205361584031\n",
            "5      \t [6.89072012 1.88822945 5.         0.9252956  8.         0.40577637]. \t  -1.4671872329107825 \t -1.380205361584031\n",
            "6      \t [ 2.42575645  9.87357367  5.          0.61143882 19.          0.11833201]. \t  -1.5217192808835498 \t -1.380205361584031\n",
            "7      \t [ 0.9931658   1.40870497 14.          0.50614818  6.          0.71944448]. \t  -1.3993577222957068 \t -1.380205361584031\n",
            "8      \t [ 9.09148899  1.42093493  5.          0.88801001 17.          0.53231573]. \t  -1.4612253332966916 \t -1.380205361584031\n",
            "9      \t [9.69554908 3.70013633 5.         0.72727157 1.         0.49530336]. \t  -1.4660245850133664 \t -1.380205361584031\n",
            "10     \t [ 2.66410938  9.83743919 13.          0.58899688  8.          0.29675269]. \t  -1.4559646932762471 \t -1.380205361584031\n",
            "11     \t [1.66316873 0.47469495 7.         0.60820298 1.         0.50689458]. \t  -1.4305575307333285 \t -1.380205361584031\n",
            "12     \t [ 1.2277143   1.05411485  5.          0.50198686 13.          0.89258454]. \t  -1.4252760814462118 \t -1.380205361584031\n",
            "13     \t [ 6.53366965  0.44467545 13.          0.98765404  1.          0.73688157]. \t  -1.3930878262516195 \t -1.380205361584031\n",
            "14     \t [ 5.50404687 10.          5.31788533  0.5         5.86405834  1.        ]. \t  -1.4215058937586893 \t -1.380205361584031\n",
            "15     \t [ 1.12264609  9.56425304 13.          0.79308235  1.          0.93526753]. \t  -1.385944228780011 \t -1.380205361584031\n",
            "16     \t [ 8.62413803  1.63568526 10.          0.78670071 12.          0.5099252 ]. \t  -1.4157220359031473 \t -1.380205361584031\n",
            "17     \t [ 3.5121134   5.24088616  9.          0.68973249 19.          0.78159968]. \t  -1.39634939916643 \t -1.380205361584031\n",
            "18     \t [ 8.31774559  9.86409044  5.          0.5896951  17.          0.89174436]. \t  -1.4240962371845975 \t -1.380205361584031\n",
            "19     \t [ 3.45271174  0.75931377  5.          0.81313484 19.          0.57119025]. \t  -1.4597641553118152 \t -1.380205361584031\n",
            "20     \t [ 6.68744311  8.81728204 13.          0.79205386  1.          0.27645475]. \t  -1.4575254740101742 \t -1.380205361584031\n",
            "21     \t [0.80138831 6.76267872 5.         0.99880544 1.         0.65221206]. \t  -1.4279467321407886 \t -1.380205361584031\n",
            "22     \t [ 6.02596154  6.1671193  14.          0.96476591 10.          0.91070146]. \t  \u001b[92m-1.374012578809786\u001b[0m \t -1.374012578809786\n",
            "23     \t [9.59349693 9.77161546 8.         0.77095844 1.         0.8854315 ]. \t  -1.3906822009021382 \t -1.374012578809786\n",
            "24     \t [ 0.05397541  0.         11.43617839  1.         20.          0.1       ]. \t  -1.6334795603821086 \t -1.374012578809786\n",
            "25     \t [0.45443553 1.29616142 5.         0.89715048 6.         0.81405591]. \t  -1.4241509527680714 \t -1.374012578809786\n",
            "26     \t [ 0.83737305 10.          7.75662973  0.5         4.34608773  1.        ]. \t  -1.3934623731001399 \t -1.374012578809786\n",
            "27     \t [ 9.95634701  4.16684449 10.          0.7692395   3.          0.22833412]. \t  -1.5147647974619214 \t -1.374012578809786\n",
            "28     \t [10.         10.         12.54268056  0.5        20.          0.1       ]. \t  -1.5125928279238532 \t -1.374012578809786\n",
            "29     \t [0.         2.62947035 9.71489047 0.5        9.40643734 0.1       ]. \t  -1.5124183109943157 \t -1.374012578809786\n",
            "30     \t [ 1.96058257  9.77802418  8.          0.65635293 15.          0.14964482]. \t  -1.5144197578621548 \t -1.374012578809786\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50792.61585818203"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UroEj_RbLSb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8e45d89-252e-41fc-a657-6d24f9771df4"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'stp' Acquisition Function run number = 9 \n",
        "\n",
        "np.random.seed(run_num_9)\n",
        "surrogate_stp_9 = tStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train9, X_test9, y_train9, y_test9 = train_test_split(X, y, test_size=test_perc, random_state=run_num_9)\n",
        "\n",
        "def f_syn_polarity9(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_9, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train9, y=y_train9).mean())\n",
        "    return operator * score\n",
        "\n",
        "stp_9 = GPGO(surrogate_stp_9, Acquisition_new(util_stp), f_syn_polarity9, param, n_jobs = -1) # Define BayesOpt\n",
        "stp_9.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_stp_9 = stp_9.getResult()[0]\n",
        "params_stp_9['max_depth'] = int(params_stp_9['max_depth'])\n",
        "params_stp_9['min_child_weight'] = int(params_stp_9['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_stp_train9 = xgb.DMatrix(X_train9, y_train9)\n",
        "dX_stp_test9 = xgb.DMatrix(X_test9, y_test9)\n",
        "model_stp_9 = xgb.train(params_stp_9, dX_stp_train9)\n",
        "pred_stp_9 = model_stp_9.predict(dX_stp_test9)\n",
        "\n",
        "rmse_stp_9 = np.sqrt(mean_squared_error(pred_stp_9, y_test9))\n",
        "rmse_stp_9"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 0.10374154  5.01874592 11.          0.50377155  2.          0.29670281]. \t  -1.5577132784573362 \t -1.3722986758568372\n",
            "init   \t [ 4.18508181  2.48101168 13.          0.69794293  2.          0.25009871]. \t  -1.557988294847283 \t -1.3722986758568372\n",
            "init   \t [ 8.78559086  9.50964032 13.          0.98395204 11.          0.90820641]. \t  -1.3722986758568372 \t -1.3722986758568372\n",
            "init   \t [ 6.66898973  5.47837783  6.          0.97165345 12.          0.72499481]. \t  -1.4672635070842577 \t -1.3722986758568372\n",
            "init   \t [ 8.24870465  4.65668475 13.          0.68760467  9.          0.98502332]. \t  -1.3809301169879382 \t -1.3722986758568372\n",
            "1      \t [6.73714319 2.39608167 5.         0.58130302 3.         0.163077  ]. \t  -1.685094312684032 \t -1.3722986758568372\n",
            "2      \t [ 1.89773665  4.24398106 11.          0.60135502  9.          0.22312501]. \t  -1.6853446147658802 \t -1.3722986758568372\n",
            "3      \t [ 3.60566534  9.79805332 11.          0.62032576 16.          0.3578496 ]. \t  -1.5497427912361297 \t -1.3722986758568372\n",
            "4      \t [ 4.86601509  0.61279594  8.          0.72162785 18.          0.68911833]. \t  -1.4494724503862535 \t -1.3722986758568372\n",
            "5      \t [9.39353565 9.93046622 5.         0.57188784 4.         0.83501032]. \t  -1.4379828751537795 \t -1.3722986758568372\n",
            "6      \t [2.65857527 6.9907833  7.         0.59902991 3.         0.89573389]. \t  -1.4040426262782961 \t -1.3722986758568372\n",
            "7      \t [4.58728604 0.17361597 5.         0.87465126 8.         0.75024655]. \t  -1.4378747295874548 \t -1.3722986758568372\n",
            "8      \t [ 7.07313313  8.94084339  5.          0.99439529 19.          0.33798274]. \t  -1.554418754580938 \t -1.3722986758568372\n",
            "9      \t [ 9.5805444   7.83819543 12.          0.79715932  3.          0.61699162]. \t  -1.4480751872578472 \t -1.3722986758568372\n",
            "10     \t [ 8.50940195  3.37126275 14.          0.60894673 14.          0.37120771]. \t  -1.551762159843039 \t -1.3722986758568372\n",
            "11     \t [ 2.99026017  0.57400525 14.          0.54537608  3.          0.20227469]. \t  -1.6877567059978766 \t -1.3722986758568372\n",
            "12     \t [ 1.960699    0.55073612 14.          0.55131138 15.          0.12137879]. \t  -1.6874361439568943 \t -1.3722986758568372\n",
            "13     \t [ 1.98261944  9.85597834 14.          0.56925415  7.          0.93739664]. \t  -1.3843549369186383 \t -1.3722986758568372\n",
            "14     \t [ 0.80844375  8.9121894   5.          0.56134557 18.          0.84901701]. \t  -1.4369210429180104 \t -1.3722986758568372\n",
            "15     \t [ 9.46084914  7.30415136 12.          0.65797111 19.          0.16868938]. \t  -1.6870360801696218 \t -1.3722986758568372\n",
            "16     \t [ 0.49502631  0.68959208  6.          0.98331869 14.          0.6333745 ]. \t  -1.467466470230912 \t -1.3722986758568372\n",
            "17     \t [ 3.89448326  9.77793126 11.          0.87312755  1.          0.25420157]. \t  -1.5586246999773308 \t -1.3722986758568372\n",
            "18     \t [ 9.9650824   0.70561372  5.          0.81536816 14.          0.22588839]. \t  -1.6891887489713497 \t -1.3722986758568372\n",
            "19     \t [ 6.17111344  2.78900239 13.          0.52513592 19.          0.72053081]. \t  -1.447331096191799 \t -1.3722986758568372\n",
            "20     \t [ 2.97786479  9.66872573  7.          0.62646987 10.          0.90664407]. \t  -1.4023687642633642 \t -1.3722986758568372\n",
            "21     \t [ 1.37104321  4.81157032  9.          0.73449461 19.          0.93225065]. \t  -1.3874372479988648 \t -1.3722986758568372\n",
            "22     \t [ 7.72461725  3.3977956   5.38866383  0.5        20.          1.        ]. \t  -1.4250302507276746 \t -1.3722986758568372\n",
            "23     \t [ 0.26688497  6.61712564 13.          0.73462536 13.          0.88698981]. \t  -1.3803244901471339 \t -1.3722986758568372\n",
            "24     \t [9.0223237  0.52522072 9.         0.65667592 8.         0.49977193]. \t  -1.4949716679043266 \t -1.3722986758568372\n",
            "25     \t [ 5.38351167 10.         15.          1.         19.          0.1       ]. \t  -1.6467564968896682 \t -1.3722986758568372\n",
            "26     \t [0.         0.         5.89715627 1.         1.         0.1       ]. \t  -1.652744165974315 \t -1.3722986758568372\n",
            "27     \t [10.         10.          8.8138654   0.5        14.43831296  1.        ]. \t  -1.3911082467408913 \t -1.3722986758568372\n",
            "28     \t [ 5.11242743  1.14266448  9.93551729  0.5        12.69936883  0.1       ]. \t  -1.6869706504029676 \t -1.3722986758568372\n",
            "29     \t [ 9.36930365  2.1961182  14.81329078  1.          3.3091353   0.1       ]. \t  -1.6479428614315879 \t -1.3722986758568372\n",
            "30     \t [ 0.         0.        15.         1.         7.3745686  1.       ]. \t  \u001b[92m-1.369721718317739\u001b[0m \t -1.369721718317739\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "48920.74055903327"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VgaJOoJbOIE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c172272f-38dc-4dd9-f597-731f9a8b2709"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'stp' Acquisition Function run number = 10 \n",
        "\n",
        "np.random.seed(run_num_10)\n",
        "surrogate_stp_10 = tStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train10, X_test10, y_train10, y_test10 = train_test_split(X, y, test_size=test_perc, random_state=run_num_10)\n",
        "\n",
        "def f_syn_polarity10(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_10, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train10, y=y_train10).mean())\n",
        "    return operator * score\n",
        "\n",
        "stp_10 = GPGO(surrogate_stp_10, Acquisition_new(util_stp), f_syn_polarity10, param, n_jobs = -1) # Define BayesOpt\n",
        "stp_10.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_stp_10 = stp_10.getResult()[0]\n",
        "params_stp_10['max_depth'] = int(params_stp_10['max_depth'])\n",
        "params_stp_10['min_child_weight'] = int(params_stp_10['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_stp_train10 = xgb.DMatrix(X_train10, y_train10)\n",
        "dX_stp_test10 = xgb.DMatrix(X_test10, y_test10)\n",
        "model_stp_10 = xgb.train(params_stp_10, dX_stp_train10)\n",
        "pred_stp_10 = model_stp_10.predict(dX_stp_test10)\n",
        "\n",
        "rmse_stp_10 = np.sqrt(mean_squared_error(pred_stp_10, y_test10))\n",
        "rmse_stp_10"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 7.71320643  0.20751949  5.          0.72150747 17.          0.12265456]. \t  -1.5966621860966772 \t -1.3816576901725537\n",
            "init   \t [ 7.0920801   2.65566127 13.          0.57518893 17.          0.83494165]. \t  -1.3816576901725537 \t -1.3816576901725537\n",
            "init   \t [ 3.36071584  8.90816531  6.          0.86087766 15.          0.75469196]. \t  -1.4046956914996547 \t -1.3816576901725537\n",
            "init   \t [ 5.40880931  1.31458152  8.          0.57108502 14.          0.62551123]. \t  -1.4201195466728969 \t -1.3816576901725537\n",
            "init   \t [1.82631436 8.26082248 6.         0.80888349 5.         0.15900694]. \t  -1.5985040415985665 \t -1.3816576901725537\n",
            "1      \t [8.31989768 3.09778055 7.         0.64798085 3.         0.98471878]. \t  -1.3861520034074002 \t -1.3816576901725537\n",
            "2      \t [ 1.51483713  6.46720195 14.          0.87676044  8.          0.10934204]. \t  -1.6003439345483486 \t -1.3816576901725537\n",
            "3      \t [ 0.44494294  2.20797313 10.          0.76097539  2.          0.34290111]. \t  -1.5495317279087673 \t -1.3816576901725537\n",
            "4      \t [ 6.23532773  8.31439809 13.          0.65134225  1.          0.75774237]. \t  -1.385366563936203 \t -1.3816576901725537\n",
            "5      \t [ 9.32103763  8.04997374 14.          0.76165598 11.          0.58576369]. \t  -1.428324678040395 \t -1.3816576901725537\n",
            "6      \t [ 0.17864568  6.30557409 14.          0.94841763 16.          0.27279561]. \t  -1.5458487296276835 \t -1.3816576901725537\n",
            "7      \t [ 9.16520307  0.72602801 12.          0.91999471  9.          0.54336218]. \t  -1.426094761499742 \t -1.3816576901725537\n",
            "8      \t [ 0.13114685  2.69967978  5.          0.89490476 19.          0.55706236]. \t  -1.441014468615035 \t -1.3816576901725537\n",
            "9      \t [ 9.57603828  8.81375557  5.          0.56495862 19.          0.45710368]. \t  -1.4509053625704245 \t -1.3816576901725537\n",
            "10     \t [ 9.82501514  7.31311253  5.          0.75029053 12.          0.39735105]. \t  -1.4509928730738761 \t -1.3816576901725537\n",
            "11     \t [ 1.9796047   9.70148323 10.          0.54207016  7.          0.64335732]. \t  -1.418050743643208 \t -1.3816576901725537\n",
            "12     \t [0.01628551 3.33913353 7.         0.55545494 9.         0.68182563]. \t  -1.4219187366532753 \t -1.3816576901725537\n",
            "13     \t [ 4.96820991  0.31274735 14.          0.75716781  7.          0.73730833]. \t  -1.4154423659025188 \t -1.3816576901725537\n",
            "14     \t [ 4.19755202  9.09268434 14.          0.54945508  1.          0.70144661]. \t  -1.4300541281398125 \t -1.3816576901725537\n",
            "15     \t [9.80244061 9.59221257 6.         0.81318958 4.         0.96637387]. \t  -1.3975977207172405 \t -1.3816576901725537\n",
            "16     \t [10.          0.          6.33887846  0.5         7.83441041  0.1       ]. \t  -1.6002245036829534 \t -1.3816576901725537\n",
            "17     \t [ 9.71047899  2.77697649 13.          0.98225484  2.          0.32725448]. \t  -1.5514962457207713 \t -1.3816576901725537\n",
            "18     \t [ 6.01246276  8.52823794 14.          0.64132538 17.          0.81401185]. \t  \u001b[92m-1.378373364241066\u001b[0m \t -1.378373364241066\n",
            "19     \t [ 0.40502173  0.97349338 14.          0.99335875 14.          0.65172397]. \t  -1.4103673455849441 \t -1.378373364241066\n",
            "20     \t [ 4.66673608  0.         13.          0.5         1.          0.1       ]. \t  -1.6042555168264858 \t -1.378373364241066\n",
            "21     \t [ 0.  10.   5.   1.  20.   0.1]. \t  -1.684090985117075 \t -1.378373364241066\n",
            "22     \t [ 9.79082732  5.88980238 10.          0.76540155  8.          0.44385408]. \t  -1.441936940383671 \t -1.378373364241066\n",
            "23     \t [ 3.12412586  5.47171275 10.          0.57156478 19.          0.1208726 ]. \t  -1.600982010127612 \t -1.378373364241066\n",
            "24     \t [1.60262213 1.1633171  5.         0.76513939 4.60866435 1.        ]. \t  -1.4174486104528576 \t -1.378373364241066\n",
            "25     \t [ 0.          4.99207624  7.3772406   0.69839939 14.56379106  1.        ]. \t  -1.3876656838193266 \t -1.378373364241066\n",
            "26     \t [ 4.89575031  4.69282195 11.05560656  0.5        10.32297306  1.        ]. \t  \u001b[92m-1.3726234688703502\u001b[0m \t -1.3726234688703502\n",
            "27     \t [ 0.98897734  4.62009018 15.          1.          1.          0.1       ]. \t  -1.687133123606269 \t -1.3726234688703502\n",
            "28     \t [ 0.         10.         15.          0.5        11.88013955  1.        ]. \t  -1.3731467095455774 \t -1.3726234688703502\n",
            "29     \t [ 0.56508666  9.47852679  5.          0.56171556 10.          0.59017483]. \t  -1.4429882080904264 \t -1.3726234688703502\n",
            "30     \t [8.33517528 6.12539597 6.         0.7706296  2.         0.87665637]. \t  -1.3991272273793727 \t -1.3726234688703502\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50780.05271753991"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51z87uHWbRGr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfdedb17-7464-4b87-9b81-9db85ecb90c7"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'stp' Acquisition Function run number = 11 \n",
        "\n",
        "np.random.seed(run_num_11)\n",
        "surrogate_stp_11 = tStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train11, X_test11, y_train11, y_test11 = train_test_split(X, y, test_size=test_perc, random_state=run_num_11)\n",
        "\n",
        "def f_syn_polarity11(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_11, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train11, y=y_train11).mean())\n",
        "    return operator * score\n",
        "\n",
        "stp_11 = GPGO(surrogate_stp_11, Acquisition_new(util_stp), f_syn_polarity11, param, n_jobs = -1) # Define BayesOpt\n",
        "stp_11.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_stp_11 = stp_11.getResult()[0]\n",
        "params_stp_11['max_depth'] = int(params_stp_11['max_depth'])\n",
        "params_stp_11['min_child_weight'] = int(params_stp_11['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_stp_train11 = xgb.DMatrix(X_train11, y_train11)\n",
        "dX_stp_test11 = xgb.DMatrix(X_test11, y_test11)\n",
        "model_stp_11 = xgb.train(params_stp_11, dX_stp_train11)\n",
        "pred_stp_11 = model_stp_11.predict(dX_stp_test11)\n",
        "\n",
        "rmse_stp_11 = np.sqrt(mean_squared_error(pred_stp_11, y_test11))\n",
        "rmse_stp_11"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 1.80269689  0.19475241  6.          0.59705781 13.          0.47818324]. \t  -1.4816591577946832 \t -1.4105425145194488\n",
            "init   \t [ 4.85427098  0.12780815  5.          0.91309068 14.          0.86571558]. \t  -1.426706936764755 \t -1.4105425145194488\n",
            "init   \t [ 7.2996447   1.08736072 10.          0.92857712 18.          0.66910061]. \t  -1.4105425145194488 \t -1.4105425145194488\n",
            "init   \t [ 0.20483613  1.16737269  7.          0.57895615 16.          0.83644782]. \t  -1.4183397861714337 \t -1.4105425145194488\n",
            "init   \t [ 3.44624491  3.18798797 14.          0.54197657 15.          0.63958906]. \t  -1.4201459936126652 \t -1.4105425145194488\n",
            "1      \t [9.77136617 6.6548802  7.         0.51036649 9.         0.81011527]. \t  -1.4198592349317078 \t -1.4105425145194488\n",
            "2      \t [0.5279662  8.15331655 5.         0.83127487 9.         0.53242685]. \t  -1.4775633373451906 \t -1.4105425145194488\n",
            "3      \t [8.62555756 1.5478147  8.         0.99964468 2.         0.74874718]. \t  -1.4123297977539668 \t -1.4105425145194488\n",
            "4      \t [ 0.90299561  9.42808632 14.          0.71344248  9.          0.5250902 ]. \t  -1.4659195951888304 \t -1.4105425145194488\n",
            "5      \t [ 0.07122179  2.9458437  13.          0.89742149  2.          0.63052749]. \t  -1.4165796433495284 \t -1.4105425145194488\n",
            "6      \t [ 2.80563958  8.51387637  8.          0.72474118 19.          0.16647242]. \t  -1.5954888498474655 \t -1.4105425145194488\n",
            "7      \t [ 8.68943806  9.29354072 13.          0.58241565  2.          0.90282292]. \t  \u001b[92m-1.3827383913835647\u001b[0m \t -1.3827383913835647\n",
            "8      \t [0.47065357 6.80536856 5.         0.94482943 1.         0.93677618]. \t  -1.4135866309918552 \t -1.3827383913835647\n",
            "9      \t [ 8.74582539  1.09960491 14.          0.69981761  9.          0.73083826]. \t  -1.4174999872552454 \t -1.3827383913835647\n",
            "10     \t [ 9.62795963  5.53773092  5.          0.74613073 18.          0.44845649]. \t  -1.482748052716914 \t -1.3827383913835647\n",
            "11     \t [ 9.31276242  9.71672249 14.          0.98885974 14.          0.59959332]. \t  -1.4617887507716631 \t -1.3827383913835647\n",
            "12     \t [4.51634165 2.99534228 6.         0.60005383 7.         0.33729133]. \t  -1.5463963481365885 \t -1.3827383913835647\n",
            "13     \t [7.15099548 7.45646917 6.         0.6919289  2.         0.48671926]. \t  -1.4808965488370525 \t -1.3827383913835647\n",
            "14     \t [ 0.58573037  2.99410259 11.          0.97681055  8.          0.25048443]. \t  -1.5451573591086598 \t -1.3827383913835647\n",
            "15     \t [ 6.43479335  7.34424748 13.          0.50651226 19.          0.72120005]. \t  -1.4195562091307028 \t -1.3827383913835647\n",
            "16     \t [ 0.61821645  2.15492808 14.          0.83982091  4.          0.10488315]. \t  -1.5970059462384498 \t -1.3827383913835647\n",
            "17     \t [ 6.49911642  6.6845191  13.          0.97968145  7.          0.46814854]. \t  -1.4758597742664896 \t -1.3827383913835647\n",
            "18     \t [ 8.62785477  1.07358311 14.          0.62117111  2.          0.4499224 ]. \t  -1.4906636670623468 \t -1.3827383913835647\n",
            "19     \t [ 0.03452186  8.83860607 13.          0.62313645 17.          0.60519619]. \t  -1.4661531073974454 \t -1.3827383913835647\n",
            "20     \t [ 4.35551014  5.79408308 15.          0.5         1.          0.1       ]. \t  -1.600726727725209 \t -1.3827383913835647\n",
            "21     \t [ 8.23950234  9.98178636  5.          0.78568893 13.          0.5877076 ]. \t  -1.4764430987770178 \t -1.3827383913835647\n",
            "22     \t [ 3.18349223  8.74823637 11.          0.77393568 13.          0.73768421]. \t  -1.413853270139426 \t -1.3827383913835647\n",
            "23     \t [0.53253664 0.10406623 8.         0.68525951 3.         0.90349139]. \t  -1.3848449072018616 \t -1.3827383913835647\n",
            "24     \t [9.27619589 0.78753966 6.         0.96256618 8.         0.7409797 ]. \t  -1.4229180018438687 \t -1.3827383913835647\n",
            "25     \t [3.87175284 9.17280548 9.         0.75814351 5.         0.64006642]. \t  -1.4146262735625803 \t -1.3827383913835647\n",
            "26     \t [ 0.         10.          5.27876107  1.         14.4078892   0.1       ]. \t  -1.593917665623687 \t -1.3827383913835647\n",
            "27     \t [10.         10.         15.          0.5         7.30658532  0.1       ]. \t  -1.5994361466611764 \t -1.3827383913835647\n",
            "28     \t [10.          0.          5.          0.5        19.67268797  1.        ]. \t  -1.4161800994182392 \t -1.3827383913835647\n",
            "29     \t [ 9.64996016  6.05907974  9.          0.55085623 14.          0.22832285]. \t  -1.5971887494437291 \t -1.3827383913835647\n",
            "30     \t [ 4.88459091  0.          5.          1.         19.9499946   0.1       ]. \t  -1.593977538201044 \t -1.3827383913835647\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "52919.564473422346"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8jZUeoWbTvn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "561b5f3d-6839-469a-f536-77104438cee7"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'stp' Acquisition Function run number = 12\n",
        "\n",
        "np.random.seed(run_num_12)\n",
        "surrogate_stp_12 = tStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train12, X_test12, y_train12, y_test12 = train_test_split(X, y, test_size=test_perc, random_state=run_num_12)\n",
        "\n",
        "def f_syn_polarity12(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_12, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train12, y=y_train12).mean())\n",
        "    return operator * score\n",
        "\n",
        "stp_12 = GPGO(surrogate_stp_12, Acquisition_new(util_stp), f_syn_polarity12, param, n_jobs = -1) # Define BayesOpt\n",
        "stp_12.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_stp_12 = stp_12.getResult()[0]\n",
        "params_stp_12['max_depth'] = int(params_stp_12['max_depth'])\n",
        "params_stp_12['min_child_weight'] = int(params_stp_12['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_stp_train12 = xgb.DMatrix(X_train12, y_train12)\n",
        "dX_stp_test12 = xgb.DMatrix(X_test12, y_test12)\n",
        "model_stp_12 = xgb.train(params_stp_12, dX_stp_train12)\n",
        "pred_stp_12 = model_stp_12.predict(dX_stp_test12)\n",
        "\n",
        "rmse_stp_12 = np.sqrt(mean_squared_error(pred_stp_12, y_test12))\n",
        "rmse_stp_12"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [1.54162842 7.40049697 6.         0.54321714 4.         0.11311747]. \t  -1.6495881989170076 \t -1.4161885061290391\n",
            "init   \t [ 9.18747008  9.00714854 14.          0.97847467 11.          0.35544552]. \t  -1.5149964971320231 \t -1.4161885061290391\n",
            "init   \t [ 6.06083184  9.44225136 14.          0.95626942  5.          0.56910342]. \t  -1.4459275331997625 \t -1.4161885061290391\n",
            "init   \t [ 5.52037633  4.85377414  7.          0.97886436 17.          0.78810441]. \t  -1.4161885061290391 \t -1.4161885061290391\n",
            "init   \t [ 0.20809798  1.35210178  5.          0.65494879 16.          0.36062811]. \t  -1.527260055706503 \t -1.4161885061290391\n",
            "1      \t [9.46555822 8.57190559 5.         0.50164398 5.         0.71992807]. \t  -1.4518180624203443 \t -1.4161885061290391\n",
            "2      \t [9.04256367 2.61736915 8.         0.66026854 8.         0.14510453]. \t  -1.6475213437726843 \t -1.4161885061290391\n",
            "3      \t [6.03751892 2.08855857 8.         0.88966175 1.         0.6215545 ]. \t  -1.4545419325214572 \t -1.4161885061290391\n",
            "4      \t [ 0.24796255  2.18203944 14.          0.56497025 17.          0.63132662]. \t  \u001b[92m-1.412665895609592\u001b[0m \t -1.412665895609592\n",
            "5      \t [ 5.97904546  9.54654633 12.          0.85402391 19.          0.25521119]. \t  -1.5145737308476037 \t -1.412665895609592\n",
            "6      \t [ 0.40359854  2.22527636 10.          0.60258213 10.          0.38255809]. \t  -1.5093017035694707 \t -1.412665895609592\n",
            "7      \t [ 5.27256334  7.51091828 10.          0.6197456   8.          0.55516265]. \t  -1.4528542954808399 \t -1.412665895609592\n",
            "8      \t [ 7.63658847  0.39719075 14.          0.96199388 14.          0.84093877]. \t  \u001b[92m-1.4012774191660697\u001b[0m \t -1.4012774191660697\n",
            "9      \t [ 1.16756887  8.11984381  6.          0.6769854  12.          0.96425924]. \t  -1.425081237519715 \t -1.4012774191660697\n",
            "10     \t [ 1.12582676  8.93847045 12.          0.90253051 15.          0.22616186]. \t  -1.646274774943813 \t -1.4012774191660697\n",
            "11     \t [ 7.63578483  4.07501457 14.          0.97723751  1.          0.2033266 ]. \t  -1.646107150050667 \t -1.4012774191660697\n",
            "12     \t [ 0.44102401  9.72347144 10.          0.78005439  2.          0.3197988 ]. \t  -1.517865660215834 \t -1.4012774191660697\n",
            "13     \t [ 1.02727376  7.17212035 13.          0.95844631  5.          0.2162272 ]. \t  -1.646710136263445 \t -1.4012774191660697\n",
            "14     \t [ 2.51777684  0.51507226 14.          0.92439966  2.          0.67900076]. \t  -1.4087217901070743 \t -1.4012774191660697\n",
            "15     \t [ 5.87564044  0.1367295   5.          0.86696309 14.          0.56330523]. \t  -1.4890922768541544 \t -1.4012774191660697\n",
            "16     \t [5.99294447 7.0114806  5.         0.86352024 2.         0.47030879]. \t  -1.5238701446854095 \t -1.4012774191660697\n",
            "17     \t [ 9.28975428  2.00051847 11.          0.70249719 10.          0.83171705]. \t  -1.4079892995970908 \t -1.4012774191660697\n",
            "18     \t [0.93465239 0.11560545 5.         0.52904926 2.         0.78190279]. \t  -1.4496071231713872 \t -1.4012774191660697\n",
            "19     \t [ 4.68656243  5.72546614  8.          0.71613414 12.          0.18941474]. \t  -1.6469981640022824 \t -1.4012774191660697\n",
            "20     \t [ 7.76768567  0.2584821  10.          0.54713046 19.          0.71740877]. \t  -1.4161669053889425 \t -1.4012774191660697\n",
            "21     \t [ 2.16269217  0.51151057  5.          0.76157702 10.          0.23342906]. \t  -1.6515245473117097 \t -1.4012774191660697\n",
            "22     \t [ 3.81903994  6.47431022  5.          0.61498548 10.          0.69682636]. \t  -1.447368405437085 \t -1.4012774191660697\n",
            "23     \t [ 7.92042467  4.36747127 14.          0.9569447  18.          0.40060995]. \t  -1.5044302101853857 \t -1.4012774191660697\n",
            "24     \t [9.35790707 1.00025736 9.         0.50647655 4.         0.94947436]. \t  -1.4137277284888046 \t -1.4012774191660697\n",
            "25     \t [ 8.8766494  10.          6.03580301  1.         14.45895325  0.1       ]. \t  -1.622123285588922 \t -1.4012774191660697\n",
            "26     \t [ 3.78722207  5.62040729 13.          0.72258675  8.          0.63637241]. \t  -1.406419098080698 \t -1.4012774191660697\n",
            "27     \t [ 6.88281536  1.55353672 14.          0.97699082  6.          0.7322005 ]. \t  -1.404194250904514 \t -1.4012774191660697\n",
            "28     \t [ 1.56773047  8.07656935  6.          0.62857433 18.          0.78313518]. \t  -1.4332240064653052 \t -1.4012774191660697\n",
            "29     \t [ 1.75563803  3.40231697  8.48769241  1.         20.          1.        ]. \t  \u001b[92m-1.38472835958118\u001b[0m \t -1.38472835958118\n",
            "30     \t [10.          9.7313809  14.00057242  1.          1.          0.1       ]. \t  -1.615191113318014 \t -1.38472835958118\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "53435.752676193224"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "snTrqE2RbWbe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1c064e2-c976-42b9-ce89-d570f26802bd"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'stp' Acquisition Function run number = 13 \n",
        "\n",
        "np.random.seed(run_num_13)\n",
        "surrogate_stp_13 = tStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train13, X_test13, y_train13, y_test13 = train_test_split(X, y, test_size=test_perc, random_state=run_num_13)\n",
        "\n",
        "def f_syn_polarity13(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_13, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train13, y=y_train13).mean())\n",
        "    return operator * score\n",
        "\n",
        "stp_13 = GPGO(surrogate_stp_13, Acquisition_new(util_stp), f_syn_polarity13, param, n_jobs = -1) # Define BayesOpt\n",
        "stp_13.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_stp_13 = stp_13.getResult()[0]\n",
        "params_stp_13['max_depth'] = int(params_stp_13['max_depth'])\n",
        "params_stp_13['min_child_weight'] = int(params_stp_13['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_stp_train13 = xgb.DMatrix(X_train13, y_train13)\n",
        "dX_stp_test13 = xgb.DMatrix(X_test13, y_test13)\n",
        "model_stp_13 = xgb.train(params_stp_13, dX_stp_train13)\n",
        "pred_stp_13 = model_stp_13.predict(dX_stp_test13)\n",
        "\n",
        "rmse_stp_13 = np.sqrt(mean_squared_error(pred_stp_13, y_test13))\n",
        "rmse_stp_13"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 7.77702411  2.3754122  11.          0.94649135 13.          0.7827256 ]. \t  -1.3814631927491285 \t -1.3814631927491285\n",
            "init   \t [ 7.51661514  6.07343344 11.          0.69402149 11.          0.13153287]. \t  -1.6959297564173816 \t -1.3814631927491285\n",
            "init   \t [ 2.98449471  0.58512492 10.          0.73579614 12.          0.33065195]. \t  -1.5246886192220386 \t -1.3814631927491285\n",
            "init   \t [ 3.47581215  0.0941277  11.          0.86143432  8.          0.58454932]. \t  -1.4185759644827896 \t -1.3814631927491285\n",
            "init   \t [ 4.70137857  6.24432527 10.          0.8149145  18.          0.10784416]. \t  -1.6944183605438403 \t -1.3814631927491285\n",
            "1      \t [1.51786663 9.25994479 9.         0.99792981 2.         0.61199673]. \t  -1.4182805465760875 \t -1.3814631927491285\n",
            "2      \t [ 8.98888343  8.3187307  12.          0.8674744   2.          0.79321204]. \t  -1.3887986537394084 \t -1.3814631927491285\n",
            "3      \t [8.39231279 2.68541099 7.         0.57298175 6.         0.49020579]. \t  -1.4776526601111564 \t -1.3814631927491285\n",
            "4      \t [ 3.74996446  2.55146251 14.          0.66084872  1.          0.77825432]. \t  -1.3958421889249872 \t -1.3814631927491285\n",
            "5      \t [ 1.38431049  2.01198974  5.          0.99962019 19.          0.43410173]. \t  -1.4812282668358374 \t -1.3814631927491285\n",
            "6      \t [0.75135379 4.33666257 5.         0.52792906 6.         0.30010782]. \t  -1.5217162458925066 \t -1.3814631927491285\n",
            "7      \t [ 9.14713824  0.07484253  6.          0.59644494 18.          0.23277246]. \t  -1.6955072679167311 \t -1.3814631927491285\n",
            "8      \t [4.44071781 9.91246761 7.         0.989      8.         0.15929465]. \t  -1.6933938071029164 \t -1.3814631927491285\n",
            "9      \t [ 1.19464241  9.09410977 14.          0.67682133 13.          0.47680262]. \t  -1.4784611551567606 \t -1.3814631927491285\n",
            "10     \t [9.03865737 8.3609218  5.         0.67278271 3.         0.94732904]. \t  -1.4363334391982163 \t -1.3814631927491285\n",
            "11     \t [ 8.95958255  8.68558585  7.          0.83565872 16.          0.19670804]. \t  -1.6944002607106452 \t -1.3814631927491285\n",
            "12     \t [ 0.25014222  1.63131458 14.          0.76511372 18.          0.34115868]. \t  -1.525866997083546 \t -1.3814631927491285\n",
            "13     \t [ 9.8386932   0.06427629 14.          0.90521004  4.          0.3283497 ]. \t  -1.5258385027616264 \t -1.3814631927491285\n",
            "14     \t [5.15880003 5.0230589  5.         0.52962923 1.         0.65578751]. \t  -1.443165949136354 \t -1.3814631927491285\n",
            "15     \t [ 5.21756474  7.41328417 10.          0.72503351  4.          0.75909455]. \t  -1.390419327005087 \t -1.3814631927491285\n",
            "16     \t [ 8.5498494   0.49523448 14.          0.75006973  9.          0.71688368]. \t  -1.4043224063569215 \t -1.3814631927491285\n",
            "17     \t [ 7.13034425  5.06408202  5.          0.68138745 11.          0.35508943]. \t  -1.5234111731990247 \t -1.3814631927491285\n",
            "18     \t [ 7.14553626  1.23155981 14.          0.66739229 19.          0.6965719 ]. \t  -1.4067956272209592 \t -1.3814631927491285\n",
            "19     \t [ 1.21564284  4.11087143  5.          0.60470588 11.          0.27851623]. \t  -1.5227776443080994 \t -1.3814631927491285\n",
            "20     \t [6.94621972 3.13671142 9.         0.80896399 9.         0.89686879]. \t  -1.3841131057012266 \t -1.3814631927491285\n",
            "21     \t [ 4.11631647  8.93314349 11.          0.93514193  8.          0.77537084]. \t  -1.3832409125762724 \t -1.3814631927491285\n",
            "22     \t [ 1.0001212   9.86097643  8.          0.56662535 14.          0.32636242]. \t  -1.5240057453922686 \t -1.3814631927491285\n",
            "23     \t [ 2.02290993  6.76428761 11.          0.59824651  3.          0.63990661]. \t  -1.4104115857810196 \t -1.3814631927491285\n",
            "24     \t [ 4.05031343 10.         15.          0.5         1.          0.1       ]. \t  -1.6961171215521742 \t -1.3814631927491285\n",
            "25     \t [0.14854021 0.01080693 8.         0.6500909  1.         0.71671091]. \t  -1.4120086109829566 \t -1.3814631927491285\n",
            "26     \t [9.82683182 2.81995664 9.         0.78390401 8.         0.68026048]. \t  -1.4070895026674262 \t -1.3814631927491285\n",
            "27     \t [ 3.72309715  8.24767299  5.          0.64133611 19.          0.94165108]. \t  -1.437178071762256 \t -1.3814631927491285\n",
            "28     \t [ 7.69738953  8.55847352 14.          0.5678416  16.          0.88672119]. \t  -1.3853116179485325 \t -1.3814631927491285\n",
            "29     \t [8.88956824e+00 8.88178420e-16 8.19373448e+00 1.00000000e+00\n",
            " 1.00000000e+00 1.00000000e-01]. \t  -1.6070073441871884 \t -1.3814631927491285\n",
            "30     \t [ 5.2160711   2.94110347  7.          0.57671878 16.          0.83708326]. \t  -1.408816006725811 \t -1.3814631927491285\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49640.64566227302"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAuEsXYbtOnC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f6a12c0-35a2-4aae-cdd8-629b96862b05"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'stp' Acquisition Function run number = 14 \n",
        "\n",
        "np.random.seed(run_num_14)\n",
        "surrogate_stp_14 = tStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train14, X_test14, y_train14, y_test14 = train_test_split(X, y, test_size=test_perc, random_state=run_num_14)\n",
        "\n",
        "def f_syn_polarity14(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_14, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train14, y=y_train14).mean())\n",
        "    return operator * score\n",
        "\n",
        "stp_14 = GPGO(surrogate_stp_14, Acquisition_new(util_stp), f_syn_polarity14, param, n_jobs = -1) # Define BayesOpt\n",
        "stp_14.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_stp_14 = stp_14.getResult()[0]\n",
        "params_stp_14['max_depth'] = int(params_stp_14['max_depth'])\n",
        "params_stp_14['min_child_weight'] = int(params_stp_14['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_stp_train14 = xgb.DMatrix(X_train14, y_train14)\n",
        "dX_stp_test14 = xgb.DMatrix(X_test14, y_test14)\n",
        "model_stp_14 = xgb.train(params_stp_14, dX_stp_train14)\n",
        "pred_stp_14 = model_stp_14.predict(dX_stp_test14)\n",
        "\n",
        "rmse_stp_14 = np.sqrt(mean_squared_error(pred_stp_14, y_test14))\n",
        "rmse_stp_14"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 5.13943344  7.73165052 12.          0.6831412  11.          0.37876233]. \t  -1.5555798623190729 \t -1.4024696810470139\n",
            "init   \t [ 9.57603739  5.13116712 14.          0.76959997 12.          0.71328228]. \t  -1.4192714165556448 \t -1.4024696810470139\n",
            "init   \t [5.34950319 2.47493539 5.         0.50293689 6.         0.29706373]. \t  -1.6043764718675084 \t -1.4024696810470139\n",
            "init   \t [ 2.94506579  3.45329697  8.          0.87620946 14.          0.9783044 ]. \t  -1.4024696810470139 \t -1.4024696810470139\n",
            "init   \t [ 1.11811929  1.73004086  5.          0.73745288 12.          0.20586008]. \t  -1.6112248980856712 \t -1.4024696810470139\n",
            "1      \t [ 6.50637223  2.67617722 14.          0.53562507  1.          0.16862152]. \t  -1.6022414457029215 \t -1.4024696810470139\n",
            "2      \t [ 9.22243919  0.59642165  6.          0.72537748 19.          0.46639325]. \t  -1.564344837026232 \t -1.4024696810470139\n",
            "3      \t [ 5.79577795  1.8570688  14.          0.83128935 19.          0.71549729]. \t  -1.4169867499577495 \t -1.4024696810470139\n",
            "4      \t [9.32373648 9.05676215 9.         0.53064322 3.         0.70657534]. \t  -1.42733721626933 \t -1.4024696810470139\n",
            "5      \t [ 9.52454394  8.82757271  9.          0.90064956 19.          0.16022914]. \t  -1.6022845508632764 \t -1.4024696810470139\n",
            "6      \t [ 3.61508571  7.70718733 10.          0.62042707  5.          0.12186292]. \t  -1.602233101109481 \t -1.4024696810470139\n",
            "7      \t [ 0.05037086  7.50461284  5.          0.70076046 19.          0.10543546]. \t  -1.6116524740300122 \t -1.4024696810470139\n",
            "8      \t [ 9.40430013  0.15700131  7.          0.99940272 12.          0.43771306]. \t  -1.5573888104973324 \t -1.4024696810470139\n",
            "9      \t [ 0.40405522  2.81796516 11.          0.8908648   1.          0.54002187]. \t  -1.4639850559345085 \t -1.4024696810470139\n",
            "10     \t [ 2.08494663  9.70581169 14.          0.64307382  3.          0.10613693]. \t  -1.6030119269054786 \t -1.4024696810470139\n",
            "11     \t [ 1.55781918  0.46142569 10.          0.80240433 16.          0.22604037]. \t  -1.60177102977272 \t -1.4024696810470139\n",
            "12     \t [ 8.32471637  8.64868248  5.          0.80719895 12.          0.64183859]. \t  -1.4404446830987008 \t -1.4024696810470139\n",
            "13     \t [ 1.63603408  9.08540306 13.          0.75743361 17.          0.35594014]. \t  -1.587913089307395 \t -1.4024696810470139\n",
            "14     \t [ 2.19312776  1.39765821 13.          0.6652195   7.          0.63762954]. \t  -1.4222324219911133 \t -1.4024696810470139\n",
            "15     \t [ 0.13252657  8.5928169   9.          0.80268616 13.          0.66907677]. \t  -1.420556379247995 \t -1.4024696810470139\n",
            "16     \t [9.87159789 0.82301761 9.         0.69884198 1.         0.99856434]. \t  -1.4075756851429293 \t -1.4024696810470139\n",
            "17     \t [ 3.45369236  4.26979372 14.          0.9430674   2.          0.58203038]. \t  -1.4663438581539545 \t -1.4024696810470139\n",
            "18     \t [ 8.75456218  4.86550421  9.          0.66492396 11.          0.97983887]. \t  -1.4048624094349145 \t -1.4024696810470139\n",
            "19     \t [ 0.  10.   5.   1.   1.   0.1]. \t  -1.6082725084296858 \t -1.4024696810470139\n",
            "20     \t [3.49244872 7.62920524 6.         0.74139713 3.         0.75714686]. \t  -1.426911455567142 \t -1.4024696810470139\n",
            "21     \t [ 9.63696428  6.23035392 14.          0.70928178  9.          0.89319858]. \t  \u001b[92m-1.3994959476662723\u001b[0m \t -1.3994959476662723\n",
            "22     \t [ 8.15121558  4.51938392 14.          0.72140328 13.          0.24929711]. \t  -1.6020406981914874 \t -1.3994959476662723\n",
            "23     \t [ 5.17276442  2.97018817  8.          0.76489956 19.          0.94442786]. \t  -1.4050814534155958 \t -1.3994959476662723\n",
            "24     \t [ 0.          0.          5.          1.         18.89308011  0.1       ]. \t  -1.6081757417194453 \t -1.3994959476662723\n",
            "25     \t [ 9.00670023  9.99970555 14.          0.96205059 15.          0.60286575]. \t  -1.458221883770709 \t -1.3994959476662723\n",
            "26     \t [ 7.36999374  9.70875324 14.          0.93099241  5.          0.8965707 ]. \t  -1.3998954384969522 \t -1.3994959476662723\n",
            "27     \t [ 7.90737578  0.61915125 11.          0.92287248  7.          0.62331479]. \t  -1.459219605023605 \t -1.3994959476662723\n",
            "28     \t [0.40195723 6.59599922 5.         0.93020884 9.         0.95072755]. \t  -1.4314374898322417 \t -1.3994959476662723\n",
            "29     \t [ 3.51526544  0.         14.58273675  1.         13.55089807  0.1       ]. \t  -1.5985132424840116 \t -1.3994959476662723\n",
            "30     \t [ 5.68726099  8.13768352  5.          0.74929324 19.          0.72948301]. \t  -1.4421415476972468 \t -1.3994959476662723\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "51620.060660923125"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgxvE7Irbbj_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eda778ee-6775-4036-96c1-92932d08c108"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'stp' Acquisition Function run number = 15 \n",
        "\n",
        "np.random.seed(run_num_15)\n",
        "surrogate_stp_15 = tStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train15, X_test15, y_train15, y_test15 = train_test_split(X, y, test_size=test_perc, random_state=run_num_15)\n",
        "\n",
        "def f_syn_polarity15(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_15, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train15, y=y_train15).mean())\n",
        "    return operator * score\n",
        "\n",
        "stp_15 = GPGO(surrogate_stp_15, Acquisition_new(util_stp), f_syn_polarity15, param, n_jobs = -1) # Define BayesOpt\n",
        "stp_15.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_stp_15 = stp_15.getResult()[0]\n",
        "params_stp_15['max_depth'] = int(params_stp_15['max_depth'])\n",
        "params_stp_15['min_child_weight'] = int(params_stp_15['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_stp_train15 = xgb.DMatrix(X_train15, y_train15)\n",
        "dX_stp_test15 = xgb.DMatrix(X_test15, y_test15)\n",
        "model_stp_15 = xgb.train(params_stp_15, dX_stp_train15)\n",
        "pred_stp_15 = model_stp_15.predict(dX_stp_test15)\n",
        "\n",
        "rmse_stp_15 = np.sqrt(mean_squared_error(pred_stp_15, y_test15))\n",
        "rmse_stp_15"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 8.48817697  1.78895925 12.          0.55549316  8.          0.93397854]. \t  -1.376451715987612 \t -1.376451715987612\n",
            "init   \t [ 0.24953032  8.22298097 12.          0.62494951 11.          0.12924598]. \t  -1.5659547455717522 \t -1.376451715987612\n",
            "init   \t [ 5.02017228  5.50882771 11.          0.85295832 19.          0.13548008]. \t  -1.5651600836199522 \t -1.376451715987612\n",
            "init   \t [2.0023081  9.98543403 7.         0.6295772  2.         0.526127  ]. \t  -1.4164354656135685 \t -1.376451715987612\n",
            "init   \t [ 5.09715306  9.45038417 11.          0.7388277  16.          0.22739973]. \t  -1.5662872595805275 \t -1.376451715987612\n",
            "1      \t [ 0.29158961  4.9949242  12.          0.89124583  3.          0.67554049]. \t  -1.3814014024038652 \t -1.376451715987612\n",
            "2      \t [3.68214008 4.55748717 6.         0.60488381 8.         0.88973248]. \t  -1.409417039109656 \t -1.376451715987612\n",
            "3      \t [9.75991344 6.15203198 6.         0.65490407 1.         0.73816291]. \t  -1.434052604843357 \t -1.376451715987612\n",
            "4      \t [ 0.04347405  0.16019908 11.          0.96902942  9.          0.40185268]. \t  -1.4912886214882008 \t -1.376451715987612\n",
            "5      \t [ 6.65116837  8.16324548 14.          0.95750787  1.          0.74925927]. \t  -1.3835754605277415 \t -1.376451715987612\n",
            "6      \t [1.13261559 9.28349969 7.         0.98964629 7.         0.37032959]. \t  -1.5321752314839754 \t -1.376451715987612\n",
            "7      \t [ 5.30770728  0.52044454  5.          0.75000665 15.          0.36204331]. \t  -1.5405533309916828 \t -1.376451715987612\n",
            "8      \t [ 9.99655383  8.39499737  6.          0.67304848 18.          0.73483896]. \t  -1.4333260183385295 \t -1.376451715987612\n",
            "9      \t [ 0.53269319  3.10786722 14.          0.59617872 16.          0.1338107 ]. \t  -1.5676411414124878 \t -1.376451715987612\n",
            "10     \t [ 8.93696009  0.85767079 13.          0.81270336  5.          0.91231878]. \t  \u001b[92m-1.367567800306326\u001b[0m \t -1.367567800306326\n",
            "11     \t [ 2.97928851  7.73905112  6.          0.87870551 18.          0.36796416]. \t  -1.5362986940304182 \t -1.367567800306326\n",
            "12     \t [3.02150875 0.49910736 5.         0.91633249 1.         0.11262301]. \t  -1.5698220321275584 \t -1.367567800306326\n",
            "13     \t [ 9.52301108  9.56759639  5.          0.87397797 11.          0.23091707]. \t  -1.569385681404325 \t -1.367567800306326\n",
            "14     \t [ 7.09557213  0.02461437 14.          0.76122797 15.          0.64719348]. \t  -1.3849435816230813 \t -1.367567800306326\n",
            "15     \t [ 2.33182114  1.6905304  12.          0.50693092 13.          0.44907303]. \t  -1.501563819069307 \t -1.367567800306326\n",
            "16     \t [ 8.70112488  8.40166533 14.          0.83503967  7.          0.91885659]. \t  \u001b[92m-1.365982982857568\u001b[0m \t -1.365982982857568\n",
            "17     \t [ 0.11138125  2.32868485  8.          0.89421542 19.          0.22148224]. \t  -1.5638657083878622 \t -1.365982982857568\n",
            "18     \t [ 9.87630512  5.87115536 10.          0.97858003 13.          0.54250565]. \t  -1.3840113172632331 \t -1.365982982857568\n",
            "19     \t [ 5.64647885  9.07152022 10.          0.83229506 10.          0.27661589]. \t  -1.5313536152160345 \t -1.365982982857568\n",
            "20     \t [ 6.85098251  5.995571    5.          0.68196248 15.          0.5605856 ]. \t  -1.458145021973218 \t -1.365982982857568\n",
            "21     \t [ 0.30914511  5.05623311  7.          0.80614285 13.          0.62974019]. \t  -1.4144876102693946 \t -1.365982982857568\n",
            "22     \t [ 7.85226032  7.70211384  5.          0.74880119 11.          0.81095165]. \t  -1.4358976930235625 \t -1.365982982857568\n",
            "23     \t [ 8.76685193 10.         15.          0.5        20.          1.        ]. \t  -1.3843117583861164 \t -1.365982982857568\n",
            "24     \t [9.52424966 0.71536288 5.         0.73236443 9.         0.44788077]. \t  -1.5267416304348789 \t -1.365982982857568\n",
            "25     \t [ 9.51292186  1.89950493 10.          0.77220987 18.          0.72312455]. \t  -1.3901439270669205 \t -1.365982982857568\n",
            "26     \t [9.25730966 0.80457908 9.         0.59559506 1.         0.63116286]. \t  -1.4011808950506366 \t -1.365982982857568\n",
            "27     \t [3.89482282 1.88863757 9.20062569 1.         4.77447194 0.75544859]. \t  -1.3729208876796803 \t -1.365982982857568\n",
            "28     \t [ 0.         10.         13.87460725  0.5        20.          1.        ]. \t  -1.3840886723375543 \t -1.365982982857568\n",
            "29     \t [ 2.44939988 10.         12.78854488  0.5         3.50842639  0.46626942]. \t  -1.50646368240661 \t -1.365982982857568\n",
            "30     \t [ 3.74163262  9.31668243 14.          0.60026621 15.          0.97529357]. \t  -1.375638022309919 \t -1.365982982857568\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49510.51161943425"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TaP6RoGuiNT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a8af1c6-1eb0-41cf-951d-d172291e7279"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'stp' Acquisition Function run number = 16 \n",
        "\n",
        "np.random.seed(run_num_16)\n",
        "surrogate_stp_16 = tStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train16, X_test16, y_train16, y_test16 = train_test_split(X, y, test_size=test_perc, random_state=run_num_16)\n",
        "\n",
        "def f_syn_polarity16(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_16, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train16, y=y_train16).mean())\n",
        "    return operator * score\n",
        "\n",
        "stp_16 = GPGO(surrogate_stp_16, Acquisition_new(util_stp), f_syn_polarity16, param, n_jobs = -1) # Define BayesOpt\n",
        "stp_16.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_stp_16 = stp_16.getResult()[0]\n",
        "params_stp_16['max_depth'] = int(params_stp_16['max_depth'])\n",
        "params_stp_16['min_child_weight'] = int(params_stp_16['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_stp_train16 = xgb.DMatrix(X_train16, y_train16)\n",
        "dX_stp_test16 = xgb.DMatrix(X_test16, y_test16)\n",
        "model_stp_16 = xgb.train(params_stp_16, dX_stp_train16)\n",
        "pred_stp_16 = model_stp_16.predict(dX_stp_test16)\n",
        "\n",
        "rmse_stp_16 = np.sqrt(mean_squared_error(pred_stp_16, y_test16))\n",
        "rmse_stp_16"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [2.23291079 5.23163341 6.         0.65430839 5.         0.30077285]. \t  -1.5445131891906443 \t -1.5311877282940682\n",
            "init   \t [6.88726162 1.63731425 7.         0.97050543 2.         0.25392012]. \t  -1.5397173057708042 \t -1.5311877282940682\n",
            "init   \t [ 5.94328983  5.6393473   5.          0.67602695 19.          0.42538144]. \t  -1.5311877282940682 \t -1.5311877282940682\n",
            "init   \t [ 0.88741148  3.08148142 14.          0.56043938  9.          0.27515386]. \t  -1.545084837896393 \t -1.5311877282940682\n",
            "init   \t [ 2.74631586  1.30996118 11.          0.52160786  8.          0.27956463]. \t  -1.5455911570787226 \t -1.5311877282940682\n",
            "1      \t [ 7.8937256   1.5972923  14.          0.61610774 17.          0.78739284]. \t  \u001b[92m-1.416411889040415\u001b[0m \t -1.416411889040415\n",
            "2      \t [ 9.01655783  8.21383177  9.          0.60772965 10.          0.9401803 ]. \t  \u001b[92m-1.3918448667936738\u001b[0m \t -1.3918448667936738\n",
            "3      \t [ 4.35132073  9.89698316 12.          0.94137984 16.          0.57741056]. \t  -1.4703780749414233 \t -1.3918448667936738\n",
            "4      \t [ 9.99266675  2.3482113  14.          0.65036483  2.          0.18233953]. \t  -1.5584826301317314 \t -1.3918448667936738\n",
            "5      \t [ 6.10466162  9.7407612  14.          0.94272754  1.          0.44776149]. \t  -1.5261434245626113 \t -1.3918448667936738\n",
            "6      \t [ 0.85309637  3.25044751 10.          0.72917812 19.          0.59717282]. \t  -1.4714651475001548 \t -1.3918448667936738\n",
            "7      \t [ 4.26860043  3.42752897  5.          0.50941556 12.          0.6715708 ]. \t  -1.4743462549929636 \t -1.3918448667936738\n",
            "8      \t [8.94430486 7.20655808 9.         0.72124353 2.         0.50974082]. \t  -1.4730433653031816 \t -1.3918448667936738\n",
            "9      \t [ 1.27230763  4.23505107 12.          0.83635418  2.          0.68972104]. \t  -1.4295645741908234 \t -1.3918448667936738\n",
            "10     \t [ 9.39421065  1.15238895 10.          0.86257926 10.          0.82976642]. \t  -1.4125632140700126 \t -1.3918448667936738\n",
            "11     \t [ 3.30054392  7.94067066 12.          0.56032466  8.          0.57253019]. \t  -1.4779140222689364 \t -1.3918448667936738\n",
            "12     \t [ 0.27759474  9.81658265  7.          0.83236986 12.          0.63764046]. \t  -1.4430267661656662 \t -1.3918448667936738\n",
            "13     \t [ 9.12869134  9.21110573  6.          0.97189779 15.          0.84522104]. \t  -1.4500711132190474 \t -1.3918448667936738\n",
            "14     \t [ 9.4593849   0.83644618  6.          0.90181599 10.          0.80544189]. \t  -1.4518891177377917 \t -1.3918448667936738\n",
            "15     \t [ 2.2998307   0.29277211 13.          0.91992618 15.          0.58998025]. \t  -1.4723586758482194 \t -1.3918448667936738\n",
            "16     \t [ 9.80203814  5.08834263 14.          0.60567693  8.          0.92815593]. \t  \u001b[92m-1.3910801221532587\u001b[0m \t -1.3910801221532587\n",
            "17     \t [ 7.61737741  6.76476275 12.          0.65155794 19.          0.32955223]. \t  -1.5413325597203997 \t -1.3910801221532587\n",
            "18     \t [ 9.24241873  9.45305055 13.          0.56260346  9.          0.81985864]. \t  -1.4170621539913 \t -1.3910801221532587\n",
            "19     \t [ 8.81510579  1.91929382  5.          0.69107062 16.          0.70425356]. \t  -1.4747383627712232 \t -1.3910801221532587\n",
            "20     \t [ 3.14083423  2.08874867 13.          0.73040064 13.          0.65921701]. \t  -1.424778739083123 \t -1.3910801221532587\n",
            "21     \t [0.66157836 9.34435957 8.         0.77097926 1.         0.98953743]. \t  -1.3964918521130474 \t -1.3910801221532587\n",
            "22     \t [ 1.0622867   9.02594281 15.          0.5         1.          0.48948515]. \t  -1.540581168466044 \t -1.3910801221532587\n",
            "23     \t [ 0.   0.  15.   0.5 20.   0.1]. \t  -1.5603485554844234 \t -1.3910801221532587\n",
            "24     \t [ 1.26403078  9.98484462  5.          0.88575999 18.          0.87148706]. \t  -1.467685813981832 \t -1.3910801221532587\n",
            "25     \t [0.17024689 0.44480284 7.9923225  0.5        1.         0.1       ]. \t  -1.5612463134191354 \t -1.3910801221532587\n",
            "26     \t [ 3.81239939  0.35246626  5.          0.52554366 18.          0.33210519]. \t  -1.5476870461075118 \t -1.3910801221532587\n",
            "27     \t [ 0.  0. 15.  1.  1.  1.]. \t  \u001b[92m-1.3757728289462086\u001b[0m \t -1.3757728289462086\n",
            "28     \t [5.07379039 7.85907939 5.         0.52936986 1.         0.84442911]. \t  -1.462175258335442 \t -1.3757728289462086\n",
            "29     \t [ 0.         10.         14.35862739  0.5        11.73303949  1.        ]. \t  -1.3863398858764566 \t -1.3757728289462086\n",
            "30     \t [ 0.  10.  15.   0.5 20.   1. ]. \t  -1.385508422770041 \t -1.3757728289462086\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "51473.30324412116"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NiOaMUmgulbx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "895b1848-22a8-43be-f2e9-82d6c69df731"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'stp' Acquisition Function run number = 17 \n",
        "\n",
        "np.random.seed(run_num_17)\n",
        "surrogate_stp_17 = tStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train17, X_test17, y_train17, y_test17 = train_test_split(X, y, test_size=test_perc, random_state=run_num_17)\n",
        "\n",
        "def f_syn_polarity17(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_17, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train17, y=y_train17).mean())\n",
        "    return operator * score\n",
        "\n",
        "stp_17 = GPGO(surrogate_stp_17, Acquisition_new(util_stp), f_syn_polarity17, param, n_jobs = -1) # Define BayesOpt\n",
        "stp_17.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_stp_17 = stp_17.getResult()[0]\n",
        "params_stp_17['max_depth'] = int(params_stp_17['max_depth'])\n",
        "params_stp_17['min_child_weight'] = int(params_stp_17['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_stp_train17 = xgb.DMatrix(X_train17, y_train17)\n",
        "dX_stp_test17 = xgb.DMatrix(X_test17, y_test17)\n",
        "model_stp_17 = xgb.train(params_stp_17, dX_stp_train17)\n",
        "pred_stp_17 = model_stp_17.predict(dX_stp_test17)\n",
        "\n",
        "rmse_stp_17 = np.sqrt(mean_squared_error(pred_stp_17, y_test17))\n",
        "rmse_stp_17"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 2.94665003  5.30586756 11.          0.94443241 14.          0.80828691]. \t  -1.432187192078573 \t -1.432187192078573\n",
            "init   \t [ 6.56333522  6.37520896 12.          0.81487881 18.          0.42203224]. \t  -1.4945483449196877 \t -1.432187192078573\n",
            "init   \t [ 9.45683187  0.6004468  11.          0.5171566  10.          0.53881211]. \t  -1.4548205565954722 \t -1.432187192078573\n",
            "init   \t [2.72705857 1.19063434 6.         0.74176431 6.         0.10101151]. \t  -1.6432713945852762 \t -1.432187192078573\n",
            "init   \t [ 4.77631812  5.24671297 13.          0.66254476 19.          0.36708086]. \t  -1.5567864797674738 \t -1.432187192078573\n",
            "1      \t [ 0.65702322  5.79284078 13.          0.75136902  1.          0.30306068]. \t  -1.5652619856245054 \t -1.432187192078573\n",
            "2      \t [ 6.93446178  8.68032298 13.          0.78195789  7.          0.91906958]. \t  \u001b[92m-1.38003104553365\u001b[0m \t -1.38003104553365\n",
            "3      \t [9.72843652 3.88893279 9.         0.6901555  1.         0.31608219]. \t  -1.5608607576489912 \t -1.38003104553365\n",
            "4      \t [ 9.65057736  8.52725784  5.          0.68420234 13.          0.40008732]. \t  -1.5175779886624106 \t -1.38003104553365\n",
            "5      \t [ 4.97204887  2.40072226  5.          0.54268748 19.          0.30995407]. \t  -1.5702611271060207 \t -1.38003104553365\n",
            "6      \t [0.12174033 8.73496008 5.         0.89827646 5.         0.85354798]. \t  -1.4615526201092108 \t -1.38003104553365\n",
            "7      \t [ 2.91443079  0.16723755 13.          0.598201    6.          0.91729605]. \t  -1.389287224690272 \t -1.38003104553365\n",
            "8      \t [7.20615247 9.36901627 6.         0.85465034 7.         0.6878262 ]. \t  -1.4551474523018149 \t -1.38003104553365\n",
            "9      \t [ 9.02586164  0.59354638 10.          0.86038693 18.          0.90794111]. \t  -1.3802009359113299 \t -1.38003104553365\n",
            "10     \t [ 0.          5.57544916  5.          0.5        12.99438489  0.1       ]. \t  -1.6485580055021984 \t -1.38003104553365\n",
            "11     \t [ 0.12410542  7.60180472 13.          0.97425003  8.          0.76245421]. \t  -1.432887901007922 \t -1.38003104553365\n",
            "12     \t [ 2.44282715  9.71851747  7.          0.86792183 17.          0.93015556]. \t  -1.3970181930296728 \t -1.38003104553365\n",
            "13     \t [9.59190042 1.26233772 5.         0.55398722 6.         0.46259714]. \t  -1.5201208467499083 \t -1.38003104553365\n",
            "14     \t [ 9.55207611  7.43715703  5.47305369  0.5        20.          0.1       ]. \t  -1.648498115784906 \t -1.38003104553365\n",
            "15     \t [ 0.59590325  0.30071901  8.          0.9148403  16.          0.62633871]. \t  -1.4373113896623342 \t -1.38003104553365\n",
            "16     \t [ 8.69529605  0.27226865 14.          0.90636352  1.          0.39638219]. \t  -1.5046635673583721 \t -1.38003104553365\n",
            "17     \t [ 5.32600557  1.19203155  6.          0.95099756 12.          0.26039234]. \t  -1.5642609520722548 \t -1.38003104553365\n",
            "18     \t [ 6.71481571  6.90535892 13.          0.88822228  1.          0.86325437]. \t  -1.441164123436047 \t -1.38003104553365\n",
            "19     \t [ 9.24004771  6.36004976 11.          0.81644504 12.          0.66235401]. \t  -1.4357648601047632 \t -1.38003104553365\n",
            "20     \t [5.68286365 5.81484664 5.         0.58385602 2.         0.89128016]. \t  -1.429453875636773 \t -1.38003104553365\n",
            "21     \t [ 3.88228969  0.88604462 14.          0.91032137 12.          0.89068146]. \t  \u001b[92m-1.3789169247649145\u001b[0m \t -1.3789169247649145\n",
            "22     \t [ 4.05865382  1.90566145 10.          0.59761233  1.          0.93758602]. \t  -1.3918044768014313 \t -1.3789169247649145\n",
            "23     \t [9.90170442 8.46894499 6.         0.54434383 1.         0.20203613]. \t  -1.6470329365769387 \t -1.3789169247649145\n",
            "24     \t [ 0.          3.22665363 15.          0.5        19.06428607  0.1       ]. \t  -1.6459383673403647 \t -1.3789169247649145\n",
            "25     \t [10.          2.81812715 15.          1.         15.66061806  0.1       ]. \t  -1.638548899049034 \t -1.3789169247649145\n",
            "26     \t [3.50489783 5.50811934 8.         0.9854684  9.         0.45141256]. \t  -1.4981193685950358 \t -1.3789169247649145\n",
            "27     \t [6.12087565 0.         5.         1.         1.         0.1       ]. \t  -1.6422012622595326 \t -1.3789169247649145\n",
            "28     \t [ 6.38884492  9.08857975 15.          0.5        13.90900155  0.1       ]. \t  -1.646300408336342 \t -1.3789169247649145\n",
            "29     \t [10.         10.         15.          0.5        18.91271171  0.1       ]. \t  -1.6459881476953218 \t -1.3789169247649145\n",
            "30     \t [0.         3.45990119 5.         1.         1.         0.1       ]. \t  -1.6422012124127314 \t -1.3789169247649145\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49631.03388986589"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5H4MWSXFcZjO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6de5349-3e35-4b95-eb93-234f5817c86a"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'stp' Acquisition Function run number = 18 \n",
        "\n",
        "np.random.seed(run_num_18)\n",
        "surrogate_stp_18 = tStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train18, X_test18, y_train18, y_test18 = train_test_split(X, y, test_size=test_perc, random_state=run_num_18)\n",
        "\n",
        "def f_syn_polarity18(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_18, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train18, y=y_train18).mean())\n",
        "    return operator * score\n",
        "\n",
        "stp_18 = GPGO(surrogate_stp_18, Acquisition_new(util_stp), f_syn_polarity18, param, n_jobs = -1) # Define BayesOpt\n",
        "stp_18.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_stp_18 = stp_18.getResult()[0]\n",
        "params_stp_18['max_depth'] = int(params_stp_18['max_depth'])\n",
        "params_stp_18['min_child_weight'] = int(params_stp_18['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_stp_train18 = xgb.DMatrix(X_train18, y_train18)\n",
        "dX_stp_test18 = xgb.DMatrix(X_test18, y_test18)\n",
        "model_stp_18 = xgb.train(params_stp_18, dX_stp_train18)\n",
        "pred_stp_18 = model_stp_18.predict(dX_stp_test18)\n",
        "\n",
        "rmse_stp_18 = np.sqrt(mean_squared_error(pred_stp_18, y_test18))\n",
        "rmse_stp_18"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [6.50374242 5.05453374 6.         0.59092011 3.         0.28357516]. \t  -1.6322360469477801 \t -1.459078835901506\n",
            "init   \t [0.11506734 4.26891483 9.         0.81785956 5.         0.63489043]. \t  -1.459078835901506 \t -1.459078835901506\n",
            "init   \t [ 2.8861259   6.35547834 11.          0.64267955 14.          0.27877092]. \t  -1.6286856942256722 \t -1.459078835901506\n",
            "init   \t [6.57189031 6.99655629 8.         0.63235896 4.         0.52894035]. \t  -1.5014828773258142 \t -1.459078835901506\n",
            "init   \t [ 6.66600348  2.11312037 14.          0.74363461  4.          0.73174558]. \t  -1.4595033750139994 \t -1.459078835901506\n",
            "1      \t [ 8.67093232  0.11649132  5.          0.92962202 15.          0.53672863]. \t  -1.5426478637399241 \t -1.459078835901506\n",
            "2      \t [ 8.43851229  2.41114508 13.          0.75771586 19.          0.86905071]. \t  \u001b[92m-1.397450772072645\u001b[0m \t -1.397450772072645\n",
            "3      \t [ 9.44281001  9.01534322  7.          0.99142432 16.          0.37631199]. \t  -1.5735752069232922 \t -1.397450772072645\n",
            "4      \t [ 3.19538294  9.91737336 14.          0.7976317   5.          0.25704487]. \t  -1.6331955318692337 \t -1.397450772072645\n",
            "5      \t [ 0.21200191  9.95034596  6.          0.77719285 19.          0.61346381]. \t  -1.5235049730081272 \t -1.397450772072645\n",
            "6      \t [ 1.26601315  0.31299408  6.          0.95296222 16.          0.13649883]. \t  -1.6433435839736728 \t -1.397450772072645\n",
            "7      \t [ 1.2588084   9.80413977  5.          0.75618546 12.          0.53020258]. \t  -1.5419263849633718 \t -1.397450772072645\n",
            "8      \t [ 6.63763513  1.21594617 14.          0.92753462 12.          0.25002233]. \t  -1.6284007766868314 \t -1.397450772072645\n",
            "9      \t [ 7.49192948  9.60283663 14.          0.93718151 19.          0.24625933]. \t  -1.6385827991593047 \t -1.397450772072645\n",
            "10     \t [ 0.45900242  1.30431521 14.          0.64901358 15.          0.91762916]. \t  \u001b[92m-1.3697478635925542\u001b[0m \t -1.3697478635925542\n",
            "11     \t [9.98653758 8.80568206 9.         0.86984433 9.         0.78984159]. \t  -1.4047041660600752 \t -1.3697478635925542\n",
            "12     \t [4.77329541 1.13129133 5.         0.67932546 9.         0.50909066]. \t  -1.5434606481763236 \t -1.3697478635925542\n",
            "13     \t [0.1681044  8.38167689 5.         0.57221101 1.         0.32539925]. \t  -1.634083946587745 \t -1.3697478635925542\n",
            "14     \t [ 4.25762222  4.02301922  9.          0.6129246  19.          0.59981465]. \t  -1.4939952222005481 \t -1.3697478635925542\n",
            "15     \t [9.66555931 0.03278214 7.         0.65118318 6.         0.28697131]. \t  -1.6306650080434544 \t -1.3697478635925542\n",
            "16     \t [ 6.80131964  5.61100356  5.          0.60827701 12.          0.4103298 ]. \t  -1.5935559549173939 \t -1.3697478635925542\n",
            "17     \t [4.62904808 8.17796855 8.         0.7827474  9.         0.73274763]. \t  -1.4676865142381286 \t -1.3697478635925542\n",
            "18     \t [ 9.56072091  9.1368036  14.          0.68050527  1.          0.47597207]. \t  -1.5809485236812564 \t -1.3697478635925542\n",
            "19     \t [ 6.17527419  7.45259387 14.          0.99494731 11.          0.1359292 ]. \t  -1.6394412622232377 \t -1.3697478635925542\n",
            "20     \t [ 0.71757549  1.10909841 12.          0.74563843  9.          0.40273808]. \t  -1.5627555237752684 \t -1.3697478635925542\n",
            "21     \t [ 2.07208012  1.48825717  9.          0.81554889 11.          0.70539991]. \t  -1.458576207872289 \t -1.3697478635925542\n",
            "22     \t [ 6.99215684  5.0752615   6.          0.8313862  19.          0.43806959]. \t  -1.5823987397236086 \t -1.3697478635925542\n",
            "23     \t [5.8651125  6.95720403 5.         0.56056787 7.         0.5685839 ]. \t  -1.543286583266158 \t -1.3697478635925542\n",
            "24     \t [ 6.90969665  3.95282248 11.          0.75767881 16.          0.8200217 ]. \t  -1.400213224932509 \t -1.3697478635925542\n",
            "25     \t [ 0.25258226  0.64125757 13.          0.71523365  1.          0.10722612]. \t  -1.639331770090159 \t -1.3697478635925542\n",
            "26     \t [ 3.01028032  2.6806302  12.          0.67746669  7.          0.99064833]. \t  -1.3721435075724515 \t -1.3697478635925542\n",
            "27     \t [4.63693775 0.         8.66822433 0.5        2.13092983 1.        ]. \t  -1.3813274908672115 \t -1.3697478635925542\n",
            "28     \t [ 2.57188927  5.66235431  5.          1.         15.50323933  1.        ]. \t  -1.4168441669217533 \t -1.3697478635925542\n",
            "29     \t [10.          5.3059462  15.          1.         15.05177402  0.1       ]. \t  -1.6074814173044192 \t -1.3697478635925542\n",
            "30     \t [ 0.88946402  5.5189184  13.          0.94375573 19.          0.82272041]. \t  -1.3918838154332167 \t -1.3697478635925542\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "48842.23404338053"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-zaPbk2uuzH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dad7ba98-fa05-422e-acbf-2eca8e46c744"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'stp' Acquisition Function run number = 19 \n",
        "\n",
        "np.random.seed(run_num_19)\n",
        "surrogate_stp_19 = tStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train19, X_test19, y_train19, y_test19 = train_test_split(X, y, test_size=test_perc, random_state=run_num_19)\n",
        "\n",
        "def f_syn_polarity19(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_19, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train19, y=y_train19).mean())\n",
        "    return operator * score\n",
        "\n",
        "stp_19 = GPGO(surrogate_stp_19, Acquisition_new(util_stp), f_syn_polarity19, param, n_jobs = -1) # Define BayesOpt\n",
        "stp_19.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_stp_19 = stp_19.getResult()[0]\n",
        "params_stp_19['max_depth'] = int(params_stp_19['max_depth'])\n",
        "params_stp_19['min_child_weight'] = int(params_stp_19['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_stp_train19 = xgb.DMatrix(X_train19, y_train19)\n",
        "dX_stp_test19 = xgb.DMatrix(X_test19, y_test19)\n",
        "model_stp_19 = xgb.train(params_stp_19, dX_stp_train19)\n",
        "pred_stp_19 = model_stp_19.predict(dX_stp_test19)\n",
        "\n",
        "rmse_stp_19 = np.sqrt(mean_squared_error(pred_stp_19, y_test19))\n",
        "rmse_stp_19"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 0.97533602  7.61249717 13.          0.85765469 11.          0.39830191]. \t  -1.4075337339770704 \t -1.4075337339770704\n",
            "init   \t [ 0.82999565  6.71977081  6.          0.50407413 19.          0.67209466]. \t  -1.4228132434714993 \t -1.4075337339770704\n",
            "init   \t [ 2.15923256  5.49027432 12.          0.52588686 10.          0.20235326]. \t  -1.6084741621894145 \t -1.4075337339770704\n",
            "init   \t [4.99659267 1.52108422 6.         0.73481085 4.         0.71949465]. \t  -1.4198106118164695 \t -1.4075337339770704\n",
            "init   \t [ 3.72927156  9.46160045  5.          0.80554614 18.          0.97708466]. \t  -1.4218628552782113 \t -1.4075337339770704\n",
            "1      \t [ 8.33060043  1.42030563  8.          0.92863724 14.          0.78606141]. \t  \u001b[92m-1.3842780004279849\u001b[0m \t -1.3842780004279849\n",
            "2      \t [ 4.70068371  4.9755295  14.          0.98901029  1.          0.96039614]. \t  \u001b[92m-1.372031481989105\u001b[0m \t -1.372031481989105\n",
            "3      \t [9.07948237 9.55063617 7.         0.80962147 4.         0.34142584]. \t  -1.472070120000281 \t -1.372031481989105\n",
            "4      \t [ 3.65000245  2.90359952 13.          0.98940034 19.          0.29019455]. \t  -1.4708108340180257 \t -1.372031481989105\n",
            "5      \t [0.25768796 8.33414072 6.         0.99948369 4.         0.66680619]. \t  -1.4172691326632303 \t -1.372031481989105\n",
            "6      \t [ 8.89243569  4.2136102  10.          0.88870164  8.          0.77683659]. \t  -1.3727429340394495 \t -1.372031481989105\n",
            "7      \t [ 7.9630536   9.9112732  14.          0.53823001 14.          0.26777722]. \t  -1.473086995627504 \t -1.372031481989105\n",
            "8      \t [1.60895472e-01 8.27074864e-03 1.30000000e+01 6.91893018e-01\n",
            " 5.00000000e+00 4.60327119e-01]. \t  -1.412265762362551 \t -1.372031481989105\n",
            "9      \t [ 0.32873959  7.7155114   5.          0.56871173 11.          0.34471029]. \t  -1.4765632459324078 \t -1.372031481989105\n",
            "10     \t [ 6.55489773  0.06438745 14.          0.53351105 11.          0.76391016]. \t  -1.3809975751973738 \t -1.372031481989105\n",
            "11     \t [ 9.32390837  9.51845123 14.          0.71072327  2.          0.55726506]. \t  -1.3894225887477218 \t -1.372031481989105\n",
            "12     \t [ 4.31405249  0.92741236  7.          0.67333637 19.          0.97097788]. \t  -1.3981247907535166 \t -1.372031481989105\n",
            "13     \t [ 0.07353347  8.4040255  13.          0.8931152   4.          0.37840671]. \t  -1.4090516400471915 \t -1.372031481989105\n",
            "14     \t [10.  0. 15.  1.  1.  1.]. \t  -1.374730569829473 \t -1.372031481989105\n",
            "15     \t [0.22611985 0.1170465  7.         0.55795985 9.         0.86758401]. \t  -1.399675395140902 \t -1.372031481989105\n",
            "16     \t [ 9.0780433   8.49155787  5.          0.8925855  13.          0.38273904]. \t  -1.44700455519301 \t -1.372031481989105\n",
            "17     \t [ 2.66360123  9.86349513 14.          0.64775009 19.          0.29460461]. \t  -1.471057474761123 \t -1.372031481989105\n",
            "18     \t [ 5.27081379  9.69565951  9.          0.57130727 12.          0.81546981]. \t  -1.3846958512286693 \t -1.372031481989105\n",
            "19     \t [ 0.17032432  0.5511349   8.          0.8772351  15.          0.24483614]. \t  -1.6073176370956888 \t -1.372031481989105\n",
            "20     \t [5.32068334 4.15685186 6.         0.78279262 9.         0.97124116]. \t  -1.4065805900992676 \t -1.372031481989105\n",
            "21     \t [ 9.63925033  0.21213822 12.          0.67633014 18.          0.33271761]. \t  -1.4702920453950845 \t -1.372031481989105\n",
            "22     \t [ 9.68796732  9.93406276 13.          0.50692703  9.          0.81230579]. \t  -1.37994789422642 \t -1.372031481989105\n",
            "23     \t [9.44634329 2.22309658 9.         0.70396484 1.         0.67627298]. \t  -1.3975473581986242 \t -1.372031481989105\n",
            "24     \t [ 8.51306325  8.47935742  9.          0.8052638  19.          0.56077288]. \t  -1.3904725397878515 \t -1.372031481989105\n",
            "25     \t [0.14886079 3.10947104 7.         0.52818873 1.         0.88078996]. \t  -1.3998190079256125 \t -1.372031481989105\n",
            "26     \t [ 5.47753561  8.1400748  11.          0.58805191  5.          0.42114657]. \t  -1.4169549477001757 \t -1.372031481989105\n",
            "27     \t [10.          2.24004823  5.          0.5         7.12469774  0.1       ]. \t  -1.606610035609398 \t -1.372031481989105\n",
            "28     \t [ 0.          6.59153416  8.99765     1.         14.43452341  1.        ]. \t  -1.3847412617017412 \t -1.372031481989105\n",
            "29     \t [ 0.04332693  3.83181893 10.          0.67809295  9.          0.69301409]. \t  -1.3920227136298273 \t -1.372031481989105\n",
            "30     \t [7.89387462 7.57127771 9.         0.80303121 6.         0.54653425]. \t  -1.3903181390387185 \t -1.372031481989105\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "51545.69791438903"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NvkuHKlQuxRy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2549ee04-e23e-439c-b32b-42302cb33da6"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'stp' Acquisition Function run number = 20 \n",
        "\n",
        "np.random.seed(run_num_20)\n",
        "surrogate_stp_20 = tStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train20, X_test20, y_train20, y_test20 = train_test_split(X, y, test_size=test_perc, random_state=run_num_20)\n",
        "\n",
        "def f_syn_polarity20(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_20, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train20, y=y_train20).mean())\n",
        "    return operator * score\n",
        "\n",
        "stp_20 = GPGO(surrogate_stp_20, Acquisition_new(util_stp), f_syn_polarity20, param, n_jobs = -1) # Define BayesOpt\n",
        "stp_20.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_stp_20 = stp_20.getResult()[0]\n",
        "params_stp_20['max_depth'] = int(params_stp_20['max_depth'])\n",
        "params_stp_20['min_child_weight'] = int(params_stp_20['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_stp_train20 = xgb.DMatrix(X_train20, y_train20)\n",
        "dX_stp_test20 = xgb.DMatrix(X_test20, y_test20)\n",
        "model_stp_20 = xgb.train(params_stp_20, dX_stp_train20)\n",
        "pred_stp_20 = model_stp_20.predict(dX_stp_test20)\n",
        "\n",
        "rmse_stp_20 = np.sqrt(mean_squared_error(pred_stp_20, y_test20))\n",
        "rmse_stp_20"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 5.88130801  8.97713728 14.          0.81074445  8.          0.95540649]. \t  -1.3748447855907977 \t -1.3748447855907977\n",
            "init   \t [6.72865655 0.41173329 8.         0.6361582  7.         0.76174061]. \t  -1.4185133726703796 \t -1.3748447855907977\n",
            "init   \t [ 4.77387703  8.66202323 10.          0.51833215  7.          0.10123387]. \t  -1.6439786774737961 \t -1.3748447855907977\n",
            "init   \t [ 5.75489985  4.74524381  8.          0.78084343 15.          0.26643049]. \t  -1.534878770114387 \t -1.3748447855907977\n",
            "init   \t [ 4.53444     4.47342833  8.          0.91974896 18.          0.35997552]. \t  -1.5336412960522285 \t -1.3748447855907977\n",
            "1      \t [ 7.96566073  7.15509535  7.          0.79906691 11.          0.34132075]. \t  -1.536147862834937 \t -1.3748447855907977\n",
            "2      \t [0.0691652  5.34850007 7.         0.63667652 1.         0.21496993]. \t  -1.645354602105705 \t -1.3748447855907977\n",
            "3      \t [ 0.31808457  1.69265297 13.          0.650995    9.          0.62426872]. \t  -1.489353811826979 \t -1.3748447855907977\n",
            "4      \t [ 7.32450119  0.97088138 14.          0.62864562  2.          0.93189305]. \t  -1.390989554525644 \t -1.3748447855907977\n",
            "5      \t [8.0846212  5.99993376 6.         0.83941375 1.         0.46362124]. \t  -1.5160706218749516 \t -1.3748447855907977\n",
            "6      \t [ 0.88245237  8.87861126 13.          0.90693744 14.          0.28127748]. \t  -1.5353549212767705 \t -1.3748447855907977\n",
            "7      \t [ 0.72788527  2.26655356 10.          0.97273032 15.          0.85843758]. \t  -1.4077391596162414 \t -1.3748447855907977\n",
            "8      \t [ 7.29847873  0.61439441  5.          0.60353619 15.          0.628184  ]. \t  -1.4345096580234407 \t -1.3748447855907977\n",
            "9      \t [ 8.4792713   2.16551796 14.          0.5955684  19.          0.9089276 ]. \t  -1.3837137256254377 \t -1.3748447855907977\n",
            "10     \t [ 8.07574107  9.26938534 14.          0.9315973  14.          0.78345994]. \t  -1.409291538603655 \t -1.3748447855907977\n",
            "11     \t [ 3.28444135  4.88068826 13.          0.83217983  5.          0.1064095 ]. \t  -1.641563546934136 \t -1.3748447855907977\n",
            "12     \t [ 0.43675166  9.24585203  6.          0.65273697 16.          0.75952231]. \t  -1.4250662642048557 \t -1.3748447855907977\n",
            "13     \t [7.12982753 6.84003365 7.         0.76458922 2.         0.82832765]. \t  -1.4176455584475862 \t -1.3748447855907977\n",
            "14     \t [ 0.72763535  0.43039316 12.          0.56482354  2.          0.35507728]. \t  -1.547688727924287 \t -1.3748447855907977\n",
            "15     \t [0.29360141 7.14831573 6.         0.85886473 9.         0.8538084 ]. \t  -1.4220591591015055 \t -1.3748447855907977\n",
            "16     \t [1.01173572 1.57355816 5.         0.66922967 6.         0.97562515]. \t  -1.4207352855515498 \t -1.3748447855907977\n",
            "17     \t [ 8.2503326   1.61920179 14.          0.80641713 11.          0.5764476 ]. \t  -1.4832537345865822 \t -1.3748447855907977\n",
            "18     \t [10.          6.10600743 10.14332853  1.          5.6876259   1.        ]. \t  \u001b[92m-1.3625294649715864\u001b[0m \t -1.3625294649715864\n",
            "19     \t [ 8.64250146  8.29138679 14.          0.77039694  1.          0.68995319]. \t  -1.4250949839080236 \t -1.3625294649715864\n",
            "20     \t [ 2.19123007 10.         11.44780673  0.5        19.82861231  1.        ]. \t  -1.380364756379366 \t -1.3625294649715864\n",
            "21     \t [ 5.33809672  0.         12.21073562  0.64578415 14.87843389  0.1       ]. \t  -1.643103586164677 \t -1.3625294649715864\n",
            "22     \t [ 8.10941441  9.74874115  6.          0.52082796 19.          0.22723491]. \t  -1.6477856724991806 \t -1.3625294649715864\n",
            "23     \t [3.44778256 1.02586448 7.         0.60721777 1.         0.1172894 ]. \t  -1.6449328160160614 \t -1.3625294649715864\n",
            "24     \t [ 4.78188245 10.          9.16058378  1.         14.4940902   1.        ]. \t  -1.3660702068072617 \t -1.3625294649715864\n",
            "25     \t [ 0. 10. 15.  1.  1.  1.]. \t  -1.3628641490007873 \t -1.3625294649715864\n",
            "26     \t [ 0.         10.          5.          0.5         3.39868145  1.        ]. \t  -1.4180551857436432 \t -1.3625294649715864\n",
            "27     \t [ 8.9394202   8.73410949 12.45098471  1.         20.          0.1       ]. \t  -1.6335782083380888 \t -1.3625294649715864\n",
            "28     \t [10.  0.  5.  1.  1.  1.]. \t  -1.4131801736850573 \t -1.3625294649715864\n",
            "29     \t [ 0.         10.         14.03532629  0.88446293  6.89630187  1.        ]. \t  \u001b[92m-1.3607036036065856\u001b[0m \t -1.3607036036065856\n",
            "30     \t [ 0.21888051  0.35132818  6.          0.77703308 19.          0.35680372]. \t  -1.539156201026812 \t -1.3607036036065856\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49844.153611607115"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFKuwvS3uzrs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbb2a149-3645-4ca6-808e-6e3d865c2ca9"
      },
      "source": [
        "end_stp = time.time()\n",
        "end_stp\n",
        "\n",
        "time_stp = end_stp - start_stp\n",
        "time_stp"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1065.0128273963928"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CU2FlhY4vHUk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98daa91d-767d-404a-f7c0-171c7a62ca7a"
      },
      "source": [
        "rmse_gp = [rmse_gp_1,\n",
        "rmse_gp_2,\n",
        "rmse_gp_3,\n",
        "rmse_gp_4,\n",
        "rmse_gp_5,\n",
        "rmse_gp_6,\n",
        "rmse_gp_7,\n",
        "rmse_gp_8,\n",
        "rmse_gp_9,\n",
        "rmse_gp_10,\n",
        "rmse_gp_11,\n",
        "rmse_gp_12,\n",
        "rmse_gp_13,\n",
        "rmse_gp_14,\n",
        "rmse_gp_15,\n",
        "rmse_gp_16,\n",
        "rmse_gp_17,\n",
        "rmse_gp_18,\n",
        "rmse_gp_19,\n",
        "rmse_gp_20]\n",
        "\n",
        "np.mean(rmse_gp)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50253.80948101508"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZ53FsWXu3J1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "116874aa-ecd1-44c7-8aa8-3354b004bb80"
      },
      "source": [
        "rmse_stp = [rmse_stp_1,\n",
        "rmse_stp_2,\n",
        "rmse_stp_3,\n",
        "rmse_stp_4,\n",
        "rmse_stp_5,\n",
        "rmse_stp_6,\n",
        "rmse_stp_7,\n",
        "rmse_stp_8,\n",
        "rmse_stp_9,\n",
        "rmse_stp_10,\n",
        "rmse_stp_11,\n",
        "rmse_stp_12,\n",
        "rmse_stp_13,\n",
        "rmse_stp_14,\n",
        "rmse_stp_15,\n",
        "rmse_stp_16,\n",
        "rmse_stp_17,\n",
        "rmse_stp_18,\n",
        "rmse_stp_19,\n",
        "rmse_stp_20]\n",
        "\n",
        "np.mean(rmse_stp)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50481.99464342658"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9FOyoH8u5Wx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32eb0383-943c-4d55-a357-e5244794de7d"
      },
      "source": [
        "min_rmse_gp = min_max_array(rmse_gp)\n",
        "min_rmse_gp, len(min_rmse_gp)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([48973.66312746987,\n",
              "  48495.7639648715,\n",
              "  48495.7639648715,\n",
              "  48495.7639648715,\n",
              "  48495.7639648715,\n",
              "  48488.50555803437,\n",
              "  48488.50555803437,\n",
              "  48488.50555803437,\n",
              "  48488.50555803437,\n",
              "  48488.50555803437,\n",
              "  48488.50555803437,\n",
              "  48488.50555803437,\n",
              "  48488.50555803437,\n",
              "  48488.50555803437,\n",
              "  48488.50555803437,\n",
              "  48488.50555803437,\n",
              "  48488.50555803437,\n",
              "  48488.50555803437,\n",
              "  48488.50555803437,\n",
              "  48488.50555803437],\n",
              " 20)"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unXOpKHcvO15",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aad7b329-abd6-48e1-c35d-0c9da1360dbe"
      },
      "source": [
        "min_rmse_stp = min_max_array(rmse_stp)\n",
        "min_rmse_stp, len(min_rmse_stp)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([48973.66312746987,\n",
              "  48973.66312746987,\n",
              "  47648.10643318531,\n",
              "  47648.10643318531,\n",
              "  47648.10643318531,\n",
              "  47648.10643318531,\n",
              "  47648.10643318531,\n",
              "  47648.10643318531,\n",
              "  47648.10643318531,\n",
              "  47648.10643318531,\n",
              "  47648.10643318531,\n",
              "  47648.10643318531,\n",
              "  47648.10643318531,\n",
              "  47648.10643318531,\n",
              "  47648.10643318531,\n",
              "  47648.10643318531,\n",
              "  47648.10643318531,\n",
              "  47648.10643318531,\n",
              "  47648.10643318531,\n",
              "  47648.10643318531],\n",
              " 20)"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yxo85-HEvRPi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 291
        },
        "outputId": "66d990d1-c519-455d-e0c9-79f5094ed5c5"
      },
      "source": [
        "### Visualise!\n",
        "\n",
        "title = obj_func\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(min_rmse_gp, color = 'Yellow', label='RMSE: GP CBM')\n",
        "plt.plot(min_rmse_stp, color = 'Green', ls='--', label='RMSE: STP CBM ' r'($\\nu$' ' = {})'.format(df))\n",
        "\n",
        "plt.title(title, weight = 'bold')\n",
        "plt.xlabel('Experiment(s)', weight = 'bold') # x-axis label\n",
        "plt.ylabel('RMSE (US Dollars $)', weight = 'bold') # y-axis label\n",
        "plt.legend(loc=0) # add plot legend\n",
        "\n",
        "### Make the x-ticks integers, not floats:\n",
        "count = len(min_rmse_gp)\n",
        "plt.xticks(np.arange(count), np.arange(1, count + 1))\n",
        "plt.grid(b=None)\n",
        "plt.show() #visualise!\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwyO7_iZvT7a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "256f22a0-eecd-4ace-d435-746ab96f6b18"
      },
      "source": [
        "time_gp, time_stp\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1025.7858633995056, 1065.0128273963928)"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHLA-0DnVXxD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f000fba1-4a88-4a16-fc2d-7dd20f5498bf"
      },
      "source": [
        "min(min_rmse_stp), min(min_rmse_gp)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(47648.10643318531, 48488.50555803437)"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iUNBRy3W0GY"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}