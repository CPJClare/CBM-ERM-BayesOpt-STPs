{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OrYfJFnSJLkS"
      },
      "source": [
        "SixHumpCamel synthetic function:\n",
        "\n",
        "GP ERM versus STP nu = 3 ERM (winner)\n",
        "\n",
        "https://www.sfu.ca/~ssurjano/camel6.html"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pyGPGO\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2FgAmLMpOX3c",
        "outputId": "ea98f67a-2aa4-4f25-9c50-c5408a4b98a8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyGPGO in /usr/local/lib/python3.7/dist-packages (0.5.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from pyGPGO) (1.1.0)\n",
            "Requirement already satisfied: pyMC3 in /usr/local/lib/python3.7/dist-packages (from pyGPGO) (3.11.5)\n",
            "Requirement already satisfied: Theano-PyMC in /usr/local/lib/python3.7/dist-packages (from pyGPGO) (1.1.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from pyGPGO) (1.7.3)\n",
            "Requirement already satisfied: mkl in /usr/local/lib/python3.7/dist-packages (from pyGPGO) (2019.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from pyGPGO) (1.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pyGPGO) (1.21.6)\n",
            "Requirement already satisfied: intel-openmp in /usr/local/lib/python3.7/dist-packages (from mkl->pyGPGO) (2022.1.0)\n",
            "Requirement already satisfied: deprecat in /usr/local/lib/python3.7/dist-packages (from pyMC3->pyGPGO) (2.1.1)\n",
            "Requirement already satisfied: cachetools>=4.2.1 in /usr/local/lib/python3.7/dist-packages (from pyMC3->pyGPGO) (4.2.4)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.7/dist-packages (from pyMC3->pyGPGO) (0.5.2)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from pyMC3->pyGPGO) (1.3.5)\n",
            "Requirement already satisfied: semver>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from pyMC3->pyGPGO) (2.13.0)\n",
            "Requirement already satisfied: fastprogress>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from pyMC3->pyGPGO) (1.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from pyMC3->pyGPGO) (4.1.1)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from pyMC3->pyGPGO) (0.3.5.1)\n",
            "Requirement already satisfied: arviz>=0.11.0 in /usr/local/lib/python3.7/dist-packages (from pyMC3->pyGPGO) (0.12.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from Theano-PyMC->pyGPGO) (3.8.0)\n",
            "Requirement already satisfied: xarray-einstats>=0.2 in /usr/local/lib/python3.7/dist-packages (from arviz>=0.11.0->pyMC3->pyGPGO) (0.2.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from arviz>=0.11.0->pyMC3->pyGPGO) (21.3)\n",
            "Requirement already satisfied: matplotlib>=3.0 in /usr/local/lib/python3.7/dist-packages (from arviz>=0.11.0->pyMC3->pyGPGO) (3.2.2)\n",
            "Requirement already satisfied: netcdf4 in /usr/local/lib/python3.7/dist-packages (from arviz>=0.11.0->pyMC3->pyGPGO) (1.6.0)\n",
            "Requirement already satisfied: xarray>=0.16.1 in /usr/local/lib/python3.7/dist-packages (from arviz>=0.11.0->pyMC3->pyGPGO) (0.20.2)\n",
            "Requirement already satisfied: setuptools>=38.4 in /usr/local/lib/python3.7/dist-packages (from arviz>=0.11.0->pyMC3->pyGPGO) (57.4.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0->arviz>=0.11.0->pyMC3->pyGPGO) (1.4.4)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0->arviz>=0.11.0->pyMC3->pyGPGO) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0->arviz>=0.11.0->pyMC3->pyGPGO) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0->arviz>=0.11.0->pyMC3->pyGPGO) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->pyMC3->pyGPGO) (2022.2.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from patsy>=0.5.1->pyMC3->pyGPGO) (1.15.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from xarray>=0.16.1->arviz>=0.11.0->pyMC3->pyGPGO) (4.12.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from deprecat->pyMC3->pyGPGO) (1.14.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->xarray>=0.16.1->arviz>=0.11.0->pyMC3->pyGPGO) (3.8.1)\n",
            "Requirement already satisfied: cftime in /usr/local/lib/python3.7/dist-packages (from netcdf4->arviz>=0.11.0->pyMC3->pyGPGO) (1.6.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pyGPGO) (3.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Dn_SAbhVJLke"
      },
      "outputs": [],
      "source": [
        "### Import modules:\n",
        "\n",
        "import numpy as np\n",
        "import scipy as sp\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import warnings\n",
        "\n",
        "from pyGPGO.logger import EventLogger\n",
        "from pyGPGO.GPGO import GPGO\n",
        "from pyGPGO.surrogates.GaussianProcess import GaussianProcess\n",
        "from pyGPGO.surrogates.tStudentProcess import tStudentProcess, logpdf\n",
        "from pyGPGO.acquisition import Acquisition\n",
        "from pyGPGO.covfunc import squaredExponential\n",
        "\n",
        "from collections import OrderedDict\n",
        "from joblib import Parallel, delayed\n",
        "from numpy.linalg import slogdet, inv, cholesky, solve\n",
        "from scipy.optimize import minimize\n",
        "from scipy.spatial.distance import cdist\n",
        "from scipy.special import gamma\n",
        "from scipy.stats import norm, t\n",
        "from matplotlib.pyplot import rc\n",
        "\n",
        "rc('text', usetex=False)\n",
        "plt.rcParams['text.latex.preamble']=[r'\\usepackage{amsmath}']\n",
        "plt.rcParams['text.latex.preamble'] = [r'\\boldmath']\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "4Nwg_XO0JLki"
      },
      "outputs": [],
      "source": [
        "### Inputs:\n",
        "\n",
        "obj_func = 'SixHumpCamel'\n",
        "n_test = 500 # test points\n",
        "df = 3 # nu\n",
        "\n",
        "util_gp = 'RegretMinimized'\n",
        "util_stp = 'tRegretMinimized'\n",
        "n_init = 5 # random initialisations\n",
        "\n",
        "cov_func = squaredExponential()\n",
        "hyperOpt = True\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "DVYGZ6jYJLkj"
      },
      "outputs": [],
      "source": [
        "### Objective function:\n",
        "\n",
        "if obj_func == 'SixHumpCamel':\n",
        "    \n",
        "    # True y bounds:\n",
        "    y_lb = -1.0316\n",
        "    operator = -1 # targets global minimum \n",
        "    y_global_orig = y_lb * operator # targets global minimum\n",
        "            \n",
        "# Constraints:\n",
        "    lb_x1 = -3\n",
        "    ub_x1 = +3\n",
        "    \n",
        "    lb_x2 = -2\n",
        "    ub_x2 = +2\n",
        "    \n",
        "# Input array dimension(s):\n",
        "    dim = 2\n",
        "\n",
        "# 2-D inputs' parameter bounds:\n",
        "    param = {'x1_training': ('cont', [lb_x1, ub_x1]),\n",
        "             'x2_training': ('cont', [lb_x2, ub_x2])}\n",
        "    \n",
        "    max_iter = 100  # iterations of Bayesian optimisation\n",
        "    \n",
        "# Test data:\n",
        "    x1_test = np.linspace(lb_x1, ub_x1, n_test)\n",
        "    x2_test = np.linspace(lb_x2, ub_x2, n_test)\n",
        "    Xstar_d = np.column_stack((x1_test, x2_test))\n",
        "\n",
        "    def f_syn_polarity(x1_training, x2_training):\n",
        "        return operator * ((4 - 2.1 * x1_training ** 2 + 1 / 3 * x1_training ** 4) * x1_training ** 2 +\n",
        "                (x1_training * x2_training) + (-4 + 4 * x2_training ** 2) * x2_training ** 2)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "hE7COdNcJLkl"
      },
      "outputs": [],
      "source": [
        "### Cumulative Regret Calculator:\n",
        "\n",
        "def min_max_array(x):\n",
        "    new_list = []\n",
        "    for i, num in enumerate(x):\n",
        "            new_list.append(np.min(x[0:i+1]))\n",
        "    return new_list\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "gkY6wLl_JLkm"
      },
      "outputs": [],
      "source": [
        "### Set-seeds:\n",
        "\n",
        "run_num_1 = 1\n",
        "run_num_2 = 2\n",
        "run_num_3 = 3\n",
        "run_num_4 = 4\n",
        "run_num_5 = 5\n",
        "run_num_6 = 6\n",
        "run_num_7 = 7\n",
        "run_num_8 = 8\n",
        "run_num_9 = 9\n",
        "run_num_10 = 10\n",
        "run_num_11 = 11\n",
        "run_num_12 = 12\n",
        "run_num_13 = 13\n",
        "run_num_14 = 14\n",
        "run_num_15 = 15\n",
        "run_num_16 = 16\n",
        "run_num_17 = 17\n",
        "run_num_18 = 18\n",
        "run_num_19 = 19\n",
        "run_num_20 = 20\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Mh53nXeyJLko"
      },
      "outputs": [],
      "source": [
        "### Acquisition function - ERM:\n",
        "\n",
        "class Acquisition_new(Acquisition):    \n",
        "    def __init__(self, mode, eps=1e-06, **params):\n",
        "        \n",
        "        self.params = params\n",
        "        self.eps = eps\n",
        "\n",
        "        mode_dict = {\n",
        "            'RegretMinimized': self.RegretMinimized,\n",
        "            'tRegretMinimized': self.tRegretMinimized\n",
        "        }\n",
        "\n",
        "        self.f = mode_dict[mode]\n",
        "   \n",
        "    def RegretMinimized(self, tau, mean, std):\n",
        "        \n",
        "        z = (mean - y_global_orig - self.eps) / (std + self.eps)\n",
        "        return z * (std + self.eps) * norm.cdf(z) + (std + self.eps) * norm.pdf(z)[0]\n",
        "    \n",
        "    def tRegretMinimized(self, tau, mean, std, nu=3.0):\n",
        "        \n",
        "        gamma = (mean - y_global_orig - self.eps) / (std + self.eps)\n",
        "        return gamma * (std + self.eps) * t.cdf(gamma, df=nu) + (std + self.eps) * (nu + gamma ** 2)/(nu - 1) * t.pdf(gamma, df=nu)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fio5AsW9JLkp",
        "outputId": "6d92523b-ef3e-48ca-bdc9-96ad3c6a8fb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [-0.49786797  0.88129797]. \t  0.2650082867644827 \t 0.2650082867644827\n",
            "init   \t [-2.99931375 -0.79066971]. \t  -110.13991869176735 \t 0.2650082867644827\n",
            "init   \t [-2.11946466 -1.63064562]. \t  -26.90935479429681 \t 0.2650082867644827\n",
            "init   \t [-1.88243873 -0.61775709]. \t  -2.8558363102363344 \t 0.2650082867644827\n",
            "init   \t [-0.61939515  0.15526694]. \t  -1.0540522096005847 \t 0.2650082867644827\n",
            "1      \t [-1.19090548 -0.31694205]. \t  -2.4158974691999036 \t 0.2650082867644827\n",
            "2      \t [-0.20496717  1.78860261]. \t  -27.938307482599367 \t 0.2650082867644827\n",
            "3      \t [ 3.         -0.85938812]. \t  -105.54945612064061 \t 0.2650082867644827\n",
            "4      \t [3. 2.]. \t  -162.89999999999998 \t 0.2650082867644827\n",
            "5      \t [-0.59640429 -0.4737148 ]. \t  -0.7584334477155306 \t 0.2650082867644827\n",
            "6      \t [-0.65513346 -0.35813321]. \t  -1.143697148042604 \t 0.2650082867644827\n",
            "7      \t [-0.68772963 -0.29781267]. \t  -1.3388915825031935 \t 0.2650082867644827\n",
            "8      \t [-0.70586268 -0.26614143]. \t  -1.4374848053096574 \t 0.2650082867644827\n",
            "9      \t [-0.15999922 -2.        ]. \t  -48.42102681138308 \t 0.2650082867644827\n",
            "10     \t [-0.91652596  0.13568504]. \t  -1.879186552412336 \t 0.2650082867644827\n",
            "11     \t [-0.89312558  0.11022522]. \t  -1.8772285382925962 \t 0.2650082867644827\n",
            "12     \t [-0.87796208  0.09339266]. \t  -1.8716179006603089 \t 0.2650082867644827\n",
            "13     \t [-0.86750774  0.08146876]. \t  -1.865948557901203 \t 0.2650082867644827\n",
            "14     \t [-3.  2.]. \t  -150.89999999999998 \t 0.2650082867644827\n",
            "15     \t [-0.72425202  0.00867711]. \t  -1.5618855459282412 \t 0.2650082867644827\n",
            "16     \t [-0.7293138  0.0057077]. \t  -1.5793384800361259 \t 0.2650082867644827\n",
            "17     \t [-0.7333449   0.00325902]. \t  -1.5932253852395128 \t 0.2650082867644827\n",
            "18     \t [-0.73661077  0.00121203]. \t  -1.604470936223004 \t 0.2650082867644827\n",
            "19     \t [-7.39295581e-01 -5.19124820e-04]. \t  -1.6137143918115602 \t 0.2650082867644827\n",
            "20     \t [-0.74153026 -0.00199799]. \t  -1.621409147979739 \t 0.2650082867644827\n",
            "21     \t [-0.7434105  -0.00327273]. \t  -1.6278859082673474 \t 0.2650082867644827\n",
            "22     \t [-0.74500753 -0.00438009]. \t  -1.633390187036482 \t 0.2650082867644827\n",
            "23     \t [-0.74637556 -0.00534845]. \t  -1.638108253880672 \t 0.2650082867644827\n",
            "24     \t [-0.74755617 -0.00620114]. \t  -1.64218346912972 \t 0.2650082867644827\n",
            "25     \t [-0.74858195 -0.0069561 ]. \t  -1.6457276039876498 \t 0.2650082867644827\n",
            "26     \t [-0.74947854 -0.00762804]. \t  -1.648828617395175 \t 0.2650082867644827\n",
            "27     \t [-0.75026698 -0.00822874]. \t  -1.6515583350264904 \t 0.2650082867644827\n",
            "28     \t [-0.75096339 -0.00876851]. \t  -1.653972509201439 \t 0.2650082867644827\n",
            "29     \t [-0.75158158 -0.00925522]. \t  -1.6561180938148587 \t 0.2650082867644827\n",
            "30     \t [-0.75213282 -0.00969575]. \t  -1.6580336728563232 \t 0.2650082867644827\n",
            "31     \t [-0.75262614 -0.01009595]. \t  -1.6597502598568337 \t 0.2650082867644827\n",
            "32     \t [-0.75306937 -0.01046068]. \t  -1.6612946062295297 \t 0.2650082867644827\n",
            "33     \t [-0.75346898 -0.01079392]. \t  -1.662688793809825 \t 0.2650082867644827\n",
            "34     \t [-0.75383031 -0.01109951]. \t  -1.6639512774258638 \t 0.2650082867644827\n",
            "35     \t [-0.75415811 -0.01138038]. \t  -1.6650982192579473 \t 0.2650082867644827\n",
            "36     \t [-0.75445629 -0.01163907]. \t  -1.666142974558708 \t 0.2650082867644827\n",
            "37     \t [-0.75472836 -0.01187803]. \t  -1.6670976072728045 \t 0.2650082867644827\n",
            "38     \t [-0.75497718 -0.01209946]. \t  -1.6679720417692496 \t 0.2650082867644827\n",
            "39     \t [-0.75520576 -0.01230465]. \t  -1.6687761398260854 \t 0.2650082867644827\n",
            "40     \t [-0.75541485 -0.01249521]. \t  -1.6695131527146139 \t 0.2650082867644827\n",
            "41     \t [-0.75560793 -0.01267276]. \t  -1.6701944995122044 \t 0.2650082867644827\n",
            "42     \t [-0.75578558 -0.01283843]. \t  -1.670822616682233 \t 0.2650082867644827\n",
            "43     \t [-0.7559497  -0.01299334]. \t  -1.6714038677249627 \t 0.2650082867644827\n",
            "44     \t [-0.75610297 -0.01313826]. \t  -1.6719466692567444 \t 0.2650082867644827\n",
            "45     \t [-0.75624375 -0.01327394]. \t  -1.6724467343508649 \t 0.2650082867644827\n",
            "46     \t [-0.75637699 -0.01340367]. \t  -1.6729207186979553 \t 0.2650082867644827\n",
            "47     \t [-0.75649644 -0.01352106]. \t  -1.6733461949393602 \t 0.2650082867644827\n",
            "48     \t [-0.75661225 -0.01363555]. \t  -1.6737590495396053 \t 0.2650082867644827\n",
            "49     \t [-0.75671733 -0.01374052]. \t  -1.6741342454952026 \t 0.2650082867644827\n",
            "50     \t [-0.75681673 -0.01384095]. \t  -1.674489790815394 \t 0.2650082867644827\n",
            "51     \t [-0.75690982 -0.01393618]. \t  -1.6748234474968848 \t 0.2650082867644827\n",
            "52     \t [-0.75699648 -0.01402539]. \t  -1.675134337907038 \t 0.2650082867644827\n",
            "53     \t [-0.7570796  -0.01411081]. \t  -1.675432381254178 \t 0.2650082867644827\n",
            "54     \t [-0.75715483 -0.01419074]. \t  -1.675703760138517 \t 0.2650082867644827\n",
            "55     \t [-0.75722745 -0.01426753]. \t  -1.675965402984512 \t 0.2650082867644827\n",
            "56     \t [-0.75729553 -0.01434017]. \t  -1.6762110979791027 \t 0.2650082867644827\n",
            "57     \t [-0.75735966 -0.01440913]. \t  -1.6764428118598942 \t 0.2650082867644827\n",
            "58     \t [-0.75742023 -0.01447479]. \t  -1.6766619669649896 \t 0.2650082867644827\n",
            "59     \t [-0.75747706 -0.01453741]. \t  -1.676868223348752 \t 0.2650082867644827\n",
            "60     \t [-0.75753119 -0.0145972 ]. \t  -1.677064742244421 \t 0.2650082867644827\n",
            "61     \t [-0.75758216 -0.01465411]. \t  -1.6772501263649318 \t 0.2650082867644827\n",
            "62     \t [-0.75763046 -0.01470847]. \t  -1.6774260682095585 \t 0.2650082867644827\n",
            "63     \t [-0.75767653 -0.01476048]. \t  -1.6775939565126368 \t 0.2650082867644827\n",
            "64     \t [-0.75772001 -0.01481016]. \t  -1.6777527674592994 \t 0.2650082867644827\n",
            "65     \t [-0.7577613  -0.01485775]. \t  -1.6779038085564382 \t 0.2650082867644827\n",
            "66     \t [-0.75780045 -0.01490323]. \t  -1.6780472741215544 \t 0.2650082867644827\n",
            "67     \t [-0.75783793 -0.01494695]. \t  -1.6781846756078895 \t 0.2650082867644827\n",
            "68     \t [-0.75787327 -0.01498874]. \t  -1.678314589605093 \t 0.2650082867644827\n",
            "69     \t [-0.75790698 -0.01502881]. \t  -1.678438646102026 \t 0.2650082867644827\n",
            "70     \t [-0.75793931 -0.01506741]. \t  -1.6785576808196727 \t 0.2650082867644827\n",
            "71     \t [-0.75796997 -0.0151045 ]. \t  -1.6786708881813832 \t 0.2650082867644827\n",
            "72     \t [-0.75799937 -0.01514013]. \t  -1.6787794922125348 \t 0.2650082867644827\n",
            "73     \t [-0.75802767 -0.01517436]. \t  -1.6788839388394325 \t 0.2650082867644827\n",
            "74     \t [-0.75805402 -0.0152073 ]. \t  -1.6789818941107613 \t 0.2650082867644827\n",
            "75     \t [-0.75807943 -0.01523897]. \t  -1.6790762655984373 \t 0.2650082867644827\n",
            "76     \t [-0.7581037  -0.01526953]. \t  -1.6791666059059602 \t 0.2650082867644827\n",
            "77     \t [-0.75812741 -0.01529906]. \t  -1.6792546468547482 \t 0.2650082867644827\n",
            "78     \t [-0.75814983 -0.01532746]. \t  -1.679338193729147 \t 0.2650082867644827\n",
            "79     \t [-0.75817106 -0.01535485]. \t  -1.679417600235154 \t 0.2650082867644827\n",
            "80     \t [-0.75819162 -0.01538067]. \t  -1.679494051426791 \t 0.2650082867644827\n",
            "81     \t [-0.75821147 -0.01540685]. \t  -1.679568665567003 \t 0.2650082867644827\n",
            "82     \t [-0.75823023 -0.01543191]. \t  -1.679639365137869 \t 0.2650082867644827\n",
            "83     \t [-0.75824857 -0.01545538]. \t  -1.6797078374045082 \t 0.2650082867644827\n",
            "84     \t [-0.75826579 -0.01547839]. \t  -1.6797727195231411 \t 0.2650082867644827\n",
            "85     \t [-0.75828238 -0.01550064]. \t  -1.679835311444231 \t 0.2650082867644827\n",
            "86     \t [-0.75829807 -0.01552203]. \t  -1.67989470301053 \t 0.2650082867644827\n",
            "87     \t [-0.75831458 -0.0155434 ]. \t  -1.6799564609290627 \t 0.2650082867644827\n",
            "88     \t [-0.758329   -0.01556353]. \t  -1.6800113453189105 \t 0.2650082867644827\n",
            "89     \t [-0.75834357 -0.0155831 ]. \t  -1.6800663090549788 \t 0.2650082867644827\n",
            "90     \t [-0.75835706 -0.01560184]. \t  -1.680117583943166 \t 0.2650082867644827\n",
            "91     \t [-0.75837072 -0.01562066]. \t  -1.6801693803638549 \t 0.2650082867644827\n",
            "92     \t [-0.75838363 -0.01563836]. \t  -1.68021830102395 \t 0.2650082867644827\n",
            "93     \t [-0.75839598 -0.01565579]. \t  -1.6802654124006189 \t 0.2650082867644827\n",
            "94     \t [-0.75840778 -0.01567252]. \t  -1.6803104618475215 \t 0.2650082867644827\n",
            "95     \t [-0.75841978 -0.01568946]. \t  -1.6803562390593376 \t 0.2650082867644827\n",
            "96     \t [-0.75843038 -0.01570451]. \t  -1.6803967313542016 \t 0.2650082867644827\n",
            "97     \t [-0.75844104 -0.01572   ]. \t  -1.6804376398489687 \t 0.2650082867644827\n",
            "98     \t [-0.75845134 -0.0157351 ]. \t  -1.6804772980891716 \t 0.2650082867644827\n",
            "99     \t [-0.75846156 -0.01574968]. \t  -1.6805163466358632 \t 0.2650082867644827\n",
            "100    \t [-0.75847111 -0.01576379]. \t  -1.6805531604744224 \t 0.2650082867644827\n"
          ]
        }
      ],
      "source": [
        "### Bayesian optimisation runs (x20): 'GP' Acquisition Function run number = 1\n",
        "\n",
        "np.random.seed(run_num_1)\n",
        "surrogate_gp_1 = GaussianProcess(cov_func, optimize=hyperOpt)\n",
        "\n",
        "gp_1 = GPGO(surrogate_gp_1, Acquisition_new(util_gp), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\n",
        "gp_1.run(max_iter = max_iter, init_evals = n_init) # run\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6CLxOiUrJLks",
        "outputId": "0933d70a-152b-4829-b471-148418ad76ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [-0.38403059 -1.89629507]. \t  -38.61280125654363 \t -0.011939608840498828\n",
            "init   \t [ 0.29797487 -0.25871043]. \t  -0.011939608840498828 \t -0.011939608840498828\n",
            "init   \t [-0.47779319 -0.67866072]. \t  -0.1381453419305213 \t -0.011939608840498828\n",
            "init   \t [-1.7721082   0.47708387]. \t  -0.626144759281101 \t -0.011939608840498828\n",
            "init   \t [-1.20207196 -0.9326909 ]. \t  -3.0693811601417798 \t -0.011939608840498828\n",
            "1      \t [-0.42476117 -0.03918374]. \t  -0.6657981553034664 \t -0.011939608840498828\n",
            "2      \t [ 1.68995655 -0.11116565]. \t  -1.8233740408450951 \t -0.011939608840498828\n",
            "3      \t [3. 2.]. \t  -162.89999999999998 \t -0.011939608840498828\n",
            "4      \t [ 3. -2.]. \t  -150.89999999999998 \t -0.011939608840498828\n",
            "5      \t [0.11639073 2.        ]. \t  -48.28658410960645 \t -0.011939608840498828\n",
            "6      \t [-3.  2.]. \t  -150.89999999999998 \t -0.011939608840498828\n",
            "7      \t [-3. -2.]. \t  -162.89999999999998 \t -0.011939608840498828\n",
            "8      \t [-2.56067474 -0.00756781]. \t  -29.93139567282478 \t -0.011939608840498828\n",
            "9      \t [-0.86119029 -0.03766943]. \t  -1.9742571256716972 \t -0.011939608840498828\n",
            "10     \t [-0.8449651  -0.05185601]. \t  -1.939797770075933 \t -0.011939608840498828\n",
            "11     \t [-0.83389114 -0.06078263]. \t  -1.9140963007174616 \t -0.011939608840498828\n",
            "12     \t [-0.82591679 -0.0669136 ]. \t  -1.8946350588335485 \t -0.011939608840498828\n",
            "13     \t [-0.81998636 -0.07134915]. \t  -1.879689613978549 \t -0.011939608840498828\n",
            "14     \t [ 0.75679062 -0.18909819]. \t  -1.3836792256633088 \t -0.011939608840498828\n",
            "15     \t [-0.82031244 -0.07396729]. \t  -1.8812252525234552 \t -0.011939608840498828\n",
            "16     \t [-0.81664135 -0.0765843 ]. \t  -1.871706351491922 \t -0.011939608840498828\n",
            "17     \t [ 0.76093571 -0.19098054]. \t  -1.3908425873429509 \t -0.011939608840498828\n",
            "18     \t [-0.81651906 -0.07821721]. \t  -1.871702952179778 \t -0.011939608840498828\n",
            "19     \t [ 0.76063316 -0.19187204]. \t  -1.388080528236481 \t -0.011939608840498828\n",
            "20     \t [-0.81579984 -0.07963571]. \t  -1.869986987634546 \t -0.011939608840498828\n",
            "21     \t [ 0.76123726 -0.19247942]. \t  -1.3883873544461671 \t -0.011939608840498828\n",
            "22     \t [-0.81493291 -0.08084534]. \t  -1.867804953904555 \t -0.011939608840498828\n",
            "23     \t [ 0.76219809 -0.19291758]. \t  -1.390023930656266 \t -0.011939608840498828\n",
            "24     \t [-0.81407285 -0.08187628]. \t  -1.8655955204268166 \t -0.011939608840498828\n",
            "25     \t [ 0.76327627 -0.19324676]. \t  -1.392210930290546 \t -0.011939608840498828\n",
            "26     \t [-0.81327324 -0.08275524]. \t  -1.8635168928933148 \t -0.011939608840498828\n",
            "27     \t [ 0.76436319 -0.19350133]. \t  -1.394580135392536 \t -0.011939608840498828\n",
            "28     \t [ 0.76315453 -0.19364433]. \t  -1.391010084845056 \t -0.011939608840498828\n",
            "29     \t [-0.81298483 -0.08343804]. \t  -1.8628218196851023 \t -0.011939608840498828\n",
            "30     \t [ 0.76447028 -0.19381575]. \t  -1.3941774361386752 \t -0.011939608840498828\n",
            "31     \t [ 0.7636283  -0.19391173]. \t  -1.391699317456302 \t -0.011939608840498828\n",
            "32     \t [-0.81253371 -0.08406015]. \t  -1.8616599959962625 \t -0.011939608840498828\n",
            "33     \t [ 0.76497578 -0.19403465]. \t  -1.3950559626002588 \t -0.011939608840498828\n",
            "34     \t [ 0.76434662 -0.19410432]. \t  -1.3932099881134974 \t -0.011939608840498828\n",
            "35     \t [ 0.76381092 -0.19416175]. \t  -1.3916413906076002 \t -0.011939608840498828\n",
            "36     \t [-0.81223288 -0.0845845 ]. \t  -1.8608987243097568 \t -0.011939608840498828\n",
            "37     \t [ 0.76520131 -0.19424528]. \t  -1.3951987727287922 \t -0.011939608840498828\n",
            "38     \t [ 0.76476712 -0.19429118]. \t  -1.3939301122210512 \t -0.011939608840498828\n",
            "39     \t [ 0.76438942 -0.19433076]. \t  -1.392826801630628 \t -0.011939608840498828\n",
            "40     \t [ 0.76405614 -0.19436586]. \t  -1.391852482986295 \t -0.011939608840498828\n",
            "41     \t [ 0.76376397 -0.19439607]. \t  -1.3909992774030455 \t -0.011939608840498828\n",
            "42     \t [-0.81205071 -0.0850284 ]. \t  -1.8604543483428027 \t -0.011939608840498828\n",
            "43     \t [ 0.76518743 -0.19444721]. \t  -1.3947167229918436 \t -0.011939608840498828\n",
            "44     \t [ 0.76492396 -0.19447331]. \t  -1.3939508211093763 \t -0.011939608840498828\n",
            "45     \t [ 0.76468938 -0.19449687]. \t  -1.3932680179998975 \t -0.011939608840498828\n",
            "46     \t [ 0.76447727 -0.19451818]. \t  -1.3926504522532868 \t -0.011939608840498828\n",
            "47     \t [ 0.76428796 -0.19453763]. \t  -1.3920982029144633 \t -0.011939608840498828\n",
            "48     \t [ 0.76410936 -0.1945536 ]. \t  -1.3915823170236958 \t -0.011939608840498828\n",
            "49     \t [-0.81175096 -0.08544396]. \t  -1.8596760711621543 \t -0.011939608840498828\n",
            "50     \t [ 0.76548771 -0.1945863 ]. \t  -1.3952172639760467 \t -0.011939608840498828\n",
            "51     \t [ 0.7653226  -0.19460236]. \t  -1.3947381441540598 \t -0.011939608840498828\n",
            "52     \t [ 0.76516357 -0.19461761]. \t  -1.3942770713313282 \t -0.011939608840498828\n",
            "53     \t [ 0.7650219  -0.19463097]. \t  -1.3938667630417574 \t -0.011939608840498828\n",
            "54     \t [ 0.76489081 -0.19464334]. \t  -1.393486992902393 \t -0.011939608840498828\n",
            "55     \t [ 0.76476941 -0.19465465]. \t  -1.393135593036856 \t -0.011939608840498828\n",
            "56     \t [ 0.76465895 -0.19466265]. \t  -1.3928208633250707 \t -0.011939608840498828\n",
            "57     \t [ 0.76455223 -0.19467504]. \t  -1.3925064719984652 \t -0.011939608840498828\n",
            "58     \t [ 0.7644545  -0.19468393]. \t  -1.3922239692899498 \t -0.011939608840498828\n",
            "59     \t [ 0.76436319 -0.19469253]. \t  -1.3919593205202694 \t -0.011939608840498828\n",
            "60     \t [ 0.76427805 -0.19470034]. \t  -1.3917130268311593 \t -0.011939608840498828\n",
            "61     \t [ 0.76419715 -0.19470747]. \t  -1.391479613567923 \t -0.011939608840498828\n",
            "62     \t [-0.81156656 -0.08579736]. \t  -1.8592095781565425 \t -0.011939608840498828\n",
            "63     \t [ 0.76553508 -0.19472541]. \t  -1.3950378382781738 \t -0.011939608840498828\n",
            "64     \t [ 0.76544991 -0.19473306]. \t  -1.394792123652749 \t -0.011939608840498828\n",
            "65     \t [ 0.76536952 -0.19474012]. \t  -1.3945605239959527 \t -0.011939608840498828\n",
            "66     \t [ 0.76529446 -0.19474699]. \t  -1.3943436521434547 \t -0.011939608840498828\n",
            "67     \t [ 0.76522258 -0.19475327]. \t  -1.394136596544209 \t -0.011939608840498828\n",
            "68     \t [ 0.76515523 -0.19475919]. \t  -1.393942512952605 \t -0.011939608840498828\n",
            "69     \t [ 0.76509147 -0.19476469]. \t  -1.3937589947738238 \t -0.011939608840498828\n",
            "70     \t [ 0.76503099 -0.19477001]. \t  -1.3935846717561815 \t -0.011939608840498828\n",
            "71     \t [ 0.7649723  -0.19477584]. \t  -1.393414032268277 \t -0.011939608840498828\n",
            "72     \t [ 0.76492004 -0.19477995]. \t  -1.3932644389546012 \t -0.011939608840498828\n",
            "73     \t [ 0.76486727 -0.19478425]. \t  -1.3931130717542977 \t -0.011939608840498828\n",
            "74     \t [ 0.76481666 -0.19478853]. \t  -1.392967541749747 \t -0.011939608840498828\n",
            "75     \t [ 0.7647712  -0.19479247]. \t  -1.3928365991247653 \t -0.011939608840498828\n",
            "76     \t [ 0.76472657 -0.19479615]. \t  -1.3927084480093161 \t -0.011939608840498828\n",
            "77     \t [ 0.76468342 -0.19479994]. \t  -1.3925840639276683 \t -0.011939608840498828\n",
            "78     \t [ 0.76464258 -0.19480336]. \t  -1.3924666765116118 \t -0.011939608840498828\n",
            "79     \t [ 0.76460564 -0.19480443]. \t  -1.3923649557048599 \t -0.011939608840498828\n",
            "80     \t [ 0.76456644 -0.19480995]. \t  -1.3922473193154368 \t -0.011939608840498828\n",
            "81     \t [ 0.76453058 -0.19481274]. \t  -1.3921446986188926 \t -0.011939608840498828\n",
            "82     \t [ 0.76449657 -0.19481548]. \t  -1.3920471889240686 \t -0.011939608840498828\n",
            "83     \t [ 0.76446331 -0.19481838]. \t  -1.3919513132705075 \t -0.011939608840498828\n",
            "84     \t [ 0.76443216 -0.19482101]. \t  -1.391861712759381 \t -0.011939608840498828\n",
            "85     \t [ 0.76440154 -0.19482348]. \t  -1.391773865264795 \t -0.011939608840498828\n",
            "86     \t [ 0.76437286 -0.19482618]. \t  -1.3916907785899773 \t -0.011939608840498828\n",
            "87     \t [ 0.76434483 -0.1948281 ]. \t  -1.3916111164084999 \t -0.011939608840498828\n",
            "88     \t [ 0.76431776 -0.19483031]. \t  -1.3915334174858356 \t -0.011939608840498828\n",
            "89     \t [ 0.7642918  -0.19483239]. \t  -1.3914589692144967 \t -0.011939608840498828\n",
            "90     \t [-0.81139967 -0.08611215]. \t  -1.858785644113935 \t -0.011939608840498828\n",
            "91     \t [ 0.76556825 -0.19484094]. \t  -1.3948721454825321 \t -0.011939608840498828\n",
            "92     \t [ 0.76553549 -0.19484367]. \t  -1.3947781206447503 \t -0.011939608840498828\n",
            "93     \t [ 0.76550359 -0.19484655]. \t  -1.3946860476042973 \t -0.011939608840498828\n",
            "94     \t [ 0.76547391 -0.19484871]. \t  -1.3946015466386754 \t -0.011939608840498828\n",
            "95     \t [ 0.76544429 -0.19485119]. \t  -1.3945164792056879 \t -0.011939608840498828\n",
            "96     \t [ 0.76541589 -0.19485349]. \t  -1.394435089698337 \t -0.011939608840498828\n",
            "97     \t [ 0.76538716 -0.19485522]. \t  -1.394354073237376 \t -0.011939608840498828\n",
            "98     \t [ 0.76536303 -0.19485858]. \t  -1.3942818080376784 \t -0.011939608840498828\n",
            "99     \t [ 0.7653365  -0.19485961]. \t  -1.3942082532635587 \t -0.011939608840498828\n",
            "100    \t [ 0.76531201 -0.19486177]. \t  -1.3941376703888846 \t -0.011939608840498828\n"
          ]
        }
      ],
      "source": [
        "### Bayesian optimisation runs (x20): 'GP' Acquisition Function run number = 2\n",
        "\n",
        "np.random.seed(run_num_2)\n",
        "surrogate_gp_2 = GaussianProcess(cov_func, optimize=hyperOpt)\n",
        "\n",
        "gp_2 = GPGO(surrogate_gp_2, Acquisition_new(util_gp), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\n",
        "gp_2.run(max_iter = max_iter, init_evals = n_init) # run\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OrboSzBtJLku",
        "outputId": "a9138911-445c-4576-e329-b7633decca73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.30478742 0.83259129]. \t  0.2431922946563294 \t 0.2431922946563294\n",
            "init   \t [-1.25457157  0.04331042]. \t  -2.3313310458730996 \t 0.2431922946563294\n",
            "init   \t [2.35768173 1.58517236]. \t  -33.54152175045586 \t 0.2431922946563294\n",
            "init   \t [-2.24648814 -1.17102849]. \t  -14.214109412296352 \t 0.2431922946563294\n",
            "init   \t [-2.69119678 -0.23676063]. \t  -45.87579771712209 \t 0.2431922946563294\n",
            "1      \t [-0.21459765  0.23025045]. \t  0.0704423164450177 \t 0.2431922946563294\n",
            "2      \t [-0.49337921  1.16293966]. \t  -2.1868332576107044 \t 0.2431922946563294\n",
            "3      \t [ 0.0877683  -0.56336094]. \t  \u001b[92m0.8853498372559109\u001b[0m \t 0.8853498372559109\n",
            "4      \t [ 0.0663957  -0.50620029]. \t  0.7783385251483066 \t 0.8853498372559109\n",
            "5      \t [ 0.0534111  -0.47037006]. \t  0.7029183637888664 \t 0.8853498372559109\n",
            "6      \t [ 0.04493833 -0.44700015]. \t  0.6515599619289595 \t 0.8853498372559109\n",
            "7      \t [ 0.03953826 -0.43247473]. \t  0.6190614457905591 \t 0.8853498372559109\n",
            "8      \t [ 0.39391875 -1.22319786]. \t  -3.0592896346672473 \t 0.8853498372559109\n",
            "9      \t [-0.10776444 -0.06132888]. \t  -0.037790739340178195 \t 0.8853498372559109\n",
            "10     \t [-0.09733158 -0.08861943]. \t  -0.01516412407932367 \t 0.8853498372559109\n",
            "11     \t [ 3. -2.]. \t  -150.89999999999998 \t 0.8853498372559109\n",
            "12     \t [-0.09195167 -0.11344586]. \t  0.006715265464509984 \t 0.8853498372559109\n",
            "13     \t [-0.08851386 -0.12981847]. \t  0.023574463126958427 \t 0.8853498372559109\n",
            "14     \t [-0.08570931 -0.14234399]. \t  0.03793372414944546 \t 0.8853498372559109\n",
            "15     \t [-0.08335635 -0.15198439]. \t  0.04990200057973489 \t 0.8853498372559109\n",
            "16     \t [-0.08134969 -0.15947057]. \t  0.05978444194435253 \t 0.8853498372559109\n",
            "17     \t [-0.07962057 -0.16534131]. \t  0.06792358272416814 \t 0.8853498372559109\n",
            "18     \t [-0.07812208 -0.16999667]. \t  0.07464030057491489 \t 0.8853498372559109\n",
            "19     \t [-0.07681849 -0.17373045]. \t  0.08020822059433247 \t 0.8853498372559109\n",
            "20     \t [-0.07567962 -0.17675504]. \t  0.08484749421387369 \t 0.8853498372559109\n",
            "21     \t [-0.07468279 -0.17923279]. \t  0.08873925245022102 \t 0.8853498372559109\n",
            "22     \t [-0.07380723 -0.18128177]. \t  0.09202472840802987 \t 0.8853498372559109\n",
            "23     \t [-0.07303542 -0.18298944]. \t  0.09481382614287938 \t 0.8853498372559109\n",
            "24     \t [-0.07235381 -0.18442582]. \t  0.09719732309055137 \t 0.8853498372559109\n",
            "25     \t [-0.07175067 -0.18564697]. \t  0.09925058875412718 \t 0.8853498372559109\n",
            "26     \t [-0.07121446 -0.18668879]. \t  0.10102500825368632 \t 0.8853498372559109\n",
            "27     \t [-0.07073684 -0.1875848 ]. \t  0.10256800783281293 \t 0.8853498372559109\n",
            "28     \t [-0.07030995 -0.18836096]. \t  0.10391779057780202 \t 0.8853498372559109\n",
            "29     \t [-0.06992777 -0.18903757]. \t  0.10510442124704825 \t 0.8853498372559109\n",
            "30     \t [-0.06958444 -0.18962977]. \t  0.10615140890898639 \t 0.8853498372559109\n",
            "31     \t [-0.06927487 -0.19014934]. \t  0.10707756887441036 \t 0.8853498372559109\n",
            "32     \t [-0.06899556 -0.19060962]. \t  0.10790283661926109 \t 0.8853498372559109\n",
            "33     \t [-0.06874293 -0.19101917]. \t  0.1086409830573453 \t 0.8853498372559109\n",
            "34     \t [-0.06851296 -0.19138221]. \t  0.10930037664095271 \t 0.8853498372559109\n",
            "35     \t [-0.06830473 -0.19170842]. \t  0.10989454307281125 \t 0.8853498372559109\n",
            "36     \t [-0.0681145  -0.19200128]. \t  0.11043075375241537 \t 0.8853498372559109\n",
            "37     \t [-0.06794068 -0.19226497]. \t  0.11091574719703653 \t 0.8853498372559109\n",
            "38     \t [-0.06778187 -0.19250421]. \t  0.11135681518476837 \t 0.8853498372559109\n",
            "39     \t [-0.06763586 -0.19272025]. \t  0.11175720442494279 \t 0.8853498372559109\n",
            "40     \t [-0.06750188 -0.19291648]. \t  0.11212204688071543 \t 0.8853498372559109\n",
            "41     \t [-0.06737846 -0.19309618]. \t  0.11245682485943638 \t 0.8853498372559109\n",
            "42     \t [-0.06726452 -0.19325956]. \t  0.11276254347904968 \t 0.8853498372559109\n",
            "43     \t [-0.06715931 -0.19341012]. \t  0.11304452890426757 \t 0.8853498372559109\n",
            "44     \t [-0.06706167 -0.19354643]. \t  0.11330163028169261 \t 0.8853498372559109\n",
            "45     \t [-0.06697194 -0.1936744 ]. \t  0.1135416561111329 \t 0.8853498372559109\n",
            "46     \t [-0.06688773 -0.19379077]. \t  0.11376188318609057 \t 0.8853498372559109\n",
            "47     \t [-0.06680974 -0.1938976 ]. \t  0.11396458552012856 \t 0.8853498372559109\n",
            "48     \t [-0.06673711 -0.19399742]. \t  0.1141538532112637 \t 0.8853498372559109\n",
            "49     \t [-0.06667061 -0.19409223]. \t  0.11433185213784652 \t 0.8853498372559109\n",
            "50     \t [-0.06660671 -0.19417661]. \t  0.11449370759284783 \t 0.8853498372559109\n",
            "51     \t [-0.06654742 -0.19425742]. \t  0.11464736279932874 \t 0.8853498372559109\n",
            "52     \t [-0.06649172 -0.19432941]. \t  0.11478635028961273 \t 0.8853498372559109\n",
            "53     \t [-0.06644048 -0.19440122]. \t  0.11492187002415775 \t 0.8853498372559109\n",
            "54     \t [-0.06639144 -0.19446367]. \t  0.11504299868535312 \t 0.8853498372559109\n",
            "55     \t [-0.06634594 -0.19452544]. \t  0.11516062671556415 \t 0.8853498372559109\n",
            "56     \t [-0.06630311 -0.19458264]. \t  0.11527008316826455 \t 0.8853498372559109\n",
            "57     \t [-0.0662631  -0.19463704]. \t  0.1153736553722629 \t 0.8853498372559109\n",
            "58     \t [-0.06622461 -0.19468591]. \t  0.11546854965846393 \t 0.8853498372559109\n",
            "59     \t [-0.06618862 -0.19473203]. \t  0.11555787834291563 \t 0.8853498372559109\n",
            "60     \t [-0.06615447 -0.19477544]. \t  0.11564215687424455 \t 0.8853498372559109\n",
            "61     \t [-0.06612263 -0.19481765]. \t  0.11572311201089754 \t 0.8853498372559109\n",
            "62     \t [-0.06609312 -0.19485773]. \t  0.11579949365186096 \t 0.8853498372559109\n",
            "63     \t [-0.06606428 -0.19489587]. \t  0.11587270624218761 \t 0.8853498372559109\n",
            "64     \t [-0.06603682 -0.19492943]. \t  0.11593863730956352 \t 0.8853498372559109\n",
            "65     \t [-0.06601098 -0.19496312]. \t  0.11600358867603917 \t 0.8853498372559109\n",
            "66     \t [-0.06598556 -0.19499141]. \t  0.11606080869402989 \t 0.8853498372559109\n",
            "67     \t [-0.06596294 -0.19502271]. \t  0.11612015809167156 \t 0.8853498372559109\n",
            "68     \t [-0.06594121 -0.19505024]. \t  0.11617367599623224 \t 0.8853498372559109\n",
            "69     \t [-0.06592012 -0.1950779 ]. \t  0.11622691767699718 \t 0.8853498372559109\n",
            "70     \t [-0.06589991 -0.19510267]. \t  0.11627554397577375 \t 0.8853498372559109\n",
            "71     \t [-0.06588105 -0.19512696]. \t  0.11632255816356586 \t 0.8853498372559109\n",
            "72     \t [-0.065863   -0.19515006]. \t  0.11636733269351777 \t 0.8853498372559109\n",
            "73     \t [-0.06584545 -0.19517101]. \t  0.1164088035610987 \t 0.8853498372559109\n",
            "74     \t [-0.06582919 -0.19519236]. \t  0.11644990398650003 \t 0.8853498372559109\n",
            "75     \t [-0.06581321 -0.19521159]. \t  0.11648786854832022 \t 0.8853498372559109\n",
            "76     \t [-0.06579799 -0.1952312 ]. \t  0.11652581712069118 \t 0.8853498372559109\n",
            "77     \t [-0.06578397 -0.19524877]. \t  0.11656009875056511 \t 0.8853498372559109\n",
            "78     \t [-0.06577006 -0.19526565]. \t  0.11659334013271097 \t 0.8853498372559109\n",
            "79     \t [-0.06575676 -0.19528137]. \t  0.11662455149901461 \t 0.8853498372559109\n",
            "80     \t [-0.06574444 -0.19529806]. \t  0.11665640103855043 \t 0.8853498372559109\n",
            "81     \t [-0.06573195 -0.19531163]. \t  0.11668407084381338 \t 0.8853498372559109\n",
            "82     \t [-0.06572039 -0.19532619]. \t  0.11671244096601022 \t 0.8853498372559109\n",
            "83     \t [-0.0657097  -0.19534066]. \t  0.11674006592525273 \t 0.8853498372559109\n",
            "84     \t [-0.06569917 -0.19535463]. \t  0.11676687975266511 \t 0.8853498372559109\n",
            "85     \t [-0.06568858 -0.19536574]. \t  0.11678979865414121 \t 0.8853498372559109\n",
            "86     \t [-0.06567837 -0.19537702]. \t  0.11681267113372987 \t 0.8853498372559109\n",
            "87     \t [-0.06566949 -0.19538974]. \t  0.11683658175330983 \t 0.8853498372559109\n",
            "88     \t [-0.06566021 -0.19540033]. \t  0.11685783696238625 \t 0.8853498372559109\n",
            "89     \t [-0.06565127 -0.19541135]. \t  0.11687944296316201 \t 0.8853498372559109\n",
            "90     \t [-0.06564317 -0.19542176]. \t  0.11689961736354441 \t 0.8853498372559109\n",
            "91     \t [-0.06563514 -0.19543173]. \t  0.11691912733240058 \t 0.8853498372559109\n",
            "92     \t [-0.065627   -0.19543983]. \t  0.11693613736466689 \t 0.8853498372559109\n",
            "93     \t [-0.06562002 -0.19545101]. \t  0.11695655567475345 \t 0.8853498372559109\n",
            "94     \t [-0.06561274 -0.19545937]. \t  0.11697331007877623 \t 0.8853498372559109\n",
            "95     \t [-0.06560541 -0.19546684]. \t  0.11698887009746858 \t 0.8853498372559109\n",
            "96     \t [-0.06559853 -0.19547425]. \t  0.11700402861409807 \t 0.8853498372559109\n",
            "97     \t [-0.06559321 -0.19548604]. \t  0.1170240970399912 \t 0.8853498372559109\n",
            "98     \t [-0.06558701 -0.19549382]. \t  0.1170392795720211 \t 0.8853498372559109\n",
            "99     \t [-0.06558016 -0.19549823]. \t  0.11705027543043092 \t 0.8853498372559109\n",
            "100    \t [-0.06557454 -0.19550658]. \t  0.11706582499659057 \t 0.8853498372559109\n"
          ]
        }
      ],
      "source": [
        "### Bayesian optimisation runs (x20): 'GP' Acquisition Function run number = 3\n",
        "\n",
        "np.random.seed(run_num_3)\n",
        "surrogate_gp_3 = GaussianProcess(cov_func, optimize=hyperOpt)\n",
        "\n",
        "gp_3 = GPGO(surrogate_gp_3, Acquisition_new(util_gp), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\n",
        "gp_3.run(max_iter = max_iter, init_evals = n_init) # run\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmlwMmKcJLkv",
        "outputId": "ddfd307f-e952-4ad0-9fee-7ed38c32f865"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [2.80217903 0.188929  ]. \t  -63.70212732873661 \t -2.3196402150601703\n",
            "init   \t [2.83610616 0.85926397]. \t  -71.43837110827245 \t -2.3196402150601703\n",
            "init   \t [ 1.18637295 -1.13564202]. \t  -2.5463267765341566 \t -2.3196402150601703\n",
            "init   \t [ 2.85764673 -1.97507898]. \t  -113.76785286351424 \t -2.3196402150601703\n",
            "init   \t [-1.48210583 -0.26083387]. \t  -2.3196402150601703 \t -2.3196402150601703\n",
            "1      \t [ 0.12626012 -1.09757571]. \t  \u001b[92m-0.9109071443411083\u001b[0m \t -0.9109071443411083\n",
            "2      \t [ 0.15931999 -1.06485198]. \t  \u001b[92m-0.5378979538717611\u001b[0m \t -0.5378979538717611\n",
            "3      \t [-3.  2.]. \t  -150.89999999999998 \t -0.5378979538717611\n",
            "4      \t [-3. -2.]. \t  -162.89999999999998 \t -0.5378979538717611\n",
            "5      \t [-0.28282789 -0.08067361]. \t  \u001b[92m-0.30365314188521697\u001b[0m \t -0.30365314188521697\n",
            "6      \t [ 0.09013544 -0.66305218]. \t  \u001b[92m1.0128311517758304\u001b[0m \t 1.0128311517758304\n",
            "7      \t [ 0.08391973 -0.64651905]. \t  0.999285050327336 \t 1.0128311517758304\n",
            "8      \t [ 0.07992207 -0.63605891]. \t  0.9889437665812275 \t 1.0128311517758304\n",
            "9      \t [ 0.07712231 -0.62884058]. \t  0.9810496800319537 \t 1.0128311517758304\n",
            "10     \t [ 0.07504796 -0.62356302]. \t  0.9749005701622784 \t 1.0128311517758304\n",
            "11     \t [ 0.073449   -0.61954254]. \t  0.970007699474239 \t 1.0128311517758304\n",
            "12     \t [ 0.07217963 -0.61638391]. \t  0.9660396553850382 \t 1.0128311517758304\n",
            "13     \t [ 0.07114859 -0.6138422 ]. \t  0.962768548494321 \t 1.0128311517758304\n",
            "14     \t [ 0.0702961  -0.61175764]. \t  0.9600343947158526 \t 1.0128311517758304\n",
            "15     \t [ 0.06958057 -0.61002071]. \t  0.9577211675106282 \t 1.0128311517758304\n",
            "16     \t [ 0.06897243 -0.60855414]. \t  0.9557433711390297 \t 1.0128311517758304\n",
            "17     \t [ 0.06845013 -0.60730194]. \t  0.9540369473424579 \t 1.0128311517758304\n",
            "18     \t [ 0.06799746 -0.60622247]. \t  0.952552850891352 \t 1.0128311517758304\n",
            "19     \t [ 0.06760195 -0.60528362]. \t  0.9512523194531626 \t 1.0128311517758304\n",
            "20     \t [ 0.0672538  -0.60446101]. \t  0.9501053422216236 \t 1.0128311517758304\n",
            "21     \t [ 0.0669457  -0.60373579]. \t  0.9490883979747791 \t 1.0128311517758304\n",
            "22     \t [ 0.0666713  -0.60309224]. \t  0.9481814709914297 \t 1.0128311517758304\n",
            "23     \t [ 0.06642567 -0.60251812]. \t  0.9473688285599173 \t 1.0128311517758304\n",
            "24     \t [ 0.06620482 -0.6020035 ]. \t  0.9466375328113059 \t 1.0128311517758304\n",
            "25     \t [ 0.06600535 -0.60154004]. \t  0.9459766381366428 \t 1.0128311517758304\n",
            "26     \t [ 0.06582451 -0.60112105]. \t  0.9453772739355035 \t 1.0128311517758304\n",
            "27     \t [ 0.0656601  -0.60074087]. \t  0.944831897500059 \t 1.0128311517758304\n",
            "28     \t [ 0.06550989 -0.60039453]. \t  0.9443337783372796 \t 1.0128311517758304\n",
            "29     \t [ 0.06537248 -0.60007824]. \t  0.94387781644143 \t 1.0128311517758304\n",
            "30     \t [ 0.0652462  -0.59978822]. \t  0.9434588247596944 \t 1.0128311517758304\n",
            "31     \t [ 0.06513    -0.59952186]. \t  0.9430732683465618 \t 1.0128311517758304\n",
            "32     \t [ 0.06502275 -0.59927637]. \t  0.9427172981544504 \t 1.0128311517758304\n",
            "33     \t [ 0.06492351 -0.5990496 ]. \t  0.9423879153750924 \t 1.0128311517758304\n",
            "34     \t [ 0.06483147 -0.59883971]. \t  0.9420825873861988 \t 1.0128311517758304\n",
            "35     \t [ 0.064746   -0.59864503]. \t  0.941798999917883 \t 1.0128311517758304\n",
            "36     \t [ 0.06466642 -0.59846399]. \t  0.9415349278075079 \t 1.0128311517758304\n",
            "37     \t [ 0.0645922  -0.59829542]. \t  0.9412887554297626 \t 1.0128311517758304\n",
            "38     \t [ 0.0645228  -0.59813804]. \t  0.9410586540948018 \t 1.0128311517758304\n",
            "39     \t [ 0.06445789 -0.59799091]. \t  0.9408433059381639 \t 1.0128311517758304\n",
            "40     \t [ 0.06439705 -0.5978532 ]. \t  0.9406415684624981 \t 1.0128311517758304\n",
            "41     \t [ 0.06433997 -0.59772419]. \t  0.9404523784101112 \t 1.0128311517758304\n",
            "42     \t [ 0.06428618 -0.59760274]. \t  0.9402741339951882 \t 1.0128311517758304\n",
            "43     \t [ 0.06423565 -0.59748869]. \t  0.9401066173268072 \t 1.0128311517758304\n",
            "44     \t [ 0.06418795 -0.59738117]. \t  0.9399485610499316 \t 1.0128311517758304\n",
            "45     \t [ 0.06414294 -0.59727981]. \t  0.9397994627129013 \t 1.0128311517758304\n",
            "46     \t [ 0.06410042 -0.59718412]. \t  0.9396586130759161 \t 1.0128311517758304\n",
            "47     \t [ 0.06406019 -0.59709377]. \t  0.9395255216684509 \t 1.0128311517758304\n",
            "48     \t [ 0.06402209 -0.59700815]. \t  0.9393993325621717 \t 1.0128311517758304\n",
            "49     \t [ 0.063986   -0.59692707]. \t  0.939279770873052 \t 1.0128311517758304\n",
            "50     \t [ 0.06395172 -0.59685021]. \t  0.939166360379553 \t 1.0128311517758304\n",
            "51     \t [ 0.06391909 -0.5967771 ]. \t  0.9390584206406932 \t 1.0128311517758304\n",
            "52     \t [ 0.0638882  -0.59670782]. \t  0.9389561122014303 \t 1.0128311517758304\n",
            "53     \t [ 0.06385871 -0.59664182]. \t  0.938858578433223 \t 1.0128311517758304\n",
            "54     \t [ 0.06383065 -0.59657906]. \t  0.9387657924092319 \t 1.0128311517758304\n",
            "55     \t [ 0.06380384 -0.59651908]. \t  0.9386770961683869 \t 1.0128311517758304\n",
            "56     \t [ 0.0637783  -0.59646209]. \t  0.9385927762276571 \t 1.0128311517758304\n",
            "57     \t [ 0.06375391 -0.59640758]. \t  0.9385120864548432 \t 1.0128311517758304\n",
            "58     \t [ 0.06373058 -0.59635553]. \t  0.9384350179949769 \t 1.0128311517758304\n",
            "59     \t [ 0.06370832 -0.5963058 ]. \t  0.9383613685964483 \t 1.0128311517758304\n",
            "60     \t [ 0.06368695 -0.59625825]. \t  0.9382909138701866 \t 1.0128311517758304\n",
            "61     \t [ 0.06366656 -0.59621276]. \t  0.9382234855390951 \t 1.0128311517758304\n",
            "62     \t [ 0.06364692 -0.59616902]. \t  0.938158640119301 \t 1.0128311517758304\n",
            "63     \t [ 0.06362816 -0.59612725]. \t  0.9380967000179099 \t 1.0128311517758304\n",
            "64     \t [ 0.06361006 -0.59608707]. \t  0.9380370949526071 \t 1.0128311517758304\n",
            "65     \t [ 0.0635928  -0.59604861]. \t  0.9379800183435009 \t 1.0128311517758304\n",
            "66     \t [ 0.06357614 -0.59601164]. \t  0.9379251430932497 \t 1.0128311517758304\n",
            "67     \t [ 0.06356023 -0.59597617]. \t  0.9378724925779109 \t 1.0128311517758304\n",
            "68     \t [ 0.06354487 -0.59594199]. \t  0.9378217422407169 \t 1.0128311517758304\n",
            "69     \t [ 0.06353004 -0.59590912]. \t  0.9377729187163378 \t 1.0128311517758304\n",
            "70     \t [ 0.06351581 -0.59587758]. \t  0.9377260540024036 \t 1.0128311517758304\n",
            "71     \t [ 0.063502   -0.59584697]. \t  0.9376805655855861 \t 1.0128311517758304\n",
            "72     \t [ 0.06348887 -0.59581779]. \t  0.9376372080996825 \t 1.0128311517758304\n",
            "73     \t [ 0.06347608 -0.59578945]. \t  0.9375950728841473 \t 1.0128311517758304\n",
            "74     \t [ 0.06346381 -0.59576224]. \t  0.9375546164087722 \t 1.0128311517758304\n",
            "75     \t [ 0.06345195 -0.59573586]. \t  0.9375153839641064 \t 1.0128311517758304\n",
            "76     \t [ 0.06344043 -0.59571048]. \t  0.9374776363465158 \t 1.0128311517758304\n",
            "77     \t [ 0.06342939 -0.59568592]. \t  0.9374411119746645 \t 1.0128311517758304\n",
            "78     \t [ 0.06341866 -0.59566217]. \t  0.9374057742655005 \t 1.0128311517758304\n",
            "79     \t [ 0.06340838 -0.59563944]. \t  0.9373719398313555 \t 1.0128311517758304\n",
            "80     \t [ 0.06339828 -0.59561717]. \t  0.9373387950660077 \t 1.0128311517758304\n",
            "81     \t [ 0.06338862 -0.59559582]. \t  0.9373070049969735 \t 1.0128311517758304\n",
            "82     \t [ 0.06337928 -0.59557505]. \t  0.9372760996675611 \t 1.0128311517758304\n",
            "83     \t [ 0.06337027 -0.59555508]. \t  0.9372463634332387 \t 1.0128311517758304\n",
            "84     \t [ 0.06336144 -0.59553564]. \t  0.9372174119812484 \t 1.0128311517758304\n",
            "85     \t [ 0.06335288 -0.59551674]. \t  0.9371892507041065 \t 1.0128311517758304\n",
            "86     \t [ 0.06334461 -0.59549851]. \t  0.9371621021400729 \t 1.0128311517758304\n",
            "87     \t [ 0.06333665 -0.59548083]. \t  0.9371357730971479 \t 1.0128311517758304\n",
            "88     \t [ 0.06332883 -0.59546367]. \t  0.9371101890797788 \t 1.0128311517758304\n",
            "89     \t [ 0.06332131 -0.59544701]. \t  0.9370853731069899 \t 1.0128311517758304\n",
            "90     \t [ 0.06331397 -0.59543084]. \t  0.9370612759069088 \t 1.0128311517758304\n",
            "91     \t [ 0.0633069  -0.59541521]. \t  0.9370379820907625 \t 1.0128311517758304\n",
            "92     \t [ 0.0633     -0.59540001]. \t  0.9370153258244223 \t 1.0128311517758304\n",
            "93     \t [ 0.06329326 -0.59538518]. \t  0.9369932154182408 \t 1.0128311517758304\n",
            "94     \t [ 0.06328678 -0.59537086]. \t  0.9369718538475419 \t 1.0128311517758304\n",
            "95     \t [ 0.06328043 -0.59535685]. \t  0.9369509691818019 \t 1.0128311517758304\n",
            "96     \t [ 0.06327426 -0.59534327]. \t  0.936930716213322 \t 1.0128311517758304\n",
            "97     \t [ 0.06326825 -0.59533004]. \t  0.9369109959236409 \t 1.0128311517758304\n",
            "98     \t [ 0.06326242 -0.59531715]. \t  0.9368917688155556 \t 1.0128311517758304\n",
            "99     \t [ 0.06325676 -0.59530467]. \t  0.9368731525304766 \t 1.0128311517758304\n",
            "100    \t [ 0.06325124 -0.59529255]. \t  0.9368550763724581 \t 1.0128311517758304\n"
          ]
        }
      ],
      "source": [
        "### Bayesian optimisation runs (x20): 'GP' Acquisition Function run number = 4\n",
        "\n",
        "np.random.seed(run_num_4)\n",
        "surrogate_gp_4 = GaussianProcess(cov_func, optimize=hyperOpt)\n",
        "\n",
        "gp_4 = GPGO(surrogate_gp_4, Acquisition_new(util_gp), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\n",
        "gp_4.run(max_iter = max_iter, init_evals = n_init) # run\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ntlcfbyWJLkw",
        "outputId": "529a8594-4301-4814-c192-92290a763e6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [-1.66804097  1.48292922]. \t  -10.126030408244933 \t 0.6512780061070701\n",
            "init   \t [-1.75968507  1.67444363]. \t  -19.4300499315822 \t 0.6512780061070701\n",
            "init   \t [-0.06953287  0.44697545]. \t  0.6512780061070701 \t 0.6512780061070701\n",
            "init   \t [1.59544714 0.07367195]. \t  -2.168775388880503 \t 0.6512780061070701\n",
            "init   \t [-1.21919699 -1.24911509]. \t  -7.420330936884148 \t 0.6512780061070701\n",
            "1      \t [0.3857265  1.13871156]. \t  -2.5276755327379994 \t 0.6512780061070701\n",
            "2      \t [ 3. -2.]. \t  -150.89999999999998 \t 0.6512780061070701\n",
            "3      \t [3. 2.]. \t  -162.89999999999998 \t 0.6512780061070701\n",
            "4      \t [ 0.45387604 -0.13660101]. \t  -0.6025627985788967 \t 0.6512780061070701\n",
            "5      \t [-3. -2.]. \t  -162.89999999999998 \t 0.6512780061070701\n",
            "6      \t [-0.0783965  -0.41997527]. \t  0.5236490019717478 \t 0.6512780061070701\n",
            "7      \t [-0.07119764 -0.40122548]. \t  0.491478071057054 \t 0.6512780061070701\n",
            "8      \t [-0.06589228 -0.38852882]. \t  0.4697406940974722 \t 0.6512780061070701\n",
            "9      \t [-0.06172632 -0.37951377]. \t  0.4545073536733868 \t 0.6512780061070701\n",
            "10     \t [-0.05837335 -0.3728832 ]. \t  0.44346507512051253 \t 0.6512780061070701\n",
            "11     \t [-0.05563974 -0.36788052]. \t  0.4352490966987407 \t 0.6512780061070701\n",
            "12     \t [-0.05339232 -0.36402862]. \t  0.42900226177894935 \t 0.6512780061070701\n",
            "13     \t [-0.05153177 -0.36101565]. \t  0.4241720939266154 \t 0.6512780061070701\n",
            "14     \t [-0.04998234 -0.35862605]. \t  0.4203809308433951 \t 0.6512780061070701\n",
            "15     \t [-0.04868413 -0.35670993]. \t  0.4173709268756029 \t 0.6512780061070701\n",
            "16     \t [-0.04759145 -0.35515448]. \t  0.4149476265626923 \t 0.6512780061070701\n",
            "17     \t [-0.04666639 -0.35388003]. \t  0.4129776476652212 \t 0.6512780061070701\n",
            "18     \t [-0.04587856 -0.35283086]. \t  0.41137037199133336 \t 0.6512780061070701\n",
            "19     \t [-0.04520518 -0.35195797]. \t  0.4100425883890404 \t 0.6512780061070701\n",
            "20     \t [-0.04462727 -0.35122244]. \t  0.4089286640825466 \t 0.6512780061070701\n",
            "21     \t [-0.04412717 -0.35060566]. \t  0.4080036540199931 \t 0.6512780061070701\n",
            "22     \t [-0.04369437 -0.35008037]. \t  0.40721922674918815 \t 0.6512780061070701\n",
            "23     \t [-0.04331661 -0.34963525]. \t  0.40656112452254406 \t 0.6512780061070701\n",
            "24     \t [-0.04298788 -0.34924756]. \t  0.4059868695580967 \t 0.6512780061070701\n",
            "25     \t [-0.04269729 -0.34891898]. \t  0.40550781840373645 \t 0.6512780061070701\n",
            "26     \t [-0.04244253 -0.34862972]. \t  0.405084844867817 \t 0.6512780061070701\n",
            "27     \t [-0.04221677 -0.34837846]. \t  0.4047200985289363 \t 0.6512780061070701\n",
            "28     \t [-0.04201598 -0.34816305]. \t  0.4044120625589079 \t 0.6512780061070701\n",
            "29     \t [-0.04183862 -0.34796803]. \t  0.4041298922828956 \t 0.6512780061070701\n",
            "30     \t [-0.0416795  -0.34779887]. \t  0.403888535907824 \t 0.6512780061070701\n",
            "31     \t [-0.04153714 -0.34764877]. \t  0.40367500705347975 \t 0.6512780061070701\n",
            "32     \t [-0.04140907 -0.34751575]. \t  0.4034869367309939 \t 0.6512780061070701\n",
            "33     \t [-0.04129354 -0.34739768]. \t  0.4033211739165251 \t 0.6512780061070701\n",
            "34     \t [-0.04118953 -0.34728974]. \t  0.40316843304217703 \t 0.6512780061070701\n",
            "35     \t [-0.04109533 -0.34719741]. \t  0.40304126247362987 \t 0.6512780061070701\n",
            "36     \t [-0.04100993 -0.34711155]. \t  0.4029214603599524 \t 0.6512780061070701\n",
            "37     \t [-0.0409318  -0.34703778]. \t  0.40282167863936397 \t 0.6512780061070701\n",
            "38     \t [-0.04086097 -0.34696651]. \t  0.4027221003499815 \t 0.6512780061070701\n",
            "39     \t [-0.04079675 -0.3469029 ]. \t  0.40263385851928296 \t 0.6512780061070701\n",
            "40     \t [-0.04073716 -0.34684708]. \t  0.4025585840354245 \t 0.6512780061070701\n",
            "41     \t [-0.04068321 -0.34679504]. \t  0.4024873067385979 \t 0.6512780061070701\n",
            "42     \t [-0.04063266 -0.34675012]. \t  0.4024284385034062 \t 0.6512780061070701\n",
            "43     \t [-0.04058762 -0.34670332]. \t  0.4023619429959754 \t 0.6512780061070701\n",
            "44     \t [-0.04054547 -0.34666474]. \t  0.4023105139623783 \t 0.6512780061070701\n",
            "45     \t [-0.04050611 -0.34662921]. \t  0.4022634817498779 \t 0.6512780061070701\n",
            "46     \t [-0.04046973 -0.34659744]. \t  0.4022222135692387 \t 0.6512780061070701\n",
            "47     \t [-0.04043583 -0.34656602]. \t  0.40217999542703853 \t 0.6512780061070701\n",
            "48     \t [-0.04040544 -0.34653837]. \t  0.40214320716082524 \t 0.6512780061070701\n",
            "49     \t [-0.04037642 -0.34651349]. \t  0.40211122361831036 \t 0.6512780061070701\n",
            "50     \t [-0.04034961 -0.34648952]. \t  0.402079627251391 \t 0.6512780061070701\n",
            "51     \t [-0.04032422 -0.34646744]. \t  0.4020509945423787 \t 0.6512780061070701\n",
            "52     \t [-0.04030193 -0.34644588]. \t  0.4020213409336736 \t 0.6512780061070701\n",
            "53     \t [-0.04027985 -0.34642605]. \t  0.40199514255626956 \t 0.6512780061070701\n",
            "54     \t [-0.04025972 -0.34640797]. \t  0.401971233046313 \t 0.6512780061070701\n",
            "55     \t [-0.04024067 -0.34639301]. \t  0.4019530464649473 \t 0.6512780061070701\n",
            "56     \t [-0.04022279 -0.34637789]. \t  0.4019337514897253 \t 0.6512780061070701\n",
            "57     \t [-0.04020612 -0.34636298]. \t  0.40191407752933445 \t 0.6512780061070701\n",
            "58     \t [-0.04019043 -0.34634918]. \t  0.40189603312806244 \t 0.6512780061070701\n",
            "59     \t [-0.04017503 -0.34633942]. \t  0.40188615892241725 \t 0.6512780061070701\n",
            "60     \t [-0.04016182 -0.34632482]. \t  0.40186479708592526 \t 0.6512780061070701\n",
            "61     \t [-0.04014898 -0.34631324]. \t  0.4018494467365317 \t 0.6512780061070701\n",
            "62     \t [-0.04013696 -0.34630182]. \t  0.40183386400029353 \t 0.6512780061070701\n",
            "63     \t [-0.04012514 -0.34629387]. \t  0.4018253253322895 \t 0.6512780061070701\n",
            "64     \t [-0.04011348 -0.34628741]. \t  0.40181976133480274 \t 0.6512780061070701\n",
            "65     \t [-0.04010367 -0.34627484]. \t  0.40180032453917924 \t 0.6512780061070701\n",
            "66     \t [-0.0400938  -0.34626868]. \t  0.40179418045368415 \t 0.6512780061070701\n",
            "67     \t [-0.0400842  -0.34626152]. \t  0.40178579008576015 \t 0.6512780061070701\n",
            "68     \t [-0.04007539 -0.34625316]. \t  0.4017743912087647 \t 0.6512780061070701\n",
            "69     \t [-0.04006731 -0.34624672]. \t  0.40176647728445997 \t 0.6512780061070701\n",
            "70     \t [-0.04005949 -0.34623859]. \t  0.4017548880251257 \t 0.6512780061070701\n",
            "71     \t [-0.0400524  -0.34623138]. \t  0.40174472053850435 \t 0.6512780061070701\n",
            "72     \t [-0.04004485 -0.34622803]. \t  0.40174282100371733 \t 0.6512780061070701\n",
            "73     \t [-0.04003847 -0.3462221 ]. \t  0.4017348300965682 \t 0.6512780061070701\n",
            "74     \t [-0.04003129 -0.34621947]. \t  0.40173417130537026 \t 0.6512780061070701\n",
            "75     \t [-0.0400259  -0.34621332]. \t  0.4017250665066173 \t 0.6512780061070701\n",
            "76     \t [-0.04001974 -0.34620956]. \t  0.40172138160629917 \t 0.6512780061070701\n",
            "77     \t [-0.04001374 -0.3462055 ]. \t  0.40171699902408103 \t 0.6512780061070701\n",
            "78     \t [-0.04000882 -0.34619981]. \t  0.40170853227972225 \t 0.6512780061070701\n",
            "79     \t [-0.04000396 -0.34619471]. \t  0.4017012320434809 \t 0.6512780061070701\n",
            "80     \t [-0.03999883 -0.34619283]. \t  0.4017007591678898 \t 0.6512780061070701\n",
            "81     \t [-0.03999451 -0.34618767]. \t  0.4016929680182369 \t 0.6512780061070701\n",
            "82     \t [-0.03998947 -0.34618735]. \t  0.40169565653064526 \t 0.6512780061070701\n",
            "83     \t [-0.0399862 -0.3461796]. \t  0.4016818386024904 \t 0.6512780061070701\n",
            "84     \t [-0.03998191 -0.34617763]. \t  0.4016806186713758 \t 0.6512780061070701\n",
            "85     \t [-0.03997753 -0.34617842]. \t  0.4016851694459631 \t 0.6512780061070701\n",
            "86     \t [-0.03997446 -0.34617121]. \t  0.40167231435139045 \t 0.6512780061070701\n",
            "87     \t [-0.03997145 -0.34616516]. \t  0.40166181104416515 \t 0.6512780061070701\n",
            "88     \t [-0.03996756 -0.34616493]. \t  0.40166392511215643 \t 0.6512780061070701\n",
            "89     \t [-0.0399638  -0.34616458]. \t  0.4016657117701693 \t 0.6512780061070701\n",
            "90     \t [-0.03996098 -0.3461616 ]. \t  0.40166142381250175 \t 0.6512780061070701\n",
            "91     \t [-0.03995806 -0.34615958]. \t  0.40165919219576945 \t 0.6512780061070701\n",
            "92     \t [-0.03995503 -0.34615701]. \t  0.4016559194809376 \t 0.6512780061070701\n",
            "93     \t [-0.03995185 -0.34615788]. \t  0.4016598150126389 \t 0.6512780061070701\n",
            "94     \t [-0.03994944 -0.34615463]. \t  0.40165471435395883 \t 0.6512780061070701\n",
            "95     \t [-0.0399471  -0.34615044]. \t  0.40164762625124756 \t 0.6512780061070701\n",
            "96     \t [-0.03994424 -0.34615099]. \t  0.4016506451667017 \t 0.6512780061070701\n",
            "97     \t [-0.03994171 -0.34614992]. \t  0.40165011893540925 \t 0.6512780061070701\n",
            "98     \t [-0.03993979 -0.34614638]. \t  0.401644101749529 \t 0.6512780061070701\n",
            "99     \t [-0.03993793 -0.34614394]. \t  0.4016402805142373 \t 0.6512780061070701\n",
            "100    \t [-0.03993566 -0.34614228]. \t  0.4016383740327665 \t 0.6512780061070701\n"
          ]
        }
      ],
      "source": [
        "### Bayesian optimisation runs (x20): 'GP' Acquisition Function run number = 5\n",
        "\n",
        "np.random.seed(run_num_5)\n",
        "surrogate_gp_5 = GaussianProcess(cov_func, optimize=hyperOpt)\n",
        "\n",
        "gp_5 = GPGO(surrogate_gp_5, Acquisition_new(util_gp), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\n",
        "gp_5.run(max_iter = max_iter, init_evals = n_init) # run\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HHrK2qnsJLkx",
        "outputId": "56cb4f94-febd-4001-842f-b49d2314a68e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 2.35716091 -0.67208078]. \t  -11.995980169715628 \t 0.3096187466378422\n",
            "init   \t [ 1.92737474 -1.8332135 ]. \t  -31.167927894156623 \t 0.3096187466378422\n",
            "init   \t [-2.35405992  0.38020826]. \t  -13.013381745677465 \t 0.3096187466378422\n",
            "init   \t [ 0.17890417 -0.32477029]. \t  0.3096187466378422 \t 0.3096187466378422\n",
            "init   \t [-0.9875529   0.49007773]. \t  -0.9989196280666852 \t 0.3096187466378422\n",
            "1      \t [0.2290865  0.98917957]. \t  -0.3465525235542021 \t 0.3096187466378422\n",
            "2      \t [3. 2.]. \t  -162.89999999999998 \t 0.3096187466378422\n",
            "3      \t [-0.09906757  0.27140284]. \t  0.26076676252374176 \t 0.3096187466378422\n",
            "4      \t [-0.09855403  0.27692565]. \t  0.27186554674050134 \t 0.3096187466378422\n",
            "5      \t [-1.22719283 -2.        ]. \t  -52.85406400442485 \t 0.3096187466378422\n",
            "6      \t [-0.05530024  0.61836295]. \t  \u001b[92m0.9666380935201604\u001b[0m \t 0.9666380935201604\n",
            "7      \t [-0.05659497  0.62178809]. \t  \u001b[92m0.9709799442195857\u001b[0m \t 0.9709799442195857\n",
            "8      \t [-0.05756287  0.62432944]. \t  \u001b[92m0.9741199034312944\u001b[0m \t 0.9741199034312944\n",
            "9      \t [-0.05832101  0.6263042 ]. \t  \u001b[92m0.9765113560974206\u001b[0m \t 0.9765113560974206\n",
            "10     \t [-0.05893541  0.62789194]. \t  \u001b[92m0.9784031660293232\u001b[0m \t 0.9784031660293232\n",
            "11     \t [-0.05944644  0.62920247]. \t  \u001b[92m0.9799437572416864\u001b[0m \t 0.9799437572416864\n",
            "12     \t [-0.05988029  0.63030681]. \t  \u001b[92m0.9812272317868034\u001b[0m \t 0.9812272317868034\n",
            "13     \t [-0.0602547   0.63125328]. \t  \u001b[92m0.9823164523396235\u001b[0m \t 0.9823164523396235\n",
            "14     \t [-0.06058226  0.63207571]. \t  \u001b[92m0.9832548499164446\u001b[0m \t 0.9832548499164446\n",
            "15     \t [-0.06087204  0.63279878]. \t  \u001b[92m0.9840736298810695\u001b[0m \t 0.9840736298810695\n",
            "16     \t [-0.06113089  0.63344086]. \t  \u001b[92m0.9847958012927271\u001b[0m \t 0.9847958012927271\n",
            "17     \t [-0.06136409  0.63401594]. \t  \u001b[92m0.9854387086523797\u001b[0m \t 0.9854387086523797\n",
            "18     \t [-0.06157561  0.63453481]. \t  \u001b[92m0.9860155942412767\u001b[0m \t 0.9860155942412767\n",
            "19     \t [-0.06176872  0.6350061 ]. \t  \u001b[92m0.986536961826117\u001b[0m \t 0.986536961826117\n",
            "20     \t [-0.061946    0.63543656]. \t  \u001b[92m0.9870109793043225\u001b[0m \t 0.9870109793043225\n",
            "21     \t [-0.06210954  0.63583184]. \t  \u001b[92m0.9874444319378198\u001b[0m \t 0.9874444319378198\n",
            "22     \t [-0.06226109  0.63619647]. \t  \u001b[92m0.9878427083949421\u001b[0m \t 0.9878427083949421\n",
            "23     \t [-0.06240211  0.63653428]. \t  \u001b[92m0.9882103654094864\u001b[0m \t 0.9882103654094864\n",
            "24     \t [-0.06253375  0.6368483 ]. \t  \u001b[92m0.9885509800894091\u001b[0m \t 0.9885509800894091\n",
            "25     \t [-0.06265708  0.63714138]. \t  \u001b[92m0.9888678665644572\u001b[0m \t 0.9888678665644572\n",
            "26     \t [-0.06277292  0.63741561]. \t  \u001b[92m0.989163503906291\u001b[0m \t 0.989163503906291\n",
            "27     \t [-0.06288208  0.63767301]. \t  \u001b[92m0.9894402280413456\u001b[0m \t 0.9894402280413456\n",
            "28     \t [-0.06298517  0.63791532]. \t  \u001b[92m0.9897000437378737\u001b[0m \t 0.9897000437378737\n",
            "29     \t [-0.06308277  0.63814385]. \t  \u001b[92m0.9899444772826542\u001b[0m \t 0.9899444772826542\n",
            "30     \t [-0.06317538  0.63835996]. \t  \u001b[92m0.9901750913138628\u001b[0m \t 0.9901750913138628\n",
            "31     \t [-0.06326342  0.63856479]. \t  \u001b[92m0.9903931808381026\u001b[0m \t 0.9903931808381026\n",
            "32     \t [-0.06334724  0.63875919]. \t  \u001b[92m0.9905997302731829\u001b[0m \t 0.9905997302731829\n",
            "33     \t [-0.06342722  0.63894414]. \t  \u001b[92m0.9907958307479126\u001b[0m \t 0.9907958307479126\n",
            "34     \t [-0.06350365  0.63912034]. \t  \u001b[92m0.9909823129657459\u001b[0m \t 0.9909823129657459\n",
            "35     \t [-0.0635768   0.63928849]. \t  \u001b[92m0.9911599328186199\u001b[0m \t 0.9911599328186199\n",
            "36     \t [-0.0636469   0.63944921]. \t  \u001b[92m0.9913294118962914\u001b[0m \t 0.9913294118962914\n",
            "37     \t [-0.06371416  0.63960299]. \t  \u001b[92m0.9914913036080599\u001b[0m \t 0.9914913036080599\n",
            "38     \t [-0.0637788   0.63975037]. \t  \u001b[92m0.991646214309595\u001b[0m \t 0.991646214309595\n",
            "39     \t [-0.06384099  0.63989181]. \t  \u001b[92m0.9917946360309506\u001b[0m \t 0.9917946360309506\n",
            "40     \t [-0.06390091  0.64002776]. \t  \u001b[92m0.9919371000611271\u001b[0m \t 0.9919371000611271\n",
            "41     \t [-0.06395867  0.64015847]. \t  \u001b[92m0.9920738649360343\u001b[0m \t 0.9920738649360343\n",
            "42     \t [-0.06401436  0.64028436]. \t  \u001b[92m0.9922054012316125\u001b[0m \t 0.9922054012316125\n",
            "43     \t [-0.06406822  0.6404056 ]. \t  \u001b[92m0.9923319248523973\u001b[0m \t 0.9923319248523973\n",
            "44     \t [-0.06412033  0.64052264]. \t  \u001b[92m0.9924539031237363\u001b[0m \t 0.9924539031237363\n",
            "45     \t [-0.06417065  0.64063557]. \t  \u001b[92m0.9925714457783398\u001b[0m \t 0.9925714457783398\n",
            "46     \t [-0.06421949  0.64074484]. \t  \u001b[92m0.9926850422954342\u001b[0m \t 0.9926850422954342\n",
            "47     \t [-0.06426676  0.64085047]. \t  \u001b[92m0.9927947278115725\u001b[0m \t 0.9927947278115725\n",
            "48     \t [-0.06431268  0.64095274]. \t  \u001b[92m0.9929008180281054\u001b[0m \t 0.9929008180281054\n",
            "49     \t [-0.06435721  0.64105182]. \t  \u001b[92m0.9930034708646178\u001b[0m \t 0.9930034708646178\n",
            "50     \t [-0.06440051  0.64114788]. \t  \u001b[92m0.9931029016366552\u001b[0m \t 0.9931029016366552\n",
            "51     \t [-0.06444255  0.64124102]. \t  \u001b[92m0.993199195207812\u001b[0m \t 0.993199195207812\n",
            "52     \t [-0.06448351  0.64133156]. \t  \u001b[92m0.9932927245408724\u001b[0m \t 0.9932927245408724\n",
            "53     \t [-0.06452328  0.6414194 ]. \t  \u001b[92m0.9933833641434359\u001b[0m \t 0.9933833641434359\n",
            "54     \t [-0.06456209  0.64150487]. \t  \u001b[92m0.9934714760748752\u001b[0m \t 0.9934714760748752\n",
            "55     \t [-0.06459989  0.64158798]. \t  \u001b[92m0.9935570847637775\u001b[0m \t 0.9935570847637775\n",
            "56     \t [-0.06463674  0.64166888]. \t  \u001b[92m0.9936403303582292\u001b[0m \t 0.9936403303582292\n",
            "57     \t [-0.06467266  0.64174762]. \t  \u001b[92m0.9937212902813126\u001b[0m \t 0.9937212902813126\n",
            "58     \t [-0.06470773  0.64182433]. \t  \u001b[92m0.9938000913442492\u001b[0m \t 0.9938000913442492\n",
            "59     \t [-0.06474198  0.64189915]. \t  \u001b[92m0.9938768893847922\u001b[0m \t 0.9938768893847922\n",
            "60     \t [-0.06477544  0.6419721 ]. \t  \u001b[92m0.9939517095106428\u001b[0m \t 0.9939517095106428\n",
            "61     \t [-0.06480812  0.64204326]. \t  \u001b[92m0.9940246339889031\u001b[0m \t 0.9940246339889031\n",
            "62     \t [-0.06484009  0.64211274]. \t  \u001b[92m0.9940957865904951\u001b[0m \t 0.9940957865904951\n",
            "63     \t [-0.06487138  0.64218063]. \t  \u001b[92m0.9941652575014576\u001b[0m \t 0.9941652575014576\n",
            "64     \t [-0.06490197  0.6422469 ]. \t  \u001b[92m0.9942330127296649\u001b[0m \t 0.9942330127296649\n",
            "65     \t [-0.0649319   0.64231169]. \t  \u001b[92m0.9942992116596807\u001b[0m \t 0.9942992116596807\n",
            "66     \t [-0.06496121  0.64237503]. \t  \u001b[92m0.9943638831316688\u001b[0m \t 0.9943638831316688\n",
            "67     \t [-0.06498994  0.64243699]. \t  \u001b[92m0.9944271111646397\u001b[0m \t 0.9944271111646397\n",
            "68     \t [-0.06501812  0.64249766]. \t  \u001b[92m0.9944889691194342\u001b[0m \t 0.9944889691194342\n",
            "69     \t [-0.06504572  0.64255703]. \t  \u001b[92m0.9945494689341695\u001b[0m \t 0.9945494689341695\n",
            "70     \t [-0.06507278  0.64261515]. \t  \u001b[92m0.9946086564478217\u001b[0m \t 0.9946086564478217\n",
            "71     \t [-0.06509931  0.64267207]. \t  \u001b[92m0.9946665747375508\u001b[0m \t 0.9946665747375508\n",
            "72     \t [-0.06512538  0.64272792]. \t  \u001b[92m0.9947233756776676\u001b[0m \t 0.9947233756776676\n",
            "73     \t [-0.06515093  0.64278261]. \t  \u001b[92m0.994778963408623\u001b[0m \t 0.994778963408623\n",
            "74     \t [-0.06517603  0.64283624]. \t  \u001b[92m0.9948334397936505\u001b[0m \t 0.9948334397936505\n",
            "75     \t [-0.0652007   0.64288887]. \t  \u001b[92m0.9948868713974874\u001b[0m \t 0.9948868713974874\n",
            "76     \t [-0.06522493  0.6429405 ]. \t  \u001b[92m0.9949392577444287\u001b[0m \t 0.9949392577444287\n",
            "77     \t [-0.06524871  0.64299117]. \t  \u001b[92m0.9949906423003444\u001b[0m \t 0.9949906423003444\n",
            "78     \t [-0.06527211  0.64304085]. \t  \u001b[92m0.9950409974901708\u001b[0m \t 0.9950409974901708\n",
            "79     \t [-0.06529513  0.64308974]. \t  \u001b[92m0.9950905195814179\u001b[0m \t 0.9950905195814179\n",
            "80     \t [-0.06531778  0.64313774]. \t  \u001b[92m0.9951391126141811\u001b[0m \t 0.9951391126141811\n",
            "81     \t [-0.06534002  0.64318486]. \t  \u001b[92m0.995186786719931\u001b[0m \t 0.995186786719931\n",
            "82     \t [-0.06536191  0.64323116]. \t  \u001b[92m0.9952336164040944\u001b[0m \t 0.9952336164040944\n",
            "83     \t [-0.06538343  0.64327667]. \t  \u001b[92m0.9952796211269757\u001b[0m \t 0.9952796211269757\n",
            "84     \t [-0.06540465  0.64332143]. \t  \u001b[92m0.9953248391485938\u001b[0m \t 0.9953248391485938\n",
            "85     \t [-0.06542552  0.64336551]. \t  \u001b[92m0.9953693514205697\u001b[0m \t 0.9953693514205697\n",
            "86     \t [-0.0654461   0.64340878]. \t  \u001b[92m0.9954130241301584\u001b[0m \t 0.9954130241301584\n",
            "87     \t [-0.06546636  0.6434514 ]. \t  \u001b[92m0.9954560219448676\u001b[0m \t 0.9954560219448676\n",
            "88     \t [-0.06548632  0.64349332]. \t  \u001b[92m0.9954982950984649\u001b[0m \t 0.9954982950984649\n",
            "89     \t [-0.065506   0.6435346]. \t  \u001b[92m0.9955399084739979\u001b[0m \t 0.9955399084739979\n",
            "90     \t [-0.06552538  0.64357526]. \t  \u001b[92m0.9955808642543702\u001b[0m \t 0.9955808642543702\n",
            "91     \t [-0.06554446  0.64361523]. \t  \u001b[92m0.9956211197169483\u001b[0m \t 0.9956211197169483\n",
            "92     \t [-0.06556332  0.64365466]. \t  \u001b[92m0.9956608105643305\u001b[0m \t 0.9956608105643305\n",
            "93     \t [-0.06558188  0.64369349]. \t  \u001b[92m0.9956998748239005\u001b[0m \t 0.9956998748239005\n",
            "94     \t [-0.0656002   0.64373174]. \t  \u001b[92m0.9957383443448805\u001b[0m \t 0.9957383443448805\n",
            "95     \t [-0.06561827  0.64376944]. \t  \u001b[92m0.995776240447028\u001b[0m \t 0.995776240447028\n",
            "96     \t [-0.06563611  0.64380657]. \t  \u001b[92m0.9958135486182779\u001b[0m \t 0.9958135486182779\n",
            "97     \t [-0.06565368  0.64384321]. \t  \u001b[92m0.9958503506251721\u001b[0m \t 0.9958503506251721\n",
            "98     \t [-0.06567101  0.64387932]. \t  \u001b[92m0.9958865988569416\u001b[0m \t 0.9958865988569416\n",
            "99     \t [-0.0656882   0.64391496]. \t  \u001b[92m0.9959223698690077\u001b[0m \t 0.9959223698690077\n",
            "100    \t [-0.06570513  0.64395006]. \t  \u001b[92m0.9959575926327288\u001b[0m \t 0.9959575926327288\n"
          ]
        }
      ],
      "source": [
        "### Bayesian optimisation runs (x20): 'GP' Acquisition Function run number = 6\n",
        "\n",
        "np.random.seed(run_num_6)\n",
        "surrogate_gp_6 = GaussianProcess(cov_func, optimize=hyperOpt)\n",
        "\n",
        "gp_6 = GPGO(surrogate_gp_6, Acquisition_new(util_gp), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\n",
        "gp_6.run(max_iter = max_iter, init_evals = n_init) # run\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rht2Y9u8JLky",
        "outputId": "75cedf03-fcb3-4e4f-961d-c8e3d96880a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [-2.54215026  1.11967517]. \t  -26.53843863832488 \t 0.46481072558790276\n",
            "init   \t [-0.36954461  0.89386071]. \t  0.46481072558790276 \t 0.46481072558790276\n",
            "init   \t [2.86793707 0.15398348]. \t  -76.66051064695093 \t 0.46481072558790276\n",
            "init   \t [ 0.00672278 -1.71179547]. \t  -22.613010892757885 \t 0.46481072558790276\n",
            "init   \t [-1.38936612e+00 -4.69996698e-04]. \t  -2.294585534557751 \t 0.46481072558790276\n",
            "1      \t [0.16121662 1.7545766 ]. \t  -25.980871892344787 \t 0.46481072558790276\n",
            "2      \t [ 2.08143936 -0.31498517]. \t  -4.006029431355211 \t 0.46481072558790276\n",
            "3      \t [ 1.18351027 -0.35588359]. \t  -1.5350817087151063 \t 0.46481072558790276\n",
            "4      \t [-0.37424687  0.48601799]. \t  0.383594391405703 \t 0.46481072558790276\n",
            "5      \t [-0.76036043  0.79902079]. \t  -0.14418488075070213 \t 0.46481072558790276\n",
            "6      \t [0.03906163 0.32941707]. \t  0.36799395523255707 \t 0.46481072558790276\n",
            "7      \t [-3. -2.]. \t  -162.89999999999998 \t 0.46481072558790276\n",
            "8      \t [ 0.42123929 -1.50062393]. \t  -11.289615085131825 \t 0.46481072558790276\n",
            "9      \t [ 2.13003793 -1.57228184]. \t  -17.25881620754027 \t 0.46481072558790276\n",
            "10     \t [2.12457327 2.        ]. \t  -58.173497114172356 \t 0.46481072558790276\n",
            "11     \t [-0.44988538  0.18277956]. \t  -0.5149268509610136 \t 0.46481072558790276\n",
            "12     \t [-0.45439234  0.19475865]. \t  -0.504833293744314 \t 0.46481072558790276\n",
            "13     \t [-0.45733586  0.20261621]. \t  -0.49767166543740515 \t 0.46481072558790276\n",
            "14     \t [-0.45934818  0.2081381 ]. \t  -0.4922528414313754 \t 0.46481072558790276\n",
            "15     \t [-0.46077377  0.21220938]. \t  -0.48797917182477285 \t 0.46481072558790276\n",
            "16     \t [-0.46181304  0.21532065]. \t  -0.48450921304899763 \t 0.46481072558790276\n",
            "17     \t [-0.46258869  0.21776578]. \t  -0.48162997292657106 \t 0.46481072558790276\n",
            "18     \t [-0.46317907  0.21973131]. \t  -0.4792000269973855 \t 0.46481072558790276\n",
            "19     \t [-0.46363575  0.22134089]. \t  -0.47712068673308927 \t 0.46481072558790276\n",
            "20     \t [-0.46399428  0.22267994]. \t  -0.47532142136665445 \t 0.46481072558790276\n",
            "21     \t [-0.46427902  0.22380883]. \t  -0.47374909955970645 \t 0.46481072558790276\n",
            "22     \t [-0.46450781  0.22477163]. \t  -0.4723643154763214 \t 0.46481072558790276\n",
            "23     \t [-0.4646932   0.22560111]. \t  -0.47113534699420345 \t 0.46481072558790276\n",
            "24     \t [-0.46484456  0.2263221 ]. \t  -0.4700374993121438 \t 0.46481072558790276\n",
            "25     \t [-0.46496914  0.22695373]. \t  -0.46905165949716887 \t 0.46481072558790276\n",
            "26     \t [-0.46507223  0.227511  ]. \t  -0.4681615872693393 \t 0.46481072558790276\n",
            "27     \t [-0.4651579   0.22800579]. \t  -0.4673540302993845 \t 0.46481072558790276\n",
            "28     \t [-0.46522959  0.22844766]. \t  -0.46661868681397134 \t 0.46481072558790276\n",
            "29     \t [-0.46528976  0.22884431]. \t  -0.4659463776893808 \t 0.46481072558790276\n",
            "30     \t [-0.46534036  0.22920201]. \t  -0.4653294715920377 \t 0.46481072558790276\n",
            "31     \t [-0.46538319  0.22952614]. \t  -0.46476170976634296 \t 0.46481072558790276\n",
            "32     \t [-0.46541944  0.2298209 ]. \t  -0.46423760204572007 \t 0.46481072558790276\n",
            "33     \t [-0.46545011  0.23008996]. \t  -0.46375223872652505 \t 0.46481072558790276\n",
            "34     \t [-0.46547618  0.23033644]. \t  -0.4633018482473298 \t 0.46481072558790276\n",
            "35     \t [-0.46549822  0.23056296]. \t  -0.4628824230747395 \t 0.46481072558790276\n",
            "36     \t [-0.46551702  0.23077168]. \t  -0.46249165408123905 \t 0.46481072558790276\n",
            "37     \t [-0.46553285  0.23096461]. \t  -0.46212608215178475 \t 0.46481072558790276\n",
            "38     \t [-0.46554632  0.23114339]. \t  -0.46178389879207726 \t 0.46481072558790276\n",
            "39     \t [-0.46555775  0.23130943]. \t  -0.4614630250653332 \t 0.46481072558790276\n",
            "40     \t [-0.46556735  0.231464  ]. \t  -0.46116139922660593 \t 0.46481072558790276\n",
            "41     \t [-0.4655755   0.23160824]. \t  -0.46087763767161516 \t 0.46481072558790276\n",
            "42     \t [-0.46558221  0.23174304]. \t  -0.4606099004075668 \t 0.46481072558790276\n",
            "43     \t [-0.46558765  0.23186932]. \t  -0.4603567086573259 \t 0.46481072558790276\n",
            "44     \t [-0.46559214  0.23198779]. \t  -0.46011747137289544 \t 0.46481072558790276\n",
            "45     \t [-0.4655959   0.23209917]. \t  -0.4598912286401793 \t 0.46481072558790276\n",
            "46     \t [-0.46559869  0.23220397]. \t  -0.4596762867338112 \t 0.46481072558790276\n",
            "47     \t [-0.46560092  0.23230279]. \t  -0.4594724591230811 \t 0.46481072558790276\n",
            "48     \t [-0.46560253  0.23239613]. \t  -0.45927855252200855 \t 0.46481072558790276\n",
            "49     \t [-0.46560379  0.23248441]. \t  -0.4590944275218185 \t 0.46481072558790276\n",
            "50     \t [-0.46560434  0.23256795]. \t  -0.45891842222617885 \t 0.46481072558790276\n",
            "51     \t [-0.46560474  0.23264715]. \t  -0.4587511620575167 \t 0.46481072558790276\n",
            "52     \t [-0.46560479  0.23272231]. \t  -0.45859156640699106 \t 0.46481072558790276\n",
            "53     \t [-0.46560432  0.23279372]. \t  -0.45843848475060667 \t 0.46481072558790276\n",
            "54     \t [-0.46560374  0.23286172]. \t  -0.4582923121407632 \t 0.46481072558790276\n",
            "55     \t [-0.46560279  0.23292639]. \t  -0.4581522424443266 \t 0.46481072558790276\n",
            "56     \t [-0.46560175  0.2329881 ]. \t  -0.4580181971168785 \t 0.46481072558790276\n",
            "57     \t [-0.46560052  0.23304696]. \t  -0.4578896831705077 \t 0.46481072558790276\n",
            "58     \t [-0.46559933  0.23310317]. \t  -0.457766896643509 \t 0.46481072558790276\n",
            "59     \t [-0.46559782  0.2331569 ]. \t  -0.4576484980422078 \t 0.46481072558790276\n",
            "60     \t [-0.46559624  0.2332083 ]. \t  -0.45753485685726253 \t 0.46481072558790276\n",
            "61     \t [-0.4655946   0.23325757]. \t  -0.45742558977333947 \t 0.46481072558790276\n",
            "62     \t [-0.46559278  0.23330472]. \t  -0.4573203218271069 \t 0.46481072558790276\n",
            "63     \t [-0.46559099  0.23334995]. \t  -0.4572192063899547 \t 0.46481072558790276\n",
            "64     \t [-0.46558903  0.23339337]. \t  -0.457121516708729 \t 0.46481072558790276\n",
            "65     \t [-0.46558716  0.23343509]. \t  -0.4570276355767295 \t 0.46481072558790276\n",
            "66     \t [-0.46558517  0.2334752 ]. \t  -0.45693687399937744 \t 0.46481072558790276\n",
            "67     \t [-0.46558318  0.23351376]. \t  -0.4568493959764537 \t 0.46481072558790276\n",
            "68     \t [-0.46558114  0.23355092]. \t  -0.4567647643247683 \t 0.46481072558790276\n",
            "69     \t [-0.46557907  0.23358665]. \t  -0.4566831034652522 \t 0.46481072558790276\n",
            "70     \t [-0.46557708  0.23362129]. \t  -0.4566039530703816 \t 0.46481072558790276\n",
            "71     \t [-0.4655748  0.2336543]. \t  -0.45652748855293923 \t 0.46481072558790276\n",
            "72     \t [-0.4655728   0.23368632]. \t  -0.4564538933097609 \t 0.46481072558790276\n",
            "73     \t [-0.46557068  0.23371715]. \t  -0.4563824817998207 \t 0.46481072558790276\n",
            "74     \t [-0.46556859  0.23374706]. \t  -0.456313120176038 \t 0.46481072558790276\n",
            "75     \t [-0.4655665   0.23377591]. \t  -0.4562460155576615 \t 0.46481072558790276\n",
            "76     \t [-0.46556445  0.23380386]. \t  -0.45618094702619894 \t 0.46481072558790276\n",
            "77     \t [-0.46556242  0.23383081]. \t  -0.4561180311895708 \t 0.46481072558790276\n",
            "78     \t [-0.46556035  0.23385697]. \t  -0.4560567308630611 \t 0.46481072558790276\n",
            "79     \t [-0.46555825  0.23388222]. \t  -0.4559972524273442 \t 0.46481072558790276\n",
            "80     \t [-0.465556    0.23390665]. \t  -0.45593911295114553 \t 0.46481072558790276\n",
            "81     \t [-0.46555408  0.23393041]. \t  -0.4558833025430789 \t 0.46481072558790276\n",
            "82     \t [-0.4655522   0.23395343]. \t  -0.45582917333326034 \t 0.46481072558790276\n",
            "83     \t [-0.46554983  0.23397586]. \t  -0.4557749701618029 \t 0.46481072558790276\n",
            "84     \t [-0.46554824  0.2339974 ]. \t  -0.4557247721550859 \t 0.46481072558790276\n",
            "85     \t [-0.4655462  0.2340184]. \t  -0.45567451399617875 \t 0.46481072558790276\n",
            "86     \t [-0.46554425  0.23403877]. \t  -0.4556258014199538 \t 0.46481072558790276\n",
            "87     \t [-0.46554229  0.23405857]. \t  -0.4555783357507744 \t 0.46481072558790276\n",
            "88     \t [-0.4655405   0.23407785]. \t  -0.45553240879266166 \t 0.46481072558790276\n",
            "89     \t [-0.46553866  0.23409664]. \t  -0.4554873732092742 \t 0.46481072558790276\n",
            "90     \t [-0.46553672  0.23411478]. \t  -0.45544347794319356 \t 0.46481072558790276\n",
            "91     \t [-0.46553492  0.23413244]. \t  -0.4554009557275229 \t 0.46481072558790276\n",
            "92     \t [-0.465533   0.2341497]. \t  -0.455358976201074 \t 0.46481072558790276\n",
            "93     \t [-0.46553125  0.23416645]. \t  -0.4553185345028752 \t 0.46481072558790276\n",
            "94     \t [-0.46552949  0.23418276]. \t  -0.45527900687755946 \t 0.46481072558790276\n",
            "95     \t [-0.46552773  0.23419863]. \t  -0.45524042373394374 \t 0.46481072558790276\n",
            "96     \t [-0.46552602  0.23421417]. \t  -0.45520266355612776 \t 0.46481072558790276\n",
            "97     \t [-0.46552434  0.23422925]. \t  -0.45516597253708646 \t 0.46481072558790276\n",
            "98     \t [-0.46552265  0.23424395]. \t  -0.4551300703084006 \t 0.46481072558790276\n",
            "99     \t [-0.46552103  0.23425836]. \t  -0.4550949674357223 \t 0.46481072558790276\n",
            "100    \t [-0.4655193   0.23427232]. \t  -0.4550605396261024 \t 0.46481072558790276\n"
          ]
        }
      ],
      "source": [
        "### Bayesian optimisation runs (x20): 'GP' Acquisition Function run number = 7\n",
        "\n",
        "np.random.seed(run_num_7)\n",
        "surrogate_gp_7 = GaussianProcess(cov_func, optimize=hyperOpt)\n",
        "\n",
        "gp_7 = GPGO(surrogate_gp_7, Acquisition_new(util_gp), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\n",
        "gp_7.run(max_iter = max_iter, init_evals = n_init) # run\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHGwZn0qJLkz",
        "outputId": "3757dcc3-0a70-4b38-fa96-9c105fcbedcb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [2.24057642 1.87416265]. \t  -48.82879577505094 \t -0.03190064766213015\n",
            "init   \t [2.21516724 0.12342277]. \t  -8.660623551418242 \t -0.03190064766213015\n",
            "init   \t [-1.60363003 -1.95440478]. \t  -48.28332373939171 \t -0.03190064766213015\n",
            "init   \t [-0.41718709 -0.39059456]. \t  -0.2801229037700297 \t -0.03190064766213015\n",
            "init   \t [ 0.13604803 -0.08643282]. \t  -0.03190064766213015 \t -0.03190064766213015\n",
            "1      \t [-0.84228478  0.91558374]. \t  -0.5864343738000131 \t -0.03190064766213015\n",
            "2      \t [-3.  2.]. \t  -150.89999999999998 \t -0.03190064766213015\n",
            "3      \t [-0.27001932  0.4386089 ]. \t  \u001b[92m0.4592996355476947\u001b[0m \t 0.4592996355476947\n",
            "4      \t [-0.27227671  0.42623368]. \t  0.4255978937321288 \t 0.4592996355476947\n",
            "5      \t [-0.27346317  0.41859608]. \t  0.4050255178462272 \t 0.4592996355476947\n",
            "6      \t [-0.27417166  0.41342685]. \t  0.39122412813367197 \t 0.4592996355476947\n",
            "7      \t [-0.27463364  0.40971754]. \t  0.38138554123987256 \t 0.4592996355476947\n",
            "8      \t [-0.2749547   0.40694351]. \t  0.37406356740171154 \t 0.4592996355476947\n",
            "9      \t [ 3. -2.]. \t  -150.89999999999998 \t 0.4592996355476947\n",
            "10     \t [-0.26136823  0.39973659]. \t  0.3779457073700342 \t 0.4592996355476947\n",
            "11     \t [-0.26205032  0.39809813]. \t  0.3728972886145126 \t 0.4592996355476947\n",
            "12     \t [-0.262597    0.39678247]. \t  0.3688420645045198 \t 0.4592996355476947\n",
            "13     \t [-0.2630441   0.39570833]. \t  0.36552816995131043 \t 0.4592996355476947\n",
            "14     \t [-0.2634158   0.39481913]. \t  0.362781146517123 \t 0.4592996355476947\n",
            "15     \t [-0.26372825  0.39407405]. \t  0.3604769156238643 \t 0.4592996355476947\n",
            "16     \t [-0.26399457  0.39344328]. \t  0.3585227664771903 \t 0.4592996355476947\n",
            "17     \t [-0.26422391  0.39290432]. \t  0.35684978431892866 \t 0.4592996355476947\n",
            "18     \t [-0.26442312  0.39243999]. \t  0.355405612731692 \t 0.4592996355476947\n",
            "19     \t [-0.26459711  0.39203699]. \t  0.3541502061693519 \t 0.4592996355476947\n",
            "20     \t [-0.26475054  0.39168503]. \t  0.3530513061764975 \t 0.4592996355476947\n",
            "21     \t [-0.26488644  0.39137559]. \t  0.35208342707159024 \t 0.4592996355476947\n",
            "22     \t [-0.26500784  0.39110226]. \t  0.35122622361234185 \t 0.4592996355476947\n",
            "23     \t [-0.26511665  0.39085956]. \t  0.3504634061897874 \t 0.4592996355476947\n",
            "24     \t [-0.26521495  0.39064304]. \t  0.3497808697800112 \t 0.4592996355476947\n",
            "25     \t [-0.265303    0.39044894]. \t  0.3491690511827847 \t 0.4592996355476947\n",
            "26     \t [-0.26538357  0.39027448]. \t  0.3486168204343616 \t 0.4592996355476947\n",
            "27     \t [-0.26545696  0.39011699]. \t  0.3481172516936478 \t 0.4592996355476947\n",
            "28     \t [-0.26552379  0.38997425]. \t  0.3476639144384349 \t 0.4592996355476947\n",
            "29     \t [-0.26558525  0.38984459]. \t  0.34725094141287616 \t 0.4592996355476947\n",
            "30     \t [-0.26564207  0.38972639]. \t  0.34687316218423986 \t 0.4592996355476947\n",
            "31     \t [-0.2656938   0.38961831]. \t  0.3465280666075289 \t 0.4592996355476947\n",
            "32     \t [-0.26574216  0.38951949]. \t  0.34621083675047504 \t 0.4592996355476947\n",
            "33     \t [-0.26578655  0.38942849]. \t  0.34591891642768535 \t 0.4592996355476947\n",
            "34     \t [-0.26582824  0.38934479]. \t  0.3456490703494411 \t 0.4592996355476947\n",
            "35     \t [-0.26586677  0.38926753]. \t  0.3453998561410828 \t 0.4592996355476947\n",
            "36     \t [-0.26590287  0.38919617]. \t  0.34516889655888094 \t 0.4592996355476947\n",
            "37     \t [-0.26593642  0.38912993]. \t  0.3449543923019524 \t 0.4592996355476947\n",
            "38     \t [-0.26596786  0.38906854]. \t  0.3447550616409562 \t 0.4592996355476947\n",
            "39     \t [-0.26599786  0.38901137]. \t  0.34456829236396125 \t 0.4592996355476947\n",
            "40     \t [-0.26602528  0.38895818]. \t  0.3443952974890458 \t 0.4592996355476947\n",
            "41     \t [-0.26605131  0.38890843]. \t  0.344232861273896 \t 0.4592996355476947\n",
            "42     \t [-0.26607569  0.38886215]. \t  0.34408149221200945 \t 0.4592996355476947\n",
            "43     \t [-0.26609843  0.38881852]. \t  0.34393918397212103 \t 0.4592996355476947\n",
            "44     \t [-0.26612064  0.3887778 ]. \t  0.3438047983674519 \t 0.4592996355476947\n",
            "45     \t [-0.26614167  0.38873966]. \t  0.3436785509024434 \t 0.4592996355476947\n",
            "46     \t [-0.26616095  0.38870372]. \t  0.3435604476168147 \t 0.4592996355476947\n",
            "47     \t [-0.26617908  0.38866982]. \t  0.34344914053004877 \t 0.4592996355476947\n",
            "48     \t [-0.2661969   0.38863808]. \t  0.34334356585946324 \t 0.4592996355476947\n",
            "49     \t [-0.26621362  0.38860807]. \t  0.3432439528454521 \t 0.4592996355476947\n",
            "50     \t [-0.26622939  0.38857965]. \t  0.3431497202201528 \t 0.4592996355476947\n",
            "51     \t [-0.26624451  0.38855287]. \t  0.3430604902504211 \t 0.4592996355476947\n",
            "52     \t [-0.26625928  0.38852733]. \t  0.3429748491999375 \t 0.4592996355476947\n",
            "53     \t [-0.26627273  0.38850347]. \t  0.34289542454687894 \t 0.4592996355476947\n",
            "54     \t [-0.26628607  0.38848071]. \t  0.342818801903462 \t 0.4592996355476947\n",
            "55     \t [-0.26629802  0.38845898]. \t  0.34274692984201616 \t 0.4592996355476947\n",
            "56     \t [-0.2663101   0.38843854]. \t  0.3426779733033619 \t 0.4592996355476947\n",
            "57     \t [-0.26632147  0.38841903]. \t  0.34261238927257975 \t 0.4592996355476947\n",
            "58     \t [-0.26633224  0.38840041]. \t  0.34254995132069926 \t 0.4592996355476947\n",
            "59     \t [-0.26634263  0.38838273]. \t  0.34249041051212986 \t 0.4592996355476947\n",
            "60     \t [-0.26635283  0.38836588]. \t  0.34243317772846915 \t 0.4592996355476947\n",
            "61     \t [-0.26636221  0.38834984]. \t  0.34237922782589336 \t 0.4592996355476947\n",
            "62     \t [-0.26637148  0.38833454]. \t  0.3423272545073107 \t 0.4592996355476947\n",
            "63     \t [-0.26638058  0.38831985]. \t  0.3422770107920552 \t 0.4592996355476947\n",
            "64     \t [-0.26638857  0.3883059 ]. \t  0.34223036269247625 \t 0.4592996355476947\n",
            "65     \t [-0.26639724  0.3882925 ]. \t  0.34218395749209757 \t 0.4592996355476947\n",
            "66     \t [-0.26640488  0.38827967]. \t  0.3421405862200807 \t 0.4592996355476947\n",
            "67     \t [-0.26641237  0.38826743]. \t  0.3420988865479639 \t 0.4592996355476947\n",
            "68     \t [-0.26641966  0.38825557]. \t  0.3420584313630378 \t 0.4592996355476947\n",
            "69     \t [-0.26642662  0.38824438]. \t  0.3420201152704995 \t 0.4592996355476947\n",
            "70     \t [-0.2664335   0.38823357]. \t  0.3419828643302548 \t 0.4592996355476947\n",
            "71     \t [-0.26643998  0.38822319]. \t  0.3419472945467674 \t 0.4592996355476947\n",
            "72     \t [-0.26644653  0.38821324]. \t  0.34191265799667675 \t 0.4592996355476947\n",
            "73     \t [-0.26645232  0.38820368]. \t  0.34188019798576064 \t 0.4592996355476947\n",
            "74     \t [-0.26645795  0.38819435]. \t  0.34184850984491144 \t 0.4592996355476947\n",
            "75     \t [-0.2664634   0.38818556]. \t  0.3418184630077309 \t 0.4592996355476947\n",
            "76     \t [-0.26646961  0.38817719]. \t  0.34178821874623955 \t 0.4592996355476947\n",
            "77     \t [-0.26647499  0.38816887]. \t  0.34175941160135476 \t 0.4592996355476947\n",
            "78     \t [-0.26647978  0.38816097]. \t  0.3417325475692284 \t 0.4592996355476947\n",
            "79     \t [-0.26648475  0.3881533 ]. \t  0.3417059841492258 \t 0.4592996355476947\n",
            "80     \t [-0.26648932  0.38814595]. \t  0.34168082491917406 \t 0.4592996355476947\n",
            "81     \t [-0.26649422  0.38813895]. \t  0.341655975630538 \t 0.4592996355476947\n",
            "82     \t [-0.26649877  0.38813208]. \t  0.3416320388597536 \t 0.4592996355476947\n",
            "83     \t [-0.26650311  0.3881255 ]. \t  0.3416091118343148 \t 0.4592996355476947\n",
            "84     \t [-0.26650735  0.38811911]. \t  0.34158682323249434 \t 0.4592996355476947\n",
            "85     \t [-0.26651151  0.388113  ]. \t  0.34156533639791975 \t 0.4592996355476947\n",
            "86     \t [-0.26651507  0.3881069 ]. \t  0.3415448272734231 \t 0.4592996355476947\n",
            "87     \t [-0.26651905  0.3881011 ]. \t  0.3415243558077072 \t 0.4592996355476947\n",
            "88     \t [-0.26652316  0.38809561]. \t  0.34150447442808474 \t 0.4592996355476947\n",
            "89     \t [-0.26652672  0.38809027]. \t  0.34148579934742124 \t 0.4592996355476947\n",
            "90     \t [-0.26653023  0.38808507]. \t  0.3414675688143526 \t 0.4592996355476947\n",
            "91     \t [-0.26653321  0.38807991]. \t  0.3414502710270406 \t 0.4592996355476947\n",
            "92     \t [-0.26653718  0.38807515]. \t  0.34143237147803696 \t 0.4592996355476947\n",
            "93     \t [-0.26654027  0.38807038]. \t  0.34141584690992766 \t 0.4592996355476947\n",
            "94     \t [-0.26654341  0.38806579]. \t  0.34139966925221155 \t 0.4592996355476947\n",
            "95     \t [-0.26654687  0.38806139]. \t  0.341383450401808 \t 0.4592996355476947\n",
            "96     \t [-0.26654953  0.38805698]. \t  0.3413685017680622 \t 0.4592996355476947\n",
            "97     \t [-0.26655191  0.38805278]. \t  0.3413544803368552 \t 0.4592996355476947\n",
            "98     \t [-0.26655527  0.38804874]. \t  0.3413392908471834 \t 0.4592996355476947\n",
            "99     \t [-0.26655841  0.38804488]. \t  0.34132492492408784 \t 0.4592996355476947\n",
            "100    \t [-0.26656051  0.388041  ]. \t  0.34131213384144476 \t 0.4592996355476947\n"
          ]
        }
      ],
      "source": [
        "### Bayesian optimisation runs (x20): 'GP' Acquisition Function run number = 8\n",
        "\n",
        "np.random.seed(run_num_8)\n",
        "surrogate_gp_8 = GaussianProcess(cov_func, optimize=hyperOpt)\n",
        "\n",
        "gp_8 = GPGO(surrogate_gp_8, Acquisition_new(util_gp), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\n",
        "gp_8.run(max_iter = max_iter, init_evals = n_init) # run\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YC6sxKgkJLkz",
        "outputId": "493afd76-04a1-4717-c4bb-d9ab08991f70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [-2.93775508  0.00749837]. \t  -92.35857237145763 \t -1.395407492769129\n",
            "init   \t [-0.02536024 -1.46468188]. \t  -9.867672894921913 \t -1.395407492769129\n",
            "init   \t [-2.14733349 -1.1257653 ]. \t  -10.24680089963123 \t -1.395407492769129\n",
            "init   \t [-0.48895092 -1.00759533]. \t  -1.395407492769129 \t -1.395407492769129\n",
            "init   \t [-2.49564209 -0.61800544]. \t  -24.58298635463645 \t -1.395407492769129\n",
            "1      \t [0.20087506 1.2956128 ]. \t  -4.974772100042532 \t -1.395407492769129\n",
            "2      \t [ 3.         -0.22076027]. \t  -108.05227926250552 \t -1.395407492769129\n",
            "3      \t [-1.45414596  2.        ]. \t  -47.311747509184165 \t -1.395407492769129\n",
            "4      \t [-1.57054129 -2.        ]. \t  -53.23319972947514 \t -1.395407492769129\n",
            "5      \t [-0.50961948 -0.13404216]. \t  \u001b[92m-0.9007741863881611\u001b[0m \t -0.9007741863881611\n",
            "6      \t [1.96414584 2.        ]. \t  -55.24423071573652 \t -0.9007741863881611\n",
            "7      \t [-0.01755752 -0.13269613]. \t  \u001b[92m0.06563016133049356\u001b[0m \t 0.06563016133049356\n",
            "8      \t [-0.02099663 -0.13414617]. \t  \u001b[92m0.06610583218381466\u001b[0m \t 0.06610583218381466\n",
            "9      \t [-0.02290169 -0.13496127]. \t  \u001b[92m0.06634288631912913\u001b[0m \t 0.06634288631912913\n",
            "10     \t [-0.0241116  -0.13548374]. \t  \u001b[92m0.0664841336316471\u001b[0m \t 0.0664841336316471\n",
            "11     \t [-0.02494716 -0.13584702]. \t  \u001b[92m0.06657776068730731\u001b[0m \t 0.06657776068730731\n",
            "12     \t [-0.02555833 -0.13611404]. \t  \u001b[92m0.06664425836858741\u001b[0m \t 0.06664425836858741\n",
            "13     \t [-0.02602431 -0.13631847]. \t  \u001b[92m0.06669393650319622\u001b[0m \t 0.06669393650319622\n",
            "14     \t [-0.02639115 -0.13647991]. \t  \u001b[92m0.06673242664449307\u001b[0m \t 0.06673242664449307\n",
            "15     \t [-0.02668718 -0.1366106 ]. \t  \u001b[92m0.06676315981272839\u001b[0m \t 0.06676315981272839\n",
            "16     \t [-0.02693101 -0.13671845]. \t  \u001b[92m0.06678820314983837\u001b[0m \t 0.06678820314983837\n",
            "17     \t [-0.02713526 -0.13680904]. \t  \u001b[92m0.0668090898535057\u001b[0m \t 0.0668090898535057\n",
            "18     \t [-0.02730869 -0.13688607]. \t  \u001b[92m0.06682669909933867\u001b[0m \t 0.06682669909933867\n",
            "19     \t [-0.02745781 -0.13695244]. \t  \u001b[92m0.06684179159371392\u001b[0m \t 0.06684179159371392\n",
            "20     \t [-0.02758736 -0.13701019]. \t  \u001b[92m0.06685486314659018\u001b[0m \t 0.06685486314659018\n",
            "21     \t [-0.02770084 -0.13706085]. \t  \u001b[92m0.06686628939721508\u001b[0m \t 0.06686628939721508\n",
            "22     \t [-0.02780113 -0.13710565]. \t  \u001b[92m0.06687632875023312\u001b[0m \t 0.06687632875023312\n",
            "23     \t [-0.02789036 -0.13714555]. \t  \u001b[92m0.06688525221325958\u001b[0m \t 0.06688525221325958\n",
            "24     \t [-0.02797021 -0.13718132]. \t  \u001b[92m0.06689324434047833\u001b[0m \t 0.06689324434047833\n",
            "25     \t [-0.02804215 -0.13721357]. \t  \u001b[92m0.06690043484013689\u001b[0m \t 0.06690043484013689\n",
            "26     \t [-0.0281072  -0.13724276]. \t  \u001b[92m0.06690692836081882\u001b[0m \t 0.06690692836081882\n",
            "27     \t [-0.02816635 -0.13726934]. \t  \u001b[92m0.06691284018575966\u001b[0m \t 0.06691284018575966\n",
            "28     \t [-0.02822037 -0.13729361]. \t  \u001b[92m0.06691821679685238\u001b[0m \t 0.06691821679685238\n",
            "29     \t [-0.02826986 -0.13731589]. \t  \u001b[92m0.06692317299165404\u001b[0m \t 0.06692317299165404\n",
            "30     \t [-0.02831534 -0.13733644]. \t  \u001b[92m0.06692778394507111\u001b[0m \t 0.06692778394507111\n",
            "31     \t [-0.02835737 -0.1373553 ]. \t  \u001b[92m0.06693189787732219\u001b[0m \t 0.06693189787732219\n",
            "32     \t [-0.02839625 -0.13737281]. \t  \u001b[92m0.0669357579252014\u001b[0m \t 0.0669357579252014\n",
            "33     \t [-0.0284323  -0.13738911]. \t  \u001b[92m0.06693938869086505\u001b[0m \t 0.06693938869086505\n",
            "34     \t [-0.02846587 -0.13740425]. \t  \u001b[92m0.06694272597485483\u001b[0m \t 0.06694272597485483\n",
            "35     \t [-0.02849718 -0.1374184 ]. \t  \u001b[92m0.06694586397554506\u001b[0m \t 0.06694586397554506\n",
            "36     \t [-0.02852644 -0.13743163]. \t  \u001b[92m0.06694879598047489\u001b[0m \t 0.06694879598047489\n",
            "37     \t [-0.02855383 -0.13744403]. \t  \u001b[92m0.06695154577248312\u001b[0m \t 0.06695154577248312\n",
            "38     \t [-0.0285796  -0.13745567]. \t  \u001b[92m0.06695410635343758\u001b[0m \t 0.06695410635343758\n",
            "39     \t [-0.0286038  -0.13746664]. \t  \u001b[92m0.06695653639844312\u001b[0m \t 0.06695653639844312\n",
            "40     \t [-0.02862659 -0.13747694]. \t  \u001b[92m0.06695879747159658\u001b[0m \t 0.06695879747159658\n",
            "41     \t [-0.02864814 -0.13748668]. \t  \u001b[92m0.06696093326027068\u001b[0m \t 0.06696093326027068\n",
            "42     \t [-0.02866846 -0.13749595]. \t  \u001b[92m0.06696302412788023\u001b[0m \t 0.06696302412788023\n",
            "43     \t [-0.02868773 -0.13750466]. \t  \u001b[92m0.06696492582187716\u001b[0m \t 0.06696492582187716\n",
            "44     \t [-0.02870599 -0.13751296]. \t  \u001b[92m0.06696677936101322\u001b[0m \t 0.06696677936101322\n",
            "45     \t [-0.0287233  -0.13752081]. \t  \u001b[92m0.06696850725240847\u001b[0m \t 0.06696850725240847\n",
            "46     \t [-0.02873974 -0.13752829]. \t  \u001b[92m0.06697017687851325\u001b[0m \t 0.06697017687851325\n",
            "47     \t [-0.02875544 -0.13753544]. \t  \u001b[92m0.06697177062865131\u001b[0m \t 0.06697177062865131\n",
            "48     \t [-0.02877035 -0.13754219]. \t  \u001b[92m0.06697324344121341\u001b[0m \t 0.06697324344121341\n",
            "49     \t [-0.02878463 -0.13754873]. \t  \u001b[92m0.06697472871953607\u001b[0m \t 0.06697472871953607\n",
            "50     \t [-0.02879821 -0.13755488]. \t  \u001b[92m0.06697607502031855\u001b[0m \t 0.06697607502031855\n",
            "51     \t [-0.02881121 -0.13756079]. \t  \u001b[92m0.06697738359821218\u001b[0m \t 0.06697738359821218\n",
            "52     \t [-0.02882364 -0.13756647]. \t  \u001b[92m0.06697865359710778\u001b[0m \t 0.06697865359710778\n",
            "53     \t [-0.02883554 -0.13757188]. \t  \u001b[92m0.06697984778825479\u001b[0m \t 0.06697984778825479\n",
            "54     \t [-0.02884694 -0.13757706]. \t  \u001b[92m0.06698099089674289\u001b[0m \t 0.06698099089674289\n",
            "55     \t [-0.02885791 -0.13758207]. \t  \u001b[92m0.0669821093448246\u001b[0m \t 0.0669821093448246\n",
            "56     \t [-0.02886843 -0.13758684]. \t  \u001b[92m0.06698314781908768\u001b[0m \t 0.06698314781908768\n",
            "57     \t [-0.0288785  -0.13759145]. \t  \u001b[92m0.06698418810675662\u001b[0m \t 0.06698418810675662\n",
            "58     \t [-0.02888823 -0.13759588]. \t  \u001b[92m0.06698516374624171\u001b[0m \t 0.06698516374624171\n",
            "59     \t [-0.02889755 -0.1376001 ]. \t  \u001b[92m0.06698608325764151\u001b[0m \t 0.06698608325764151\n",
            "60     \t [-0.02890656 -0.1376043 ]. \t  \u001b[92m0.06698708240318745\u001b[0m \t 0.06698708240318745\n",
            "61     \t [-0.02891522 -0.1376082 ]. \t  \u001b[92m0.06698790626260764\u001b[0m \t 0.06698790626260764\n",
            "62     \t [-0.02892356 -0.13761202]. \t  \u001b[92m0.06698877869254571\u001b[0m \t 0.06698877869254571\n",
            "63     \t [-0.02893164 -0.13761568]. \t  \u001b[92m0.06698955900963019\u001b[0m \t 0.06698955900963019\n",
            "64     \t [-0.02893942 -0.13761927]. \t  \u001b[92m0.06699039056730566\u001b[0m \t 0.06699039056730566\n",
            "65     \t [-0.02894691 -0.13762266]. \t  \u001b[92m0.06699112136567106\u001b[0m \t 0.06699112136567106\n",
            "66     \t [-0.02895419 -0.13762603]. \t  \u001b[92m0.06699191037646401\u001b[0m \t 0.06699191037646401\n",
            "67     \t [-0.02896125 -0.13762923]. \t  \u001b[92m0.0669925944372321\u001b[0m \t 0.0669925944372321\n",
            "68     \t [-0.02896802 -0.13763233]. \t  \u001b[92m0.06699329233164215\u001b[0m \t 0.06699329233164215\n",
            "69     \t [-0.02897462 -0.13763534]. \t  \u001b[92m0.06699396293225104\u001b[0m \t 0.06699396293225104\n",
            "70     \t [-0.02898098 -0.13763827]. \t  \u001b[92m0.06699463382445128\u001b[0m \t 0.06699463382445128\n",
            "71     \t [-0.02898716 -0.13764108]. \t  \u001b[92m0.06699523920615791\u001b[0m \t 0.06699523920615791\n",
            "72     \t [-0.02899314 -0.13764384]. \t  \u001b[92m0.06699588218102544\u001b[0m \t 0.06699588218102544\n",
            "73     \t [-0.02899897 -0.13764648]. \t  \u001b[92m0.06699644534229501\u001b[0m \t 0.06699644534229501\n",
            "74     \t [-0.0290046  -0.13764907]. \t  \u001b[92m0.0669970344158852\u001b[0m \t 0.0669970344158852\n",
            "75     \t [-0.02901005 -0.13765155]. \t  \u001b[92m0.06699757211921165\u001b[0m \t 0.06699757211921165\n",
            "76     \t [-0.02901537 -0.137654  ]. \t  \u001b[92m0.06699813004208653\u001b[0m \t 0.06699813004208653\n",
            "77     \t [-0.02902052 -0.13765633]. \t  \u001b[92m0.0669986286713299\u001b[0m \t 0.0669986286713299\n",
            "78     \t [-0.02902547 -0.13765869]. \t  \u001b[92m0.06699923854202343\u001b[0m \t 0.06699923854202343\n",
            "79     \t [-0.02903041 -0.1376609 ]. \t  \u001b[92m0.06699967950095648\u001b[0m \t 0.06699967950095648\n",
            "80     \t [-0.0290352 -0.1376631]. \t  \u001b[92m0.06700017643958052\u001b[0m \t 0.06700017643958052\n",
            "81     \t [-0.02903982 -0.13766522]. \t  \u001b[92m0.06700065651067556\u001b[0m \t 0.06700065651067556\n",
            "82     \t [-0.0290443  -0.13766726]. \t  \u001b[92m0.06700110697201538\u001b[0m \t 0.06700110697201538\n",
            "83     \t [-0.02904869 -0.13766923]. \t  \u001b[92m0.06700151170066068\u001b[0m \t 0.06700151170066068\n",
            "84     \t [-0.02905294 -0.13767125]. \t  \u001b[92m0.06700201628332775\u001b[0m \t 0.06700201628332775\n",
            "85     \t [-0.0290571  -0.13767308]. \t  \u001b[92m0.06700236203998677\u001b[0m \t 0.06700236203998677\n",
            "86     \t [-0.02906108 -0.13767496]. \t  \u001b[92m0.06700283058277857\u001b[0m \t 0.06700283058277857\n",
            "87     \t [-0.02906508 -0.13767681]. \t  \u001b[92m0.06700325890488511\u001b[0m \t 0.06700325890488511\n",
            "88     \t [-0.02906891 -0.13767858]. \t  \u001b[92m0.06700366847023285\u001b[0m \t 0.06700366847023285\n",
            "89     \t [-0.02907273 -0.13768033]. \t  \u001b[92m0.06700405287787643\u001b[0m \t 0.06700405287787643\n",
            "90     \t [-0.02907635 -0.13768199]. \t  \u001b[92m0.06700442162254362\u001b[0m \t 0.06700442162254362\n",
            "91     \t [-0.02907992 -0.13768362]. \t  \u001b[92m0.06700478317095895\u001b[0m \t 0.06700478317095895\n",
            "92     \t [-0.02908342 -0.13768525]. \t  \u001b[92m0.06700517216280621\u001b[0m \t 0.06700517216280621\n",
            "93     \t [-0.02908682 -0.1376868 ]. \t  \u001b[92m0.06700550485590655\u001b[0m \t 0.06700550485590655\n",
            "94     \t [-0.02909017 -0.13768835]. \t  \u001b[92m0.06700586718852568\u001b[0m \t 0.06700586718852568\n",
            "95     \t [-0.02909344 -0.13768984]. \t  \u001b[92m0.0670061891396482\u001b[0m \t 0.0670061891396482\n",
            "96     \t [-0.0290966  -0.13769129]. \t  \u001b[92m0.0670065134628972\u001b[0m \t 0.0670065134628972\n",
            "97     \t [-0.02909971 -0.13769274]. \t  \u001b[92m0.06700685636039928\u001b[0m \t 0.06700685636039928\n",
            "98     \t [-0.02910276 -0.13769414]. \t  \u001b[92m0.06700717130796816\u001b[0m \t 0.06700717130796816\n",
            "99     \t [-0.02910576 -0.13769549]. \t  \u001b[92m0.06700744995923885\u001b[0m \t 0.06700744995923885\n",
            "100    \t [-0.02910867 -0.13769684]. \t  \u001b[92m0.06700776365671707\u001b[0m \t 0.06700776365671707\n"
          ]
        }
      ],
      "source": [
        "### Bayesian optimisation runs (x20): 'GP' Acquisition Function run number = 9\n",
        "\n",
        "np.random.seed(run_num_9)\n",
        "surrogate_gp_9 = GaussianProcess(cov_func, optimize=hyperOpt)\n",
        "\n",
        "gp_9 = GPGO(surrogate_gp_9, Acquisition_new(util_gp), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\n",
        "gp_9.run(max_iter = max_iter, init_evals = n_init) # run\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-0wfCEIJLk0",
        "outputId": "64b823d4-2a80-4cb9-c223-9e62e75210c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 1.62792386 -1.9169922 ]. \t  -38.25414770674631 \t -0.7775687473184012\n",
            "init   \t [0.80188941 0.99521553]. \t  -2.552651714051803 \t -0.7775687473184012\n",
            "init   \t [-0.00895793 -1.10081342]. \t  -1.0367630165263393 \t -0.7775687473184012\n",
            "init   \t [-1.81162281  1.04212285]. \t  -0.7775687473184012 \t -0.7775687473184012\n",
            "init   \t [-1.98533498 -1.64664074]. \t  -25.383481436170044 \t -0.7775687473184012\n",
            "1      \t [3. 2.]. \t  -162.89999999999998 \t -0.7775687473184012\n",
            "2      \t [-3.  2.]. \t  -150.89999999999998 \t -0.7775687473184012\n",
            "3      \t [-0.97453316  0.37274809]. \t  -1.348480034205919 \t -0.7775687473184012\n",
            "4      \t [ 3.         -0.31734861]. \t  -107.5856837146818 \t -0.7775687473184012\n",
            "5      \t [-0.5891859   0.83922221]. \t  \u001b[92m0.17807259252024998\u001b[0m \t 0.17807259252024998\n",
            "6      \t [-0.65569297  0.76426403]. \t  0.11477805934642471 \t 0.17807259252024998\n",
            "7      \t [-0.68873864  0.7305229 ]. \t  0.03812114548834189 \t 0.17807259252024998\n",
            "8      \t [-0.70638367  0.71377939]. \t  -0.010624908252659049 \t 0.17807259252024998\n",
            "9      \t [-0.7159207   0.70545399]. \t  -0.03835458573835848 \t 0.17807259252024998\n",
            "10     \t [-0.72107634  0.70145248]. \t  -0.053380216103117495 \t 0.17807259252024998\n",
            "11     \t [-0.72386745  0.69965891]. \t  -0.061295453211591355 \t 0.17807259252024998\n",
            "12     \t [-0.72539802  0.69895923]. \t  -0.06541040141334475 \t 0.17807259252024998\n",
            "13     \t [-0.72626755  0.69877249]. \t  -0.06756884228047177 \t 0.17807259252024998\n",
            "14     \t [-0.72679486  0.69880499]. \t  -0.06875219812754041 \t 0.17807259252024998\n",
            "15     \t [-0.30598848  1.22475754]. \t  -2.9818666112523045 \t 0.17807259252024998\n",
            "16     \t [-0.95847306  0.44456169]. \t  -1.1004123161503379 \t 0.17807259252024998\n",
            "17     \t [-0.91282938  0.49215999]. \t  -0.8843516208198405 \t 0.17807259252024998\n",
            "18     \t [-0.88257932  0.52406362]. \t  -0.7397545209267934 \t 0.17807259252024998\n",
            "19     \t [-0.8617628   0.54621502]. \t  -0.6408404966760168 \t 0.17807259252024998\n",
            "20     \t [-0.84694554  0.56210837]. \t  -0.5711553526153454 \t 0.17807259252024998\n",
            "21     \t [-0.83608697  0.57384424]. \t  -0.5206203099656592 \t 0.17807259252024998\n",
            "22     \t [-0.82792992  0.58272689]. \t  -0.4830052859714895 \t 0.17807259252024998\n",
            "23     \t [-0.82167112  0.58959407]. \t  -0.45436033621361094 \t 0.17807259252024998\n",
            "24     \t [-0.8167812   0.59500071]. \t  -0.43211130352314153 \t 0.17807259252024998\n",
            "25     \t [-0.81290026  0.59932558]. \t  -0.41452991230482417 \t 0.17807259252024998\n",
            "26     \t [-0.80977772  0.60283334]. \t  -0.40042728329598953 \t 0.17807259252024998\n",
            "27     \t [-0.80723482  0.6057136 ]. \t  -0.38896437410590134 \t 0.17807259252024998\n",
            "28     \t [-0.80514156  0.60810429]. \t  -0.37953798638020797 \t 0.17807259252024998\n",
            "29     \t [-0.80340219  0.61010809]. \t  -0.37170599698421636 \t 0.17807259252024998\n",
            "30     \t [-0.80194431  0.61180229]. \t  -0.365137947386712 \t 0.17807259252024998\n",
            "31     \t [-0.80071311  0.613246  ]. \t  -0.35958444659625355 \t 0.17807259252024998\n",
            "32     \t [-0.79966569  0.61448547]. \t  -0.3548517596910996 \t 0.17807259252024998\n",
            "33     \t [-0.79876934  0.61555604]. \t  -0.3507929470681971 \t 0.17807259252024998\n",
            "34     \t [-0.79799738  0.61648688]. \t  -0.3472882060662502 \t 0.17807259252024998\n",
            "35     \t [-0.797329    0.61730049]. \t  -0.3442449880070657 \t 0.17807259252024998\n",
            "36     \t [-0.79674809  0.61801519]. \t  -0.3415901550416657 \t 0.17807259252024998\n",
            "37     \t [-0.79624029  0.61864592]. \t  -0.3392616489206808 \t 0.17807259252024998\n",
            "38     \t [-0.79579438  0.61920535]. \t  -0.3372091730848742 \t 0.17807259252024998\n",
            "39     \t [-0.7954019   0.61970322]. \t  -0.3353944195774201 \t 0.17807259252024998\n",
            "40     \t [-0.79505458  0.62014821]. \t  -0.3337818927090006 \t 0.17807259252024998\n",
            "41     \t [-0.79474657  0.62054725]. \t  -0.332344921159211 \t 0.17807259252024998\n",
            "42     \t [-0.79447249  0.62090626]. \t  -0.3310599842701687 \t 0.17807259252024998\n",
            "43     \t [-0.79422765  0.62123044]. \t  -0.32990648259152755 \t 0.17807259252024998\n",
            "44     \t [-0.79400873  0.62152381]. \t  -0.32886919936199366 \t 0.17807259252024998\n",
            "45     \t [-0.79381211  0.6217903 ]. \t  -0.3279325633208302 \t 0.17807259252024998\n",
            "46     \t [-0.79363523  0.62203285]. \t  -0.3270851319053747 \t 0.17807259252024998\n",
            "47     \t [-0.79347569  0.62225421]. \t  -0.32631633608143595 \t 0.17807259252024998\n",
            "48     \t [-0.79333134  0.62245677]. \t  -0.3256167959939559 \t 0.17807259252024998\n",
            "49     \t [-0.79320072  0.62264248]. \t  -0.32497953625572595 \t 0.17807259252024998\n",
            "50     \t [-0.79308223  0.62281297]. \t  -0.32439785762396167 \t 0.17807259252024998\n",
            "51     \t [-0.7929747   0.62297003]. \t  -0.3238658014034904 \t 0.17807259252024998\n",
            "52     \t [-0.7928763   0.62311517]. \t  -0.3233764509204571 \t 0.17807259252024998\n",
            "53     \t [-0.79278667  0.62324914]. \t  -0.3229275046478568 \t 0.17807259252024998\n",
            "54     \t [-0.79270499  0.62337311]. \t  -0.3225149760205849 \t 0.17807259252024998\n",
            "55     \t [-0.79263037  0.62348795]. \t  -0.32213521528894407 \t 0.17807259252024998\n",
            "56     \t [-0.79256151  0.62359505]. \t  -0.32178275150474533 \t 0.17807259252024998\n",
            "57     \t [-0.79249839  0.62369471]. \t  -0.3214569558148943 \t 0.17807259252024998\n",
            "58     \t [-0.79244035  0.62378739]. \t  -0.32115549799071197 \t 0.17807259252024998\n",
            "59     \t [-0.79238729  0.62387385]. \t  -0.320876684481776 \t 0.17807259252024998\n",
            "60     \t [-0.79233828  0.62395463]. \t  -0.3206174899678512 \t 0.17807259252024998\n",
            "61     \t [-0.79229317  0.62403025]. \t  -0.32037656822227356 \t 0.17807259252024998\n",
            "62     \t [-0.79225135  0.62410124]. \t  -0.32015156811432055 \t 0.17807259252024998\n",
            "63     \t [-0.79221267  0.62416787]. \t  -0.31994169816048246 \t 0.17807259252024998\n",
            "64     \t [-0.79217709  0.6242302 ]. \t  -0.3197467181523622 \t 0.17807259252024998\n",
            "65     \t [-0.79214438  0.62428884]. \t  -0.3195649690558905 \t 0.17807259252024998\n",
            "66     \t [-0.7921132   0.62434463]. \t  -0.31939195577471247 \t 0.17807259252024998\n",
            "67     \t [-0.79208501  0.62439653]. \t  -0.31923278479219563 \t 0.17807259252024998\n",
            "68     \t [-0.79205862  0.62444582]. \t  -0.3190824929084246 \t 0.17807259252024998\n",
            "69     \t [-0.79203415  0.62449218]. \t  -0.3189418993626746 \t 0.17807259252024998\n",
            "70     \t [-0.79201118  0.62453641]. \t  -0.31880861759039303 \t 0.17807259252024998\n",
            "71     \t [-0.79199001  0.62457794]. \t  -0.31868433867318036 \t 0.17807259252024998\n",
            "72     \t [-0.79197043  0.6246172 ]. \t  -0.3185678246395164 \t 0.17807259252024998\n",
            "73     \t [-0.79195223  0.62465452]. \t  -0.3184579726427592 \t 0.17807259252024998\n",
            "74     \t [-0.79193484  0.62469014]. \t  -0.3183530697490792 \t 0.17807259252024998\n",
            "75     \t [-0.79191907  0.62472365]. \t  -0.31825566963081076 \t 0.17807259252024998\n",
            "76     \t [-0.79190409  0.62475556]. \t  -0.3181630403059945 \t 0.17807259252024998\n",
            "77     \t [-0.79189018  0.62478607]. \t  -0.3180753783114977 \t 0.17807259252024998\n",
            "78     \t [-0.79187718  0.62481496]. \t  -0.3179927280849242 \t 0.17807259252024998\n",
            "79     \t [-0.79186481  0.62484271]. \t  -0.31791360657709933 \t 0.17807259252024998\n",
            "80     \t [-0.79185342  0.62486908]. \t  -0.31783923521415514 \t 0.17807259252024998\n",
            "81     \t [-0.79184308  0.62489396]. \t  -0.31776991229148577 \t 0.17807259252024998\n",
            "82     \t [-0.79183303  0.62491807]. \t  -0.3177027070124462 \t 0.17807259252024998\n",
            "83     \t [-0.79182375  0.62494077]. \t  -0.317639828225866 \t 0.17807259252024998\n",
            "84     \t [-0.79181522  0.62496259]. \t  -0.31758023082063414 \t 0.17807259252024998\n",
            "85     \t [-0.79180677  0.62498393]. \t  -0.31752171609201063 \t 0.17807259252024998\n",
            "86     \t [-0.79179917  0.6250039 ]. \t  -0.31746762872569156 \t 0.17807259252024998\n",
            "87     \t [-0.79179228  0.62502288]. \t  -0.31741696573139955 \t 0.17807259252024998\n",
            "88     \t [-0.79178583  0.62504093]. \t  -0.3173689580780711 \t 0.17807259252024998\n",
            "89     \t [-0.79177946  0.62505864]. \t  -0.3173218174632134 \t 0.17807259252024998\n",
            "90     \t [-0.79177389  0.62507531]. \t  -0.31727833939401917 \t 0.17807259252024998\n",
            "91     \t [-0.79176811  0.62509172]. \t  -0.3172349183823908 \t 0.17807259252024998\n",
            "92     \t [-0.79176291  0.6251075 ]. \t  -0.31719395183004784 \t 0.17807259252024998\n",
            "93     \t [-0.79175808  0.6251224 ]. \t  -0.31715542285464515 \t 0.17807259252024998\n",
            "94     \t [-0.79175357  0.62513679]. \t  -0.31711856521043913 \t 0.17807259252024998\n",
            "95     \t [-0.79174933  0.62515067]. \t  -0.31708326466251013 \t 0.17807259252024998\n",
            "96     \t [-0.79174509  0.62516432]. \t  -0.3170483778174633 \t 0.17807259252024998\n",
            "97     \t [-0.79174162  0.62517684]. \t  -0.3170172976592195 \t 0.17807259252024998\n",
            "98     \t [-0.79173826  0.62518903]. \t  -0.3169870697319197 \t 0.17807259252024998\n",
            "99     \t [-0.79173509  0.62520086]. \t  -0.31695793173055 \t 0.17807259252024998\n",
            "100    \t [-0.79173185  0.62521255]. \t  -0.3169288996819093 \t 0.17807259252024998\n"
          ]
        }
      ],
      "source": [
        "### Bayesian optimisation runs (x20): 'GP' Acquisition Function run number = 10\n",
        "\n",
        "np.random.seed(run_num_10)\n",
        "surrogate_gp_10 = GaussianProcess(cov_func, optimize=hyperOpt)\n",
        "\n",
        "gp_10 = GPGO(surrogate_gp_10, Acquisition_new(util_gp), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\n",
        "gp_10.run(max_iter = max_iter, init_evals = n_init) # run\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z6wmPCIEJLk2",
        "outputId": "479a7eef-7332-4c72-df49-fbde17175f14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [-1.91838187 -1.92209903]. \t  -46.39910375151002 \t 0.6254688257880329\n",
            "init   \t [-0.22068884  0.89973572]. \t  0.6254688257880329 \t 0.6254688257880329\n",
            "init   \t [-0.47877837 -0.05829161]. \t  -0.8249470187639529 \t 0.6254688257880329\n",
            "init   \t [-2.92331511 -0.05051357]. \t  -88.99028404075307 \t 0.6254688257880329\n",
            "init   \t [2.65083991 1.40318036]. \t  -51.423425402262914 \t 0.6254688257880329\n",
            "1      \t [ 1.79063726 -2.        ]. \t  -46.64254246955394 \t 0.6254688257880329\n",
            "2      \t [-0.42003216  2.        ]. \t  -47.802108630641015 \t 0.6254688257880329\n",
            "3      \t [ 0.09429169 -0.00574364]. \t  -0.03472439478003897 \t 0.6254688257880329\n",
            "4      \t [ 0.08276052 -0.00260124]. \t  -0.027056458121901918 \t 0.6254688257880329\n",
            "5      \t [ 0.07672207 -0.00090945]. \t  -0.023399329995854014 \t 0.6254688257880329\n",
            "6      \t [0.0730166  0.00015318]. \t  -0.02127714539359677 \t 0.6254688257880329\n",
            "7      \t [0.07052171 0.00088308]. \t  -0.019900505534536265 \t 0.6254688257880329\n",
            "8      \t [0.06873442 0.00141516]. \t  -0.018940105857391754 \t 0.6254688257880329\n",
            "9      \t [0.06739555 0.00182003]. \t  -0.01823475882326874 \t 0.6254688257880329\n",
            "10     \t [0.06635777 0.00213815]. \t  -0.01769632390421982 \t 0.6254688257880329\n",
            "11     \t [0.06553175 0.0023946 ]. \t  -0.01727292372625328 \t 0.6254688257880329\n",
            "12     \t [0.0648599  0.00260561]. \t  -0.01693192973467238 \t 0.6254688257880329\n",
            "13     \t [0.0643037  0.00278216]. \t  -0.01665192405195861 \t 0.6254688257880329\n",
            "14     \t [0.06383619 0.00293198]. \t  -0.016418167263080888 \t 0.6254688257880329\n",
            "15     \t [0.0634383  0.00306065]. \t  -0.01622037378725258 \t 0.6254688257880329\n",
            "16     \t [0.06309589 0.00317237]. \t  -0.016051011862823126 \t 0.6254688257880329\n",
            "17     \t [0.06279841 0.00327017]. \t  -0.015904507264032468 \t 0.6254688257880329\n",
            "18     \t [0.06253769 0.00335651]. \t  -0.01577659638393243 \t 0.6254688257880329\n",
            "19     \t [0.0623075  0.00343324]. \t  -0.015664036522160803 \t 0.6254688257880329\n",
            "20     \t [0.06210304 0.003502  ]. \t  -0.015564361003758038 \t 0.6254688257880329\n",
            "21     \t [0.0619202  0.00356376]. \t  -0.015475460212604143 \t 0.6254688257880329\n",
            "22     \t [0.06175588 0.00361966]. \t  -0.015395755183792822 \t 0.6254688257880329\n",
            "23     \t [0.06160743 0.00367046]. \t  -0.015323908956072612 \t 0.6254688257880329\n",
            "24     \t [0.06147272 0.00371677]. \t  -0.015258835670276822 \t 0.6254688257880329\n",
            "25     \t [0.06135001 0.00375918]. \t  -0.01519966178824247 \t 0.6254688257880329\n",
            "26     \t [0.06123773 0.00379816]. \t  -0.01514561344290725 \t 0.6254688257880329\n",
            "27     \t [0.0611348  0.00383413]. \t  -0.015096135046006117 \t 0.6254688257880329\n",
            "28     \t [0.06103999 0.00386739]. \t  -0.01505062439572872 \t 0.6254688257880329\n",
            "29     \t [0.06095245 0.00389827]. \t  -0.01500866127926681 \t 0.6254688257880329\n",
            "30     \t [0.0608714  0.00392691]. \t  -0.014969850837042985 \t 0.6254688257880329\n",
            "31     \t [0.06079615 0.00395367]. \t  -0.014933858974638786 \t 0.6254688257880329\n",
            "32     \t [0.06072615 0.00397867]. \t  -0.014900410234263441 \t 0.6254688257880329\n",
            "33     \t [0.08375994 0.75936217]. \t  \u001b[92m0.884947022527404\u001b[0m \t 0.884947022527404\n",
            "34     \t [0.10800535 0.13273593]. \t  0.008522033645879272 \t 0.884947022527404\n",
            "35     \t [0.10654345 0.13147675]. \t  0.008805404500632705 \t 0.884947022527404\n",
            "36     \t [0.10522344 0.13032551]. \t  0.009040827804697248 \t 0.884947022527404\n",
            "37     \t [0.10402599 0.12926887]. \t  0.009237356774566455 \t 0.884947022527404\n",
            "38     \t [0.10293533 0.12829538]. \t  0.009401638003848356 \t 0.884947022527404\n",
            "39     \t [0.10193822 0.12739555]. \t  0.009539215743501736 \t 0.884947022527404\n",
            "40     \t [0.10102343 0.12656131]. \t  0.009654565399495038 \t 0.884947022527404\n",
            "41     \t [0.10018155 0.1257857 ]. \t  0.009751231363086615 \t 0.884947022527404\n",
            "42     \t [0.09940454 0.12506273]. \t  0.009832092162976439 \t 0.884947022527404\n",
            "43     \t [0.09868533 0.12438723]. \t  0.00989967226457742 \t 0.884947022527404\n",
            "44     \t [0.0980181  0.12375471]. \t  0.009955845242850814 \t 0.884947022527404\n",
            "45     \t [0.09739749 0.12316113]. \t  0.010002322757245656 \t 0.884947022527404\n",
            "46     \t [0.09681905 0.12260304]. \t  0.010040467249840472 \t 0.884947022527404\n",
            "47     \t [0.09627886 0.12207748]. \t  0.010071481663613754 \t 0.884947022527404\n",
            "48     \t [0.09577334 0.12158159]. \t  0.010096312552126063 \t 0.884947022527404\n",
            "49     \t [0.09529943 0.121113  ]. \t  0.010115822971567767 \t 0.884947022527404\n",
            "50     \t [0.0948545  0.12066953]. \t  0.010130639744738733 \t 0.884947022527404\n",
            "51     \t [0.09443593 0.12024921]. \t  0.010141498337859309 \t 0.884947022527404\n",
            "52     \t [0.09404164 0.11985034]. \t  0.01014887863697541 \t 0.884947022527404\n",
            "53     \t [0.09366965 0.11947131]. \t  0.010153255199901269 \t 0.884947022527404\n",
            "54     \t [0.09331826 0.11911074]. \t  0.01015498060171064 \t 0.884947022527404\n",
            "55     \t [0.09298591 0.11876728]. \t  0.010154366495136784 \t 0.884947022527404\n",
            "56     \t [0.09267108 0.11843978]. \t  0.010151798165934964 \t 0.884947022527404\n",
            "57     \t [0.09237261 0.11812721]. \t  0.010147459613363462 \t 0.884947022527404\n",
            "58     \t [0.09208922 0.11782849]. \t  0.01014159156011591 \t 0.884947022527404\n",
            "59     \t [0.09181998 0.11754285]. \t  0.01013437847122757 \t 0.884947022527404\n",
            "60     \t [0.09156375 0.11726936]. \t  0.010126035822464623 \t 0.884947022527404\n",
            "61     \t [0.09131984 0.11700744]. \t  0.010116720664925284 \t 0.884947022527404\n",
            "62     \t [0.09108731 0.11675625]. \t  0.010106521710998018 \t 0.884947022527404\n",
            "63     \t [0.09086551 0.11651516]. \t  0.010095522507659153 \t 0.884947022527404\n",
            "64     \t [0.09065369 0.11628363]. \t  0.010083905749906905 \t 0.884947022527404\n",
            "65     \t [0.09045126 0.11606111]. \t  0.010071731323971218 \t 0.884947022527404\n",
            "66     \t [0.09025767 0.11584707]. \t  0.01005904343946687 \t 0.884947022527404\n",
            "67     \t [0.09007236 0.11564107]. \t  0.010045959046941354 \t 0.884947022527404\n",
            "68     \t [0.08989483 0.11544266]. \t  0.010032539294924987 \t 0.884947022527404\n",
            "69     \t [0.08972466 0.11525147]. \t  0.010018833469646313 \t 0.884947022527404\n",
            "70     \t [0.08956143 0.11506711]. \t  0.01000489333354325 \t 0.884947022527404\n",
            "71     \t [0.08940472 0.1148892 ]. \t  0.009990746575203352 \t 0.884947022527404\n",
            "72     \t [0.0892542  0.11471744]. \t  0.009976446905307162 \t 0.884947022527404\n",
            "73     \t [0.08910952 0.11455153]. \t  0.00996203978679018 \t 0.884947022527404\n",
            "74     \t [0.08897038 0.11439116]. \t  0.00994752658567831 \t 0.884947022527404\n",
            "75     \t [0.0888365  0.11423612]. \t  0.00993295996981456 \t 0.884947022527404\n",
            "76     \t [0.08870755 0.1140861 ]. \t  0.009918380836272181 \t 0.884947022527404\n",
            "77     \t [0.08858335 0.1139409 ]. \t  0.009903766619476964 \t 0.884947022527404\n",
            "78     \t [0.08846363 0.11380022]. \t  0.009889115222518688 \t 0.884947022527404\n",
            "79     \t [0.08834812 0.11366399]. \t  0.009874570774275601 \t 0.884947022527404\n",
            "80     \t [0.08823671 0.1135319 ]. \t  0.009860006360438572 \t 0.884947022527404\n",
            "81     \t [0.08812911 0.11340384]. \t  0.009845544589144675 \t 0.884947022527404\n",
            "82     \t [0.08802526 0.11327957]. \t  0.009831056090668103 \t 0.884947022527404\n",
            "83     \t [0.08792484 0.11315898]. \t  0.009816703020717021 \t 0.884947022527404\n",
            "84     \t [0.08782783 0.1130419 ]. \t  0.009802398369816785 \t 0.884947022527404\n",
            "85     \t [0.08773392 0.11292815]. \t  0.00978821167165933 \t 0.884947022527404\n",
            "86     \t [0.08764305 0.11281763]. \t  0.009774136853165187 \t 0.884947022527404\n",
            "87     \t [0.08755515 0.11271023]. \t  0.009760140394683953 \t 0.884947022527404\n",
            "88     \t [0.08746999 0.1126058 ]. \t  0.009746280652852553 \t 0.884947022527404\n",
            "89     \t [0.0873875  0.11250417]. \t  0.009732497217865357 \t 0.884947022527404\n",
            "90     \t [0.08730755 0.11240531]. \t  0.00971885975792467 \t 0.884947022527404\n",
            "91     \t [0.08723004 0.11230908]. \t  0.009705326508829569 \t 0.884947022527404\n",
            "92     \t [0.08715488 0.11221541]. \t  0.009691941028241474 \t 0.884947022527404\n",
            "93     \t [0.08708195 0.11212416]. \t  0.009678663627716223 \t 0.884947022527404\n",
            "94     \t [0.08701113 0.11203522]. \t  0.009665529712287922 \t 0.884947022527404\n",
            "95     \t [0.08694243 0.11194859]. \t  0.00965251161003551 \t 0.884947022527404\n",
            "96     \t [0.08687565 0.11186413]. \t  0.009639665657953059 \t 0.884947022527404\n",
            "97     \t [0.08681083 0.11178172]. \t  0.009626873104825004 \t 0.884947022527404\n",
            "98     \t [0.08674782 0.11170137]. \t  0.00961425714858015 \t 0.884947022527404\n",
            "99     \t [0.08668654 0.11162297]. \t  0.009601782010412917 \t 0.884947022527404\n",
            "100    \t [0.08662694 0.11154645]. \t  0.00958944406826863 \t 0.884947022527404\n"
          ]
        }
      ],
      "source": [
        "### Bayesian optimisation runs (x20): 'GP' Acquisition Function run number = 11\n",
        "\n",
        "np.random.seed(run_num_11)\n",
        "surrogate_gp_11 = GaussianProcess(cov_func, optimize=hyperOpt)\n",
        "\n",
        "gp_11 = GPGO(surrogate_gp_11, Acquisition_new(util_gp), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\n",
        "gp_11.run(max_iter = max_iter, init_evals = n_init) # run\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oNR6-n7iJLk3",
        "outputId": "6b19d874-0587-4a34-e6c6-6935333c610e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [-2.07502295  0.96019879]. \t  -2.6185857163917037 \t -1.9967735906956543\n",
            "init   \t [-1.42010991  0.13495757]. \t  -1.9967735906956543 \t -1.9967735906956543\n",
            "init   \t [-2.91255023  1.67498803]. \t  -101.67816714332157 \t -1.9967735906956543\n",
            "init   \t [ 2.40428912 -1.86631429]. \t  -47.44624883788006 \t -1.9967735906956543\n",
            "init   \t [ 2.74169602 -1.45116271]. \t  -58.32400185681089 \t -1.9967735906956543\n",
            "1      \t [-1.2477584  0.9198662]. \t  \u001b[92m-0.7267928205662857\u001b[0m \t -0.7267928205662857\n",
            "2      \t [1.77328709 2.        ]. \t  -53.72420422974635 \t -0.7267928205662857\n",
            "3      \t [-3. -2.]. \t  -162.89999999999998 \t -0.7267928205662857\n",
            "4      \t [-0.16304956 -2.        ]. \t  -48.43096180942048 \t -0.7267928205662857\n",
            "5      \t [-0.56695593  2.        ]. \t  -47.94593653385309 \t -0.7267928205662857\n",
            "6      \t [-1.22619909  0.24116394]. \t  -1.884989355487105 \t -0.7267928205662857\n",
            "7      \t [-1.23740627  0.24737985]. \t  -1.8619519445127457 \t -0.7267928205662857\n",
            "8      \t [-1.24382499  0.25108121]. \t  -1.8477775994154804 \t -0.7267928205662857\n",
            "9      \t [-1.24793586  0.25353426]. \t  -1.838237161079374 \t -0.7267928205662857\n",
            "10     \t [-1.25076386  0.2552739 ]. \t  -1.8314187137350353 \t -0.7267928205662857\n",
            "11     \t [-1.25281067  0.25656816]. \t  -1.8263269968720162 \t -0.7267928205662857\n",
            "12     \t [-1.25434977  0.25756599]. \t  -1.8223954749547144 \t -0.7267928205662857\n",
            "13     \t [-1.25554236  0.25835712]. \t  -1.8192777795670723 \t -0.7267928205662857\n",
            "14     \t [-1.25648884  0.25899844]. \t  -1.8167519938742611 \t -0.7267928205662857\n",
            "15     \t [-1.25725512  0.25952795]. \t  -1.814668821955692 \t -0.7267928205662857\n",
            "16     \t [-1.25788601  0.25997199]. \t  -1.8129243613401607 \t -0.7267928205662857\n",
            "17     \t [-1.25841299  0.26034918]. \t  -1.8114447653373398 \t -0.7267928205662857\n",
            "18     \t [ 0.79076378 -0.00087141]. \t  -1.7609181373909566 \t -0.7267928205662857\n",
            "19     \t [-1.20363263  0.25549943]. \t  -1.8493400418535981 \t -0.7267928205662857\n",
            "20     \t [-1.20612717  0.25598424]. \t  -1.847317400070459 \t -0.7267928205662857\n",
            "21     \t [3.         0.50859394]. \t  -109.65874675377847 \t -0.7267928205662857\n",
            "22     \t [-1.15956699  0.25056742]. \t  -1.8661103632897598 \t -0.7267928205662857\n",
            "23     \t [-1.16434637  0.25128702]. \t  -1.8645037421129635 \t -0.7267928205662857\n",
            "24     \t [-1.16832303  0.25189023]. \t  -1.8630111432757743 \t -0.7267928205662857\n",
            "25     \t [-1.17167558  0.25240267]. \t  -1.8616407962596737 \t -0.7267928205662857\n",
            "26     \t [-1.17453573  0.25284382]. \t  -1.8603874270695826 \t -0.7267928205662857\n",
            "27     \t [-1.17699939  0.25322746]. \t  -1.8592435821040123 \t -0.7267928205662857\n",
            "28     \t [-1.17914021  0.2535638 ]. \t  -1.858200728363269 \t -0.7267928205662857\n",
            "29     \t [-1.18101434  0.2538613 ]. \t  -1.8572480983825461 \t -0.7267928205662857\n",
            "30     \t [-1.18266744  0.25412547]. \t  -1.856378899098228 \t -0.7267928205662857\n",
            "31     \t [-1.18413279  0.25436244]. \t  -1.855581584977243 \t -0.7267928205662857\n",
            "32     \t [-1.18544014  0.25457566]. \t  -1.854850171553537 \t -0.7267928205662857\n",
            "33     \t [-1.18661031  0.2547684 ]. \t  -1.8541781575217566 \t -0.7267928205662857\n",
            "34     \t [-1.18766361  0.25494338]. \t  -1.8535593033147335 \t -0.7267928205662857\n",
            "35     \t [-1.18861731  0.25510355]. \t  -1.852986086502298 \t -0.7267928205662857\n",
            "36     \t [-1.18948209  0.25524989]. \t  -1.8524566474929598 \t -0.7267928205662857\n",
            "37     \t [-1.19026891  0.25538397]. \t  -1.8519668738540358 \t -0.7267928205662857\n",
            "38     \t [-1.19098862  0.25550827]. \t  -1.8515096064538679 \t -0.7267928205662857\n",
            "39     \t [-1.19164578  0.25562215]. \t  -1.8510872384247499 \t -0.7267928205662857\n",
            "40     \t [-1.19225218  0.2557287 ]. \t  -1.8506900359278942 \t -0.7267928205662857\n",
            "41     \t [-1.19280752  0.25582736]. \t  -1.8503204424494948 \t -0.7267928205662857\n",
            "42     \t [-1.19332516  0.25591945]. \t  -1.8499733343237623 \t -0.7267928205662857\n",
            "43     \t [-1.19380179  0.2560051 ]. \t  -1.849649215326626 \t -0.7267928205662857\n",
            "44     \t [-1.19424522  0.2560854 ]. \t  -1.8493442154464432 \t -0.7267928205662857\n",
            "45     \t [-1.19465405  0.25616107]. \t  -1.8490567127927815 \t -0.7267928205662857\n",
            "46     \t [-1.19503768  0.25623089]. \t  -1.848789250841754 \t -0.7267928205662857\n",
            "47     \t [-1.19539454  0.25629716]. \t  -1.8485354179861908 \t -0.7267928205662857\n",
            "48     \t [-1.19572919  0.25635971]. \t  -1.8482952626178462 \t -0.7267928205662857\n",
            "49     \t [-1.19604447  0.25641829]. \t  -1.8480692102633578 \t -0.7267928205662857\n",
            "50     \t [-1.19633499  0.25647407]. \t  -1.847854820339104 \t -0.7267928205662857\n",
            "51     \t [-1.19661044  0.25652696]. \t  -1.8476509108712982 \t -0.7267928205662857\n",
            "52     \t [-1.1968681   0.25657646]. \t  -1.8474595393964155 \t -0.7267928205662857\n",
            "53     \t [-1.19711276  0.25662366]. \t  -1.8472767098474578 \t -0.7267928205662857\n",
            "54     \t [-1.19734322  0.25666761]. \t  -1.8471056056013109 \t -0.7267928205662857\n",
            "55     \t [-1.19756072  0.25671173]. \t  -1.8469358353221992 \t -0.7267928205662857\n",
            "56     \t [-1.19776618  0.25675261]. \t  -1.8467774676643396 \t -0.7267928205662857\n",
            "57     \t [-1.19796032  0.25679104]. \t  -1.8466281220243197 \t -0.7267928205662857\n",
            "58     \t [-1.19814467  0.25682805]. \t  -1.8464844726260714 \t -0.7267928205662857\n",
            "59     \t [-1.19831899  0.25686322]. \t  -1.846347883423829 \t -0.7267928205662857\n",
            "60     \t [-1.19848454  0.25689677]. \t  -1.8462174581823239 \t -0.7267928205662857\n",
            "61     \t [-1.1986425   0.25692904]. \t  -1.8460920436356103 \t -0.7267928205662857\n",
            "62     \t [-1.19879252  0.25695994]. \t  -1.8459720057168856 \t -0.7267928205662857\n",
            "63     \t [-1.19893426  0.25699043]. \t  -1.8458545577405907 \t -0.7267928205662857\n",
            "64     \t [-1.19907098  0.25701765]. \t  -1.8457476418655858 \t -0.7267928205662857\n",
            "65     \t [-1.19920067  0.25704481]. \t  -1.8456420813906134 \t -0.7267928205662857\n",
            "66     \t [-1.19932425  0.25707075]. \t  -1.8455411817591627 \t -0.7267928205662857\n",
            "67     \t [-1.19944255  0.25709612]. \t  -1.8454428930464708 \t -0.7267928205662857\n",
            "68     \t [-1.19955531  0.25711988]. \t  -1.845350355968458 \t -0.7267928205662857\n",
            "69     \t [-1.19966222  0.25714154]. \t  -1.8452650839594995 \t -0.7267928205662857\n",
            "70     \t [-1.19976748  0.25716543]. \t  -1.8451734169183136 \t -0.7267928205662857\n",
            "71     \t [-1.19986713  0.25718719]. \t  -1.8450890812650735 \t -0.7267928205662857\n",
            "72     \t [-1.19996156  0.25720756]. \t  -1.8450098483446253 \t -0.7267928205662857\n",
            "73     \t [-1.20005356  0.25722714]. \t  -1.8449333759263435 \t -0.7267928205662857\n",
            "74     \t [-1.20013857  0.25724777]. \t  -1.8448550680106408 \t -0.7267928205662857\n",
            "75     \t [-1.20022435  0.25726611]. \t  -1.8447834160434589 \t -0.7267928205662857\n",
            "76     \t [-1.20030524  0.25728341]. \t  -1.8447157399658172 \t -0.7267928205662857\n",
            "77     \t [-1.20038398  0.25730019]. \t  -1.844650027468977 \t -0.7267928205662857\n",
            "78     \t [-1.20045182  0.2573163 ]. \t  -1.8445883987566223 \t -0.7267928205662857\n",
            "79     \t [-1.20052494  0.25733748]. \t  -1.8445105473884933 \t -0.7267928205662857\n",
            "80     \t [-1.2005992   0.25734923]. \t  -1.8444606016431588 \t -0.7267928205662857\n",
            "81     \t [-1.20066571  0.25736427]. \t  -1.8444023145441362 \t -0.7267928205662857\n",
            "82     \t [-1.20073182  0.25737818]. \t  -1.8443474716258659 \t -0.7267928205662857\n",
            "83     \t [-1.2007913   0.25739386]. \t  -1.8442886471910165 \t -0.7267928205662857\n",
            "84     \t [-1.2008512   0.25740743]. \t  -1.8442360112700633 \t -0.7267928205662857\n",
            "85     \t [-1.2009094   0.25742079]. \t  -1.8441843037614727 \t -0.7267928205662857\n",
            "86     \t [-1.20096674  0.2574327 ]. \t  -1.844137085747719 \t -0.7267928205662857\n",
            "87     \t [-1.20101912  0.25744728]. \t  -1.8440828542449066 \t -0.7267928205662857\n",
            "88     \t [-1.20107204  0.25745888]. \t  -1.8440374247905615 \t -0.7267928205662857\n",
            "89     \t [-1.20112301  0.25747064]. \t  -1.843991853114101 \t -0.7267928205662857\n",
            "90     \t [-1.20116665  0.25748135]. \t  -1.8439509173120041 \t -0.7267928205662857\n",
            "91     \t [-1.20121886  0.25749365]. \t  -1.8439034858385484 \t -0.7267928205662857\n",
            "92     \t [-1.20126467  0.25750463]. \t  -1.8438612597390045 \t -0.7267928205662857\n",
            "93     \t [-1.20131091  0.25751467]. \t  -1.8438217282252092 \t -0.7267928205662857\n",
            "94     \t [-1.20135224  0.25752563]. \t  -1.8437804508228028 \t -0.7267928205662857\n",
            "95     \t [-1.2013928   0.25753606]. \t  -1.8437409107934775 \t -0.7267928205662857\n",
            "96     \t [-1.20143168  0.25754534]. \t  -1.84370514316805 \t -0.7267928205662857\n",
            "97     \t [-1.20147288  0.25755514]. \t  -1.843667324380859 \t -0.7267928205662857\n",
            "98     \t [-1.20151306  0.2575633 ]. \t  -1.8436346236123133 \t -0.7267928205662857\n",
            "99     \t [-1.20154839  0.25757328]. \t  -1.843597464340807 \t -0.7267928205662857\n",
            "100    \t [-1.20158348  0.25758246]. \t  -1.8435627108394337 \t -0.7267928205662857\n"
          ]
        }
      ],
      "source": [
        "### Bayesian optimisation runs (x20): 'GP' Acquisition Function run number = 12\n",
        "\n",
        "np.random.seed(run_num_12)\n",
        "surrogate_gp_12 = GaussianProcess(cov_func, optimize=hyperOpt)\n",
        "\n",
        "gp_12 = GPGO(surrogate_gp_12, Acquisition_new(util_gp), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\n",
        "gp_12.run(max_iter = max_iter, init_evals = n_init) # run\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1CyiX30JLk4",
        "outputId": "b126ee85-e2e9-4f0d-f9bb-da6cd86ff951"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 1.66621446 -1.04983512]. \t  -0.752930921147986 \t -0.752930921147986\n",
            "init   \t [1.9456712  1.86299679]. \t  -41.05776363102951 \t -0.752930921147986\n",
            "init   \t [ 2.83560668 -0.18620301]. \t  -69.0134544723513 \t -0.752930921147986\n",
            "init   \t [0.65425478 1.10210606]. \t  -3.117452174069064 \t -0.752930921147986\n",
            "init   \t [0.84968007 0.88807292]. \t  -2.006601529383926 \t -0.752930921147986\n",
            "1      \t [ 0.68819929 -1.55983024]. \t  -14.332396382766602 \t -0.752930921147986\n",
            "2      \t [-3.         0.1441294]. \t  -108.386244780951 \t -0.752930921147986\n",
            "3      \t [-1.18947978  2.        ]. \t  -48.0207425461905 \t -0.752930921147986\n",
            "4      \t [0.31737209 0.12269227]. \t  \u001b[92m-0.3615671266530721\u001b[0m \t -0.3615671266530721\n",
            "5      \t [0.3208117  0.12860491]. \t  -0.3659948524789032 \t -0.3615671266530721\n",
            "6      \t [0.32255309 0.13164693]. \t  -0.368146996144656 \t -0.3615671266530721\n",
            "7      \t [0.32360629 0.13350142]. \t  -0.3694192590924201 \t -0.3615671266530721\n",
            "8      \t [0.3243114  0.13474868]. \t  -0.37025881211757006 \t -0.3615671266530721\n",
            "9      \t [0.32481599 0.13564368]. \t  -0.3708537764677314 \t -0.3615671266530721\n",
            "10     \t [0.32519468 0.13631648]. \t  -0.3712972601424728 \t -0.3615671266530721\n",
            "11     \t [0.32548913 0.13684013]. \t  -0.37164038172839586 \t -0.3615671266530721\n",
            "12     \t [0.32572438 0.13725887]. \t  -0.37191341733338695 \t -0.3615671266530721\n",
            "13     \t [0.32591664 0.13760115]. \t  -0.3721359312973041 \t -0.3615671266530721\n",
            "14     \t [0.32607654 0.1378859 ]. \t  -0.3723205665255405 \t -0.3615671266530721\n",
            "15     \t [0.32621159 0.13812648]. \t  -0.3724761927685001 \t -0.3615671266530721\n",
            "16     \t [0.32632714 0.13833225]. \t  -0.37260918647090335 \t -0.3615671266530721\n",
            "17     \t [0.32642708 0.1385102 ]. \t  -0.37272408871651735 \t -0.3615671266530721\n",
            "18     \t [0.32651428 0.13866561]. \t  -0.37282415480085473 \t -0.3615671266530721\n",
            "19     \t [0.32659118 0.13880233]. \t  -0.37291253442128536 \t -0.3615671266530721\n",
            "20     \t [0.32665928 0.13892355]. \t  -0.3729906395806077 \t -0.3615671266530721\n",
            "21     \t [0.32672019 0.13903187]. \t  -0.3730605003381726 \t -0.3615671266530721\n",
            "22     \t [0.32677485 0.1391291 ]. \t  -0.37312315133517504 \t -0.3615671266530721\n",
            "23     \t [0.3268242  0.13921684]. \t  -0.37317970168155373 \t -0.3615671266530721\n",
            "24     \t [0.326869   0.13929644]. \t  -0.3732310523582919 \t -0.3615671266530721\n",
            "25     \t [0.32690979 0.13936894]. \t  -0.37327776485077757 \t -0.3615671266530721\n",
            "26     \t [0.32694712 0.13943528]. \t  -0.37332051590982773 \t -0.3615671266530721\n",
            "27     \t [0.32698141 0.13949616]. \t  -0.37335978585909024 \t -0.3615671266530721\n",
            "28     \t [0.32701302 0.13955225]. \t  -0.37339603733977533 \t -0.3615671266530721\n",
            "29     \t [0.32704219 0.13960402]. \t  -0.373429438226607 \t -0.3615671266530721\n",
            "30     \t [0.32706924 0.139652  ]. \t  -0.37346042162639265 \t -0.3615671266530721\n",
            "31     \t [0.32709435 0.13969661]. \t  -0.3734891298289199 \t -0.3615671266530721\n",
            "32     \t [0.32711786 0.139738  ]. \t  -0.37351629116162477 \t -0.3615671266530721\n",
            "33     \t [0.32713969 0.13977689]. \t  -0.37354115462970894 \t -0.3615671266530721\n",
            "34     \t [0.32716017 0.13981322]. \t  -0.3735645944635737 \t -0.3615671266530721\n",
            "35     \t [0.32717941 0.13984722]. \t  -0.37358668931194217 \t -0.3615671266530721\n",
            "36     \t [0.32719748 0.13987924]. \t  -0.3736073968370037 \t -0.3615671266530721\n",
            "37     \t [0.32721442 0.13990925]. \t  -0.3736267999329165 \t -0.3615671266530721\n",
            "38     \t [0.32723044 0.1399376 ]. \t  -0.3736451550902033 \t -0.3615671266530721\n",
            "39     \t [0.32724556 0.13996435]. \t  -0.3736625141859665 \t -0.3615671266530721\n",
            "40     \t [0.32725993 0.13998968]. \t  -0.3736790453773649 \t -0.3615671266530721\n",
            "41     \t [0.32727344 0.14001361]. \t  -0.3736945051206637 \t -0.3615671266530721\n",
            "42     \t [0.32728632 0.14003638]. \t  -0.3737092871120813 \t -0.3615671266530721\n",
            "43     \t [0.32729851 0.14005792]. \t  -0.3737232661956151 \t -0.3615671266530721\n",
            "44     \t [0.3273101  0.14007846]. \t  -0.3737365249414199 \t -0.3615671266530721\n",
            "45     \t [0.32732122 0.140098  ]. \t  -0.37374936501174183 \t -0.3615671266530721\n",
            "46     \t [0.32733175 0.14011665]. \t  -0.3737614269639674 \t -0.3615671266530721\n",
            "47     \t [0.32734181 0.14013442]. \t  -0.3737729583691506 \t -0.3615671266530721\n",
            "48     \t [0.32735142 0.14015134]. \t  -0.3737840321800971 \t -0.3615671266530721\n",
            "49     \t [0.32736062 0.14016757]. \t  -0.37379461569775124 \t -0.3615671266530721\n",
            "50     \t [0.32736939 0.14018311]. \t  -0.3738046406162243 \t -0.3615671266530721\n",
            "51     \t [0.32737781 0.14019796]. \t  -0.37381431480831645 \t -0.3615671266530721\n",
            "52     \t [0.32738592 0.14021222]. \t  -0.3738236474077778 \t -0.3615671266530721\n",
            "53     \t [0.32739369 0.14022593]. \t  -0.37383257328813424 \t -0.3615671266530721\n",
            "54     \t [0.32740113 0.14023898]. \t  -0.37384117471273265 \t -0.3615671266530721\n",
            "55     \t [0.3274083  0.14025159]. \t  -0.3738494537442434 \t -0.3615671266530721\n",
            "56     \t [0.32741518 0.14026374]. \t  -0.3738573257621354 \t -0.3615671266530721\n",
            "57     \t [0.3274218  0.14027542]. \t  -0.37386494657238933 \t -0.3615671266530721\n",
            "58     \t [0.32742817 0.14028664]. \t  -0.37387225223695664 \t -0.3615671266530721\n",
            "59     \t [0.32743433 0.14029746]. \t  -0.37387937220593 \t -0.3615671266530721\n",
            "60     \t [0.32744011 0.14030822]. \t  -0.3738855886985839 \t -0.3615671266530721\n",
            "61     \t [0.32744598 0.14031794]. \t  -0.3738927858897701 \t -0.3615671266530721\n",
            "62     \t [0.3274515  0.14032771]. \t  -0.3738991120778877 \t -0.3615671266530721\n",
            "63     \t [0.32745684 0.14033709]. \t  -0.37390526080628067 \t -0.3615671266530721\n",
            "64     \t [0.32746204 0.14034617]. \t  -0.3739113140838877 \t -0.3615671266530721\n",
            "65     \t [0.32746704 0.14035495]. \t  -0.3739170627765881 \t -0.3615671266530721\n",
            "66     \t [0.32747187 0.14036346]. \t  -0.3739226152998072 \t -0.3615671266530721\n",
            "67     \t [0.32747654 0.14037165]. \t  -0.3739280186795477 \t -0.3615671266530721\n",
            "68     \t [0.32748106 0.14037957]. \t  -0.3739332433312456 \t -0.3615671266530721\n",
            "69     \t [0.32748548 0.14038732]. \t  -0.3739383547133527 \t -0.3615671266530721\n",
            "70     \t [0.32748972 0.14039484]. \t  -0.3739431796513506 \t -0.3615671266530721\n",
            "71     \t [0.32749386 0.1404021 ]. \t  -0.37394797096151333 \t -0.3615671266530721\n",
            "72     \t [0.32749786 0.14040911]. \t  -0.3739526013865254 \t -0.3615671266530721\n",
            "73     \t [0.32750175 0.14041594]. \t  -0.3739570866233429 \t -0.3615671266530721\n",
            "74     \t [0.32750555 0.14042259]. \t  -0.37396148705419086 \t -0.3615671266530721\n",
            "75     \t [0.32750921 0.140429  ]. \t  -0.3739657053172737 \t -0.3615671266530721\n",
            "76     \t [0.32751276 0.14043525]. \t  -0.37396980036448463 \t -0.3615671266530721\n",
            "77     \t [0.32751625 0.14044137]. \t  -0.37397382498209797 \t -0.3615671266530721\n",
            "78     \t [0.32751965 0.14044732]. \t  -0.3739777570272546 \t -0.3615671266530721\n",
            "79     \t [0.32752296 0.14045311]. \t  -0.37398160509174927 \t -0.3615671266530721\n",
            "80     \t [0.32752619 0.14045873]. \t  -0.37398535440258257 \t -0.3615671266530721\n",
            "81     \t [0.32752926 0.14046415]. \t  -0.37398886549742716 \t -0.3615671266530721\n",
            "82     \t [0.32753232 0.14046948]. \t  -0.3739924349130218 \t -0.3615671266530721\n",
            "83     \t [0.32753527 0.14047471]. \t  -0.3739957999791062 \t -0.3615671266530721\n",
            "84     \t [0.32753819 0.14047966]. \t  -0.3739992833620456 \t -0.3615671266530721\n",
            "85     \t [0.32754098 0.14048464]. \t  -0.37400244440596836 \t -0.3615671266530721\n",
            "86     \t [0.32754371 0.14048944]. \t  -0.3740055871814238 \t -0.3615671266530721\n",
            "87     \t [0.32754637 0.14049415]. \t  -0.3740086413731091 \t -0.3615671266530721\n",
            "88     \t [0.327549   0.14049874]. \t  -0.37401167418848064 \t -0.3615671266530721\n",
            "89     \t [0.32755157 0.14050319]. \t  -0.3740146813838613 \t -0.3615671266530721\n",
            "90     \t [0.32755403 0.14050753]. \t  -0.37401752137208977 \t -0.3615671266530721\n",
            "91     \t [0.32755645 0.14051175]. \t  -0.37402031753611986 \t -0.3615671266530721\n",
            "92     \t [0.32755886 0.14051594]. \t  -0.3740231248757619 \t -0.3615671266530721\n",
            "93     \t [0.32756118 0.14052002]. \t  -0.37402581011205127 \t -0.3615671266530721\n",
            "94     \t [0.32756345 0.140524  ]. \t  -0.3740284367524328 \t -0.3615671266530721\n",
            "95     \t [0.3275657  0.14052783]. \t  -0.37403110729548217 \t -0.3615671266530721\n",
            "96     \t [0.32756785 0.14053164]. \t  -0.3740335482063316 \t -0.3615671266530721\n",
            "97     \t [0.32756996 0.14053536]. \t  -0.3740359790975321 \t -0.3615671266530721\n",
            "98     \t [0.32757211 0.14053902]. \t  -0.3740385504032503 \t -0.3615671266530721\n",
            "99     \t [0.32757407 0.14054255]. \t  -0.37404073905022955 \t -0.3615671266530721\n",
            "100    \t [0.32757607 0.14054603]. \t  -0.3740430535485027 \t -0.3615671266530721\n"
          ]
        }
      ],
      "source": [
        "### Bayesian optimisation runs (x20): 'GP' Acquisition Function run number = 13\n",
        "\n",
        "np.random.seed(run_num_13)\n",
        "surrogate_gp_13 = GaussianProcess(cov_func, optimize=hyperOpt)\n",
        "\n",
        "gp_13 = GPGO(surrogate_gp_13, Acquisition_new(util_gp), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\n",
        "gp_13.run(max_iter = max_iter, init_evals = n_init) # run\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dx5l3xHMJLk5",
        "outputId": "ed32586d-4ec1-452f-f1ab-96e64df7612a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.08366006 1.09266021]. \t  -1.0453292732107575 \t 1.029299726828387\n",
            "init   \t [ 2.22256611 -1.96781221]. \t  -48.81113313056442 \t 1.029299726828387\n",
            "init   \t [-1.14158445  1.83041496]. \t  -31.794043287944216 \t 1.029299726828387\n",
            "init   \t [ 0.07870027 -0.7268623 ]. \t  1.029299726828387 \t 1.029299726828387\n",
            "init   \t [ 0.23519962 -1.11498023]. \t  -1.161934062902255 \t 1.029299726828387\n",
            "1      \t [-1.4544454   0.80460528]. \t  -0.13632292703505466 \t 1.029299726828387\n",
            "2      \t [ 0.06051083 -1.22941829]. \t  -3.032505907483532 \t 1.029299726828387\n",
            "3      \t [ 0.07221267 -0.58197053]. \t  0.9171399719969583 \t 1.029299726828387\n",
            "4      \t [ 2.28584625 -1.87403497]. \t  -42.12313738585593 \t 1.029299726828387\n",
            "5      \t [ 0.05156011 -0.18537694]. \t  0.13167384505154514 \t 1.029299726828387\n",
            "6      \t [-1.62233454  0.24541874]. \t  -1.4335115362537232 \t 1.029299726828387\n",
            "7      \t [ 0.55082075 -0.3029371 ]. \t  -0.5293510496183202 \t 1.029299726828387\n",
            "8      \t [-0.40609259 -0.35061617]. \t  -0.3151333974926743 \t 1.029299726828387\n",
            "9      \t [2.97875074 1.63290688]. \t  -125.65112112034933 \t 1.029299726828387\n",
            "10     \t [-3. -2.]. \t  -162.89999999999998 \t 1.029299726828387\n",
            "11     \t [-3.          0.93863841]. \t  -105.66485698802852 \t 1.029299726828387\n",
            "12     \t [0.88734672 2.        ]. \t  -51.78500430829675 \t 1.029299726828387\n",
            "13     \t [-0.62440975  0.07857849]. \t  -1.1864692559811632 \t 1.029299726828387\n",
            "14     \t [-0.60313248  0.06355437]. \t  -1.1388093964140464 \t 1.029299726828387\n",
            "15     \t [-0.58725655  0.05276978]. \t  -1.10129194582908 \t 1.029299726828387\n",
            "16     \t [-0.57477625  0.04446996]. \t  -1.0708351419685098 \t 1.029299726828387\n",
            "17     \t [-0.56469189  0.03784206]. \t  -1.0456935487651564 \t 1.029299726828387\n",
            "18     \t [-0.55641229  0.03243265]. \t  -1.0247384179026122 \t 1.029299726828387\n",
            "19     \t [-0.54954413  0.02795446]. \t  -1.0071636996129152 \t 1.029299726828387\n",
            "20     \t [-0.54380523  0.02420989]. \t  -0.9923577677967077 \t 1.029299726828387\n",
            "21     \t [-0.53898429  0.02105545]. \t  -0.9798427959704884 \t 1.029299726828387\n",
            "22     \t [-0.53491722  0.01838247]. \t  -0.9692349602430631 \t 1.029299726828387\n",
            "23     \t [-0.53147476  0.01610713]. \t  -0.9602238984320576 \t 1.029299726828387\n",
            "24     \t [-0.52855199  0.01416211]. \t  -0.9525524602685586 \t 1.029299726828387\n",
            "25     \t [-0.52606448  0.0124939 ]. \t  -0.9460104441606004 \t 1.029299726828387\n",
            "26     \t [-0.52394278  0.01105855]. \t  -0.9404227373845095 \t 1.029299726828387\n",
            "27     \t [-0.52212917  0.00982027]. \t  -0.9356419034181523 \t 1.029299726828387\n",
            "28     \t [-0.52057599  0.00874896]. \t  -0.9315455375249831 \t 1.029299726828387\n",
            "29     \t [-0.51924354  0.00781976]. \t  -0.9280309452953244 \t 1.029299726828387\n",
            "30     \t [-0.51809849  0.00701215]. \t  -0.9250111186315718 \t 1.029299726828387\n",
            "31     \t [-0.51711269  0.00630821]. \t  -0.9224125891629916 \t 1.029299726828387\n",
            "32     \t [-0.51626279  0.00569331]. \t  -0.9201740095542641 \t 1.029299726828387\n",
            "33     \t [-0.51552881  0.0051552 ]. \t  -0.9182425971863797 \t 1.029299726828387\n",
            "34     \t [-0.51489417  0.00468311]. \t  -0.9165747062224446 \t 1.029299726828387\n",
            "35     \t [-0.5143444   0.00426787]. \t  -0.915132059282704 \t 1.029299726828387\n",
            "36     \t [-0.51386676  0.00390181]. \t  -0.9138805765850821 \t 1.029299726828387\n",
            "37     \t [-0.51345251  0.00357882]. \t  -0.9127974031356051 \t 1.029299726828387\n",
            "38     \t [-0.51309249  0.00329321]. \t  -0.9118580335160688 \t 1.029299726828387\n",
            "39     \t [-0.51277845  0.00303963]. \t  -0.9110405916765717 \t 1.029299726828387\n",
            "40     \t [-0.51250421  0.00281406]. \t  -0.9103285216240724 \t 1.029299726828387\n",
            "41     \t [-0.0084205  -0.27925757]. \t  0.28497756256221607 \t 1.029299726828387\n",
            "42     \t [ 0.01773578 -0.28732298]. \t  0.30679487553713103 \t 1.029299726828387\n",
            "43     \t [ 0.03669085 -0.29156489]. \t  0.31645017036150624 \t 1.029299726828387\n",
            "44     \t [ 0.05134722 -0.29391025]. \t  0.3202446132537567 \t 1.029299726828387\n",
            "45     \t [ 0.06310541 -0.29520816]. \t  0.3209457737739063 \t 1.029299726828387\n",
            "46     \t [ 0.07277438 -0.29589293]. \t  0.3199565005949354 \t 1.029299726828387\n",
            "47     \t [ 0.08087198 -0.29620533]. \t  0.31804217982226335 \t 1.029299726828387\n",
            "48     \t [ 0.08775147 -0.29628673]. \t  0.3156405777344667 \t 1.029299726828387\n",
            "49     \t [ 0.09366503 -0.29622336]. \t  0.3130087117188806 \t 1.029299726828387\n",
            "50     \t [ 0.09879874 -0.29606943]. \t  0.3102996521593218 \t 1.029299726828387\n",
            "51     \t [ 0.10329341 -0.29585972]. \t  0.3076047059721351 \t 1.029299726828387\n",
            "52     \t [ 0.10725788 -0.295617  ]. \t  0.30497766916851604 \t 1.029299726828387\n",
            "53     \t [ 0.11077766 -0.2953563 ]. \t  0.30244909802948217 \t 1.029299726828387\n",
            "54     \t [ 0.11392102 -0.2950875 ]. \t  0.3000348082156671 \t 1.029299726828387\n",
            "55     \t [ 0.11674307 -0.29481737]. \t  0.29774199503957244 \t 1.029299726828387\n",
            "56     \t [ 0.11928862 -0.29455012]. \t  0.2955717046850313 \t 1.029299726828387\n",
            "57     \t [ 0.1215949  -0.29428865]. \t  0.2935216915649862 \t 1.029299726828387\n",
            "58     \t [ 0.12369268 -0.2940348 ]. \t  0.29158779957055064 \t 1.029299726828387\n",
            "59     \t [ 0.12560783 -0.29378974]. \t  0.2897647254984716 \t 1.029299726828387\n",
            "60     \t [ 0.12736213 -0.29355386]. \t  0.2880460602163989 \t 1.029299726828387\n",
            "61     \t [ 0.12897422 -0.29332756]. \t  0.2864258033128863 \t 1.029299726828387\n",
            "62     \t [ 0.13045989 -0.29311071]. \t  0.28489749472139153 \t 1.029299726828387\n",
            "63     \t [ 0.13183273 -0.29290331]. \t  0.2834554325486049 \t 1.029299726828387\n",
            "64     \t [ 0.13310457 -0.29270511]. \t  0.282093817272729 \t 1.029299726828387\n",
            "65     \t [ 0.13428568 -0.29251564]. \t  0.2808068411861485 \t 1.029299726828387\n",
            "66     \t [ 0.1353849  -0.29233474]. \t  0.27958990095077907 \t 1.029299726828387\n",
            "67     \t [ 0.13641012 -0.29216195]. \t  0.27843799035104777 \t 1.029299726828387\n",
            "68     \t [ 0.13736821 -0.29199675]. \t  0.2773463951589015 \t 1.029299726828387\n",
            "69     \t [ 0.13826515 -0.29183909]. \t  0.27631178907808773 \t 1.029299726828387\n",
            "70     \t [ 0.1391065  -0.29168834]. \t  0.27532969877158087 \t 1.029299726828387\n",
            "71     \t [ 0.13989683 -0.29154418]. \t  0.27439687233813287 \t 1.029299726828387\n",
            "72     \t [ 0.14064056 -0.29140626]. \t  0.2735099374995873 \t 1.029299726828387\n",
            "73     \t [ 0.14134141 -0.29127436]. \t  0.2726661906897226 \t 1.029299726828387\n",
            "74     \t [ 0.1420029  -0.29114806]. \t  0.2718625952895107 \t 1.029299726828387\n",
            "75     \t [ 0.14262787 -0.29102693]. \t  0.27109652499718817 \t 1.029299726828387\n",
            "76     \t [ 0.14321933 -0.29091084]. \t  0.27036573997642055 \t 1.029299726828387\n",
            "77     \t [ 0.14377972 -0.29079952]. \t  0.2696680620639893 \t 1.029299726828387\n",
            "78     \t [ 0.14431128 -0.29069285]. \t  0.2690018140882707 \t 1.029299726828387\n",
            "79     \t [ 0.14481597 -0.29059025]. \t  0.268364472996524 \t 1.029299726828387\n",
            "80     \t [ 0.14529596 -0.29049177]. \t  0.267754632599527 \t 1.029299726828387\n",
            "81     \t [ 0.14575246 -0.29039711]. \t  0.2671709104124125 \t 1.029299726828387\n",
            "82     \t [ 0.14618749 -0.29030607]. \t  0.26661140803708006 \t 1.029299726828387\n",
            "83     \t [ 0.14660231 -0.29021846]. \t  0.26607489985589844 \t 1.029299726828387\n",
            "84     \t [ 0.14699817 -0.29013418]. \t  0.2655602646662643 \t 1.029299726828387\n",
            "85     \t [ 0.14737634 -0.29005299]. \t  0.2650660932532271 \t 1.029299726828387\n",
            "86     \t [ 0.14773789 -0.28997473]. \t  0.2645912735600138 \t 1.029299726828387\n",
            "87     \t [ 0.14808381 -0.28989922]. \t  0.26413474079397115 \t 1.029299726828387\n",
            "88     \t [ 0.1484151  -0.28982646]. \t  0.26369571795073693 \t 1.029299726828387\n",
            "89     \t [ 0.14873252 -0.28975621]. \t  0.26327318359699664 \t 1.029299726828387\n",
            "90     \t [ 0.14903701 -0.28968838]. \t  0.2628661863777927 \t 1.029299726828387\n",
            "91     \t [ 0.14932924 -0.28962286]. \t  0.2624740550062667 \t 1.029299726828387\n",
            "92     \t [ 0.14960987 -0.28955957]. \t  0.2620960935407456 \t 1.029299726828387\n",
            "93     \t [ 0.1498796  -0.28949832]. \t  0.26173138772484983 \t 1.029299726828387\n",
            "94     \t [ 0.15013897 -0.28943912]. \t  0.2613795202894739 \t 1.029299726828387\n",
            "95     \t [ 0.15038852 -0.2893818 ]. \t  0.2610397392389521 \t 1.029299726828387\n",
            "96     \t [ 0.15062877 -0.2893263 ]. \t  0.26071149769794444 \t 1.029299726828387\n",
            "97     \t [ 0.15086028 -0.2892726 ]. \t  0.2603943422101267 \t 1.029299726828387\n",
            "98     \t [ 0.15108342 -0.28922054]. \t  0.26008762620301523 \t 1.029299726828387\n",
            "99     \t [ 0.15129865 -0.28917002]. \t  0.2597907790528945 \t 1.029299726828387\n",
            "100    \t [ 0.15150631 -0.28912108]. \t  0.25950365088375676 \t 1.029299726828387\n"
          ]
        }
      ],
      "source": [
        "### Bayesian optimisation runs (x20): 'GP' Acquisition Function run number = 14\n",
        "\n",
        "np.random.seed(run_num_14)\n",
        "surrogate_gp_14 = GaussianProcess(cov_func, optimize=hyperOpt)\n",
        "\n",
        "gp_14 = GPGO(surrogate_gp_14, Acquisition_new(util_gp), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\n",
        "gp_14.run(max_iter = max_iter, init_evals = n_init) # run\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNCLg6LHJLk6",
        "outputId": "55319116-fc84-47eb-e8a6-a7f182fc197e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 2.09290618 -1.2844163 ]. \t  -6.84252100896936 \t -2.1163170846379233\n",
            "init   \t [-2.67382071 -0.55384622]. \t  -43.69785230561242 \t -2.1163170846379233\n",
            "init   \t [-1.34759443  0.1200009 ]. \t  -2.1163170846379233 \t -2.1163170846379233\n",
            "init   \t [-1.16448651 -0.78210256]. \t  -2.3544087277459513 \t -2.1163170846379233\n",
            "init   \t [-2.32955234 -1.00040394]. \t  -15.469119251600274 \t -2.1163170846379233\n",
            "1      \t [-0.25714052  1.36624973]. \t  -6.374883133491508 \t -2.1163170846379233\n",
            "2      \t [3. 2.]. \t  -162.89999999999998 \t -2.1163170846379233\n",
            "3      \t [-3.  2.]. \t  -150.89999999999998 \t -2.1163170846379233\n",
            "4      \t [-0.23930258 -0.51468311]. \t  \u001b[92m0.43350570349947654\u001b[0m \t 0.43350570349947654\n",
            "5      \t [-0.25722929 -0.50665369]. \t  0.37732002117668184 \t 0.43350570349947654\n",
            "6      \t [-0.26633193 -0.50276006]. \t  0.3483199462265014 \t 0.43350570349947654\n",
            "7      \t [-0.27184683 -0.50069549]. \t  0.3310089634345319 \t 0.43350570349947654\n",
            "8      \t [-0.27552598 -0.49954695]. \t  0.3197535872015991 \t 0.43350570349947654\n",
            "9      \t [-0.26919724 -2.        ]. \t  -48.817361834724885 \t 0.43350570349947654\n",
            "10     \t [-0.31242214  0.08697482]. \t  -0.31353069255944926 \t 0.43350570349947654\n",
            "11     \t [-0.32957998  0.05669877]. \t  -0.37863683223852784 \t 0.43350570349947654\n",
            "12     \t [-0.33931533  0.03723406]. \t  -0.4150387360580767 \t 0.43350570349947654\n",
            "13     \t [-0.34536192  0.02358733]. \t  -0.4374190357987463 \t 0.43350570349947654\n",
            "14     \t [-0.34932978  0.01348827]. \t  -0.45201903319622583 \t 0.43350570349947654\n",
            "15     \t [-0.3520339   0.00572631]. \t  -0.4619468452350328 \t 0.43350570349947654\n",
            "16     \t [-0.35392912 -0.00041145]. \t  -0.4689112435943678 \t 0.43350570349947654\n",
            "17     \t [-0.35528631 -0.00537474]. \t  -0.4739173351392317 \t 0.43350570349947654\n",
            "18     \t [-0.35627485 -0.00946179]. \t  -0.47758717899721426 \t 0.43350570349947654\n",
            "19     \t [-0.35700448 -0.01287866]. \t  -0.48032079469375355 \t 0.43350570349947654\n",
            "20     \t [-0.35754906 -0.01577205]. \t  -0.4823851290103531 \t 0.43350570349947654\n",
            "21     \t [-0.35795873 -0.01824932]. \t  -0.483961144130798 \t 0.43350570349947654\n",
            "22     \t [-0.35826886 -0.02039077]. \t  -0.4851757977739147 \t 0.43350570349947654\n",
            "23     \t [-0.35850457 -0.02225763]. \t  -0.48611912259248924 \t 0.43350570349947654\n",
            "24     \t [-0.35868406 -0.0238973 ]. \t  -0.4868563919982801 \t 0.43350570349947654\n",
            "25     \t [-0.35882084 -0.02534716]. \t  -0.48743578255357234 \t 0.43350570349947654\n",
            "26     \t [-0.35892461 -0.02663685]. \t  -0.48789236450267165 \t 0.43350570349947654\n",
            "27     \t [-0.35900288 -0.02779035]. \t  -0.4882531100574628 \t 0.43350570349947654\n",
            "28     \t [-0.35906146 -0.02882723]. \t  -0.4885387737342617 \t 0.43350570349947654\n",
            "29     \t [-0.35910452 -0.02976343]. \t  -0.4887646265836223 \t 0.43350570349947654\n",
            "30     \t [-0.35913541 -0.0306122 ]. \t  -0.48894287295832606 \t 0.43350570349947654\n",
            "31     \t [-0.35915666 -0.03138471]. \t  -0.4890828114298502 \t 0.43350570349947654\n",
            "32     \t [-0.35917047 -0.03209032]. \t  -0.4891923448865022 \t 0.43350570349947654\n",
            "33     \t [-0.35917838 -0.03273683]. \t  -0.4892772672825493 \t 0.43350570349947654\n",
            "34     \t [-0.35918144 -0.03333113]. \t  -0.48934175182875816 \t 0.43350570349947654\n",
            "35     \t [-0.35918088 -0.03387884]. \t  -0.48939014328300645 \t 0.43350570349947654\n",
            "36     \t [-0.35917738 -0.03438503]. \t  -0.4894252156336805 \t 0.43350570349947654\n",
            "37     \t [-0.35917163 -0.03485405]. \t  -0.4894495239340784 \t 0.43350570349947654\n",
            "38     \t [-0.35916406 -0.03528954]. \t  -0.48946490946438276 \t 0.43350570349947654\n",
            "39     \t [-0.35915515 -0.03569483]. \t  -0.48947311383918696 \t 0.43350570349947654\n",
            "40     \t [-0.35914537 -0.0360728 ]. \t  -0.4894758940552975 \t 0.43350570349947654\n",
            "41     \t [-0.35913452 -0.03642594]. \t  -0.4894730910989685 \t 0.43350570349947654\n",
            "42     \t [-0.35912335 -0.03675655]. \t  -0.48946701408127996 \t 0.43350570349947654\n",
            "43     \t [-0.35911157 -0.03706657]. \t  -0.4894572321947536 \t 0.43350570349947654\n",
            "44     \t [-0.35909975 -0.03735772]. \t  -0.4894453950795973 \t 0.43350570349947654\n",
            "45     \t [-0.35908772 -0.03763162]. \t  -0.48943136125940306 \t 0.43350570349947654\n",
            "46     \t [-0.35907569 -0.03788973]. \t  -0.48941581237304327 \t 0.43350570349947654\n",
            "47     \t [-0.35906357 -0.03813322]. \t  -0.4893986937196776 \t 0.43350570349947654\n",
            "48     \t [-0.35905166 -0.0383632 ]. \t  -0.4893809481372094 \t 0.43350570349947654\n",
            "49     \t [-0.35903981 -0.03858084]. \t  -0.48936226239328384 \t 0.43350570349947654\n",
            "50     \t [-0.35902819 -0.03878691]. \t  -0.48934321407694475 \t 0.43350570349947654\n",
            "51     \t [-0.35901666 -0.03898233]. \t  -0.48932356029226104 \t 0.43350570349947654\n",
            "52     \t [-0.3590053  -0.03916785]. \t  -0.4893035413320247 \t 0.43350570349947654\n",
            "53     \t [-0.35899435 -0.0393442 ]. \t  -0.48928389677167 \t 0.43350570349947654\n",
            "54     \t [-0.3589836  -0.03951187]. \t  -0.48926411612613424 \t 0.43350570349947654\n",
            "55     \t [-0.35897297 -0.0396716 ]. \t  -0.4892440895351404 \t 0.43350570349947654\n",
            "56     \t [-0.35896282 -0.03982387]. \t  -0.48922474891808415 \t 0.43350570349947654\n",
            "57     \t [-0.35895271 -0.03996908]. \t  -0.48920503662881926 \t 0.43350570349947654\n",
            "58     \t [-0.35894303 -0.04010779]. \t  -0.4891860013090547 \t 0.43350570349947654\n",
            "59     \t [-0.35893346 -0.04024033]. \t  -0.48916685710689 \t 0.43350570349947654\n",
            "60     \t [-0.35892416 -0.04036707]. \t  -0.48914803923019223 \t 0.43350570349947654\n",
            "61     \t [-0.35891521 -0.04048846]. \t  -0.4891297748110282 \t 0.43350570349947654\n",
            "62     \t [-0.35890643 -0.04060471]. \t  -0.48911165743392326 \t 0.43350570349947654\n",
            "63     \t [-0.35889795 -0.04071618]. \t  -0.4890940194420126 \t 0.43350570349947654\n",
            "64     \t [-0.35888958 -0.04082313]. \t  -0.48907642181132677 \t 0.43350570349947654\n",
            "65     \t [-0.35888154 -0.0409258 ]. \t  -0.4890594349048708 \t 0.43350570349947654\n",
            "66     \t [-0.35887366 -0.04102439]. \t  -0.4890426235029043 \t 0.43350570349947654\n",
            "67     \t [-0.3588661 -0.0411192]. \t  -0.4890264131264293 \t 0.43350570349947654\n",
            "68     \t [-0.35885866 -0.04121042]. \t  -0.4890103560900336 \t 0.43350570349947654\n",
            "69     \t [-0.35885137 -0.04129815]. \t  -0.48899449994511685 \t 0.43350570349947654\n",
            "70     \t [-0.35884444 -0.04138266]. \t  -0.4889793956427991 \t 0.43350570349947654\n",
            "71     \t [-0.35883767 -0.04146408]. \t  -0.4889645458315737 \t 0.43350570349947654\n",
            "72     \t [-0.35883098 -0.0415426 ]. \t  -0.4889497916388389 \t 0.43350570349947654\n",
            "73     \t [-0.35882464 -0.04161833]. \t  -0.4889357751567853 \t 0.43350570349947654\n",
            "74     \t [-0.35881823 -0.0416914 ]. \t  -0.488921464201946 \t 0.43350570349947654\n",
            "75     \t [-0.35881223 -0.04176203]. \t  -0.4889080935150968 \t 0.43350570349947654\n",
            "76     \t [-0.35880633 -0.0418302 ]. \t  -0.488894892539849 \t 0.43350570349947654\n",
            "77     \t [-0.35880062 -0.04189613]. \t  -0.48888204874895197 \t 0.43350570349947654\n",
            "78     \t [-0.35879502 -0.04195984]. \t  -0.48886942416373436 \t 0.43350570349947654\n",
            "79     \t [-0.3587895 -0.0420215]. \t  -0.4888569101179049 \t 0.43350570349947654\n",
            "80     \t [-0.35878422 -0.04208117]. \t  -0.48884491145150955 \t 0.43350570349947654\n",
            "81     \t [-0.35877907 -0.04213894]. \t  -0.4888331837980272 \t 0.43350570349947654\n",
            "82     \t [-0.35877402 -0.0421949 ]. \t  -0.4888216552526195 \t 0.43350570349947654\n",
            "83     \t [-0.35876909 -0.04224913]. \t  -0.48881035574774906 \t 0.43350570349947654\n",
            "84     \t [-0.35876434 -0.0423017 ]. \t  -0.4887994334370973 \t 0.43350570349947654\n",
            "85     \t [-0.35875968 -0.04235268]. \t  -0.4887887179754456 \t 0.43350570349947654\n",
            "86     \t [-0.35875526 -0.04240216]. \t  -0.488778529575558 \t 0.43350570349947654\n",
            "87     \t [-0.35875077 -0.04245016]. \t  -0.4887681483388435 \t 0.43350570349947654\n",
            "88     \t [-0.35874645 -0.04249678]. \t  -0.4887581177675683 \t 0.43350570349947654\n",
            "89     \t [-0.35874227 -0.04254205]. \t  -0.4887484176762666 \t 0.43350570349947654\n",
            "90     \t [-0.35873817 -0.04258601]. \t  -0.48873887242779523 \t 0.43350570349947654\n",
            "91     \t [-0.35873425 -0.04262879]. \t  -0.4887297371157411 \t 0.43350570349947654\n",
            "92     \t [-0.35873038 -0.04267034]. \t  -0.48872071638744313 \t 0.43350570349947654\n",
            "93     \t [-0.35872651 -0.04271061]. \t  -0.4887116258820231 \t 0.43350570349947654\n",
            "94     \t [-0.35872284 -0.04275005]. \t  -0.48870303059744574 \t 0.43350570349947654\n",
            "95     \t [-0.35871938 -0.04278838]. \t  -0.4886949575002312 \t 0.43350570349947654\n",
            "96     \t [-0.35871567 -0.04282555]. \t  -0.4886861959997821 \t 0.43350570349947654\n",
            "97     \t [-0.35871223 -0.04286182]. \t  -0.48867809127400375 \t 0.43350570349947654\n",
            "98     \t [-0.35870892 -0.04289712]. \t  -0.48867028307131966 \t 0.43350570349947654\n",
            "99     \t [-0.35870556 -0.0429315 ]. \t  -0.4886623288124639 \t 0.43350570349947654\n",
            "100    \t [-0.35870231 -0.04296503]. \t  -0.4886546402825316 \t 0.43350570349947654\n"
          ]
        }
      ],
      "source": [
        "### Bayesian optimisation runs (x20): 'GP' Acquisition Function run number = 15\n",
        "\n",
        "np.random.seed(run_num_15)\n",
        "surrogate_gp_15 = GaussianProcess(cov_func, optimize=hyperOpt)\n",
        "\n",
        "gp_15 = GPGO(surrogate_gp_15, Acquisition_new(util_gp), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\n",
        "gp_15.run(max_iter = max_iter, init_evals = n_init) # run\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xwjkr9RJLk6",
        "outputId": "baba851b-7ccf-43ec-f1c7-4ff72b0c08b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [-1.66025353  0.09265337]. \t  -1.8632773736203017 \t -1.8632773736203017\n",
            "init   \t [ 0.30420874 -1.8175922 ]. \t  -30.24114424375299 \t -1.8632773736203017\n",
            "init   \t [-0.83562699 -1.10767623]. \t  -3.922061281476444 \t -1.8632773736203017\n",
            "init   \t [ 1.13235697 -1.3450743 ]. \t  -6.7121671493737685 \t -1.8632773736203017\n",
            "init   \t [-2.5780508   1.76404344]. \t  -53.42443470756798 \t -1.8632773736203017\n",
            "1      \t [ 3.         -0.02175059]. \t  -108.83285676520858 \t -1.8632773736203017\n",
            "2      \t [-3. -2.]. \t  -162.89999999999998 \t -1.8632773736203017\n",
            "3      \t [0.52364005 2.        ]. \t  -49.993059006085105 \t -1.8632773736203017\n",
            "4      \t [-0.849958    0.00561249]. \t  -1.914500797155091 \t -1.8632773736203017\n",
            "5      \t [-1.02889713 -0.08098713]. \t  -2.3337866625156605 \t -1.8632773736203017\n",
            "6      \t [ 2.29756817 -2.        ]. \t  -55.03475841716943 \t -1.8632773736203017\n",
            "7      \t [-0.77479579 -0.15236217]. \t  \u001b[92m-1.743915764583875\u001b[0m \t -1.743915764583875\n",
            "8      \t [-0.78771917 -0.15040074]. \t  -1.783133883303033 \t -1.743915764583875\n",
            "9      \t [-0.79640818 -0.14903681]. \t  -1.8091213381254154 \t -1.743915764583875\n",
            "10     \t [-0.80260246 -0.14804819]. \t  -1.8274486785362136 \t -1.743915764583875\n",
            "11     \t [-0.80720748 -0.14731046]. \t  -1.8409610544364665 \t -1.743915764583875\n",
            "12     \t [-0.81074271 -0.14674527]. \t  -1.8512668639151555 \t -1.743915764583875\n",
            "13     \t [-0.81352587 -0.14630358]. \t  -1.8593376326627 \t -1.743915764583875\n",
            "14     \t [-0.81576161 -0.14595161]. \t  -1.8657932225739118 \t -1.743915764583875\n",
            "15     \t [-0.81759203 -0.14566848]. \t  -1.871059026084912 \t -1.743915764583875\n",
            "16     \t [-0.81910854 -0.14543625]. \t  -1.875408753836193 \t -1.743915764583875\n",
            "17     \t [-0.82038295 -0.14524487]. \t  -1.8790543226925986 \t -1.743915764583875\n",
            "18     \t [-0.82146631 -0.14508433]. \t  -1.8821464808284771 \t -1.743915764583875\n",
            "19     \t [-0.82239265 -0.1449501 ]. \t  -1.8847850336513563 \t -1.743915764583875\n",
            "20     \t [-0.82319335 -0.14483608]. \t  -1.8870617828937128 \t -1.743915764583875\n",
            "21     \t [-0.82389147 -0.1447387 ]. \t  -1.8890436646906734 \t -1.743915764583875\n",
            "22     \t [-0.82450261 -0.14465471]. \t  -1.8907763129098245 \t -1.743915764583875\n",
            "23     \t [-0.8250432  -0.14458251]. \t  -1.8923068269313692 \t -1.743915764583875\n",
            "24     \t [-0.82552632 -0.14452394]. \t  -1.8936717245217753 \t -1.743915764583875\n",
            "25     \t [-0.82594967 -0.14446498]. \t  -1.894868979040633 \t -1.743915764583875\n",
            "26     \t [-0.82633145 -0.14441672]. \t  -1.8959465339029247 \t -1.743915764583875\n",
            "27     \t [-0.82667585 -0.14437498]. \t  -1.8969174745043076 \t -1.743915764583875\n",
            "28     \t [-0.82698723 -0.14433649]. \t  -1.8977950130549597 \t -1.743915764583875\n",
            "29     \t [-0.82726798 -0.14430424]. \t  -1.8985851558036788 \t -1.743915764583875\n",
            "30     \t [-0.82752447 -0.1442749 ]. \t  -1.8993066624886488 \t -1.743915764583875\n",
            "31     \t [-0.82775916 -0.14424883]. \t  -1.899966329087186 \t -1.743915764583875\n",
            "32     \t [-0.82797276 -0.14422509]. \t  -1.9005664816631604 \t -1.743915764583875\n",
            "33     \t [-0.8281672  -0.14420705]. \t  -1.9011116296726056 \t -1.743915764583875\n",
            "34     \t [-0.82834889 -0.14418596]. \t  -1.9016220242473563 \t -1.743915764583875\n",
            "35     \t [-0.82851515 -0.14416909]. \t  -1.9020882580154554 \t -1.743915764583875\n",
            "36     \t [-0.828669  -0.1441543]. \t  -1.9025193472450408 \t -1.743915764583875\n",
            "37     \t [-0.82881145 -0.14414041]. \t  -1.9029184582441911 \t -1.743915764583875\n",
            "38     \t [-0.82894406 -0.1441282 ]. \t  -1.903289695712591 \t -1.743915764583875\n",
            "39     \t [-0.82906758 -0.14411683]. \t  -1.903635432821346 \t -1.743915764583875\n",
            "40     \t [-0.82918158 -0.14410708]. \t  -1.903954247014764 \t -1.743915764583875\n",
            "41     \t [-0.82928433 -0.14409923]. \t  -1.904241280492697 \t -1.743915764583875\n",
            "42     \t [-0.82939012 -0.14408974]. \t  -1.9045371365721702 \t -1.743915764583875\n",
            "43     \t [-0.82948352 -0.14408258]. \t  -1.9047979529180257 \t -1.743915764583875\n",
            "44     \t [-0.82957086 -0.14407535]. \t  -1.9050419805010874 \t -1.743915764583875\n",
            "45     \t [-0.82965342 -0.14406892]. \t  -1.9052724864655204 \t -1.743915764583875\n",
            "46     \t [-0.82973109 -0.14406331]. \t  -1.9054892012140259 \t -1.743915764583875\n",
            "47     \t [-0.82980591 -0.14405817]. \t  -1.9056978427232791 \t -1.743915764583875\n",
            "48     \t [-0.82987312 -0.14405328]. \t  -1.9058853355642436 \t -1.743915764583875\n",
            "49     \t [-0.82993868 -0.14404897]. \t  -1.9060680753464723 \t -1.743915764583875\n",
            "50     \t [-0.8300008  -0.14404553]. \t  -1.9062410436062238 \t -1.743915764583875\n",
            "51     \t [-0.83005497 -0.14405213]. \t  -1.906389194052183 \t -1.743915764583875\n",
            "52     \t [-0.83011334 -0.14403847]. \t  -1.9065545434362177 \t -1.743915764583875\n",
            "53     \t [-0.83016571 -0.14403547]. \t  -1.9067003334530488 \t -1.743915764583875\n",
            "54     \t [-0.83021583 -0.14403287]. \t  -1.9068397941172333 \t -1.743915764583875\n",
            "55     \t [-0.83026331 -0.14402996]. \t  -1.9069720017146852 \t -1.743915764583875\n",
            "56     \t [-0.83030761 -0.1440281 ]. \t  -1.9070951130870382 \t -1.743915764583875\n",
            "57     \t [-0.83035078 -0.14402602]. \t  -1.907215137610272 \t -1.743915764583875\n",
            "58     \t [-0.8303916  -0.14402411]. \t  -1.907328606019259 \t -1.743915764583875\n",
            "59     \t [-0.83043069 -0.1440225 ]. \t  -1.9074372149595546 \t -1.743915764583875\n",
            "60     \t [-0.83046731 -0.14402072]. \t  -1.9075390330976745 \t -1.743915764583875\n",
            "61     \t [-0.83050224 -0.14401966]. \t  -1.9076359438273955 \t -1.743915764583875\n",
            "62     \t [-0.83053617 -0.14401844]. \t  -1.9077301477958664 \t -1.743915764583875\n",
            "63     \t [-0.83056846 -0.14401732]. \t  -1.9078197760095355 \t -1.743915764583875\n",
            "64     \t [-0.83060055 -0.14401616]. \t  -1.9079088673358457 \t -1.743915764583875\n",
            "65     \t [-0.83062979 -0.14401522]. \t  -1.9079899856220621 \t -1.743915764583875\n",
            "66     \t [-0.83065837 -0.14401455]. \t  -1.9080692221722553 \t -1.743915764583875\n",
            "67     \t [-0.83068559 -0.14401348]. \t  -1.9081447892397612 \t -1.743915764583875\n",
            "68     \t [-0.8307115  -0.14401291]. \t  -1.9082166218066055 \t -1.743915764583875\n",
            "69     \t [-0.8307361  -0.14401268]. \t  -1.9082846870708665 \t -1.743915764583875\n",
            "70     \t [-0.83076136 -0.14401193]. \t  -1.908354752069988 \t -1.743915764583875\n",
            "71     \t [-0.8307847  -0.14401205]. \t  -1.90841925689908 \t -1.743915764583875\n",
            "72     \t [-0.83080839 -0.14401118]. \t  -1.9084850187041538 \t -1.743915764583875\n",
            "73     \t [-0.83082813 -0.14401084]. \t  -1.9085396965585915 \t -1.743915764583875\n",
            "74     \t [-0.83084819 -0.1440108 ]. \t  -1.9085951585544225 \t -1.743915764583875\n",
            "75     \t [-0.8308678  -0.14401015]. \t  -1.9086495480883017 \t -1.743915764583875\n",
            "76     \t [-0.83088471 -0.14401143]. \t  -1.908695971239243 \t -1.743915764583875\n",
            "77     \t [-0.83090637 -0.14400988]. \t  -1.9087562602923307 \t -1.743915764583875\n",
            "78     \t [-0.83092454 -0.1440098 ]. \t  -1.908806520050803 \t -1.743915764583875\n",
            "79     \t [-0.83094065 -0.14401003]. \t  -1.9088509971532441 \t -1.743915764583875\n",
            "80     \t [-0.83095697 -0.14401099]. \t  -1.908895847519481 \t -1.743915764583875\n",
            "81     \t [-0.83097373 -0.14401   ]. \t  -1.9089424460250723 \t -1.743915764583875\n",
            "82     \t [-0.83098955 -0.14401032]. \t  -1.9089861003887827 \t -1.743915764583875\n",
            "83     \t [-0.83100493 -0.14401012]. \t  -1.9090286653350415 \t -1.743915764583875\n",
            "84     \t [-0.83101849 -0.14401009]. \t  -1.9090661401528137 \t -1.743915764583875\n",
            "85     \t [-0.83103236 -0.14400985]. \t  -1.909104561490478 \t -1.743915764583875\n",
            "86     \t [-0.83104545 -0.14401063]. \t  -1.9091405077119685 \t -1.743915764583875\n",
            "87     \t [-0.83105935 -0.14401057]. \t  -1.9091789551437925 \t -1.743915764583875\n",
            "88     \t [-0.83107328 -0.14401022]. \t  -1.9092175412341128 \t -1.743915764583875\n",
            "89     \t [-0.83108565 -0.14401117]. \t  -1.9092514779347614 \t -1.743915764583875\n",
            "90     \t [-0.83109741 -0.14401037]. \t  -1.9092842029902692 \t -1.743915764583875\n",
            "91     \t [-0.83110901 -0.14401143]. \t  -1.909315976889299 \t -1.743915764583875\n",
            "92     \t [-0.83112214 -0.14401128]. \t  -1.9093522896633652 \t -1.743915764583875\n",
            "93     \t [-0.83113106 -0.144012  ]. \t  -1.9093767624085674 \t -1.743915764583875\n",
            "94     \t [-0.83114309 -0.14401225]. \t  -1.9094099302988514 \t -1.743915764583875\n",
            "95     \t [-0.83115152 -0.1440122 ]. \t  -1.9094332390461297 \t -1.743915764583875\n",
            "96     \t [-0.83116115 -0.1440125 ]. \t  -1.909459767851238 \t -1.743915764583875\n",
            "97     \t [-0.83117135 -0.14401254]. \t  -1.9094879450178823 \t -1.743915764583875\n",
            "98     \t [-0.83118082 -0.14401301]. \t  -1.909513994848921 \t -1.743915764583875\n",
            "99     \t [-0.83118965 -0.14401325]. \t  -1.909538333367376 \t -1.743915764583875\n",
            "100    \t [-0.8311983  -0.14401368]. \t  -1.9095621200896187 \t -1.743915764583875\n"
          ]
        }
      ],
      "source": [
        "### Bayesian optimisation runs (x20): 'GP' Acquisition Function run number = 16\n",
        "\n",
        "np.random.seed(run_num_16)\n",
        "surrogate_gp_16 = GaussianProcess(cov_func, optimize=hyperOpt)\n",
        "\n",
        "gp_16 = GPGO(surrogate_gp_16, Acquisition_new(util_gp), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\n",
        "gp_16.run(max_iter = max_iter, init_evals = n_init) # run\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zbpfP0FWJLk7",
        "outputId": "f7ad7e5e-7337-4508-a921-8eca8d7d5ed9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [-1.23200998  0.12234702]. \t  -2.189206652278967 \t -1.7722768782964888\n",
            "init   \t [-1.85087528 -1.72839857]. \t  -29.406067820453675 \t -1.7722768782964888\n",
            "init   \t [1.72191276 0.62533409]. \t  -2.2113401446731897 \t -1.7722768782964888\n",
            "init   \t [0.82512538 0.30241158]. \t  -1.7722768782964888 \t -1.7722768782964888\n",
            "init   \t [-2.7656225  -0.56874558]. \t  -57.5922315952177 \t -1.7722768782964888\n",
            "1      \t [-0.57939852  1.17144643]. \t  -2.48356156718488 \t -1.7722768782964888\n",
            "2      \t [ 3. -2.]. \t  -150.89999999999998 \t -1.7722768782964888\n",
            "3      \t [3. 2.]. \t  -162.89999999999998 \t -1.7722768782964888\n",
            "4      \t [-2.11301115  2.        ]. \t  -49.438700373024105 \t -1.7722768782964888\n",
            "5      \t [-0.10548772  0.24415895]. \t  \u001b[92m0.20574396053309435\u001b[0m \t 0.20574396053309435\n",
            "6      \t [-0.09880327  0.26581485]. \t  \u001b[92m0.25007503735775843\u001b[0m \t 0.25007503735775843\n",
            "7      \t [-0.09470478  0.27617426]. \t  \u001b[92m0.2722668222047941\u001b[0m \t 0.2722668222047941\n",
            "8      \t [-0.09216592  0.28190821]. \t  \u001b[92m0.28478104055574865\u001b[0m \t 0.28478104055574865\n",
            "9      \t [-0.09054075  0.28538451]. \t  \u001b[92m0.29243392501911597\u001b[0m \t 0.29243392501911597\n",
            "10     \t [0.68849477 0.31496512]. \t  -1.319139858673207 \t 0.29243392501911597\n",
            "11     \t [-0.23591441  0.22977056]. \t  0.03806013623988316 \t 0.29243392501911597\n",
            "12     \t [-0.2297251   0.23866203]. \t  0.06439249664870933 \t 0.29243392501911597\n",
            "13     \t [-0.22523945  0.24463657]. \t  0.08259359190802706 \t 0.29243392501911597\n",
            "14     \t [-0.22188516  0.24883805]. \t  0.09567672347604086 \t 0.29243392501911597\n",
            "15     \t [-0.21930869  0.25190176]. \t  0.10539188199634475 \t 0.29243392501911597\n",
            "16     \t [-0.21728364  0.25420281]. \t  0.11280497454031749 \t 0.29243392501911597\n",
            "17     \t [-0.2156603   0.25597427]. \t  0.11859338353694704 \t 0.29243392501911597\n",
            "18     \t [-0.21433594  0.25736709]. \t  0.12320460255559042 \t 0.29243392501911597\n",
            "19     \t [-0.21323965  0.25848171]. \t  0.1269400059759329 \t 0.29243392501911597\n",
            "20     \t [-0.21232077  0.25938759]. \t  0.13001029839505318 \t 0.29243392501911597\n",
            "21     \t [-0.21154143  0.26013377]. \t  0.13256706595128062 \t 0.29243392501911597\n",
            "22     \t [-0.21087385  0.26075574]. \t  0.13472037523562932 \t 0.29243392501911597\n",
            "23     \t [-0.2102965   0.26127996]. \t  0.1365533904531424 \t 0.29243392501911597\n",
            "24     \t [-0.20979344  0.26172571]. \t  0.13812701928309593 \t 0.29243392501911597\n",
            "25     \t [-0.20935179  0.26210814]. \t  0.13948953544245676 \t 0.29243392501911597\n",
            "26     \t [-0.20896115  0.262439  ]. \t  0.14067890649405432 \t 0.29243392501911597\n",
            "27     \t [-0.20861469  0.26272647]. \t  0.14172105323500542 \t 0.29243392501911597\n",
            "28     \t [-0.20830416  0.26297883]. \t  0.1426438387114184 \t 0.29243392501911597\n",
            "29     \t [-0.20802624  0.26320046]. \t  0.14346073254594505 \t 0.29243392501911597\n",
            "30     \t [-0.2077751   0.26339708]. \t  0.14419117022594197 \t 0.29243392501911597\n",
            "31     \t [-0.20754756  0.26357203]. \t  0.14484617674887545 \t 0.29243392501911597\n",
            "32     \t [-0.20734045  0.26372849]. \t  0.14543649730964292 \t 0.29243392501911597\n",
            "33     \t [-0.20715103  0.26386938]. \t  0.14597172873474834 \t 0.29243392501911597\n",
            "34     \t [-0.20697802  0.26399588]. \t  0.14645595372766596 \t 0.29243392501911597\n",
            "35     \t [-0.20681922  0.26411033]. \t  0.14689691596828597 \t 0.29243392501911597\n",
            "36     \t [-0.20667228  0.26421413]. \t  0.14730054260681952 \t 0.29243392501911597\n",
            "37     \t [-0.20653743  0.26430873]. \t  0.1476695040927231 \t 0.29243392501911597\n",
            "38     \t [-0.20641159  0.26439549]. \t  0.1480106423401439 \t 0.29243392501911597\n",
            "39     \t [-0.20629483  0.26447473]. \t  0.14832451563695884 \t 0.29243392501911597\n",
            "40     \t [-0.20618646  0.2645476 ]. \t  0.14861441287682664 \t 0.29243392501911597\n",
            "41     \t [-0.20608537  0.26461449]. \t  0.14888254418746866 \t 0.29243392501911597\n",
            "42     \t [-0.20599085  0.26467626]. \t  0.1491316355399741 \t 0.29243392501911597\n",
            "43     \t [-0.20590225  0.26473347]. \t  0.14936368254095803 \t 0.29243392501911597\n",
            "44     \t [-0.20581947  0.26478623]. \t  0.1495790222061382 \t 0.29243392501911597\n",
            "45     \t [-0.20574133  0.26483559]. \t  0.14978139158029405 \t 0.29243392501911597\n",
            "46     \t [-0.2056683  0.2648811]. \t  0.1499691907706734 \t 0.29243392501911597\n",
            "47     \t [-0.20559938  0.26492335]. \t  0.15014498153243128 \t 0.29243392501911597\n",
            "48     \t [-0.20553363  0.26496356]. \t  0.15031247656974178 \t 0.29243392501911597\n",
            "49     \t [-0.20547227  0.26500058]. \t  0.1504677357838763 \t 0.29243392501911597\n",
            "50     \t [-0.20541411  0.2650352 ]. \t  0.15061391004265728 \t 0.29243392501911597\n",
            "51     \t [-0.20535813  0.26506839]. \t  0.15075432093112598 \t 0.29243392501911597\n",
            "52     \t [-0.20530585  0.26509882]. \t  0.15088430311875048 \t 0.29243392501911597\n",
            "53     \t [-0.20525617  0.26512774]. \t  0.15100778881498156 \t 0.29243392501911597\n",
            "54     \t [-0.20520801  0.26515529]. \t  0.1511265010500581 \t 0.29243392501911597\n",
            "55     \t [-0.2051633   0.26518064]. \t  0.15123623649714235 \t 0.29243392501911597\n",
            "56     \t [-0.20512021  0.2652049 ]. \t  0.1513416427573684 \t 0.29243392501911597\n",
            "57     \t [-0.20507845  0.26522831]. \t  0.15144356596390462 \t 0.29243392501911597\n",
            "58     \t [-0.20503994  0.2652495 ]. \t  0.1515367685098717 \t 0.29243392501911597\n",
            "59     \t [-0.20500198  0.26527029]. \t  0.15162839942767775 \t 0.29243392501911597\n",
            "60     \t [-0.20496679  0.26528925]. \t  0.15171271384185608 \t 0.29243392501911597\n",
            "61     \t [-0.20493201  0.26530816]. \t  0.15179638151088665 \t 0.29243392501911597\n",
            "62     \t [-0.20489897  0.26532578]. \t  0.15187516551822752 \t 0.29243392501911597\n",
            "63     \t [-0.20486729  0.26534255]. \t  0.15195043656152857 \t 0.29243392501911597\n",
            "64     \t [-0.20483749  0.26535814]. \t  0.15202086134100196 \t 0.29243392501911597\n",
            "65     \t [-0.20480829  0.26537341]. \t  0.15208985816731582 \t 0.29243392501911597\n",
            "66     \t [-0.20478077  0.26538757]. \t  0.15215440137093425 \t 0.29243392501911597\n",
            "67     \t [-0.20475362  0.26540156]. \t  0.15221811253189457 \t 0.29243392501911597\n",
            "68     \t [-0.20472777  0.2654147 ]. \t  0.15227840242524787 \t 0.29243392501911597\n",
            "69     \t [-0.20470348  0.26542688]. \t  0.15233472472292076 \t 0.29243392501911597\n",
            "70     \t [-0.20467917  0.26543907]. \t  0.1523910825053328 \t 0.29243392501911597\n",
            "71     \t [-0.20465604  0.26545064]. \t  0.15244462770849407 \t 0.29243392501911597\n",
            "72     \t [-0.20463364  0.2654617 ]. \t  0.15249619520947574 \t 0.29243392501911597\n",
            "73     \t [-0.2046126   0.26547192]. \t  0.15254430862499924 \t 0.29243392501911597\n",
            "74     \t [-0.20459162  0.26548218]. \t  0.1525923930910129 \t 0.29243392501911597\n",
            "75     \t [-0.20457162  0.26549189]. \t  0.15263809757632948 \t 0.29243392501911597\n",
            "76     \t [-0.20455222  0.26550126]. \t  0.1526823193984604 \t 0.29243392501911597\n",
            "77     \t [-0.2045334  0.2655103]. \t  0.15272512941795147 \t 0.29243392501911597\n",
            "78     \t [-0.20451525  0.26551894]. \t  0.15276625128389965 \t 0.29243392501911597\n",
            "79     \t [-0.20449757  0.26552726]. \t  0.15280609554895982 \t 0.29243392501911597\n",
            "80     \t [-0.20448055  0.26553513]. \t  0.15284417082451368 \t 0.29243392501911597\n",
            "81     \t [-0.20446447  0.26554261]. \t  0.15288024846943224 \t 0.29243392501911597\n",
            "82     \t [-0.20444837  0.26554999]. \t  0.15291613079188315 \t 0.29243392501911597\n",
            "83     \t [-0.20443257  0.26555736]. \t  0.15295161047119912 \t 0.29243392501911597\n",
            "84     \t [-0.20441812  0.26556383]. \t  0.15298351541431787 \t 0.29243392501911597\n",
            "85     \t [-0.20440335  0.26557066]. \t  0.15301655350975313 \t 0.29243392501911597\n",
            "86     \t [-0.20438929  0.26557667]. \t  0.15304701913901717 \t 0.29243392501911597\n",
            "87     \t [-0.20437525  0.26558329]. \t  0.1530786754165798 \t 0.29243392501911597\n",
            "88     \t [-0.20436183  0.26558944]. \t  0.15310857202604936 \t 0.29243392501911597\n",
            "89     \t [-0.20434919  0.26559476]. \t  0.15313578249047488 \t 0.29243392501911597\n",
            "90     \t [-0.20433649  0.26560042]. \t  0.15316375606857688 \t 0.29243392501911597\n",
            "91     \t [-0.20432435  0.2656058 ]. \t  0.15319045018772603 \t 0.29243392501911597\n",
            "92     \t [-0.20431191  0.26561127]. \t  0.1532176771377995 \t 0.29243392501911597\n",
            "93     \t [-0.20430059  0.26561605]. \t  0.15324208697972014 \t 0.29243392501911597\n",
            "94     \t [-0.20428917  0.26562098]. \t  0.1532669046221015 \t 0.29243392501911597\n",
            "95     \t [-0.20427818  0.26562586]. \t  0.15329106688954658 \t 0.29243392501911597\n",
            "96     \t [-0.20426759  0.26563042]. \t  0.15331407724893367 \t 0.29243392501911597\n",
            "97     \t [-0.20425739  0.26563438]. \t  0.1533353300747764 \t 0.29243392501911597\n",
            "98     \t [-0.20424669  0.26563917]. \t  0.15335893861350597 \t 0.29243392501911597\n",
            "99     \t [-0.20423696  0.26564322]. \t  0.1533797816182636 \t 0.29243392501911597\n",
            "100    \t [-0.20422699  0.26564743]. \t  0.15340127457505146 \t 0.29243392501911597\n"
          ]
        }
      ],
      "source": [
        "### Bayesian optimisation runs (x20): 'GP' Acquisition Function run number = 17\n",
        "\n",
        "np.random.seed(run_num_17)\n",
        "surrogate_gp_17 = GaussianProcess(cov_func, optimize=hyperOpt)\n",
        "\n",
        "gp_17 = GPGO(surrogate_gp_17, Acquisition_new(util_gp), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\n",
        "gp_17.run(max_iter = max_iter, init_evals = n_init) # run\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1d-1rDI5JLk8",
        "outputId": "8a9d1d57-8c10-4044-e2fa-9863ede77448"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.90224545 0.02181349]. \t  -2.062169771852028 \t -2.062169771852028\n",
            "init   \t [ 2.27160883 -1.2726391 ]. \t  -11.64729291207819 \t -2.062169771852028\n",
            "init   \t [2.11339841 1.00054514]. \t  -7.792128760671214 \t -2.062169771852028\n",
            "init   \t [0.99661    1.95158179]. \t  -46.96206222999227 \t -2.062169771852028\n",
            "init   \t [-1.45818946 -1.8867763 ]. \t  -41.4190528039297 \t -2.062169771852028\n",
            "1      \t [-3.  2.]. \t  -150.89999999999998 \t -2.062169771852028\n",
            "2      \t [3.         0.48915628]. \t  -109.63938130936914 \t -2.062169771852028\n",
            "3      \t [-1.03461681  0.47305787]. \t  \u001b[92m-1.1000866844597135\u001b[0m \t -1.1000866844597135\n",
            "4      \t [-1.39242244  1.91666559]. \t  -38.90899733568827 \t -1.1000866844597135\n",
            "5      \t [ 0.17215445 -0.22410269]. \t  \u001b[92m0.11266659382318968\u001b[0m \t 0.11266659382318968\n",
            "6      \t [ 0.18005855 -0.22609959]. \t  0.1072534950734143 \t 0.11266659382318968\n",
            "7      \t [ 0.18402812 -0.22709003]. \t  0.10436287795877638 \t 0.11266659382318968\n",
            "8      \t [ 0.18637079 -0.22764885]. \t  0.1025634842091841 \t 0.11266659382318968\n",
            "9      \t [ 0.18789441 -0.22799179]. \t  0.10133714252922164 \t 0.11266659382318968\n",
            "10     \t [ 0.18895235 -0.22821476]. \t  0.10044922995917793 \t 0.11266659382318968\n",
            "11     \t [ 0.18972315 -0.22836606]. \t  0.09977741581777602 \t 0.11266659382318968\n",
            "12     \t [ 0.19030596 -0.22847222]. \t  0.0992518118409408 \t 0.11266659382318968\n",
            "13     \t [ 0.19075944 -0.22854847]. \t  0.09882969851563124 \t 0.11266659382318968\n",
            "14     \t [ 0.19112084 -0.22860435]. \t  0.09848339421797048 \t 0.11266659382318968\n",
            "15     \t [ 0.19141413 -0.22864586]. \t  0.09819468411301553 \t 0.11266659382318968\n",
            "16     \t [ 0.19165654 -0.2286771 ]. \t  0.09794999571842065 \t 0.11266659382318968\n",
            "17     \t [ 0.19185958 -0.22870076]. \t  0.09774017764933576 \t 0.11266659382318968\n",
            "18     \t [ 0.19203138 -0.22871865]. \t  0.09755853021250088 \t 0.11266659382318968\n",
            "19     \t [ 0.1921788  -0.22873248]. \t  0.09739969134017432 \t 0.11266659382318968\n",
            "20     \t [ 0.19230635 -0.22874288]. \t  0.09725928030298935 \t 0.11266659382318968\n",
            "21     \t [ 0.19241707 -0.22875056]. \t  0.09713484733400543 \t 0.11266659382318968\n",
            "22     \t [ 0.19251466 -0.2287564 ]. \t  0.09702339560001408 \t 0.11266659382318968\n",
            "23     \t [ 0.19260103 -0.22876073]. \t  0.09692317515653456 \t 0.11266659382318968\n",
            "24     \t [ 0.19267767 -0.2287635 ]. \t  0.0968322238726487 \t 0.11266659382318968\n",
            "25     \t [ 0.19274614 -0.22876578]. \t  0.09675058369046853 \t 0.11266659382318968\n",
            "26     \t [ 0.19280781 -0.22876701]. \t  0.09667551497637131 \t 0.11266659382318968\n",
            "27     \t [ 0.19286349 -0.22876765]. \t  0.09660686063739383 \t 0.11266659382318968\n",
            "28     \t [ 0.1929139  -0.22876768]. \t  0.09654366393627803 \t 0.11266659382318968\n",
            "29     \t [ 0.19295964 -0.22876734]. \t  0.09648564766223394 \t 0.11266659382318968\n",
            "30     \t [ 0.19300154 -0.22876671]. \t  0.09643188154988216 \t 0.11266659382318968\n",
            "31     \t [ 0.19304008 -0.22876587]. \t  0.09638196295748486 \t 0.11266659382318968\n",
            "32     \t [ 0.19307555 -0.22876476]. \t  0.09633539688675824 \t 0.11266659382318968\n",
            "33     \t [ 0.19310803 -0.22876339]. \t  0.09629208655057313 \t 0.11266659382318968\n",
            "34     \t [ 0.19313802 -0.22876194]. \t  0.09625175354071523 \t 0.11266659382318968\n",
            "35     \t [ 0.19316587 -0.22876033]. \t  0.09621381014029406 \t 0.11266659382318968\n",
            "36     \t [ 0.19319192 -0.22875877]. \t  0.09617822898688369 \t 0.11266659382318968\n",
            "37     \t [ 0.19321593 -0.22875698]. \t  0.09614475977121223 \t 0.11266659382318968\n",
            "38     \t [ 0.19323844 -0.22875523]. \t  0.09611326795721381 \t 0.11266659382318968\n",
            "39     \t [ 0.19325949 -0.2287534 ]. \t  0.09608344760664154 \t 0.11266659382318968\n",
            "40     \t [ 0.19327909 -0.22875159]. \t  0.09605548877418453 \t 0.11266659382318968\n",
            "41     \t [ 0.19329762 -0.22874979]. \t  0.09602888452993213 \t 0.11266659382318968\n",
            "42     \t [ 0.19331466 -0.22874787]. \t  0.09600394762034795 \t 0.11266659382318968\n",
            "43     \t [ 0.19333108 -0.22874598]. \t  0.09597983942359933 \t 0.11266659382318968\n",
            "44     \t [ 0.19334675 -0.22874432]. \t  0.09595707749257099 \t 0.11266659382318968\n",
            "45     \t [ 0.19336106 -0.22874236]. \t  0.09593549879395968 \t 0.11266659382318968\n",
            "46     \t [ 0.19337492 -0.22874058]. \t  0.0959147806593487 \t 0.11266659382318968\n",
            "47     \t [ 0.19338798 -0.22873883]. \t  0.09589516243297183 \t 0.11266659382318968\n",
            "48     \t [ 0.19340038 -0.2287371 ]. \t  0.09587638317848726 \t 0.11266659382318968\n",
            "49     \t [ 0.19341187 -0.22873527]. \t  0.09585858859179641 \t 0.11266659382318968\n",
            "50     \t [ 0.19342319 -0.2287336 ]. \t  0.09584127720159964 \t 0.11266659382318968\n",
            "51     \t [ 0.1934337  -0.22873188]. \t  0.09582489517245597 \t 0.11266659382318968\n",
            "52     \t [ 0.19344365 -0.22873016]. \t  0.09580921052751037 \t 0.11266659382318968\n",
            "53     \t [ 0.19345315 -0.22872844]. \t  0.09579411061702364 \t 0.11266659382318968\n",
            "54     \t [ 0.19346243 -0.22872689]. \t  0.09577960363849944 \t 0.11266659382318968\n",
            "55     \t [ 0.19347104 -0.22872525]. \t  0.09576575599099743 \t 0.11266659382318968\n",
            "56     \t [ 0.19347965 -0.22872377]. \t  0.09575219950348106 \t 0.11266659382318968\n",
            "57     \t [ 0.19348752 -0.22872217]. \t  0.09573936262355323 \t 0.11266659382318968\n",
            "58     \t [ 0.19349495 -0.22872057]. \t  0.09572707663673852 \t 0.11266659382318968\n",
            "59     \t [ 0.19350228 -0.22871911]. \t  0.09571517968322404 \t 0.11266659382318968\n",
            "60     \t [ 0.19350943 -0.22871764]. \t  0.0957034805308774 \t 0.11266659382318968\n",
            "61     \t [ 0.1935163  -0.22871631]. \t  0.09569239384394575 \t 0.11266659382318968\n",
            "62     \t [ 0.19352284 -0.22871493]. \t  0.09568163971768512 \t 0.11266659382318968\n",
            "63     \t [ 0.19352898 -0.22871348]. \t  0.09567123995556617 \t 0.11266659382318968\n",
            "64     \t [ 0.19353491 -0.22871207]. \t  0.09566119066272394 \t 0.11266659382318968\n",
            "65     \t [ 0.1935408 -0.2287108]. \t  0.09565146974695438 \t 0.11266659382318968\n",
            "66     \t [ 0.19354603 -0.22870931]. \t  0.09564214778376358 \t 0.11266659382318968\n",
            "67     \t [ 0.19355148 -0.22870807]. \t  0.09563300091990315 \t 0.11266659382318968\n",
            "68     \t [ 0.19355657 -0.22870679]. \t  0.09562424989155482 \t 0.11266659382318968\n",
            "69     \t [ 0.19356143 -0.2287055 ]. \t  0.09561576382865251 \t 0.11266659382318968\n",
            "70     \t [ 0.19356653 -0.22870444]. \t  0.09560739927801576 \t 0.11266659382318968\n",
            "71     \t [ 0.19357076 -0.22870308]. \t  0.09559958471727883 \t 0.11266659382318968\n",
            "72     \t [ 0.19357553 -0.22870196]. \t  0.09559152043589848 \t 0.11266659382318968\n",
            "73     \t [ 0.19357975 -0.22870081]. \t  0.09558411322719698 \t 0.11266659382318968\n",
            "74     \t [ 0.19358392 -0.22869966]. \t  0.09557674475262432 \t 0.11266659382318968\n",
            "75     \t [ 0.19358814 -0.22869864]. \t  0.09556956490373837 \t 0.11266659382318968\n",
            "76     \t [ 0.19359215 -0.2286976 ]. \t  0.09556260780596709 \t 0.11266659382318968\n",
            "77     \t [ 0.19359559 -0.22869637]. \t  0.09555600867360045 \t 0.11266659382318968\n",
            "78     \t [ 0.19359943 -0.22869535]. \t  0.09554931681505671 \t 0.11266659382318968\n",
            "79     \t [ 0.19360279 -0.22869423]. \t  0.0955430336255665 \t 0.11266659382318968\n",
            "80     \t [ 0.19360636 -0.22869331]. \t  0.09553683611544705 \t 0.11266659382318968\n",
            "81     \t [ 0.19360974 -0.22869234]. \t  0.09553081316734977 \t 0.11266659382318968\n",
            "82     \t [ 0.1936131  -0.22869133]. \t  0.09552472022428721 \t 0.11266659382318968\n",
            "83     \t [ 0.19361614 -0.22869035]. \t  0.0955190954521904 \t 0.11266659382318968\n",
            "84     \t [ 0.19361932 -0.22868943]. \t  0.09551341853485906 \t 0.11266659382318968\n",
            "85     \t [ 0.1936222  -0.22868846]. \t  0.09550800848820121 \t 0.11266659382318968\n",
            "86     \t [ 0.19362513 -0.22868756]. \t  0.09550266927132427 \t 0.11266659382318968\n",
            "87     \t [ 0.19362796 -0.22868667]. \t  0.09549745918109087 \t 0.11266659382318968\n",
            "88     \t [ 0.1936304  -0.22868565]. \t  0.0954925297785997 \t 0.11266659382318968\n",
            "89     \t [ 0.19363325 -0.22868489]. \t  0.09548753873100513 \t 0.11266659382318968\n",
            "90     \t [ 0.19363604 -0.22868406]. \t  0.09548252013691635 \t 0.11266659382318968\n",
            "91     \t [ 0.19363809 -0.22868302]. \t  0.09547801349164614 \t 0.11266659382318968\n",
            "92     \t [ 0.1936409  -0.22868233]. \t  0.09547322937450167 \t 0.11266659382318968\n",
            "93     \t [ 0.19364313 -0.22868145]. \t  0.09546879841888545 \t 0.11266659382318968\n",
            "94     \t [ 0.1936454  -0.22868055]. \t  0.09546427474313746 \t 0.11266659382318968\n",
            "95     \t [ 0.19364772 -0.22867989]. \t  0.09546014879526732 \t 0.11266659382318968\n",
            "96     \t [ 0.19365015 -0.22867922]. \t  0.09545586340162812 \t 0.11266659382318968\n",
            "97     \t [ 0.19365225 -0.22867842]. \t  0.09545175631330041 \t 0.11266659382318968\n",
            "98     \t [ 0.19365405 -0.2286775 ]. \t  0.09544778799064027 \t 0.11266659382318968\n",
            "99     \t [ 0.1936566  -0.22867697]. \t  0.09544362024343557 \t 0.11266659382318968\n",
            "100    \t [ 0.19365794 -0.22867572]. \t  0.0954396467974361 \t 0.11266659382318968\n"
          ]
        }
      ],
      "source": [
        "### Bayesian optimisation runs (x20): 'GP' Acquisition Function run number = 18\n",
        "\n",
        "np.random.seed(run_num_18)\n",
        "surrogate_gp_18 = GaussianProcess(cov_func, optimize=hyperOpt)\n",
        "\n",
        "gp_18 = GPGO(surrogate_gp_18, Acquisition_new(util_gp), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\n",
        "gp_18.run(max_iter = max_iter, init_evals = n_init) # run\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E7485DWlJLk8",
        "outputId": "eee3b462-83de-4b5b-9160-de9b7a63bf77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [-2.41479839  1.04499887]. \t  -15.890475442873509 \t -6.578088852480828\n",
            "init   \t [-1.51837216 -1.44747325]. \t  -13.520839509777993 \t -6.578088852480828\n",
            "init   \t [-1.01132062 -1.66800174]. \t  -23.772158573571232 \t -6.578088852480828\n",
            "init   \t [1.03186249 1.22637519]. \t  -6.578088852480828 \t -6.578088852480828\n",
            "init   \t [2.89645149 0.54264294]. \t  -83.31828503667734 \t -6.578088852480828\n",
            "1      \t [-0.0893227  2.       ]. \t  -47.853135267681516 \t -6.578088852480828\n",
            "2      \t [ 1.65748576 -2.        ]. \t  -46.73604076286675 \t -6.578088852480828\n",
            "3      \t [-3. -2.]. \t  -162.89999999999998 \t -6.578088852480828\n",
            "4      \t [-0.30055672 -0.24803334]. \t  \u001b[92m-0.18805151000986672\u001b[0m \t -0.18805151000986672\n",
            "5      \t [-0.25263153 -0.23127222]. \t  \u001b[92m-0.10274608530062904\u001b[0m \t -0.10274608530062904\n",
            "6      \t [-0.22983218 -0.22458376]. \t  \u001b[92m-0.06552196508153613\u001b[0m \t -0.06552196508153613\n",
            "7      \t [-0.21578576 -0.22083649]. \t  \u001b[92m-0.04382641598378456\u001b[0m \t -0.04382641598378456\n",
            "8      \t [-0.20589297 -0.21836901]. \t  \u001b[92m-0.029135185077499015\u001b[0m \t -0.029135185077499015\n",
            "9      \t [-0.19835478 -0.21658427]. \t  \u001b[92m-0.018275241418694688\u001b[0m \t -0.018275241418694688\n",
            "10     \t [-0.19230528 -0.21521117]. \t  \u001b[92m-0.00977362570701551\u001b[0m \t -0.00977362570701551\n",
            "11     \t [-0.18727474 -0.21410893]. \t  \u001b[92m-0.0028514682458766483\u001b[0m \t -0.0028514682458766483\n",
            "12     \t [-0.1829777  -0.21319519]. \t  \u001b[92m0.002953347436781245\u001b[0m \t 0.002953347436781245\n",
            "13     \t [-0.17923301 -0.21241944]. \t  \u001b[92m0.007929741858095196\u001b[0m \t 0.007929741858095196\n",
            "14     \t [-0.1759172  -0.21174807]. \t  \u001b[92m0.01227120624300887\u001b[0m \t 0.01227120624300887\n",
            "15     \t [-0.17294255 -0.21115793]. \t  \u001b[92m0.016113394552931065\u001b[0m \t 0.016113394552931065\n",
            "16     \t [-0.1702443  -0.21063208]. \t  \u001b[92m0.0195547008572792\u001b[0m \t 0.0195547008572792\n",
            "17     \t [-0.16777551 -0.21015886]. \t  \u001b[92m0.022666673855727126\u001b[0m \t 0.022666673855727126\n",
            "18     \t [-0.1654997  -0.20972908]. \t  \u001b[92m0.025503890382522015\u001b[0m \t 0.025503890382522015\n",
            "19     \t [-0.16338769 -0.20933561]. \t  \u001b[92m0.028109544714568585\u001b[0m \t 0.028109544714568585\n",
            "20     \t [-0.16141627 -0.20897289]. \t  \u001b[92m0.030517779311981935\u001b[0m \t 0.030517779311981935\n",
            "21     \t [-0.15956765 -0.20863665]. \t  \u001b[92m0.032754770705910735\u001b[0m \t 0.032754770705910735\n",
            "22     \t [-0.15782494 -0.20832291]. \t  \u001b[92m0.034844427734645717\u001b[0m \t 0.034844427734645717\n",
            "23     \t [-0.15617734 -0.20802927]. \t  \u001b[92m0.03680301711050307\u001b[0m \t 0.03680301711050307\n",
            "24     \t [-0.15461324 -0.20775306]. \t  \u001b[92m0.03864685670486112\u001b[0m \t 0.03864685670486112\n",
            "25     \t [-0.15312365 -0.2074922 ]. \t  \u001b[92m0.040388619865031644\u001b[0m \t 0.040388619865031644\n",
            "26     \t [-0.15170201 -0.20724527]. \t  \u001b[92m0.04203801160689319\u001b[0m \t 0.04203801160689319\n",
            "27     \t [-0.15033972 -0.20701035]. \t  \u001b[92m0.043606457323930925\u001b[0m \t 0.043606457323930925\n",
            "28     \t [-0.14903316 -0.2067867 ]. \t  \u001b[92m0.04509975803001855\u001b[0m \t 0.04509975803001855\n",
            "29     \t [-0.147777   -0.20657316]. \t  \u001b[92m0.04652520977161234\u001b[0m \t 0.04652520977161234\n",
            "30     \t [-0.14656561 -0.20636835]. \t  \u001b[92m0.04789000201119216\u001b[0m \t 0.04789000201119216\n",
            "31     \t [-0.14539666 -0.20617198]. \t  \u001b[92m0.04919808409004617\u001b[0m \t 0.04919808409004617\n",
            "32     \t [-0.14426598 -0.20598309]. \t  \u001b[92m0.05045484641778805\u001b[0m \t 0.05045484641778805\n",
            "33     \t [-0.143171   -0.20580115]. \t  \u001b[92m0.05166394817533085\u001b[0m \t 0.05166394817533085\n",
            "34     \t [-0.14210948 -0.2056257 ]. \t  \u001b[92m0.052828605099208115\u001b[0m \t 0.052828605099208115\n",
            "35     \t [-0.14107667 -0.20545559]. \t  \u001b[92m0.05395430814954007\u001b[0m \t 0.05395430814954007\n",
            "36     \t [-0.14007298 -0.20529114]. \t  \u001b[92m0.05504158717007944\u001b[0m \t 0.05504158717007944\n",
            "37     \t [-0.13909611 -0.20513187]. \t  \u001b[92m0.05609346759677819\u001b[0m \t 0.05609346759677819\n",
            "38     \t [-0.1381432  -0.20497703]. \t  \u001b[92m0.05711319945670831\u001b[0m \t 0.05711319945670831\n",
            "39     \t [-0.13721469 -0.2048269 ]. \t  \u001b[92m0.0581011215558917\u001b[0m \t 0.0581011215558917\n",
            "40     \t [-0.13630678 -0.2046805 ]. \t  \u001b[92m0.059061259540480804\u001b[0m \t 0.059061259540480804\n",
            "41     \t [-0.13541921 -0.20453792]. \t  \u001b[92m0.05999447565771432\u001b[0m \t 0.05999447565771432\n",
            "42     \t [-0.13455075 -0.20439894]. \t  \u001b[92m0.06090245132893285\u001b[0m \t 0.06090245132893285\n",
            "43     \t [-0.13370038 -0.20426328]. \t  \u001b[92m0.061786448293567206\u001b[0m \t 0.061786448293567206\n",
            "44     \t [-0.1328667  -0.20413068]. \t  \u001b[92m0.06264823276409724\u001b[0m \t 0.06264823276409724\n",
            "45     \t [-0.13204872 -0.20400089]. \t  \u001b[92m0.06348898030024497\u001b[0m \t 0.06348898030024497\n",
            "46     \t [-0.1312462 -0.203874 ]. \t  \u001b[92m0.06430942744286694\u001b[0m \t 0.06430942744286694\n",
            "47     \t [-0.13045838 -0.20374982]. \t  \u001b[92m0.06511052865593286\u001b[0m \t 0.06511052865593286\n",
            "48     \t [-0.12968314 -0.20362778]. \t  \u001b[92m0.06589436532947077\u001b[0m \t 0.06589436532947077\n",
            "49     \t [-0.12892217 -0.20350853]. \t  \u001b[92m0.06665997883484542\u001b[0m \t 0.06665997883484542\n",
            "50     \t [-0.12817268 -0.2033912 ]. \t  \u001b[92m0.06740983387865589\u001b[0m \t 0.06740983387865589\n",
            "51     \t [-0.12743462 -0.20327592]. \t  \u001b[92m0.06814433797502804\u001b[0m \t 0.06814433797502804\n",
            "52     \t [-0.12670758 -0.20316263]. \t  \u001b[92m0.06886412050313923\u001b[0m \t 0.06886412050313923\n",
            "53     \t [-0.12599111 -0.20305117]. \t  \u001b[92m0.06956966173935608\u001b[0m \t 0.06956966173935608\n",
            "54     \t [-0.12528503 -0.20294157]. \t  \u001b[92m0.07026140889135189\u001b[0m \t 0.07026140889135189\n",
            "55     \t [-0.12458854 -0.20283376]. \t  \u001b[92m0.07094039070679672\u001b[0m \t 0.07094039070679672\n",
            "56     \t [-0.12390193 -0.20272765]. \t  \u001b[92m0.07160626724167192\u001b[0m \t 0.07160626724167192\n",
            "57     \t [-0.12322346 -0.20262305]. \t  \u001b[92m0.07226099214351794\u001b[0m \t 0.07226099214351794\n",
            "58     \t [-0.12255318 -0.20251976]. \t  \u001b[92m0.07290436288395659\u001b[0m \t 0.07290436288395659\n",
            "59     \t [-0.12189095 -0.20241792]. \t  \u001b[92m0.07353685141588547\u001b[0m \t 0.07353685141588547\n",
            "60     \t [-0.12123729 -0.20231766]. \t  \u001b[92m0.07415816176309112\u001b[0m \t 0.07415816176309112\n",
            "61     \t [-0.12058952 -0.20221822]. \t  \u001b[92m0.0747704702115358\u001b[0m \t 0.0747704702115358\n",
            "62     \t [-0.11995003 -0.20212037]. \t  \u001b[92m0.07537218527779002\u001b[0m \t 0.07537218527779002\n",
            "63     \t [-0.11931695 -0.20202358]. \t  \u001b[92m0.07596482131512156\u001b[0m \t 0.07596482131512156\n",
            "64     \t [-0.11869104 -0.2019281 ]. \t  \u001b[92m0.076547970767477\u001b[0m \t 0.076547970767477\n",
            "65     \t [-0.1180712  -0.20183363]. \t  \u001b[92m0.07712255829275264\u001b[0m \t 0.07712255829275264\n",
            "66     \t [-0.11745639 -0.2017399 ]. \t  \u001b[92m0.07768948422949526\u001b[0m \t 0.07768948422949526\n",
            "67     \t [-0.11684873 -0.20164757]. \t  \u001b[92m0.07824734173938719\u001b[0m \t 0.07824734173938719\n",
            "68     \t [-0.11624632 -0.20155601]. \t  \u001b[92m0.07879747330839967\u001b[0m \t 0.07879747330839967\n",
            "69     \t [-0.1156493  -0.20146545]. \t  \u001b[92m0.07934013762152324\u001b[0m \t 0.07934013762152324\n",
            "70     \t [-0.1150574  -0.20137568]. \t  \u001b[92m0.07987540693525562\u001b[0m \t 0.07987540693525562\n",
            "71     \t [-0.11447062 -0.20128682]. \t  \u001b[92m0.08040353905284\u001b[0m \t 0.08040353905284\n",
            "72     \t [-0.11388895 -0.20119881]. \t  \u001b[92m0.08092449406391256\u001b[0m \t 0.08092449406391256\n",
            "73     \t [-0.11331184 -0.20111156]. \t  \u001b[92m0.08143884064077542\u001b[0m \t 0.08143884064077542\n",
            "74     \t [-0.1127391  -0.20102502]. \t  \u001b[92m0.08194679026931577\u001b[0m \t 0.08194679026931577\n",
            "75     \t [-0.1121707  -0.20093923]. \t  \u001b[92m0.08244846224402537\u001b[0m \t 0.08244846224402537\n",
            "76     \t [-0.11160704 -0.2008542 ]. \t  \u001b[92m0.08294351396893701\u001b[0m \t 0.08294351396893701\n",
            "77     \t [-0.11104721 -0.20076988]. \t  \u001b[92m0.08343291500915828\u001b[0m \t 0.08343291500915828\n",
            "78     \t [-0.11049087 -0.200686  ]. \t  \u001b[92m0.08391670212945143\u001b[0m \t 0.08391670212945143\n",
            "79     \t [-0.10993987 -0.20060321]. \t  \u001b[92m0.0843938485714873\u001b[0m \t 0.0843938485714873\n",
            "80     \t [-0.10939155 -0.20052071]. \t  \u001b[92m0.08486614144237788\u001b[0m \t 0.08486614144237788\n",
            "81     \t [-0.10884727 -0.20043897]. \t  \u001b[92m0.08533281545423888\u001b[0m \t 0.08533281545423888\n",
            "82     \t [-0.10830673 -0.20035782]. \t  \u001b[92m0.08579403548211549\u001b[0m \t 0.08579403548211549\n",
            "83     \t [-0.10776873 -0.200277  ]. \t  \u001b[92m0.08625072451424819\u001b[0m \t 0.08625072451424819\n",
            "84     \t [-0.10723492 -0.20019693]. \t  \u001b[92m0.08670177091612448\u001b[0m \t 0.08670177091612448\n",
            "85     \t [-0.10670403 -0.20011731]. \t  \u001b[92m0.08714814659141017\u001b[0m \t 0.08714814659141017\n",
            "86     \t [-0.10617636 -0.20003821]. \t  \u001b[92m0.08758965067056898\u001b[0m \t 0.08758965067056898\n",
            "87     \t [-0.10565211 -0.19995971]. \t  \u001b[92m0.08802625627622512\u001b[0m \t 0.08802625627622512\n",
            "88     \t [-0.10513014 -0.19988151]. \t  \u001b[92m0.0884587380672675\u001b[0m \t 0.0884587380672675\n",
            "89     \t [-0.10461187 -0.19980397]. \t  \u001b[92m0.08888618813348792\u001b[0m \t 0.08888618813348792\n",
            "90     \t [-0.10409489 -0.19972641]. \t  \u001b[92m0.08931015464254\u001b[0m \t 0.08931015464254\n",
            "91     \t [-0.10358237 -0.19964979]. \t  \u001b[92m0.08972876694415059\u001b[0m \t 0.08972876694415059\n",
            "92     \t [-0.10307157 -0.19957334]. \t  \u001b[92m0.09014378589532898\u001b[0m \t 0.09014378589532898\n",
            "93     \t [-0.10256418 -0.19949753]. \t  \u001b[92m0.09055417565319246\u001b[0m \t 0.09055417565319246\n",
            "94     \t [-0.1020584  -0.19942181]. \t  \u001b[92m0.0909610329232077\u001b[0m \t 0.0909610329232077\n",
            "95     \t [-0.10155618 -0.19934684]. \t  \u001b[92m0.09136332322643721\u001b[0m \t 0.09136332322643721\n",
            "96     \t [-0.10105539 -0.19927193]. \t  \u001b[92m0.09176227545621608\u001b[0m \t 0.09176227545621608\n",
            "97     \t [-0.10055788 -0.19919767]. \t  \u001b[92m0.09215685520144563\u001b[0m \t 0.09215685520144563\n",
            "98     \t [-0.10006281 -0.19912378]. \t  \u001b[92m0.09254759590071884\u001b[0m \t 0.09254759590071884\n",
            "99     \t [-0.09956877 -0.19904985]. \t  \u001b[92m0.09293530521765762\u001b[0m \t 0.09293530521765762\n",
            "100    \t [-0.09907751 -0.19897644]. \t  \u001b[92m0.09331905211450606\u001b[0m \t 0.09331905211450606\n"
          ]
        }
      ],
      "source": [
        "### Bayesian optimisation runs (x20): 'GP' Acquisition Function run number = 19\n",
        "\n",
        "np.random.seed(run_num_19)\n",
        "surrogate_gp_19 = GaussianProcess(cov_func, optimize=hyperOpt)\n",
        "\n",
        "gp_19 = GPGO(surrogate_gp_19, Acquisition_new(util_gp), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\n",
        "gp_19.run(max_iter = max_iter, init_evals = n_init) # run\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9oZm6NvJLk9",
        "outputId": "c64ce047-f974-4957-8235-1b2e56bf9bb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.52878481 1.59085491]. \t  -17.29968374481291 \t -1.5037392797834441\n",
            "init   \t [2.34918438 1.26334991]. \t  -20.91583049569433 \t -1.5037392797834441\n",
            "init   \t [-2.78466249  0.76703033]. \t  -57.06253405225224 \t -1.5037392797834441\n",
            "init   \t [-0.72791435  0.07404378]. \t  -1.5037392797834441 \t -1.5037392797834441\n",
            "init   \t [ 0.94770879 -1.22459913]. \t  -3.9766737661914173 \t -1.5037392797834441\n",
            "1      \t [-1.17018689 -2.        ]. \t  -52.735919686258626 \t -1.5037392797834441\n",
            "2      \t [ 3. -2.]. \t  -150.89999999999998 \t -1.5037392797834441\n",
            "3      \t [ 0.43932856 -0.30904381]. \t  \u001b[92m-0.2148874753072924\u001b[0m \t -0.2148874753072924\n",
            "4      \t [ 0.44030325 -0.31029131]. \t  \u001b[92m-0.21430421804036365\u001b[0m \t -0.21430421804036365\n",
            "5      \t [ 0.4408062  -0.31090829]. \t  \u001b[92m-0.21406695937967968\u001b[0m \t -0.21406695937967968\n",
            "6      \t [ 0.44110331 -0.31127036]. \t  \u001b[92m-0.2139322142219265\u001b[0m \t -0.2139322142219265\n",
            "7      \t [ 0.44129796 -0.31150724]. \t  \u001b[92m-0.21384455747711023\u001b[0m \t -0.21384455747711023\n",
            "8      \t [ 0.44143458 -0.31167376]. \t  \u001b[92m-0.21378228326001714\u001b[0m \t -0.21378228326001714\n",
            "9      \t [ 0.44153604 -0.31179738]. \t  \u001b[92m-0.21373611546373034\u001b[0m \t -0.21373611546373034\n",
            "10     \t [ 0.44161398 -0.31189246]. \t  \u001b[92m-0.21370034577524039\u001b[0m \t -0.21370034577524039\n",
            "11     \t [ 0.44167567 -0.31196785]. \t  \u001b[92m-0.2136716925912175\u001b[0m \t -0.2136716925912175\n",
            "12     \t [ 0.44172573 -0.31202908]. \t  \u001b[92m-0.21364830136068863\u001b[0m \t -0.21364830136068863\n",
            "13     \t [ 0.44176702 -0.31207971]. \t  \u001b[92m-0.213628675336464\u001b[0m \t -0.213628675336464\n",
            "14     \t [ 0.44180211 -0.31212255]. \t  \u001b[92m-0.21361246481946705\u001b[0m \t -0.21361246481946705\n",
            "15     \t [ 0.44183152 -0.31215873]. \t  \u001b[92m-0.2135981759259808\u001b[0m \t -0.2135981759259808\n",
            "16     \t [ 0.44185712 -0.31219014]. \t  \u001b[92m-0.2135859610785919\u001b[0m \t -0.2135859610785919\n",
            "17     \t [ 0.44187938 -0.3122175 ]. \t  \u001b[92m-0.21357521425187148\u001b[0m \t -0.21357521425187148\n",
            "18     \t [ 0.44189894 -0.31224156]. \t  \u001b[92m-0.21356570099333888\u001b[0m \t -0.21356570099333888\n",
            "19     \t [ 0.4419162  -0.31226277]. \t  \u001b[92m-0.21355739014296343\u001b[0m \t -0.21355739014296343\n",
            "20     \t [ 0.44193153 -0.31228165]. \t  \u001b[92m-0.21354989023114201\u001b[0m \t -0.21354989023114201\n",
            "21     \t [ 0.44194552 -0.31229878]. \t  \u001b[92m-0.21354330898289003\u001b[0m \t -0.21354330898289003\n",
            "22     \t [ 0.441958   -0.31231418]. \t  \u001b[92m-0.21353711652965224\u001b[0m \t -0.21353711652965224\n",
            "23     \t [ 0.44196923 -0.31232805]. \t  \u001b[92m-0.21353151177866136\u001b[0m \t -0.21353151177866136\n",
            "24     \t [ 0.44197959 -0.31234076]. \t  \u001b[92m-0.21352655611154125\u001b[0m \t -0.21352655611154125\n",
            "25     \t [ 0.44198884 -0.31235229]. \t  \u001b[92m-0.2135217044301142\u001b[0m \t -0.2135217044301142\n",
            "26     \t [ 0.4419975  -0.31236296]. \t  \u001b[92m-0.21351746051899745\u001b[0m \t -0.21351746051899745\n",
            "27     \t [ 0.44200551 -0.31237278]. \t  \u001b[92m-0.21351364005747764\u001b[0m \t -0.21351364005747764\n",
            "28     \t [ 0.44201287 -0.31238191]. \t  \u001b[92m-0.2135098970265744\u001b[0m \t -0.2135098970265744\n",
            "29     \t [ 0.44201966 -0.31239021]. \t  \u001b[92m-0.21350673611382553\u001b[0m \t -0.21350673611382553\n",
            "30     \t [ 0.44202582 -0.31239795]. \t  \u001b[92m-0.2135033299605747\u001b[0m \t -0.2135033299605747\n",
            "31     \t [ 0.44203191 -0.31240535]. \t  \u001b[92m-0.2135006138752476\u001b[0m \t -0.2135006138752476\n",
            "32     \t [ 0.44203719 -0.31241201]. \t  \u001b[92m-0.21349762163277436\u001b[0m \t -0.21349762163277436\n",
            "33     \t [ 0.44204233 -0.3124184 ]. \t  \u001b[92m-0.21349496164369036\u001b[0m \t -0.21349496164369036\n",
            "34     \t [ 0.44204734 -0.31242446]. \t  \u001b[92m-0.21349276387013832\u001b[0m \t -0.21349276387013832\n",
            "35     \t [ 0.44205161 -0.31242988]. \t  \u001b[92m-0.21349028917139984\u001b[0m \t -0.21349028917139984\n",
            "36     \t [ 0.44205609 -0.3124353 ]. \t  \u001b[92m-0.21348834722184662\u001b[0m \t -0.21348834722184662\n",
            "37     \t [ 0.44205992 -0.31244015]. \t  \u001b[92m-0.21348612955973262\u001b[0m \t -0.21348612955973262\n",
            "38     \t [ 0.44206369 -0.31244484]. \t  \u001b[92m-0.2134841712190283\u001b[0m \t -0.2134841712190283\n",
            "39     \t [ 0.44206737 -0.31244934]. \t  \u001b[92m-0.21348245065112043\u001b[0m \t -0.21348245065112043\n",
            "40     \t [ 0.44207071 -0.31245352]. \t  \u001b[92m-0.21348065590479204\u001b[0m \t -0.21348065590479204\n",
            "41     \t [ 0.44207406 -0.3124576 ]. \t  \u001b[92m-0.21347912480877945\u001b[0m \t -0.21347912480877945\n",
            "42     \t [ 0.44207713 -0.31246141]. \t  \u001b[92m-0.2134775424768503\u001b[0m \t -0.2134775424768503\n",
            "43     \t [ 0.44208001 -0.31246496]. \t  \u001b[92m-0.21347612382063608\u001b[0m \t -0.21347612382063608\n",
            "44     \t [ 0.44208257 -0.3124683 ]. \t  \u001b[92m-0.2134744263843812\u001b[0m \t -0.2134744263843812\n",
            "45     \t [ 0.44208512 -0.31247151]. \t  \u001b[92m-0.2134729989904638\u001b[0m \t -0.2134729989904638\n",
            "46     \t [ 0.44208787 -0.3124748 ]. \t  \u001b[92m-0.2134718892127993\u001b[0m \t -0.2134718892127993\n",
            "47     \t [ 0.44209028 -0.31247776]. \t  \u001b[92m-0.21347072360823816\u001b[0m \t -0.21347072360823816\n",
            "48     \t [ 0.44209248 -0.31248056]. \t  \u001b[92m-0.21346944139657525\u001b[0m \t -0.21346944139657525\n",
            "49     \t [ 0.44209451 -0.3124832 ]. \t  \u001b[92m-0.2134680927367696\u001b[0m \t -0.2134680927367696\n",
            "50     \t [ 0.44209695 -0.31248604]. \t  \u001b[92m-0.21346730854143514\u001b[0m \t -0.21346730854143514\n",
            "51     \t [ 0.4420988  -0.31248845]. \t  \u001b[92m-0.21346607256760725\u001b[0m \t -0.21346607256760725\n",
            "52     \t [ 0.4421009  -0.31249096]. \t  \u001b[92m-0.21346524483020068\u001b[0m \t -0.21346524483020068\n",
            "53     \t [ 0.44210261 -0.31249321]. \t  \u001b[92m-0.21346404319901563\u001b[0m \t -0.21346404319901563\n",
            "54     \t [ 0.44210444 -0.31249542]. \t  \u001b[92m-0.21346324616426604\u001b[0m \t -0.21346324616426604\n",
            "55     \t [ 0.44210614 -0.31249761]. \t  \u001b[92m-0.21346219779069675\u001b[0m \t -0.21346219779069675\n",
            "56     \t [ 0.44210737 -0.31249933]. \t  \u001b[92m-0.2134610794061052\u001b[0m \t -0.2134610794061052\n",
            "57     \t [ 0.44210948 -0.31250164]. \t  \u001b[92m-0.21346077750598208\u001b[0m \t -0.21346077750598208\n",
            "58     \t [ 0.44211098 -0.3125035 ]. \t  \u001b[92m-0.2134599945747938\u001b[0m \t -0.2134599945747938\n",
            "59     \t [ 0.44211268 -0.31250554]. \t  \u001b[92m-0.21345929250357804\u001b[0m \t -0.21345929250357804\n",
            "60     \t [ 0.44211395 -0.31250724]. \t  \u001b[92m-0.21345834423038879\u001b[0m \t -0.21345834423038879\n",
            "61     \t [ 0.4421153  -0.31250893]. \t  \u001b[92m-0.21345762881832453\u001b[0m \t -0.21345762881832453\n",
            "62     \t [ 0.44211632 -0.31251037]. \t  \u001b[92m-0.21345665365357835\u001b[0m \t -0.21345665365357835\n",
            "63     \t [ 0.44211779 -0.31251211]. \t  \u001b[92m-0.21345611515516766\u001b[0m \t -0.21345611515516766\n",
            "64     \t [ 0.44211935 -0.31251387]. \t  \u001b[92m-0.21345574591207256\u001b[0m \t -0.21345574591207256\n",
            "65     \t [ 0.44212034 -0.31251521]. \t  \u001b[92m-0.2134549469625553\u001b[0m \t -0.2134549469625553\n",
            "66     \t [ 0.44212169 -0.31251682]. \t  \u001b[92m-0.21345442980049273\u001b[0m \t -0.21345442980049273\n",
            "67     \t [ 0.44212265 -0.31251812]. \t  \u001b[92m-0.21345364894511698\u001b[0m \t -0.21345364894511698\n",
            "68     \t [ 0.44212372 -0.31251945]. \t  \u001b[92m-0.21345310746906487\u001b[0m \t -0.21345310746906487\n",
            "69     \t [ 0.44212476 -0.3125208 ]. \t  \u001b[92m-0.2134524387552582\u001b[0m \t -0.2134524387552582\n",
            "70     \t [ 0.44212586 -0.31252212]. \t  \u001b[92m-0.21345197697699198\u001b[0m \t -0.21345197697699198\n",
            "71     \t [ 0.442127   -0.31252347]. \t  \u001b[92m-0.21345155343726885\u001b[0m \t -0.21345155343726885\n",
            "72     \t [ 0.44212772 -0.31252452]. \t  \u001b[92m-0.2134508059186624\u001b[0m \t -0.2134508059186624\n",
            "73     \t [ 0.44212887 -0.3125258 ]. \t  \u001b[92m-0.2134505683017382\u001b[0m \t -0.2134505683017382\n",
            "74     \t [ 0.44212972 -0.31252695]. \t  \u001b[92m-0.21344990312127388\u001b[0m \t -0.21344990312127388\n",
            "75     \t [ 0.44213064 -0.31252804]. \t  \u001b[92m-0.21344954201465877\u001b[0m \t -0.21344954201465877\n",
            "76     \t [ 0.44213143 -0.31252911]. \t  \u001b[92m-0.21344893887314054\u001b[0m \t -0.21344893887314054\n",
            "77     \t [ 0.44213236 -0.31253019]. \t  \u001b[92m-0.21344864193753876\u001b[0m \t -0.21344864193753876\n",
            "78     \t [ 0.44213303 -0.31253115]. \t  \u001b[92m-0.21344798084755168\u001b[0m \t -0.21344798084755168\n",
            "79     \t [ 0.44213385 -0.31253219]. \t  \u001b[92m-0.21344748770845973\u001b[0m \t -0.21344748770845973\n",
            "80     \t [ 0.44213493 -0.31253335]. \t  \u001b[92m-0.21344740310020116\u001b[0m \t -0.21344740310020116\n",
            "81     \t [ 0.44213566 -0.31253422]. \t  \u001b[92m-0.21344710040297915\u001b[0m \t -0.21344710040297915\n",
            "82     \t [ 0.44213606 -0.31253497]. \t  \u001b[92m-0.21344629094677242\u001b[0m \t -0.21344629094677242\n",
            "83     \t [ 0.44213692 -0.31253598]. \t  \u001b[92m-0.21344599386140384\u001b[0m \t -0.21344599386140384\n",
            "84     \t [ 0.4421376  -0.31253682]. \t  \u001b[92m-0.21344563623656482\u001b[0m \t -0.21344563623656482\n",
            "85     \t [ 0.44213852 -0.31253785]. \t  \u001b[92m-0.2134454345284334\u001b[0m \t -0.2134454345284334\n",
            "86     \t [ 0.44213906 -0.31253859]. \t  \u001b[92m-0.21344499289116753\u001b[0m \t -0.21344499289116753\n",
            "87     \t [ 0.44214005 -0.31253962]. \t  \u001b[92m-0.21344497270034601\u001b[0m \t -0.21344497270034601\n",
            "88     \t [ 0.44214037 -0.31254023]. \t  \u001b[92m-0.21344429088978545\u001b[0m \t -0.21344429088978545\n",
            "89     \t [ 0.44214131 -0.31254118]. \t  -0.2134443275939748 \t -0.21344429088978545\n",
            "90     \t [ 0.4421415  -0.31254169]. \t  \u001b[92m-0.2134435555999587\u001b[0m \t -0.2134435555999587\n",
            "91     \t [ 0.44214217 -0.3125425 ]. \t  \u001b[92m-0.21344328525586198\u001b[0m \t -0.21344328525586198\n",
            "92     \t [ 0.44214285 -0.31254331]. \t  \u001b[92m-0.2134430274758387\u001b[0m \t -0.2134430274758387\n",
            "93     \t [ 0.44214337 -0.31254397]. \t  \u001b[92m-0.21344269323774134\u001b[0m \t -0.21344269323774134\n",
            "94     \t [ 0.44214389 -0.31254469]. \t  \u001b[92m-0.213442238680304\u001b[0m \t -0.213442238680304\n",
            "95     \t [ 0.44214451 -0.31254537]. \t  \u001b[92m-0.213442143309088\u001b[0m \t -0.213442143309088\n",
            "96     \t [ 0.44214503 -0.31254606]. \t  \u001b[92m-0.21344177917821033\u001b[0m \t -0.21344177917821033\n",
            "97     \t [ 0.44214525 -0.3125465 ]. \t  \u001b[92m-0.2134412529020671\u001b[0m \t -0.2134412529020671\n",
            "98     \t [ 0.44214612 -0.31254733]. \t  -0.2134414274925669 \t -0.2134412529020671\n",
            "99     \t [ 0.44214657 -0.31254797]. \t  \u001b[92m-0.21344099233439956\u001b[0m \t -0.21344099233439956\n",
            "100    \t [ 0.44214721 -0.31254866]. \t  \u001b[92m-0.21344091519465425\u001b[0m \t -0.21344091519465425\n"
          ]
        }
      ],
      "source": [
        "### Bayesian optimisation runs (x20): 'GP' Acquisition Function run number = 20\n",
        "\n",
        "np.random.seed(run_num_20)\n",
        "surrogate_gp_20 = GaussianProcess(cov_func, optimize=hyperOpt)\n",
        "\n",
        "gp_20 = GPGO(surrogate_gp_20, Acquisition_new(util_gp), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\n",
        "gp_20.run(max_iter = max_iter, init_evals = n_init) # run\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3W7oEVSJLk9",
        "outputId": "49ba759b-a3ae-4115-dec8-cc6ed1aca44a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [-0.49786797  0.88129797]. \t  0.2650082867644827 \t 0.2650082867644827\n",
            "init   \t [-2.99931375 -0.79066971]. \t  -110.13991869176735 \t 0.2650082867644827\n",
            "init   \t [-2.11946466 -1.63064562]. \t  -26.90935479429681 \t 0.2650082867644827\n",
            "init   \t [-1.88243873 -0.61775709]. \t  -2.8558363102363344 \t 0.2650082867644827\n",
            "init   \t [-0.61939515  0.15526694]. \t  -1.0540522096005847 \t 0.2650082867644827\n",
            "1      \t [1.68704702 2.        ]. \t  -53.432639721661204 \t 0.2650082867644827\n",
            "2      \t [ 3. -2.]. \t  -150.89999999999998 \t 0.2650082867644827\n",
            "3      \t [-2.05786186  2.        ]. \t  -48.478014548651274 \t 0.2650082867644827\n",
            "4      \t [-0.20980682 -1.61322651]. \t  -17.192521889865652 \t 0.2650082867644827\n",
            "5      \t [ 0.86625864 -0.08576329]. \t  -1.8564473278768476 \t 0.2650082867644827\n",
            "6      \t [3.         0.60778234]. \t  -109.79157310675082 \t 0.2650082867644827\n",
            "7      \t [-0.13209991  2.        ]. \t  -47.804964009406675 \t 0.2650082867644827\n",
            "8      \t [-0.61412261 -0.35354002]. \t  -1.0074102848270408 \t 0.2650082867644827\n",
            "9      \t [ 0.15221337 -0.15671325]. \t  0.0281249311012408 \t 0.2650082867644827\n",
            "10     \t [-1.27891483 -1.17923467]. \t  -6.063788528897984 \t 0.2650082867644827\n",
            "11     \t [-1.04927289  0.08703435]. \t  -2.18184696637356 \t 0.2650082867644827\n",
            "12     \t [ 0.95567963 -2.        ]. \t  -48.24415176947416 \t 0.2650082867644827\n",
            "13     \t [0.53266077 0.78576439]. \t  -0.4471717737443459 \t 0.2650082867644827\n",
            "14     \t [-3.          1.17520275]. \t  -107.47975116812616 \t 0.2650082867644827\n",
            "15     \t [3. 2.]. \t  -162.89999999999998 \t 0.2650082867644827\n",
            "16     \t [ 1.95975972 -0.58099869]. \t  -1.2372614372264992 \t 0.2650082867644827\n",
            "17     \t [ 1.12054453 -0.86045806]. \t  -0.6384852648178553 \t 0.2650082867644827\n",
            "18     \t [-1.25447826 -2.        ]. \t  -52.90214386223562 \t 0.2650082867644827\n",
            "19     \t [ 0.97534666 -0.1083213 ]. \t  -2.0396928508281933 \t 0.2650082867644827\n",
            "20     \t [-0.01480853 -0.04663097]. \t  0.0071112723572223195 \t 0.2650082867644827\n",
            "21     \t [1.45777385 0.73288435]. \t  -2.2896034431559737 \t 0.2650082867644827\n",
            "22     \t [-1.3948992  -0.59055732]. \t  -2.2032861103776344 \t 0.2650082867644827\n",
            "23     \t [0.87692307 0.03644044]. \t  -2.0123702632023908 \t 0.2650082867644827\n",
            "24     \t [ 1.42992794 -0.18851963]. \t  -1.8419432857313072 \t 0.2650082867644827\n",
            "25     \t [ 0.11527919 -0.80834401]. \t  \u001b[92m0.9462473298359376\u001b[0m \t 0.9462473298359376\n",
            "26     \t [-0.68269858 -0.19052625]. \t  -1.4320205937311377 \t 0.9462473298359376\n",
            "27     \t [0.70843632 0.03231662]. \t  -1.5394285316252907 \t 0.9462473298359376\n",
            "28     \t [-0.69024687 -0.18500785]. \t  -1.4605974974014415 \t 0.9462473298359376\n",
            "29     \t [-1.35406615  0.94595161]. \t  -0.6716218209691118 \t 0.9462473298359376\n",
            "30     \t [-1.81895623  0.23203226]. \t  -1.693130950440303 \t 0.9462473298359376\n",
            "31     \t [-0.98806621  0.09519902]. \t  -2.0837437699260715 \t 0.9462473298359376\n",
            "32     \t [-3. -2.]. \t  -162.89999999999998 \t 0.9462473298359376\n",
            "33     \t [-1.06530261 -0.06816765]. \t  -2.3761562392267814 \t 0.9462473298359376\n",
            "34     \t [ 0.89372755 -0.06668793]. \t  -1.9477524043265617 \t 0.9462473298359376\n",
            "35     \t [-1.04508678 -0.06969442]. \t  -2.3515093754686447 \t 0.9462473298359376\n",
            "36     \t [ 0.87756308 -0.06090873]. \t  -1.9190108893914624 \t 0.9462473298359376\n",
            "37     \t [-1.02847522 -0.07018155]. \t  -2.328511820907047 \t 0.9462473298359376\n",
            "38     \t [ 0.86553157 -0.05707223]. \t  -1.8957818474667683 \t 0.9462473298359376\n",
            "39     \t [-1.01490274 -0.07005921]. \t  -2.3079390701382283 \t 0.9462473298359376\n",
            "40     \t [ 0.85757593 -0.05541964]. \t  -1.8787425005975047 \t 0.9462473298359376\n",
            "41     \t [-1.00387648 -0.06967114]. \t  -2.2901006929805288 \t 0.9462473298359376\n",
            "42     \t [ 0.85318601 -0.05569978]. \t  -1.867640987333984 \t 0.9462473298359376\n",
            "43     \t [-0.99496393 -0.06925516]. \t  -2.2749978355312837 \t 0.9462473298359376\n",
            "44     \t [ 0.85130891 -0.05712667]. \t  -1.861165347852551 \t 0.9462473298359376\n",
            "45     \t [-0.98779429 -0.06895347]. \t  -2.2624550264399255 \t 0.9462473298359376\n",
            "46     \t [ 0.85066488 -0.05871572]. \t  -1.8574935819089775 \t 0.9462473298359376\n",
            "47     \t [-0.98205917 -0.06883187]. \t  -2.2522150147720104 \t 0.9462473298359376\n",
            "48     \t [0.43630757 0.247894  ]. \t  -0.5651131206895494 \t 0.9462473298359376\n",
            "49     \t [ 0.89953296 -0.10770169]. \t  -1.8955404417163377 \t 0.9462473298359376\n",
            "50     \t [-0.96878551 -0.05482666]. \t  -2.2210654923640067 \t 0.9462473298359376\n",
            "51     \t [ 0.86897532 -0.07683089]. \t  -1.8763323061324209 \t 0.9462473298359376\n",
            "52     \t [-0.96718751 -0.06379942]. \t  -2.2225127129656004 \t 0.9462473298359376\n",
            "53     \t [ 0.84595568 -0.05461229]. \t  -1.8511416750611511 \t 0.9462473298359376\n",
            "54     \t [-0.96520344 -0.06658562]. \t  -2.21998984942831 \t 0.9462473298359376\n",
            "55     \t [0.50626712 0.20538484]. \t  -0.8352483194575013 \t 0.9462473298359376\n",
            "56     \t [ 0.88882809 -0.09737077]. \t  -1.8896458183409748 \t 0.9462473298359376\n",
            "57     \t [-0.95834178 -0.05813459]. \t  -2.202806491145336 \t 0.9462473298359376\n",
            "58     \t [ 0.86331316 -0.07184349]. \t  -1.8701572882097528 \t 0.9462473298359376\n",
            "59     \t [-0.95855969 -0.0662524 ]. \t  -2.2070046478125898 \t 0.9462473298359376\n",
            "60     \t [ 0.84409466 -0.05335277]. \t  -1.8480954065848212 \t 0.9462473298359376\n",
            "61     \t [-0.95716988 -0.0659366 ]. \t  -2.2041444831169703 \t 0.9462473298359376\n",
            "62     \t [ 0.8341152  -0.04436486]. \t  -1.8338547790628645 \t 0.9462473298359376\n",
            "63     \t [-0.95656319 -0.06698277]. \t  -2.2034011927384745 \t 0.9462473298359376\n",
            "64     \t [ 0.83126182 -0.04237626]. \t  -1.8288678712452584 \t 0.9462473298359376\n",
            "65     \t [0.30101918 0.23438714]. \t  -0.20833397918531602 \t 0.9462473298359376\n",
            "66     \t [-0.74200976  0.2360935 ]. \t  -1.2356440728691445 \t 0.9462473298359376\n",
            "67     \t [0.75863623 0.02263279]. \t  -1.685192210266023 \t 0.9462473298359376\n",
            "68     \t [-0.95775841 -0.1059596 ]. \t  -2.216540913093743 \t 0.9462473298359376\n",
            "69     \t [ 0.80448076 -0.02331842]. \t  -1.7785900567515938 \t 0.9462473298359376\n",
            "70     \t [-0.9495567  -0.07102045]. \t  -2.1910684622002745 \t 0.9462473298359376\n",
            "71     \t [ 0.809348   -0.02853614]. \t  -1.7864418342104 \t 0.9462473298359376\n",
            "72     \t [ 0.80984763 -0.0296554 ]. \t  -1.7866175445406385 \t 0.9462473298359376\n",
            "73     \t [-0.94553415 -0.05729959]. \t  -2.176901957649139 \t 0.9462473298359376\n",
            "74     \t [ 0.81129418 -0.03115297]. \t  -1.7889174440375586 \t 0.9462473298359376\n",
            "75     \t [-0.94484872 -0.05641921]. \t  -2.175073516147656 \t 0.9462473298359376\n",
            "76     \t [ 0.81171699 -0.03160697]. \t  -1.7895664880437345 \t 0.9462473298359376\n",
            "77     \t [ 0.81043588 -0.03076272]. \t  -1.787031266156676 \t 0.9462473298359376\n",
            "78     \t [-0.94458527 -0.05613821]. \t  -2.1743972377118554 \t 0.9462473298359376\n",
            "79     \t [ 0.81151483 -0.03176113]. \t  -1.7888616433448734 \t 0.9462473298359376\n",
            "80     \t [-0.94436047 -0.05644488]. \t  -2.174091464030749 \t 0.9462473298359376\n",
            "81     \t [ 0.81174502 -0.0319376 ]. \t  -1.789289197435828 \t 0.9462473298359376\n",
            "82     \t [-0.94410065 -0.05646959]. \t  -2.173573705248552 \t 0.9462473298359376\n",
            "83     \t [ 0.81183002 -0.03197492]. \t  -1.7894766464197631 \t 0.9462473298359376\n",
            "84     \t [ 0.81045282 -0.03093553]. \t  -1.7868940636946458 \t 0.9462473298359376\n",
            "85     \t [-0.94396013 -0.05626096]. \t  -2.173183404300738 \t 0.9462473298359376\n",
            "86     \t [ 0.81161591 -0.03196226]. \t  -1.788917633495476 \t 0.9462473298359376\n",
            "87     \t [0.48533198 0.19202164]. \t  -0.7811748983752278 \t 0.9462473298359376\n",
            "88     \t [ 0.80078051 -0.02222703]. \t  -1.7695958894081862 \t 0.9462473298359376\n",
            "89     \t [-0.92998442 -0.02848332]. \t  -2.1275683338835254 \t 0.9462473298359376\n",
            "90     \t [ 0.80439167 -0.02553002]. \t  -1.7761377274933043 \t 0.9462473298359376\n",
            "91     \t [-0.94108548 -0.05966699]. \t  -2.1689246044614947 \t 0.9462473298359376\n",
            "92     \t [ 0.80478216 -0.02587507]. \t  -1.7768475464871536 \t 0.9462473298359376\n",
            "93     \t [ 0.80386939 -0.02532116]. \t  -1.7749315076194452 \t 0.9462473298359376\n",
            "94     \t [-0.94003068 -0.05574274]. \t  -2.1648549581358516 \t 0.9462473298359376\n",
            "95     \t [ 0.80461997 -0.02595966]. \t  -1.7763224961759367 \t 0.9462473298359376\n",
            "96     \t [ 0.80377125 -0.02542046]. \t  -1.774565243343152 \t 0.9462473298359376\n",
            "97     \t [-0.94013949 -0.05551951]. \t  -2.1649686469443035 \t 0.9462473298359376\n",
            "98     \t [ 0.80454114 -0.0260527 ]. \t  -1.7760147093060688 \t 0.9462473298359376\n",
            "99     \t [-0.94028798 -0.05579906]. \t  -2.1654144208452273 \t 0.9462473298359376\n",
            "100    \t [ 0.80486594 -0.02628055]. \t  -1.776663658730829 \t 0.9462473298359376\n"
          ]
        }
      ],
      "source": [
        "### Bayesian optimisation runs (x20): 'STP' Acquisition Function run number = 1 \n",
        "\n",
        "np.random.seed(run_num_1)\n",
        "surrogate_stp_1 = tStudentProcess(cov_func, nu = df, optimize=hyperOpt)\n",
        "\n",
        "stp_1 = GPGO(surrogate_stp_1, Acquisition_new(util_stp), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\n",
        "stp_1.run(max_iter = max_iter, init_evals = n_init) # run\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FGw67C40JLk-",
        "outputId": "32dc83db-1b57-463e-ad61-9f51cbd47e38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [-0.38403059 -1.89629507]. \t  -38.61280125654363 \t -0.011939608840498828\n",
            "init   \t [ 0.29797487 -0.25871043]. \t  -0.011939608840498828 \t -0.011939608840498828\n",
            "init   \t [-0.47779319 -0.67866072]. \t  -0.1381453419305213 \t -0.011939608840498828\n",
            "init   \t [-1.7721082   0.47708387]. \t  -0.626144759281101 \t -0.011939608840498828\n",
            "init   \t [-1.20207196 -0.9326909 ]. \t  -3.0693811601417798 \t -0.011939608840498828\n",
            "1      \t [-0.41162109  0.69775235]. \t  \u001b[92m0.6674548409997004\u001b[0m \t 0.6674548409997004\n",
            "2      \t [0.73672632 2.        ]. \t  -51.07916531803823 \t 0.6674548409997004\n",
            "3      \t [ 3.         -1.01587953]. \t  -105.98450515620056 \t 0.6674548409997004\n",
            "4      \t [-3.  2.]. \t  -150.89999999999998 \t 0.6674548409997004\n",
            "5      \t [-3.         -1.42268919]. \t  -121.45891465512346 \t 0.6674548409997004\n",
            "6      \t [3. 2.]. \t  -162.89999999999998 \t 0.6674548409997004\n",
            "7      \t [-0.92185449  0.17264688]. \t  -1.8124166171012224 \t 0.6674548409997004\n",
            "8      \t [-0.88467279  2.        ]. \t  -48.23471464405271 \t 0.6674548409997004\n",
            "9      \t [ 1.36980785 -2.        ]. \t  -47.57434337358956 \t 0.6674548409997004\n",
            "10     \t [1.21928725 0.53682769]. \t  -2.23457066925897 \t 0.6674548409997004\n",
            "11     \t [-3.         0.2089725]. \t  -108.1060325889515 \t 0.6674548409997004\n",
            "12     \t [0.47420797 0.65865255]. \t  -0.12694632647608473 \t 0.6674548409997004\n",
            "13     \t [ 1.37944755 -0.4520731 ]. \t  -1.0302448077122581 \t 0.6674548409997004\n",
            "14     \t [-1.29764829  0.91423737]. \t  -0.6373572235562778 \t 0.6674548409997004\n",
            "15     \t [-1.60982531 -2.        ]. \t  -53.28370688760307 \t 0.6674548409997004\n",
            "16     \t [ 0.58726027 -1.03491156]. \t  -0.8399937198294756 \t 0.6674548409997004\n",
            "17     \t [3.         0.36450677]. \t  -109.5326722014545 \t 0.6674548409997004\n",
            "18     \t [ 0.99300978 -0.10783159]. \t  -2.068926053004636 \t 0.6674548409997004\n",
            "19     \t [-0.50968683  0.02783798]. \t  -0.8859598726762957 \t 0.6674548409997004\n",
            "20     \t [ 0.27506026 -0.06300018]. \t  -0.2576142875375484 \t 0.6674548409997004\n",
            "21     \t [-0.90997324  0.08796966]. \t  -1.9507916083854724 \t 0.6674548409997004\n",
            "22     \t [-1.66843197 -0.36675036]. \t  -2.1984538619913647 \t 0.6674548409997004\n",
            "23     \t [-0.83320505  0.03636582]. \t  -1.8407611035936082 \t 0.6674548409997004\n",
            "24     \t [ 0.48998494 -0.0745871 ]. \t  -0.785232228869073 \t 0.6674548409997004\n",
            "25     \t [-1.23239645  0.10036901]. \t  -2.2352658534889067 \t 0.6674548409997004\n",
            "26     \t [ 0.48641458 -0.07360583]. \t  -0.7758984243892634 \t 0.6674548409997004\n",
            "27     \t [ 0.82809105 -0.51684059]. \t  -0.6518698861099499 \t 0.6674548409997004\n",
            "28     \t [-0.79347925  0.03369959]. \t  -1.7378973033696323 \t 0.6674548409997004\n",
            "29     \t [0.79967019 0.01521586]. \t  -1.79755443028717 \t 0.6674548409997004\n",
            "30     \t [-1.22422226  0.27709087]. \t  -1.7773050708179556 \t 0.6674548409997004\n",
            "31     \t [-0.75089752  0.007868  ]. \t  -1.6413466708523738 \t 0.6674548409997004\n",
            "32     \t [-1.17311512 -0.44946384]. \t  -2.2788080869011034 \t 0.6674548409997004\n",
            "33     \t [ 0.45575724 -0.07648585]. \t  -0.685118241700506 \t 0.6674548409997004\n",
            "34     \t [-0.79773977  0.04443721]. \t  -1.7376527468430214 \t 0.6674548409997004\n",
            "35     \t [ 0.50341001 -0.07890126]. \t  -0.8197780800399755 \t 0.6674548409997004\n",
            "36     \t [-0.82703973  0.05110415]. \t  -1.8074807248670517 \t 0.6674548409997004\n",
            "37     \t [ 0.52971379 -0.08173194]. \t  -0.8945720630672989 \t 0.6674548409997004\n",
            "38     \t [-0.84485048  0.05442159]. \t  -1.8486259155320157 \t 0.6674548409997004\n",
            "39     \t [ 0.54601653 -0.08434448]. \t  -0.9404060857236571 \t 0.6674548409997004\n",
            "40     \t [ 0.54620533 -0.08651445]. \t  -0.9383284257398367 \t 0.6674548409997004\n",
            "41     \t [-0.86216188  0.05779747]. \t  -1.8867352724885813 \t 0.6674548409997004\n",
            "42     \t [ 0.55735803 -0.08817309]. \t  -0.9699298852649452 \t 0.6674548409997004\n",
            "43     \t [-0.86869209  0.05795912]. \t  -1.9021397712934744 \t 0.6674548409997004\n",
            "44     \t [ 0.56498067 -0.0896281 ]. \t  -0.9911707269678903 \t 0.6674548409997004\n",
            "45     \t [-0.87356152  0.05790832]. \t  -1.9137062330776506 \t 0.6674548409997004\n",
            "46     \t [ 0.57038347 -0.09086369]. \t  -1.00597511772656 \t 0.6674548409997004\n",
            "47     \t [-0.87727013  0.05774853]. \t  -1.9225916570149293 \t 0.6674548409997004\n",
            "48     \t [ 0.57432489 -0.09189624]. \t  -1.0166053214315935 \t 0.6674548409997004\n",
            "49     \t [ 0.57220662 -0.09279292]. \t  -1.0090109881004823 \t 0.6674548409997004\n",
            "50     \t [-0.88234515  0.05831081]. \t  -1.9335818445795792 \t 0.6674548409997004\n",
            "51     \t [ 0.57569065 -0.09340137]. \t  -1.0187900649689134 \t 0.6674548409997004\n",
            "52     \t [-0.88413041  0.05785703]. \t  -1.9382893730133954 \t 0.6674548409997004\n",
            "53     \t [ 0.57833522 -0.09393088]. \t  -1.0261252228672688 \t 0.6674548409997004\n",
            "54     \t [ 0.57646338 -0.09445321]. \t  -1.0197534600867268 \t 0.6674548409997004\n",
            "55     \t [-0.88708178  0.05802463]. \t  -1.9447986622966749 \t 0.6674548409997004\n",
            "56     \t [ 0.5789094 -0.0947651]. \t  -1.0267679233781248 \t 0.6674548409997004\n",
            "57     \t [ 0.57730612 -0.09512605]. \t  -1.0214222879594232 \t 0.6674548409997004\n",
            "58     \t [-0.88919837  0.05800568]. \t  -1.9496238080921888 \t 0.6674548409997004\n",
            "59     \t [ 0.57954072 -0.09531158]. \t  -1.0279605743927471 \t 0.6674548409997004\n",
            "60     \t [-0.88973626  0.05750202]. \t  -1.9515187619050458 \t 0.6674548409997004\n",
            "61     \t [ 0.58131566 -0.09549361]. \t  -1.0331093613822455 \t 0.6674548409997004\n",
            "62     \t [ 0.57991838 -0.09574016]. \t  -1.0285373723221338 \t 0.6674548409997004\n",
            "63     \t [-0.89111393  0.05744851]. \t  -1.9546977502795768 \t 0.6674548409997004\n",
            "64     \t [ 0.58158757 -0.09584658]. \t  -1.0334648824369868 \t 0.6674548409997004\n",
            "65     \t [ 0.58037674 -0.09602925]. \t  -1.029543811539059 \t 0.6674548409997004\n",
            "66     \t [ 0.57932807 -0.0961664 ]. \t  -1.0261768821455346 \t 0.6674548409997004\n",
            "67     \t [-0.8928687   0.05762205]. \t  -1.958405135930983 \t 0.6674548409997004\n",
            "68     \t [ 0.58104538 -0.09619059]. \t  -1.0313587982933918 \t 0.6674548409997004\n",
            "69     \t [ 0.58009653 -0.09630439]. \t  -1.028325596100108 \t 0.6674548409997004\n",
            "70     \t [-0.89350693  0.05741046]. \t  -1.960120042623584 \t 0.6674548409997004\n",
            "71     \t [ 0.58164922 -0.09631647]. \t  -1.0330243217478396 \t 0.6674548409997004\n",
            "72     \t [ 0.58078742 -0.09641219]. \t  -1.030279196563437 \t 0.6674548409997004\n",
            "73     \t [-0.89399128  0.05720642]. \t  -1.961478483631403 \t 0.6674548409997004\n",
            "74     \t [ 0.58219686 -0.09641694]. \t  -1.0345531221233004 \t 0.6674548409997004\n",
            "75     \t [ 0.5814113  -0.09649909]. \t  -1.0320573493184033 \t 0.6674548409997004\n",
            "76     \t [ 0.58071347 -0.09656152]. \t  -1.0298547979093935 \t 0.6674548409997004\n",
            "77     \t [-0.89480367  0.0571907 ]. \t  -1.9633135398201749 \t 0.6674548409997004\n",
            "78     \t [ 0.58208426 -0.09654591]. \t  -1.0340383543842053 \t 0.6674548409997004\n",
            "79     \t [ 0.58143233 -0.09660437]. \t  -1.0319801867123033 \t 0.6674548409997004\n",
            "80     \t [ 0.58084854 -0.09664881]. \t  -1.0301480223697734 \t 0.6674548409997004\n",
            "81     \t [-0.89538449  0.05712141]. \t  -1.9647015145111415 \t 0.6674548409997004\n",
            "82     \t [ 0.58215395 -0.09662534]. \t  -1.034143531258532 \t 0.6674548409997004\n",
            "83     \t [ 0.58159896 -0.09666986]. \t  -1.0323984107782351 \t 0.6674548409997004\n",
            "84     \t [ 0.58109784 -0.09670399]. \t  -1.0308310318218488 \t 0.6674548409997004\n",
            "85     \t [-0.89579917  0.0570227 ]. \t  -1.9657577555603098 \t 0.6674548409997004\n",
            "86     \t [ 0.58232772 -0.09667849]. \t  -1.0346000312545607 \t 0.6674548409997004\n",
            "87     \t [ 0.58184547 -0.09671449]. \t  -1.0330871769758603 \t 0.6674548409997004\n",
            "88     \t [ 0.5814074  -0.09674233]. \t  -1.0317195673899442 \t 0.6674548409997004\n",
            "89     \t [-0.89609336  0.05690889]. \t  -1.9665655418910233 \t 0.6674548409997004\n",
            "90     \t [ 0.58255942 -0.09671753]. \t  -1.0352513611557914 \t 0.6674548409997004\n",
            "91     \t [ 0.58213404 -0.09674768]. \t  -1.0339189833923126 \t 0.6674548409997004\n",
            "92     \t [ 0.58174532 -0.09677132]. \t  -1.0327068111788322 \t 0.6674548409997004\n",
            "93     \t [ 0.58138925 -0.09678951]. \t  -1.0316012132941053 \t 0.6674548409997004\n",
            "94     \t [-0.89652014  0.05687751]. \t  -1.96755615000871 \t 0.6674548409997004\n",
            "95     \t [ 0.58249615 -0.09676269]. \t  -1.0349986149350425 \t 0.6674548409997004\n",
            "96     \t [ 0.58214379 -0.09678454]. \t  -1.0338991301453877 \t 0.6674548409997004\n",
            "97     \t [ 0.58181898 -0.09680203]. \t  -1.0328893105560173 \t 0.6674548409997004\n",
            "98     \t [ 0.58151982 -0.09681538]. \t  -1.031962974099846 \t 0.6674548409997004\n",
            "99     \t [-0.89681048  0.05681323]. \t  -1.9682873646168408 \t 0.6674548409997004\n",
            "100    \t [ 0.58257005 -0.09678985]. \t  -1.0351865933246656 \t 0.6674548409997004\n"
          ]
        }
      ],
      "source": [
        "### Bayesian optimisation runs (x20): 'STP' Acquisition Function run number = 2 \n",
        "\n",
        "np.random.seed(run_num_2)\n",
        "surrogate_stp_2 = tStudentProcess(cov_func, nu = df, optimize=hyperOpt)\n",
        "\n",
        "stp_2 = GPGO(surrogate_stp_2, Acquisition_new(util_stp), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\n",
        "stp_2.run(max_iter = max_iter, init_evals = n_init) # run\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFLQAtDZJLk_",
        "outputId": "482fb731-0e26-42c1-b19f-a9dc00083f80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.30478742 0.83259129]. \t  0.2431922946563294 \t 0.2431922946563294\n",
            "init   \t [-1.25457157  0.04331042]. \t  -2.3313310458730996 \t 0.2431922946563294\n",
            "init   \t [2.35768173 1.58517236]. \t  -33.54152175045586 \t 0.2431922946563294\n",
            "init   \t [-2.24648814 -1.17102849]. \t  -14.214109412296352 \t 0.2431922946563294\n",
            "init   \t [-2.69119678 -0.23676063]. \t  -45.87579771712209 \t 0.2431922946563294\n",
            "1      \t [ 0.3382372 -1.1492001]. \t  -1.7358659447366556 \t 0.2431922946563294\n",
            "2      \t [ 3. -2.]. \t  -150.89999999999998 \t 0.2431922946563294\n",
            "3      \t [-1.05350192  2.        ]. \t  -48.20138691794771 \t 0.2431922946563294\n",
            "4      \t [-0.76679255 -2.        ]. \t  -51.227233765045575 \t 0.2431922946563294\n",
            "5      \t [ 0.81300242 -0.09673897]. \t  -1.7069568080916864 \t 0.2431922946563294\n",
            "6      \t [-3.  2.]. \t  -150.89999999999998 \t 0.2431922946563294\n",
            "7      \t [-3. -2.]. \t  -162.89999999999998 \t 0.2431922946563294\n",
            "8      \t [0.77710324 2.        ]. \t  -51.277340365952156 \t 0.2431922946563294\n",
            "9      \t [-0.26880485 -0.10617285]. \t  -0.2621433382149191 \t 0.2431922946563294\n",
            "10     \t [3.         0.35256096]. \t  -109.52228715382891 \t 0.2431922946563294\n",
            "11     \t [-0.04345519 -0.08823213]. \t  0.01951714582443518 \t 0.2431922946563294\n",
            "12     \t [-1.49648228 -0.81983037]. \t  -2.5150911438574237 \t 0.2431922946563294\n",
            "13     \t [ 0.979414 -2.      ]. \t  -48.240057748405775 \t 0.2431922946563294\n",
            "14     \t [-0.56959199 -0.21757426]. \t  -1.0316193517961154 \t 0.2431922946563294\n",
            "15     \t [3. 2.]. \t  -162.89999999999998 \t 0.2431922946563294\n",
            "16     \t [1.56263854 1.05295805]. \t  -4.226717247101997 \t 0.2431922946563294\n",
            "17     \t [-0.67554482  0.95080725]. \t  -0.4304300091511523 \t 0.2431922946563294\n",
            "18     \t [1.7514231 2.       ]. \t  -53.63404033005017 \t 0.2431922946563294\n",
            "19     \t [ 1.19423524 -0.94467019]. \t  -0.8880462073609827 \t 0.2431922946563294\n",
            "20     \t [0.76509029 0.10103448]. \t  -1.7256312314946127 \t 0.2431922946563294\n",
            "21     \t [1.22955899 0.341042  ]. \t  -2.407530428140425 \t 0.2431922946563294\n",
            "22     \t [ 0.54333045 -0.19151382]. \t  -0.7610127163292475 \t 0.2431922946563294\n",
            "23     \t [-1.70828776  0.86031126]. \t  0.16586715536347685 \t 0.2431922946563294\n",
            "24     \t [-1.06044574  0.58260073]. \t  -0.8018734195920996 \t 0.2431922946563294\n",
            "25     \t [ 1.92339098 -0.58704798]. \t  -0.9015568757024577 \t 0.2431922946563294\n",
            "26     \t [-0.40704825 -0.91005902]. \t  -0.40793721216526013 \t 0.2431922946563294\n",
            "27     \t [-1.05664069 -0.02458086]. \t  -2.335682814202942 \t 0.2431922946563294\n",
            "28     \t [ 1.26287823 -0.42033313]. \t  -1.277456124423019 \t 0.2431922946563294\n",
            "29     \t [ 0.86741925 -0.12047787]. \t  -1.8010581751138377 \t 0.2431922946563294\n",
            "30     \t [-0.95910565  0.02247362]. \t  -2.138434523160173 \t 0.2431922946563294\n",
            "31     \t [ 0.85290998 -0.1226716 ]. \t  -1.7629255313741001 \t 0.2431922946563294\n",
            "32     \t [-0.85284612  0.07307543]. \t  -1.843112147404033 \t 0.2431922946563294\n",
            "33     \t [ 0.84914138 -0.12484186]. \t  -1.749951587214514 \t 0.2431922946563294\n",
            "34     \t [-0.95877994  0.00993553]. \t  -2.1514732196291506 \t 0.2431922946563294\n",
            "35     \t [-0.16650338  0.19893542]. \t  0.07587323214009277 \t 0.2431922946563294\n",
            "36     \t [ 0.8552333  -0.13037132]. \t  -1.7543393607516233 \t 0.2431922946563294\n",
            "37     \t [-0.97041795  0.0062593 ]. \t  -2.1766679050635402 \t 0.2431922946563294\n",
            "38     \t [ 0.83678221 -0.12613015]. \t  -1.7174838350286152 \t 0.2431922946563294\n",
            "39     \t [-0.38494299  0.20427659]. \t  -0.30911262054982935 \t 0.2431922946563294\n",
            "40     \t [ 0.83524134 -0.12426591]. \t  -1.717042740515483 \t 0.2431922946563294\n",
            "41     \t [-0.98894743 -0.0064194 ]. \t  -2.2213954522187804 \t 0.2431922946563294\n",
            "42     \t [ 0.8164575  -0.12020742]. \t  -1.6768854635069863 \t 0.2431922946563294\n",
            "43     \t [-0.4845488   0.19303857]. \t  -0.5906637244303113 \t 0.2431922946563294\n",
            "44     \t [-0.97886834 -0.00172007]. \t  -2.199603917608327 \t 0.2431922946563294\n",
            "45     \t [ 0.81834871 -0.11787548]. \t  -1.6857954045768315 \t 0.2431922946563294\n",
            "46     \t [-0.04278806  0.03922176]. \t  0.0005059076219756592 \t 0.2431922946563294\n",
            "47     \t [-0.72650799  0.16223583]. \t  -1.3548594554639448 \t 0.2431922946563294\n",
            "48     \t [ 0.83372474 -0.11811208]. \t  -1.7242035380539433 \t 0.2431922946563294\n",
            "49     \t [-0.91251452  0.01407746]. \t  -2.053485180810945 \t 0.2431922946563294\n",
            "50     \t [ 0.81313022 -0.11773403]. \t  -1.6726245252439476 \t 0.2431922946563294\n",
            "51     \t [ 0.00540524 -0.01894286]. \t  0.0014203389865321372 \t 0.2431922946563294\n",
            "52     \t [ 0.81488001 -0.11261647]. \t  -1.6858965978419373 \t 0.2431922946563294\n",
            "53     \t [-0.67826948  0.16914571]. \t  -1.2023048811951227 \t 0.2431922946563294\n",
            "54     \t [-0.88072567  0.00832932]. \t  -1.9871469516387807 \t 0.2431922946563294\n",
            "55     \t [ 0.80269672 -0.11704404]. \t  -1.6466374775540689 \t 0.2431922946563294\n",
            "56     \t [-0.07646613  0.03333195]. \t  -0.016328645473319785 \t 0.2431922946563294\n",
            "57     \t [-0.65529144  0.16847798]. \t  -1.1360820528463442 \t 0.2431922946563294\n",
            "58     \t [ 0.79182141 -0.11569724]. \t  -1.6201216471047155 \t 0.2431922946563294\n",
            "59     \t [-0.84729326  0.01976581]. \t  -1.8943308943882948 \t 0.2431922946563294\n",
            "60     \t [ 0.78534125 -0.10292931]. \t  -1.6236567718519896 \t 0.2431922946563294\n",
            "61     \t [-0.57962112  0.16783361]. \t  -0.9126778003316612 \t 0.2431922946563294\n",
            "62     \t [ 0.7825117  -0.11939754]. \t  -1.5888098221014322 \t 0.2431922946563294\n",
            "63     \t [-0.87144691  0.0053368 ]. \t  -1.9677961900826155 \t 0.2431922946563294\n",
            "64     \t [ 0.14197838 -0.12160917]. \t  -0.0042346605104817 \t 0.2431922946563294\n",
            "65     \t [ 0.77484063 -0.09580885]. \t  -1.606078407556022 \t 0.2431922946563294\n",
            "66     \t [-0.51200634  0.15967157]. \t  -0.7291562440517564 \t 0.2431922946563294\n",
            "67     \t [ 0.76802516 -0.12400304]. \t  -1.5413940716397743 \t 0.2431922946563294\n",
            "68     \t [-0.73250313  0.08573332]. \t  -1.501165395591626 \t 0.2431922946563294\n",
            "69     \t [ 0.03204369 -0.06003427]. \t  0.012183234497549596 \t 0.2431922946563294\n",
            "70     \t [ 0.75225493 -0.10486242]. \t  -1.529090126995416 \t 0.2431922946563294\n",
            "71     \t [-0.6816637   0.08908351]. \t  -1.3464683521112384 \t 0.2431922946563294\n",
            "72     \t [-0.74000107  0.05165037]. \t  -1.566556647510086 \t 0.2431922946563294\n",
            "73     \t [ 0.75800792 -0.10719451]. \t  -1.5415560085858042 \t 0.2431922946563294\n",
            "74     \t [-0.06254772  0.02515175]. \t  -0.011514723012214224 \t 0.2431922946563294\n",
            "75     \t [-0.62307609  0.10856952]. \t  -1.1416514338723276 \t 0.2431922946563294\n",
            "76     \t [ 0.73484319 -0.10472932]. \t  -1.4797655554157811 \t 0.2431922946563294\n",
            "77     \t [-0.7530284   0.03972447]. \t  -1.617519130380453 \t 0.2431922946563294\n",
            "78     \t [ 0.73867779 -0.09880431]. \t  -1.4998488234992693 \t 0.2431922946563294\n",
            "79     \t [-0.63500813  0.10699215]. \t  -1.1801331668766248 \t 0.2431922946563294\n",
            "80     \t [ 0.74329815 -0.11116743]. \t  -1.4937118544001469 \t 0.2431922946563294\n",
            "81     \t [-0.78358817  0.03057626]. \t  -1.7137903236257006 \t 0.2431922946563294\n",
            "82     \t [ 0.7426264  -0.09687563]. \t  -1.5140519493696918 \t 0.2431922946563294\n",
            "83     \t [-0.11448646  0.0469346 ]. \t  -0.03790318489995126 \t 0.2431922946563294\n",
            "84     \t [-0.53286301  0.12561436]. \t  -0.8450379835266926 \t 0.2431922946563294\n",
            "85     \t [ 0.06440562 -0.05161349]. \t  -0.0026046038473656677 \t 0.2431922946563294\n",
            "86     \t [ 0.67434661 -0.10280486]. \t  -1.3049022494755496 \t 0.2431922946563294\n",
            "87     \t [-0.59837788  0.09281878]. \t  -1.0885919160270132 \t 0.2431922946563294\n",
            "88     \t [-0.6491655   0.07273278]. \t  -1.269404315037436 \t 0.2431922946563294\n",
            "89     \t [ 0.70580923 -0.09810004]. \t  -1.4053557063914996 \t 0.2431922946563294\n",
            "90     \t [-0.68764075  0.06196386]. \t  -1.3991996651847451 \t 0.2431922946563294\n",
            "91     \t [ 0.71401705 -0.09991073]. \t  -1.426758410233988 \t 0.2431922946563294\n",
            "92     \t [-0.68076389  0.06932008]. \t  -1.369587231461916 \t 0.2431922946563294\n",
            "93     \t [ 0.71953782 -0.10133266]. \t  -1.4407306708711667 \t 0.2431922946563294\n",
            "94     \t [-0.68648438  0.06910109]. \t  -1.387102503487954 \t 0.2431922946563294\n",
            "95     \t [ 0.72304475 -0.10176433]. \t  -1.4502707073909418 \t 0.2431922946563294\n",
            "96     \t [-0.68439104  0.07126044]. \t  -1.3781193353712826 \t 0.2431922946563294\n",
            "97     \t [0.0048093  0.00058324]. \t  -9.396050166326537e-05 \t 0.2431922946563294\n",
            "98     \t [-0.00792191  0.00335894]. \t  -0.00017927961259633175 \t 0.2431922946563294\n",
            "99     \t [-0.02703914  0.00761864]. \t  -0.002485175656387908 \t 0.2431922946563294\n",
            "100    \t [-0.06056938  0.01533021]. \t  -0.012777970577912504 \t 0.2431922946563294\n"
          ]
        }
      ],
      "source": [
        "### Bayesian optimisation runs (x20): 'STP' Acquisition Function run number = 3 \n",
        "\n",
        "np.random.seed(run_num_3)\n",
        "surrogate_stp_3 = tStudentProcess(cov_func, nu = df, optimize=hyperOpt)\n",
        "\n",
        "stp_3 = GPGO(surrogate_stp_3, Acquisition_new(util_stp), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\n",
        "stp_3.run(max_iter = max_iter, init_evals = n_init) # run\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zhFOxkF0JLk_",
        "outputId": "ef698b32-8f00-48f0-ba81-3b25f6d05ff1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [2.80217903 0.188929  ]. \t  -63.70212732873661 \t -2.3196402150601703\n",
            "init   \t [2.83610616 0.85926397]. \t  -71.43837110827245 \t -2.3196402150601703\n",
            "init   \t [ 1.18637295 -1.13564202]. \t  -2.5463267765341566 \t -2.3196402150601703\n",
            "init   \t [ 2.85764673 -1.97507898]. \t  -113.76785286351424 \t -2.3196402150601703\n",
            "init   \t [-1.48210583 -0.26083387]. \t  -2.3196402150601703 \t -2.3196402150601703\n",
            "1      \t [-0.37440222 -2.        ]. \t  -49.2691665069199 \t -2.3196402150601703\n",
            "2      \t [-3.  2.]. \t  -150.89999999999998 \t -2.3196402150601703\n",
            "3      \t [-3. -2.]. \t  -162.89999999999998 \t -2.3196402150601703\n",
            "4      \t [-0.02128815  0.92443339]. \t  \u001b[92m0.5149674839052885\u001b[0m \t 0.5149674839052885\n",
            "5      \t [0.60024043 2.        ]. \t  -50.38462808378267 \t 0.5149674839052885\n",
            "6      \t [ 0.09368555 -0.1640065 ]. \t  0.08511714862445714 \t 0.5149674839052885\n",
            "7      \t [-0.9179701  0.5150514]. \t  -0.826518157566208 \t 0.5149674839052885\n",
            "8      \t [ 0.65930064 -0.1194189 ]. \t  -1.234339784136823 \t 0.5149674839052885\n",
            "9      \t [-0.87155467  2.        ]. \t  -48.22971200025549 \t 0.5149674839052885\n",
            "10     \t [-3.          0.02792551]. \t  -108.81310657576175 \t 0.5149674839052885\n",
            "11     \t [ 0.98719735 -2.        ]. \t  -48.2378680403273 \t 0.5149674839052885\n",
            "12     \t [-0.90119403 -0.6647253 ]. \t  -1.6545958334757729 \t 0.5149674839052885\n",
            "13     \t [3. 2.]. \t  -162.89999999999998 \t 0.5149674839052885\n",
            "14     \t [1.39227613 0.88007306]. \t  -2.817605214590406 \t 0.5149674839052885\n",
            "15     \t [ 0.43411557 -0.99847602]. \t  -0.23587376047497025 \t 0.5149674839052885\n",
            "16     \t [-0.84637694 -0.06414643]. \t  -1.9482096770577602 \t 0.5149674839052885\n",
            "17     \t [-1.49308518 -2.        ]. \t  -53.159876605058045 \t 0.5149674839052885\n",
            "18     \t [0.68430957 0.78431926]. \t  -1.03660869534734 \t 0.5149674839052885\n",
            "19     \t [ 0.99399573 -0.05903969]. \t  -2.1510177662730725 \t 0.5149674839052885\n",
            "20     \t [-0.19202894  0.07901737]. \t  -0.10466897996169622 \t 0.5149674839052885\n",
            "21     \t [0.04172049 0.01185721]. \t  -0.006888430769296238 \t 0.5149674839052885\n",
            "22     \t [0.54476858 0.02677174]. \t  -1.0225678401690794 \t 0.5149674839052885\n",
            "23     \t [ 1.81475001 -0.62424161]. \t  -0.21901229005555645 \t 0.5149674839052885\n",
            "24     \t [ 1.21359165 -0.56180024]. \t  -0.8550978904850483 \t 0.5149674839052885\n",
            "25     \t [ 0.86978391 -0.06619179]. \t  -1.8935116631069622 \t 0.5149674839052885\n",
            "26     \t [-0.48579687  0.01273524]. \t  -0.8245801557095505 \t 0.5149674839052885\n",
            "27     \t [ 0.83188417 -0.07306165]. \t  -1.7908758652833605 \t 0.5149674839052885\n",
            "28     \t [-1.59653181  0.80699243]. \t  0.12479791703085641 \t 0.5149674839052885\n",
            "29     \t [-0.17189471 -0.7497331 ]. \t  \u001b[92m0.7393330253059258\u001b[0m \t 0.7393330253059258\n",
            "30     \t [-0.75048123  0.17324244]. \t  -1.3998192522683635 \t 0.7393330253059258\n",
            "31     \t [-1.21597282  0.43362687]. \t  -1.2628091745482735 \t 0.7393330253059258\n",
            "32     \t [-0.68145944  0.11679236]. \t  -1.304647498150016 \t 0.7393330253059258\n",
            "33     \t [-0.6746986   0.10808856]. \t  -1.2980334400678437 \t 0.7393330253059258\n",
            "34     \t [ 1.09504013 -0.37954041]. \t  -1.442831443890309 \t 0.7393330253059258\n",
            "35     \t [ 0.73201252 -0.11043344]. \t  -1.462661632560321 \t 0.7393330253059258\n",
            "36     \t [-0.67944382  0.10391494]. \t  -1.3184971361091056 \t 0.7393330253059258\n",
            "37     \t [ 0.74270657 -0.11930787]. \t  -1.478680548277921 \t 0.7393330253059258\n",
            "38     \t [-0.68423531  0.10140873]. \t  -1.336518980133042 \t 0.7393330253059258\n",
            "39     \t [ 0.75008627 -0.12597498]. \t  -1.4881623876200953 \t 0.7393330253059258\n",
            "40     \t [-0.68747431  0.09962576]. \t  -1.3487981541500076 \t 0.7393330253059258\n",
            "41     \t [ 0.75512778 -0.13090221]. \t  -1.4936468375560021 \t 0.7393330253059258\n",
            "42     \t [-0.68970471  0.09835078]. \t  -1.3573053490958185 \t 0.7393330253059258\n",
            "43     \t [-0.68411568  0.09505075]. \t  -1.3454116793354771 \t 0.7393330253059258\n",
            "44     \t [ 0.76811897 -0.13692805]. \t  -1.5186942356769269 \t 0.7393330253059258\n",
            "45     \t [-0.68736447  0.09522159]. \t  -1.354865698236753 \t 0.7393330253059258\n",
            "46     \t [ 0.76644176 -0.13861197]. \t  -1.5110245967299243 \t 0.7393330253059258\n",
            "47     \t [-0.68977482  0.09534067]. \t  -1.361878610930433 \t 0.7393330253059258\n",
            "48     \t [ 0.76547799 -0.1398161 ]. \t  -1.5061715754207696 \t 0.7393330253059258\n",
            "49     \t [-0.69156719  0.09541465]. \t  -1.3671075852163295 \t 0.7393330253059258\n",
            "50     \t [ 0.76497184 -0.14068955]. \t  -1.503173682094621 \t 0.7393330253059258\n",
            "51     \t [-0.69290602  0.09545365]. \t  -1.3710330201167769 \t 0.7393330253059258\n",
            "52     \t [ 0.76474944 -0.14133225]. \t  -1.50137591733597 \t 0.7393330253059258\n",
            "53     \t [-0.69391186  0.09546795]. \t  -1.3740015646529402 \t 0.7393330253059258\n",
            "54     \t [ 0.76469633 -0.14181132]. \t  -1.5003430614982547 \t 0.7393330253059258\n",
            "55     \t [-0.69467367  0.095466  ]. \t  -1.376267138507641 \t 0.7393330253059258\n",
            "56     \t [ 0.7647398  -0.14217355]. \t  -1.4997903779258632 \t 0.7393330253059258\n",
            "57     \t [-0.6952566   0.09545441]. \t  -1.378014599056387 \t 0.7393330253059258\n",
            "58     \t [ 0.76483486 -0.14245114]. \t  -1.4995354840839439 \t 0.7393330253059258\n",
            "59     \t [-0.6957078   0.09543831]. \t  -1.379377060118491 \t 0.7393330253059258\n",
            "60     \t [-0.69234582  0.09388485]. \t  -1.3716203832904312 \t 0.7393330253059258\n",
            "61     \t [ 0.77051684 -0.14447743]. \t  -1.5112669561772791 \t 0.7393330253059258\n",
            "62     \t [-0.69345067  0.09430859]. \t  -1.3742994033990064 \t 0.7393330253059258\n",
            "63     \t [ 0.76849691 -0.14389903]. \t  -1.506849250151883 \t 0.7393330253059258\n",
            "64     \t [-0.69435151  0.0946269 ]. \t  -1.3765195097231218 \t 0.7393330253059258\n",
            "65     \t [ 0.76728475 -0.14356546]. \t  -1.5041639996930758 \t 0.7393330253059258\n",
            "66     \t [-0.69507421  0.09486146]. \t  -1.3783285008621131 \t 0.7393330253059258\n",
            "67     \t [ 0.76657829 -0.1433878 ]. \t  -1.5025647444093797 \t 0.7393330253059258\n",
            "68     \t [-0.69564908  0.09503192]. \t  -1.3797895095411932 \t 0.7393330253059258\n",
            "69     \t [ 0.76618295 -0.14330616]. \t  -1.5016356637142254 \t 0.7393330253059258\n",
            "70     \t [-0.69610525  0.09515422]. \t  -1.3809668227543663 \t 0.7393330253059258\n",
            "71     \t [-0.6938419   0.09411882]. \t  -1.3757345095295412 \t 0.7393330253059258\n",
            "72     \t [ 0.769864   -0.14469998]. \t  -1.5090723692261214 \t 0.7393330253059258\n",
            "73     \t [-0.69462727  0.09445737]. \t  -1.3775823941506082 \t 0.7393330253059258\n",
            "74     \t [ 0.76842354 -0.14415565]. \t  -1.506168508996135 \t 0.7393330253059258\n",
            "75     \t [-0.69527922  0.09471911]. \t  -1.379142201072533 \t 0.7393330253059258\n",
            "76     \t [ 0.76752126 -0.14382715]. \t  -1.5043208204072542 \t 0.7393330253059258\n",
            "77     \t [-0.69581393  0.09491893]. \t  -1.3804417257154575 \t 0.7393330253059258\n",
            "78     \t [ 0.76696362 -0.14363673]. \t  -1.5031532853146898 \t 0.7393330253059258\n",
            "79     \t [-0.69625042  0.09507051]. \t  -1.3815183757358003 \t 0.7393330253059258\n",
            "80     \t [ 0.76662569 -0.14353249]. \t  -1.5024242015805827 \t 0.7393330253059258\n",
            "81     \t [-0.69660576  0.09518458]. \t  -1.3824078635994534 \t 0.7393330253059258\n",
            "82     \t [-0.69502002  0.09446028]. \t  -1.378744785218867 \t 0.7393330253059258\n",
            "83     \t [ 0.76916115 -0.1445544 ]. \t  -1.507431556654405 \t 0.7393330253059258\n",
            "84     \t [-0.69555596  0.09469329]. \t  -1.3800010054566845 \t 0.7393330253059258\n",
            "85     \t [ 0.76822734 -0.14416535]. \t  -1.5056150937855914 \t 0.7393330253059258\n",
            "86     \t [-0.69601006  0.09487941]. \t  -1.3810807678228798 \t 0.7393330253059258\n",
            "87     \t [ 0.76760874 -0.14391772]. \t  -1.5043902768305397 \t 0.7393330253059258\n",
            "88     \t [-0.69639245  0.09502687]. \t  -1.3820027414775826 \t 0.7393330253059258\n",
            "89     \t [ 0.76720129 -0.14376411]. \t  -1.5035646874754787 \t 0.7393330253059258\n",
            "90     \t [-0.69671334  0.09514324]. \t  -1.3827866566132623 \t 0.7393330253059258\n",
            "91     \t [-0.69552342  0.09460319]. \t  -1.3800340579719235 \t 0.7393330253059258\n",
            "92     \t [ 0.76898131 -0.14450328]. \t  -1.50703743574178 \t 0.7393330253059258\n",
            "93     \t [-0.69595186  0.09479014]. \t  -1.3810366716776739 \t 0.7393330253059258\n",
            "94     \t [ 0.76827236 -0.14419696]. \t  -1.5056786922523573 \t 0.7393330253059258\n",
            "95     \t [-0.69632076  0.09494313]. \t  -1.381910840551505 \t 0.7393330253059258\n",
            "96     \t [ 0.76777821 -0.14399208]. \t  -1.504713831419947 \t 0.7393330253059258\n",
            "97     \t [-0.69663706  0.0950677 ]. \t  -1.3826694402936115 \t 0.7393330253059258\n",
            "98     \t [-0.69568605  0.09463974]. \t  -1.3804642600528347 \t 0.7393330253059258\n",
            "99     \t [ 0.76906666 -0.14453215]. \t  -1.5072158309337516 \t 0.7393330253059258\n",
            "100    \t [-0.69607114  0.0948088 ]. \t  -1.381363760240262 \t 0.7393330253059258\n"
          ]
        }
      ],
      "source": [
        "### Bayesian optimisation runs (x20): 'STP' Acquisition Function run number = 4 \n",
        "\n",
        "np.random.seed(run_num_4)\n",
        "surrogate_stp_4 = tStudentProcess(cov_func, nu = df, optimize=hyperOpt)\n",
        "\n",
        "stp_4 = GPGO(surrogate_stp_4, Acquisition_new(util_stp), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\n",
        "stp_4.run(max_iter = max_iter, init_evals = n_init) # run\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YdzaqIajJLlA",
        "outputId": "4a42fa23-26d0-42e7-8cfc-15aeda5d9ddd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [-1.66804097  1.48292922]. \t  -10.126030408244933 \t 0.6512780061070701\n",
            "init   \t [-1.75968507  1.67444363]. \t  -19.4300499315822 \t 0.6512780061070701\n",
            "init   \t [-0.06953287  0.44697545]. \t  0.6512780061070701 \t 0.6512780061070701\n",
            "init   \t [1.59544714 0.07367195]. \t  -2.168775388880503 \t 0.6512780061070701\n",
            "init   \t [-1.21919699 -1.24911509]. \t  -7.420330936884148 \t 0.6512780061070701\n",
            "1      \t [ 3. -2.]. \t  -150.89999999999998 \t 0.6512780061070701\n",
            "2      \t [3. 2.]. \t  -162.89999999999998 \t 0.6512780061070701\n",
            "3      \t [-3. -2.]. \t  -162.89999999999998 \t 0.6512780061070701\n",
            "4      \t [ 0.16168936 -2.        ]. \t  -47.77976572254321 \t 0.6512780061070701\n",
            "5      \t [-1.70025821  0.05330367]. \t  -1.9646720809240745 \t 0.6512780061070701\n",
            "6      \t [0.20266095 2.        ]. \t  -48.5660884079462 \t 0.6512780061070701\n",
            "7      \t [-3.          0.81810648]. \t  -105.5603280967681 \t 0.6512780061070701\n",
            "8      \t [-0.62895287 -0.19824406]. \t  -1.2480042747917641 \t 0.6512780061070701\n",
            "9      \t [ 0.67108953 -0.23013019]. \t  -1.0509013817373523 \t 0.6512780061070701\n",
            "10     \t [-0.81511345  0.10272039]. \t  -1.7028910533903612 \t 0.6512780061070701\n",
            "11     \t [ 3.         -0.03083579]. \t  -108.80369284814388 \t 0.6512780061070701\n",
            "12     \t [1.04467087 0.7426601 ]. \t  -2.083942887787712 \t 0.6512780061070701\n",
            "13     \t [-0.89382828  1.55832243]. \t  -14.506846450080614 \t 0.6512780061070701\n",
            "14     \t [ 1.43578797 -1.24300917]. \t  -3.825773792379814 \t 0.6512780061070701\n",
            "15     \t [ 1.34009163 -2.        ]. \t  -47.661140965006005 \t 0.6512780061070701\n",
            "16     \t [ 1.42765312 -0.58736478]. \t  -0.5088120874187684 \t 0.6512780061070701\n",
            "17     \t [-1.03451557 -2.        ]. \t  -52.35323355195576 \t 0.6512780061070701\n",
            "18     \t [-1.39628016 -0.59798606]. \t  -2.2026121895227506 \t 0.6512780061070701\n",
            "19     \t [ 0.06598658 -1.00499837]. \t  0.008450623564513149 \t 0.6512780061070701\n",
            "20     \t [ 0.79480697 -0.2557587 ]. \t  -1.3250492672492047 \t 0.6512780061070701\n",
            "21     \t [ 0.61363152 -0.1510536 ]. \t  -1.0443444083744091 \t 0.6512780061070701\n",
            "22     \t [-0.67946527 -0.15756406]. \t  -1.4421136054435022 \t 0.6512780061070701\n",
            "23     \t [ 0.85653124 -0.24138292]. \t  -1.5096768373019906 \t 0.6512780061070701\n",
            "24     \t [-1.10128336  0.67063094]. \t  -0.6285298977992874 \t 0.6512780061070701\n",
            "25     \t [-0.75898151 -0.12854735]. \t  -1.7036322176284875 \t 0.6512780061070701\n",
            "26     \t [ 0.69752677 -0.12284818]. \t  -1.3422993148195546 \t 0.6512780061070701\n",
            "27     \t [ 0.7232432  -0.14800691]. \t  -1.3726922890974371 \t 0.6512780061070701\n",
            "28     \t [-0.83520141 -0.10753924]. \t  -1.9256383130043377 \t 0.6512780061070701\n",
            "29     \t [ 0.75614681 -0.1639476 ]. \t  -1.4342369750906099 \t 0.6512780061070701\n",
            "30     \t [-1.10416194 -0.21822382]. \t  -2.41888009816046 \t 0.6512780061070701\n",
            "31     \t [ 1.02018137 -0.72675545]. \t  -0.5258961368112945 \t 0.6512780061070701\n",
            "32     \t [ 0.75923632 -0.16615173]. \t  -1.4382866645479342 \t 0.6512780061070701\n",
            "33     \t [-0.74333701 -0.06593897]. \t  -1.65697765630989 \t 0.6512780061070701\n",
            "34     \t [ 0.7811009  -0.18246858]. \t  -1.4631937008156142 \t 0.6512780061070701\n",
            "35     \t [ 0.78309822 -0.1914745 ]. \t  -1.448887802193936 \t 0.6512780061070701\n",
            "36     \t [-0.80901854 -0.0651536 ]. \t  -1.8476996337816247 \t 0.6512780061070701\n",
            "37     \t [ 0.79300259 -0.19816103]. \t  -1.4598034198129988 \t 0.6512780061070701\n",
            "38     \t [-0.8245732  -0.07091889]. \t  -1.8921047312726498 \t 0.6512780061070701\n",
            "39     \t [ 0.79860127 -0.20232468]. \t  -1.4647494447286062 \t 0.6512780061070701\n",
            "40     \t [ 0.79748615 -0.20474435]. \t  -1.4563515629973174 \t 0.6512780061070701\n",
            "41     \t [-0.83860451 -0.07421593]. \t  -1.930694788126914 \t 0.6512780061070701\n",
            "42     \t [ 0.80128305 -0.20654714]. \t  -1.4618827342136291 \t 0.6512780061070701\n",
            "43     \t [-0.84160805 -0.07742561]. \t  -1.9394352118964269 \t 0.6512780061070701\n",
            "44     \t [ 0.80372918 -0.20772273]. \t  -1.4653648770551488 \t 0.6512780061070701\n",
            "45     \t [ 0.80228851 -0.20844984]. \t  -1.460024385631156 \t 0.6512780061070701\n",
            "46     \t [-0.84691203 -0.07881271]. \t  -1.9537269553780618 \t 0.6512780061070701\n",
            "47     \t [ 0.80428504 -0.20897605]. \t  -1.4638557936566037 \t 0.6512780061070701\n",
            "48     \t [ 0.80303249 -0.20931161]. \t  -1.4599041909505206 \t 0.6512780061070701\n",
            "49     \t [-0.84960063 -0.07986405]. \t  -1.9609952889062734 \t 0.6512780061070701\n",
            "50     \t [ 0.80471356 -0.20955782]. \t  -1.46358198134819 \t 0.6512780061070701\n",
            "51     \t [ 0.80361904 -0.20971762]. \t  -1.4604421430074006 \t 0.6512780061070701\n",
            "52     \t [-0.85099709 -0.0806021 ]. \t  -1.9647964778437512 \t 0.6512780061070701\n",
            "53     \t [ 0.80506229 -0.20984119]. \t  -1.4638008390875548 \t 0.6512780061070701\n",
            "54     \t [ 0.80410167 -0.20991846]. \t  -1.4611938230261217 \t 0.6512780061070701\n",
            "55     \t [-0.85171935 -0.08110683]. \t  -1.966783891427313 \t 0.6512780061070701\n",
            "56     \t [ 0.80535733 -0.20998746]. \t  -1.4642035524015968 \t 0.6512780061070701\n",
            "57     \t [ 0.80451018 -0.21002364]. \t  -1.4619804525909592 \t 0.6512780061070701\n",
            "58     \t [-0.85207955 -0.08145086]. \t  -1.967792947358495 \t 0.6512780061070701\n",
            "59     \t [ 0.80561244 -0.2100681 ]. \t  -1.4646584858668046 \t 0.6512780061070701\n",
            "60     \t [ 0.80486263 -0.21008318]. \t  -1.4627313987520496 \t 0.6512780061070701\n",
            "61     \t [-0.85224185 -0.08168619]. \t  -1.9682638653514193 \t 0.6512780061070701\n",
            "62     \t [ 0.80583715 -0.21011605]. \t  -1.4651128759260637 \t 0.6512780061070701\n",
            "63     \t [ 0.80517003 -0.21011943]. \t  -1.4634225504798524 \t 0.6512780061070701\n",
            "64     \t [-0.85229598 -0.08184873]. \t  -1.968438190585274 \t 0.6512780061070701\n",
            "65     \t [ 0.80603657 -0.21014707]. \t  -1.4655429064666639 \t 0.6512780061070701\n",
            "66     \t [ 0.80544077 -0.21014402]. \t  -1.4640480511951106 \t 0.6512780061070701\n",
            "67     \t [ 0.80493235 -0.21013672]. \t  -1.4627822368588463 \t 0.6512780061070701\n",
            "68     \t [-0.85313421 -0.08181443]. \t  -1.970607952885161 \t 0.6512780061070701\n",
            "69     \t [ 0.80577823 -0.21016104]. \t  -1.4648591632183645 \t 0.6512780061070701\n",
            "70     \t [ 0.80530608 -0.2101521 ]. \t  -1.4636894260441202 \t 0.6512780061070701\n",
            "71     \t [-0.85286064 -0.08194957]. \t  -1.969925821882854 \t 0.6512780061070701\n",
            "72     \t [ 0.80605337 -0.21017567]. \t  -1.465518332357534 \t 0.6512780061070701\n",
            "73     \t [ 0.80561685 -0.21016566]. \t  -1.4644414924680893 \t 0.6512780061070701\n",
            "74     \t [ 0.80523668 -0.21015521]. \t  -1.4635070532517807 \t 0.6512780061070701\n",
            "75     \t [-0.85325352 -0.08193896]. \t  -1.9709432881847764 \t 0.6512780061070701\n",
            "76     \t [ 0.80594716 -0.21017901]. \t  -1.4652429067268107 \t 0.6512780061070701\n",
            "77     \t [ 0.80558679 -0.21016826]. \t  -1.4643596355949342 \t 0.6512780061070701\n",
            "78     \t [ 0.80526964 -0.21015791]. \t  -1.4635839048324384 \t 0.6512780061070701\n",
            "79     \t [-0.85343814 -0.08195185]. \t  -1.9714248490871273 \t 0.6512780061070701\n",
            "80     \t [ 0.80593431 -0.21018195]. \t  -1.4652036300241944 \t 0.6512780061070701\n",
            "81     \t [ 0.80562865 -0.21017117]. \t  -1.4644583575960168 \t 0.6512780061070701\n",
            "82     \t [ 0.80535698 -0.21016116]. \t  -1.4637966242357563 \t 0.6512780061070701\n",
            "83     \t [-0.85350099 -0.08197392]. \t  -1.9715924065953363 \t 0.6512780061070701\n",
            "84     \t [ 0.80597409 -0.21018526]. \t  -1.4652961553314219 \t 0.6512780061070701\n",
            "85     \t [ 0.8057093  -0.21017486]. \t  -1.4646530621998441 \t 0.6512780061070701\n",
            "86     \t [ 0.80547217 -0.21016531]. \t  -1.464077452133497 \t 0.6512780061070701\n",
            "87     \t [-0.85349241 -0.0819988 ]. \t  -1.971575275476861 \t 0.6512780061070701\n",
            "88     \t [ 0.80604319 -0.21018898]. \t  -1.4654615816778713 \t 0.6512780061070701\n",
            "89     \t [ 0.8058102  -0.21017934]. \t  -1.4648969408446266 \t 0.6512780061070701\n",
            "90     \t [ 0.80560031 -0.21017048]. \t  -1.4643885293384515 \t 0.6512780061070701\n",
            "91     \t [ 0.80541024 -0.21016224]. \t  -1.4639284619343518 \t 0.6512780061070701\n",
            "92     \t [-0.8537433  -0.08197665]. \t  -1.9722211729443404 \t 0.6512780061070701\n",
            "93     \t [ 0.80595312 -0.21018594]. \t  -1.4652417096161154 \t 0.6512780061070701\n",
            "94     \t [ 0.80576229 -0.21017726]. \t  -1.4647810445745952 \t 0.6512780061070701\n",
            "95     \t [ 0.80558896 -0.21016969]. \t  -1.4643617636253672 \t 0.6512780061070701\n",
            "96     \t [-0.85360454 -0.08201194]. \t  -1.971868749110129 \t 0.6512780061070701\n",
            "97     \t [ 0.80608727 -0.21019211]. \t  -1.4655652999348059 \t 0.6512780061070701\n",
            "98     \t [ 0.80591345 -0.21018416]. \t  -1.465145894120443 \t 0.6512780061070701\n",
            "99     \t [ 0.80575443 -0.2101766 ]. \t  -1.4647627778084806 \t 0.6512780061070701\n",
            "100    \t [ 0.80560864 -0.21016976]. \t  -1.4644112151206892 \t 0.6512780061070701\n"
          ]
        }
      ],
      "source": [
        "### Bayesian optimisation runs (x20): 'STP' Acquisition Function run number = 5 \n",
        "\n",
        "np.random.seed(run_num_5)\n",
        "surrogate_stp_5 = tStudentProcess(cov_func, nu = df, optimize=hyperOpt)\n",
        "\n",
        "stp_5 = GPGO(surrogate_stp_5, Acquisition_new(util_stp), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\n",
        "stp_5.run(max_iter = max_iter, init_evals = n_init) # run\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_KSBbC1zJLlA",
        "outputId": "f5458025-08c1-47d0-8c33-61f8a36cc41b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 2.35716091 -0.67208078]. \t  -11.995980169715628 \t 0.3096187466378422\n",
            "init   \t [ 1.92737474 -1.8332135 ]. \t  -31.167927894156623 \t 0.3096187466378422\n",
            "init   \t [-2.35405992  0.38020826]. \t  -13.013381745677465 \t 0.3096187466378422\n",
            "init   \t [ 0.17890417 -0.32477029]. \t  0.3096187466378422 \t 0.3096187466378422\n",
            "init   \t [-0.9875529   0.49007773]. \t  -0.9989196280666852 \t 0.3096187466378422\n",
            "1      \t [0.53713807 1.83587893]. \t  -33.931352836037846 \t 0.3096187466378422\n",
            "2      \t [-1.18927702 -2.        ]. \t  -52.77822733153016 \t 0.3096187466378422\n",
            "3      \t [3. 2.]. \t  -162.89999999999998 \t 0.3096187466378422\n",
            "4      \t [-3.  2.]. \t  -150.89999999999998 \t 0.3096187466378422\n",
            "5      \t [-3.         -1.10157262]. \t  -113.24083127856485 \t 0.3096187466378422\n",
            "6      \t [1.05469762 0.02383175]. \t  -2.3326870071505588 \t 0.3096187466378422\n",
            "7      \t [ 0.49620851 -2.        ]. \t  -47.8701363411531 \t 0.3096187466378422\n",
            "8      \t [ 3. -2.]. \t  -150.89999999999998 \t 0.3096187466378422\n",
            "9      \t [-0.29987324  0.43945028]. \t  \u001b[92m0.41211262403502846\u001b[0m \t 0.41211262403502846\n",
            "10     \t [-0.77638931  2.        ]. \t  -48.16832565623921 \t 0.41211262403502846\n",
            "11     \t [-0.82251281 -0.15656278]. \t  -1.8813056152122236 \t 0.41211262403502846\n",
            "12     \t [ 1.39790455 -0.92028201]. \t  -0.47971401280566317 \t 0.41211262403502846\n",
            "13     \t [3.        0.1620505]. \t  -109.28386846324499 \t 0.41211262403502846\n",
            "14     \t [-1.71413687 -0.01890378]. \t  -2.1096324843927396 \t 0.41211262403502846\n",
            "15     \t [ 1.77986004 -0.5506724 ]. \t  -0.3688484043607726 \t 0.41211262403502846\n",
            "16     \t [0.68954447 0.77429518]. \t  -1.0365012681347405 \t 0.41211262403502846\n",
            "17     \t [0.37422759 0.22556865]. \t  -0.4111582531940161 \t 0.41211262403502846\n",
            "18     \t [1.48319615 1.32183677]. \t  -9.368482913529453 \t 0.41211262403502846\n",
            "19     \t [-0.48062377 -1.10101727]. \t  -2.3743611223947996 \t 0.41211262403502846\n",
            "20     \t [ 0.99030818 -0.43533624]. \t  -1.1719700161504942 \t 0.41211262403502846\n",
            "21     \t [-1.65435252  0.85675253]. \t  0.14731129972716617 \t 0.41211262403502846\n",
            "22     \t [-1.07935855  0.09481604]. \t  -2.198912576618842 \t 0.41211262403502846\n",
            "23     \t [ 0.90889606 -0.18582476]. \t  -1.7569361269745483 \t 0.41211262403502846\n",
            "24     \t [-0.61952396 -0.00791278]. \t  -1.2493866775945783 \t 0.41211262403502846\n",
            "25     \t [ 0.91444325 -0.18239737]. \t  -1.7758825782074354 \t 0.41211262403502846\n",
            "26     \t [-0.15139718 -0.36751177]. \t  0.3210640949931065 \t 0.41211262403502846\n",
            "27     \t [-1.27559048  0.30327302]. \t  -1.66371796047296 \t 0.41211262403502846\n",
            "28     \t [-1.4054396 -0.8693261]. \t  -2.759868535682901 \t 0.41211262403502846\n",
            "29     \t [-0.90856191 -0.05423654]. \t  -2.095993796233343 \t 0.41211262403502846\n",
            "30     \t [1.65816065 0.5750074 ]. \t  -2.1192302177989797 \t 0.41211262403502846\n",
            "31     \t [1.15046054 0.615027  ]. \t  -2.1551608714529995 \t 0.41211262403502846\n",
            "32     \t [ 1.04143085 -0.06948251]. \t  -2.201749480655838 \t 0.41211262403502846\n",
            "33     \t [ 1.02544508 -0.06338587]. \t  -2.1906820829412985 \t 0.41211262403502846\n",
            "34     \t [-0.94772289 -0.02498254]. \t  -2.161301627661463 \t 0.41211262403502846\n",
            "35     \t [ 1.01010713 -0.05766752]. \t  -2.1776269220441793 \t 0.41211262403502846\n",
            "36     \t [-0.94515103 -0.01300437]. \t  -2.1466707330725345 \t 0.41211262403502846\n",
            "37     \t [ 0.99843466 -0.05365066]. \t  -2.165772867056981 \t 0.41211262403502846\n",
            "38     \t [-0.94369106 -0.00401649]. \t  -2.1358878175370655 \t 0.41211262403502846\n",
            "39     \t [ 0.9902237  -0.05193197]. \t  -2.1551659437722037 \t 0.41211262403502846\n",
            "40     \t [-0.94277427  0.00265149]. \t  -2.1278097844625727 \t 0.41211262403502846\n",
            "41     \t [ 0.98508703 -0.05261082]. \t  -2.145810661767697 \t 0.41211262403502846\n",
            "42     \t [-0.94184587  0.0074305 ]. \t  -2.1212654036862872 \t 0.41211262403502846\n",
            "43     \t [ 0.9822024  -0.05488605]. \t  -2.1378040972003145 \t 0.41211262403502846\n",
            "44     \t [-0.94043767  0.01059751]. \t  -2.115247807650138 \t 0.41211262403502846\n",
            "45     \t [ 0.97960175 -0.05579152]. \t  -2.1321479278573396 \t 0.41211262403502846\n",
            "46     \t [-0.50505683 -0.14209831]. \t  -0.8818521931931553 \t 0.41211262403502846\n",
            "47     \t [-1.05675447  0.08015515]. \t  -2.202020448839038 \t 0.41211262403502846\n",
            "48     \t [0.9075928  0.05903567]. \t  -2.095995103116316 \t 0.41211262403502846\n",
            "49     \t [ 1.0705227  -0.24580947]. \t  -1.8375021422004618 \t 0.41211262403502846\n",
            "50     \t [-0.97504431  0.03243618]. \t  -2.155359528646582 \t 0.41211262403502846\n",
            "51     \t [0.85532652 0.13546114]. \t  -1.976713155091255 \t 0.41211262403502846\n",
            "52     \t [-0.54278387 -0.1419626 ]. \t  -1.0027724065565 \t 0.41211262403502846\n",
            "53     \t [-1.03401336  0.0680633 ]. \t  -2.1947026422854488 \t 0.41211262403502846\n",
            "54     \t [ 1.06073209 -0.22622108]. \t  -1.8826913798856375 \t 0.41211262403502846\n",
            "55     \t [-0.94217239  0.0149537 ]. \t  -2.114153764702385 \t 0.41211262403502846\n",
            "56     \t [0.89354319 0.07906153]. \t  -2.0704385592518095 \t 0.41211262403502846\n",
            "57     \t [ 1.05718673 -0.21875661]. \t  -1.8992428116732056 \t 0.41211262403502846\n",
            "58     \t [-0.5277763  -0.14097842]. \t  -0.9549441513019208 \t 0.41211262403502846\n",
            "59     \t [-1.00670714  0.05412397]. \t  -2.1777320236301847 \t 0.41211262403502846\n",
            "60     \t [0.88737255 0.08483639]. \t  -2.057070890347876 \t 0.41211262403502846\n",
            "61     \t [-0.93484754  0.01163525]. \t  -2.1029186338294474 \t 0.41211262403502846\n",
            "62     \t [ 1.04612001 -0.20099327]. \t  -1.933983281246385 \t 0.41211262403502846\n",
            "63     \t [-0.51678574 -0.14176658]. \t  -0.9193245162468305 \t 0.41211262403502846\n",
            "64     \t [-0.97748516  0.03834291]. \t  -2.152153504672259 \t 0.41211262403502846\n",
            "65     \t [0.89895963 0.05977883]. \t  -2.0764811205172595 \t 0.41211262403502846\n",
            "66     \t [ 1.03791113 -0.1882709 ]. \t  -1.9565622036849786 \t 0.41211262403502846\n",
            "67     \t [-0.89358288 -0.00932564]. \t  -2.032716770525534 \t 0.41211262403502846\n",
            "68     \t [0.89588698 0.06438291]. \t  -2.071170963206636 \t 0.41211262403502846\n",
            "69     \t [-0.91768663  0.00501245]. \t  -2.0736322120970314 \t 0.41211262403502846\n",
            "70     \t [ 1.03541493 -0.18495245]. \t  -1.9617581343807182 \t 0.41211262403502846\n",
            "71     \t [-0.53497347 -0.1388416 ]. \t  -0.9792475966876923 \t 0.41211262403502846\n",
            "72     \t [-0.96038374  0.03112376]. \t  -2.1306502808114716 \t 0.41211262403502846\n",
            "73     \t [0.90585904 0.04206135]. \t  -2.083499653087187 \t 0.41211262403502846\n",
            "74     \t [-0.88206974 -0.01351988]. \t  -2.009131278841195 \t 0.41211262403502846\n",
            "75     \t [ 1.02397653 -0.16715505]. \t  -1.9897999842740541 \t 0.41211262403502846\n",
            "76     \t [-0.62145752 -0.11956316]. \t  -1.2687480410067702 \t 0.41211262403502846\n",
            "77     \t [-0.97746525  0.04285144]. \t  -2.1462528808297607 \t 0.41211262403502846\n",
            "78     \t [0.91504824 0.02533789]. \t  -2.0932540264315826 \t 0.41211262403502846\n",
            "79     \t [-0.91150991  0.00429144]. \t  -2.060942249787611 \t 0.41211262403502846\n",
            "80     \t [ 1.01506178 -0.15237747]. \t  -2.0112180756597193 \t 0.41211262403502846\n",
            "81     \t [-0.58304137 -0.12774493]. \t  -1.1404433845169017 \t 0.41211262403502846\n",
            "82     \t [0.9124533  0.02805868]. \t  -2.0894455157541825 \t 0.41211262403502846\n",
            "83     \t [-0.94307098  0.02300271]. \t  -2.107120123984462 \t 0.41211262403502846\n",
            "84     \t [ 1.01323164 -0.15064501]. \t  -2.0125158544202213 \t 0.41211262403502846\n",
            "85     \t [-0.87789271 -0.01299002]. \t  -1.9987612776230042 \t 0.41211262403502846\n",
            "86     \t [0.91696735 0.01832604]. \t  -2.0922449577128237 \t 0.41211262403502846\n",
            "87     \t [-0.88487702 -0.00882036]. \t  -2.0120328065349176 \t 0.41211262403502846\n",
            "88     \t [ 1.01103865 -0.14718773]. \t  -2.0169621832281908 \t 0.41211262403502846\n",
            "89     \t [-0.67609324 -0.10133525]. \t  -1.4493239574762815 \t 0.41211262403502846\n",
            "90     \t [-0.95319327  0.03102559]. \t  -2.117326625864779 \t 0.41211262403502846\n",
            "91     \t [0.92486477 0.0042318 ]. \t  -2.0974589889950113 \t 0.41211262403502846\n",
            "92     \t [-0.8945137  -0.00250411]. \t  -2.029079601843464 \t 0.41211262403502846\n",
            "93     \t [ 1.00223887 -0.13200299]. \t  -2.0361142782492263 \t 0.41211262403502846\n",
            "94     \t [-0.63619799 -0.11274003]. \t  -1.3185997112202759 \t 0.41211262403502846\n",
            "95     \t [-0.9339592   0.02040869]. \t  -2.091792735823771 \t 0.41211262403502846\n",
            "96     \t [ 0.92685875 -0.00110929]. \t  -2.0967726263978417 \t 0.41211262403502846\n",
            "97     \t [-0.88325471 -0.0080099 ]. \t  -2.0075471798083804 \t 0.41211262403502846\n",
            "98     \t [ 0.99617685 -0.12244012]. \t  -2.0461244135383687 \t 0.41211262403502846\n",
            "99     \t [-0.84275735 -0.02870029]. \t  -1.921954075998711 \t 0.41211262403502846\n",
            "100    \t [ 0.93501918 -0.01493069]. \t  -2.0998360226180885 \t 0.41211262403502846\n"
          ]
        }
      ],
      "source": [
        "### Bayesian optimisation runs (x20): 'STP' Acquisition Function run number = 6 \n",
        "\n",
        "np.random.seed(run_num_6)\n",
        "surrogate_stp_6 = tStudentProcess(cov_func, nu = df, optimize=hyperOpt)\n",
        "\n",
        "stp_6 = GPGO(surrogate_stp_6, Acquisition_new(util_stp), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\n",
        "stp_6.run(max_iter = max_iter, init_evals = n_init) # run\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WB64BgXFJLlB",
        "outputId": "6c9e2b95-b55b-4104-edb1-4f709d4ef754"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [-2.54215026  1.11967517]. \t  -26.53843863832488 \t 0.46481072558790276\n",
            "init   \t [-0.36954461  0.89386071]. \t  0.46481072558790276 \t 0.46481072558790276\n",
            "init   \t [2.86793707 0.15398348]. \t  -76.66051064695093 \t 0.46481072558790276\n",
            "init   \t [ 0.00672278 -1.71179547]. \t  -22.613010892757885 \t 0.46481072558790276\n",
            "init   \t [-1.38936612e+00 -4.69996698e-04]. \t  -2.294585534557751 \t 0.46481072558790276\n",
            "1      \t [-3. -2.]. \t  -162.89999999999998 \t 0.46481072558790276\n",
            "2      \t [0.78025074 2.        ]. \t  -51.292561606765204 \t 0.46481072558790276\n",
            "3      \t [ 3. -2.]. \t  -150.89999999999998 \t 0.46481072558790276\n",
            "4      \t [-1.2873807  2.       ]. \t  -47.80381450308264 \t 0.46481072558790276\n",
            "5      \t [ 0.16293594 -0.13902214]. \t  -0.006252473373122014 \t 0.46481072558790276\n",
            "6      \t [3. 2.]. \t  -162.89999999999998 \t 0.46481072558790276\n",
            "7      \t [-0.61152735 -0.28603116]. \t  -1.094044727759152 \t 0.46481072558790276\n",
            "8      \t [ 0.79244977 -0.1102103 ]. \t  -1.6309790452465658 \t 0.46481072558790276\n",
            "9      \t [-3.  2.]. \t  -150.89999999999998 \t 0.46481072558790276\n",
            "10     \t [-0.6327984   0.27966065]. \t  -0.8210670149453112 \t 0.46481072558790276\n",
            "11     \t [-3.          0.15693529]. \t  -108.33310568243921 \t 0.46481072558790276\n",
            "12     \t [-0.07763725  0.187211  ]. \t  0.12577899792151495 \t 0.46481072558790276\n",
            "13     \t [-1.70065098  0.89227674]. \t  0.09968942067386377 \t 0.46481072558790276\n",
            "14     \t [-1.16197345 -2.        ]. \t  -52.716849685870926 \t 0.46481072558790276\n",
            "15     \t [ 1.16828637 -2.        ]. \t  -48.05840820127873 \t 0.46481072558790276\n",
            "16     \t [ 1.39923247 -0.84758499]. \t  -0.2881498080104119 \t 0.46481072558790276\n",
            "17     \t [ 0.76362285 -0.94141377]. \t  -0.5624132578479631 \t 0.46481072558790276\n",
            "18     \t [-0.2142006  2.       ]. \t  -47.75073777075433 \t 0.46481072558790276\n",
            "19     \t [1.48324603 0.91539746]. \t  -2.9999330406946316 \t 0.46481072558790276\n",
            "20     \t [0.84743567 0.07001495]. \t  -1.9528233784763183 \t 0.46481072558790276\n",
            "21     \t [-0.92780302  0.35706762]. \t  -1.3235253865547885 \t 0.46481072558790276\n",
            "22     \t [0.57332936 0.82241263]. \t  -0.6956923727535814 \t 0.46481072558790276\n",
            "23     \t [ 1.7121459  -0.04213291]. \t  -1.9974742075041436 \t 0.46481072558790276\n",
            "24     \t [1.16119542 0.28176239]. \t  -2.4274573068259144 \t 0.46481072558790276\n",
            "25     \t [ 0.73155699 -0.06679375]. \t  -1.5236996160478877 \t 0.46481072558790276\n",
            "26     \t [ 0.74411819 -0.04888948]. \t  -1.5816654960609096 \t 0.46481072558790276\n",
            "27     \t [-0.86018509  0.33145148]. \t  -1.2687241584339526 \t 0.46481072558790276\n",
            "28     \t [ 0.76155868 -0.03697467]. \t  -1.6449240080129932 \t 0.46481072558790276\n",
            "29     \t [-1.93582054 -0.87373487]. \t  -4.009815055416196 \t 0.46481072558790276\n",
            "30     \t [ 2.20028284 -0.90889421]. \t  -5.393890165912233 \t 0.46481072558790276\n",
            "31     \t [-1.03553312 -0.05985403]. \t  -2.3332700825264228 \t 0.46481072558790276\n",
            "32     \t [-1.01863636  0.05200999]. \t  -2.198120161193712 \t 0.46481072558790276\n",
            "33     \t [ 1.12954033 -0.23374009]. \t  -1.9066937230129588 \t 0.46481072558790276\n",
            "34     \t [ 1.08913675 -0.1987308 ]. \t  -1.978134080271826 \t 0.46481072558790276\n",
            "35     \t [-0.97979794  0.10205036]. \t  -2.0583435445168052 \t 0.46481072558790276\n",
            "36     \t [ 1.0428608  -0.15799148]. \t  -2.033054754011854 \t 0.46481072558790276\n",
            "37     \t [-0.95097995  0.12268049]. \t  -1.9705083044029952 \t 0.46481072558790276\n",
            "38     \t [ 0.99386423 -0.11443158]. \t  -2.0579590332542206 \t 0.46481072558790276\n",
            "39     \t [-0.92770071  0.13174485]. \t  -1.9091253996043065 \t 0.46481072558790276\n",
            "40     \t [ 0.94037775 -0.06829143]. \t  -2.042755326576669 \t 0.46481072558790276\n",
            "41     \t [-0.9131291   0.13741294]. \t  -1.868885177127053 \t 0.46481072558790276\n",
            "42     \t [0.17545341 0.11757522]. \t  -0.08725290787660413 \t 0.46481072558790276\n",
            "43     \t [ 0.95435075 -0.08489377]. \t  -2.043331248841826 \t 0.46481072558790276\n",
            "44     \t [-0.89103866  0.13647242]. \t  -1.8241613033126811 \t 0.46481072558790276\n",
            "45     \t [ 0.90363374 -0.03946692]. \t  -2.005616475605441 \t 0.46481072558790276\n",
            "46     \t [-0.88742376  0.14175528]. \t  -1.8059302806566706 \t 0.46481072558790276\n",
            "47     \t [ 0.94340684 -0.08576087]. \t  -2.0214863167927573 \t 0.46481072558790276\n",
            "48     \t [-0.01732453  0.09625914]. \t  0.03718713998530411 \t 0.46481072558790276\n",
            "49     \t [-0.86856712  0.13777332]. \t  -1.771426135520492 \t 0.46481072558790276\n",
            "50     \t [0.70417197 0.10427766]. \t  -1.5381412750142869 \t 0.46481072558790276\n",
            "51     \t [ 0.98399278 -0.14652545]. \t  -1.9785916261499472 \t 0.46481072558790276\n",
            "52     \t [-0.8698965   0.14192332]. \t  -1.7664013357292554 \t 0.46481072558790276\n",
            "53     \t [0.71899522 0.08663444]. \t  -1.5851527181134564 \t 0.46481072558790276\n",
            "54     \t [-0.87378557  0.14382633]. \t  -1.7714944297881217 \t 0.46481072558790276\n",
            "55     \t [ 0.99394174 -0.15771139]. \t  -1.9697355533612684 \t 0.46481072558790276\n",
            "56     \t [-0.86259092  0.1410759 ]. \t  -1.7512254680848036 \t 0.46481072558790276\n",
            "57     \t [ 0.91471524 -0.07279108]. \t  -1.98424791317017 \t 0.46481072558790276\n",
            "58     \t [-0.04952576  0.09431987]. \t  0.03014107219480721 \t 0.46481072558790276\n",
            "59     \t [-0.82536209  0.13016552]. \t  -1.6816748279070575 \t 0.46481072558790276\n",
            "60     \t [0.64794679 0.11324642]. \t  -1.3565945681991762 \t 0.46481072558790276\n",
            "61     \t [ 0.93175677 -0.10644314]. \t  -1.964003126909161 \t 0.46481072558790276\n",
            "62     \t [-0.840253   0.1408391]. \t  -1.6985122141397622 \t 0.46481072558790276\n",
            "63     \t [0.7242686  0.06897085]. \t  -1.5995368939680046 \t 0.46481072558790276\n",
            "64     \t [-0.84758117  0.14321862]. \t  -1.7116193779023965 \t 0.46481072558790276\n",
            "65     \t [ 0.95724476 -0.13260625]. \t  -1.9624515129742763 \t 0.46481072558790276\n",
            "66     \t [-0.84180281  0.14229466]. \t  -1.699473556256078 \t 0.46481072558790276\n",
            "67     \t [ 0.8275243  -0.00666165]. \t  -1.8557528906281848 \t 0.46481072558790276\n",
            "68     \t [-0.84448984  0.14350017]. \t  -1.7036368574115732 \t 0.46481072558790276\n",
            "69     \t [ 0.93301315 -0.10733703]. \t  -1.9648761982846805 \t 0.46481072558790276\n",
            "70     \t [-0.04272515  0.10254142]. \t  0.03870307379001934 \t 0.46481072558790276\n",
            "71     \t [-0.77785472  0.1262016 ]. \t  -1.5644091099185884 \t 0.46481072558790276\n",
            "72     \t [0.57120594 0.12163093]. \t  -1.1043004016184454 \t 0.46481072558790276\n",
            "73     \t [0.75032777 0.03791727]. \t  -1.6685412939394304 \t 0.46481072558790276\n",
            "74     \t [-0.81105789  0.13864825]. \t  -1.6295630235325664 \t 0.46481072558790276\n",
            "75     \t [ 0.90489613 -0.0924739 ]. \t  -1.93272651206093 \t 0.46481072558790276\n",
            "76     \t [-0.81415686  0.14110709]. \t  -1.6328615538669038 \t 0.46481072558790276\n",
            "77     \t [0.79609945 0.00448227]. \t  -1.7799345341894852 \t 0.46481072558790276\n",
            "78     \t [-0.82065783  0.14284677]. \t  -1.6460516826213412 \t 0.46481072558790276\n",
            "79     \t [ 0.90195533 -0.08868521]. \t  -1.9325367900257802 \t 0.46481072558790276\n",
            "80     \t [-0.82004432  0.14310726]. \t  -1.6440028105626963 \t 0.46481072558790276\n",
            "81     \t [0.68230508 0.07398787]. \t  -1.4693698929595407 \t 0.46481072558790276\n",
            "82     \t [-0.82629643  0.1437066 ]. \t  -1.658558119708019 \t 0.46481072558790276\n",
            "83     \t [ 0.92262181 -0.10710596]. \t  -1.9446965344751286 \t 0.46481072558790276\n",
            "84     \t [-0.8231063   0.14325695]. \t  -1.6514310066280724 \t 0.46481072558790276\n",
            "85     \t [ 0.85078282 -0.03932388]. \t  -1.8818494229657365 \t 0.46481072558790276\n",
            "86     \t [-0.06246773  0.10677503]. \t  0.036176791050965454 \t 0.46481072558790276\n",
            "87     \t [-0.07324033  0.10700871]. \t  0.031720110634789266 \t 0.46481072558790276\n",
            "88     \t [-0.09968627  0.10647212]. \t  0.01590265050808611 \t 0.46481072558790276\n",
            "89     \t [-0.42518665  0.1017402 ]. \t  -0.5722362303625894 \t 0.46481072558790276\n",
            "90     \t [0.3836938  0.12511524]. \t  -0.5308027700095351 \t 0.46481072558790276\n",
            "91     \t [-0.61652039  0.1152144 ]. \t  -1.1118742195875664 \t 0.46481072558790276\n",
            "92     \t [0.48301881 0.11386542]. \t  -0.8269643327957453 \t 0.46481072558790276\n",
            "93     \t [-0.66483508  0.12323772]. \t  -1.2447722712189908 \t 0.46481072558790276\n",
            "94     \t [0.55201837 0.0975923 ]. \t  -1.0494681374129096 \t 0.46481072558790276\n",
            "95     \t [-0.69619025  0.12866946]. \t  -1.3286484889964003 \t 0.46481072558790276\n",
            "96     \t [0.60902942 0.07780031]. \t  -1.2350786406986964 \t 0.46481072558790276\n",
            "97     \t [-0.71763055  0.13231616]. \t  -1.3847860130965706 \t 0.46481072558790276\n",
            "98     \t [0.65864751 0.05550493]. \t  -1.3915401588172174 \t 0.46481072558790276\n",
            "99     \t [-0.73238576  0.1348042 ]. \t  -1.4227037567794694 \t 0.46481072558790276\n",
            "100    \t [0.70106916 0.03265744]. \t  -1.5169050709927756 \t 0.46481072558790276\n"
          ]
        }
      ],
      "source": [
        "### Bayesian optimisation runs (x20): 'STP' Acquisition Function run number = 7 \n",
        "\n",
        "np.random.seed(run_num_7)\n",
        "surrogate_stp_7 = tStudentProcess(cov_func, nu = df, optimize=hyperOpt)\n",
        "\n",
        "stp_7 = GPGO(surrogate_stp_7, Acquisition_new(util_stp), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\n",
        "stp_7.run(max_iter = max_iter, init_evals = n_init) # run\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCh1YYTlJLlB",
        "outputId": "fa9524eb-420b-4baf-8335-1c818dbbc634"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [2.24057642 1.87416265]. \t  -48.82879577505094 \t -0.03190064766213015\n",
            "init   \t [2.21516724 0.12342277]. \t  -8.660623551418242 \t -0.03190064766213015\n",
            "init   \t [-1.60363003 -1.95440478]. \t  -48.28332373939171 \t -0.03190064766213015\n",
            "init   \t [-0.41718709 -0.39059456]. \t  -0.2801229037700297 \t -0.03190064766213015\n",
            "init   \t [ 0.13604803 -0.08643282]. \t  -0.03190064766213015 \t -0.03190064766213015\n",
            "1      \t [-1.51603875  1.59659505]. \t  -15.522270662341809 \t -0.03190064766213015\n",
            "2      \t [ 3. -2.]. \t  -150.89999999999998 \t -0.03190064766213015\n",
            "3      \t [-3.          0.24383794]. \t  -107.94479894208206 \t -0.03190064766213015\n",
            "4      \t [-2.43142906e-04  2.00000000e+00]. \t  -47.999513950661196 \t -0.03190064766213015\n",
            "5      \t [ 0.41254853 -2.        ]. \t  -47.79650121224432 \t -0.03190064766213015\n",
            "6      \t [0.96464903 0.03060498]. \t  -2.1981338019394068 \t -0.03190064766213015\n",
            "7      \t [-3.  2.]. \t  -150.89999999999998 \t -0.03190064766213015\n",
            "8      \t [-0.66184252  0.4140094 ]. \t  -0.5351132430670493 \t -0.03190064766213015\n",
            "9      \t [-3. -2.]. \t  -162.89999999999998 \t -0.03190064766213015\n",
            "10     \t [3.         0.75416616]. \t  -110.18141385137524 \t -0.03190064766213015\n",
            "11     \t [ 1.01229    -0.32971573]. \t  -1.5311062440067378 \t -0.03190064766213015\n",
            "12     \t [ 1.93749905 -0.53338615]. \t  -1.208249299334589 \t -0.03190064766213015\n",
            "13     \t [-0.66637795 -2.        ]. \t  -50.724085381510214 \t -0.03190064766213015\n",
            "14     \t [-1.58550661 -0.40927915]. \t  -2.1710676674185567 \t -0.03190064766213015\n",
            "15     \t [-1.49515851  0.50679294]. \t  -0.6500478195315925 \t -0.03190064766213015\n",
            "16     \t [1.23691793 2.        ]. \t  -52.871807759461795 \t -0.03190064766213015\n",
            "17     \t [ 1.71192515 -0.10347619]. \t  -1.856973675063662 \t -0.03190064766213015\n",
            "18     \t [ 3.         -0.50433569]. \t  -106.62835981117176 \t -0.03190064766213015\n",
            "19     \t [-0.97387333  0.0275891 ]. \t  -2.1591949303472826 \t -0.03190064766213015\n",
            "20     \t [1.43581622 0.1996764 ]. \t  -2.3753127413927073 \t -0.03190064766213015\n",
            "21     \t [ 1.293303   -0.72802974]. \t  -0.4372455993976774 \t -0.03190064766213015\n",
            "22     \t [-0.96787988  1.14434838]. \t  -2.692071759812824 \t -0.03190064766213015\n",
            "23     \t [0.32023333 0.77119178]. \t  \u001b[92m0.32866584057672066\u001b[0m \t 0.32866584057672066\n",
            "24     \t [-0.68340683  0.26417897]. \t  -1.0038426451840377 \t 0.32866584057672066\n",
            "25     \t [ 1.55464638 -1.72034261]. \t  -22.630256560507455 \t 0.32866584057672066\n",
            "26     \t [-1.03622973 -0.77549157]. \t  -2.131203114677292 \t 0.32866584057672066\n",
            "27     \t [ 0.95995016 -0.16835118]. \t  -1.8918337164344776 \t 0.32866584057672066\n",
            "28     \t [ 1.39863504 -0.25458038]. \t  -1.6854668354704672 \t 0.32866584057672066\n",
            "29     \t [-0.9990339  -0.06633997]. \t  -2.28053360268674 \t 0.32866584057672066\n",
            "30     \t [-0.68653718  0.22012816]. \t  -1.1181508649241971 \t 0.32866584057672066\n",
            "31     \t [ 1.45089766 -0.24907179]. \t  -1.6297769320319446 \t 0.32866584057672066\n",
            "32     \t [ 1.22281879 -0.16152332]. \t  -2.1010721756985578 \t 0.32866584057672066\n",
            "33     \t [-0.71349585  0.19867373]. \t  -1.2426432418128464 \t 0.32866584057672066\n",
            "34     \t [ 0.91802598 -0.13815107]. \t  -1.8773501904242667 \t 0.32866584057672066\n",
            "35     \t [-0.74484403  0.18764106]. \t  -1.3540808299199005 \t 0.32866584057672066\n",
            "36     \t [ 0.96877843 -0.15328474]. \t  -1.9396495388335229 \t 0.32866584057672066\n",
            "37     \t [-0.76192264  0.17825435]. \t  -1.4207207532058244 \t 0.32866584057672066\n",
            "38     \t [ 1.00075483 -0.16214196]. \t  -1.9698792635472162 \t 0.32866584057672066\n",
            "39     \t [-0.77205755  0.17105803]. \t  -1.4630656663280535 \t 0.32866584057672066\n",
            "40     \t [ 1.02246837 -0.16750951]. \t  -1.9870848446317588 \t 0.32866584057672066\n",
            "41     \t [-0.77833172  0.16578195]. \t  -1.4906755293197937 \t 0.32866584057672066\n",
            "42     \t [ 1.03800108 -0.17087325]. \t  -1.9981001846193611 \t 0.32866584057672066\n",
            "43     \t [-0.78230533  0.16200827]. \t  -1.5088964246890053 \t 0.32866584057672066\n",
            "44     \t [ 1.04954104 -0.17304375]. \t  -2.0057643190812526 \t 0.32866584057672066\n",
            "45     \t [-0.78485089  0.1593489 ]. \t  -1.5209867027100936 \t 0.32866584057672066\n",
            "46     \t [ 1.05836469 -0.17447978]. \t  -2.0114152053071845 \t 0.32866584057672066\n",
            "47     \t [-0.78648647  0.15749064]. \t  -1.529020884269916 \t 0.32866584057672066\n",
            "48     \t [-0.78599836  0.15536617]. \t  -1.531925422516456 \t 0.32866584057672066\n",
            "49     \t [ 1.0660925  -0.17566893]. \t  -2.0160048434563675 \t 0.32866584057672066\n",
            "50     \t [-0.78717766  0.15477826]. \t  -1.5362093739603464 \t 0.32866584057672066\n",
            "51     \t [ 1.07138708 -0.17624657]. \t  -2.0194350132382715 \t 0.32866584057672066\n",
            "52     \t [-0.78793327  0.15435019]. \t  -1.5390518568590261 \t 0.32866584057672066\n",
            "53     \t [ 1.07568837 -0.17665687]. \t  -2.0221972629332363 \t 0.32866584057672066\n",
            "54     \t [-0.78840901  0.15403702]. \t  -1.5409257610368692 \t 0.32866584057672066\n",
            "55     \t [ 1.07922669 -0.17695147]. \t  -2.0244615865869595 \t 0.32866584057672066\n",
            "56     \t [-0.78869837  0.15380528]. \t  -1.5421458245745803 \t 0.32866584057672066\n",
            "57     \t [-0.78817961  0.15309414]. \t  -1.5421655594454136 \t 0.32866584057672066\n",
            "58     \t [ 1.08255927 -0.17725169]. \t  -2.0264478596254345 \t 0.32866584057672066\n",
            "59     \t [-0.7884444   0.15314466]. \t  -1.542767682542388 \t 0.32866584057672066\n",
            "60     \t [ 1.08495802 -0.17738023]. \t  -2.0280337813161227 \t 0.32866584057672066\n",
            "61     \t [-0.78860566  0.15316537]. \t  -1.5431539395223386 \t 0.32866584057672066\n",
            "62     \t [ 1.08699336 -0.17747491]. \t  -2.029378437871366 \t 0.32866584057672066\n",
            "63     \t [-0.78869586  0.15316782]. \t  -1.5433877966940561 \t 0.32866584057672066\n",
            "64     \t [-0.78832912  0.15276431]. \t  -1.543206044320686 \t 0.32866584057672066\n",
            "65     \t [ 1.08898346 -0.17759717]. \t  -2.0305896241665122 \t 0.32866584057672066\n",
            "66     \t [-0.78842974  0.1528716 ]. \t  -1.5432627681477271 \t 0.32866584057672066\n",
            "67     \t [ 1.09044245 -0.17763469]. \t  -2.031583734511928 \t 0.32866584057672066\n",
            "68     \t [-0.78848682  0.15293904]. \t  -1.543282032492953 \t 0.32866584057672066\n",
            "69     \t [-0.788214    0.15265285]. \t  -1.5431188941926972 \t 0.32866584057672066\n",
            "70     \t [ 1.09189835 -0.17770083]. \t  -2.0324894638642608 \t 0.32866584057672066\n",
            "71     \t [-0.78827928  0.15276915]. \t  -1.5430646405740316 \t 0.32866584057672066\n",
            "72     \t [ 1.09297537 -0.17771096]. \t  -2.0332427548344176 \t 0.32866584057672066\n",
            "73     \t [-0.78831648  0.15284732]. \t  -1.543010378735334 \t 0.32866584057672066\n",
            "74     \t [-0.78811053  0.15262806]. \t  -1.5428932824286974 \t 0.32866584057672066\n",
            "75     \t [ 1.09406989 -0.17774738]. \t  -2.0339355878073877 \t 0.32866584057672066\n",
            "76     \t [-0.78815393  0.15273248]. \t  -1.5428043189547942 \t 0.32866584057672066\n",
            "77     \t [ 1.09488432 -0.17774407]. \t  -2.034518748730239 \t 0.32866584057672066\n",
            "78     \t [-0.7881787   0.15280588]. \t  -1.5427265362237106 \t 0.32866584057672066\n",
            "79     \t [-0.78802072  0.15263069]. \t  -1.5426502636957582 \t 0.32866584057672066\n",
            "80     \t [ 1.09572604 -0.17776377]. \t  -2.0350598768689014 \t 0.32866584057672066\n",
            "81     \t [-0.78805002  0.15272003]. \t  -1.5425534440215734 \t 0.32866584057672066\n",
            "82     \t [-0.78791827  0.15257604]. \t  -1.5424855439413843 \t 0.32866584057672066\n",
            "83     \t [ 1.09646045 -0.17777526]. \t  -2.035541292398233 \t 0.32866584057672066\n",
            "84     \t [-0.78794919  0.15267085]. \t  -1.5423824148807546 \t 0.32866584057672066\n",
            "85     \t [ 1.09701081 -0.17776198]. \t  -2.0359524700759994 \t 0.32866584057672066\n",
            "86     \t [-0.78796862  0.15274075]. \t  -1.5422973718258393 \t 0.32866584057672066\n",
            "87     \t [-0.78786441  0.15261724]. \t  -1.5422624571763874 \t 0.32866584057672066\n",
            "88     \t [ 1.09759211 -0.17776737]. \t  -2.0363370096942295 \t 0.32866584057672066\n",
            "89     \t [-0.78788515  0.15269254]. \t  -1.5421704007210926 \t 0.32866584057672066\n",
            "90     \t [-0.78779665  0.15258749]. \t  -1.5421409871093292 \t 0.32866584057672066\n",
            "91     \t [ 1.09810646 -0.17776865]. \t  -2.0366835040747704 \t 0.32866584057672066\n",
            "92     \t [-0.78781768  0.15266324]. \t  -1.5420488341303753 \t 0.32866584057672066\n",
            "93     \t [-0.78774168  0.1525719 ]. \t  -1.5420257256827548 \t 0.32866584057672066\n",
            "94     \t [ 1.09856348 -0.17776732]. \t  -2.03699565848477 \t 0.32866584057672066\n",
            "95     \t [-0.78776222  0.15264609]. \t  -1.5419353594517387 \t 0.32866584057672066\n",
            "96     \t [-0.78769643  0.15256517]. \t  -1.5419189586039188 \t 0.32866584057672066\n",
            "97     \t [ 1.09897118 -0.17776381]. \t  -2.0372783702343784 \t 0.32866584057672066\n",
            "98     \t [-0.78771622  0.1526363 ]. \t  -1.5418325830496487 \t 0.32866584057672066\n",
            "99     \t [-0.78765891  0.15256387]. \t  -1.5418220630401995 \t 0.32866584057672066\n",
            "100    \t [ 1.09933634 -0.17775886]. \t  -2.037534892349272 \t 0.32866584057672066\n"
          ]
        }
      ],
      "source": [
        "### Bayesian optimisation runs (x20): 'STP' Acquisition Function run number = 8 \n",
        "\n",
        "np.random.seed(run_num_8)\n",
        "surrogate_stp_8 = tStudentProcess(cov_func, nu = df, optimize=hyperOpt)\n",
        "\n",
        "stp_8 = GPGO(surrogate_stp_8, Acquisition_new(util_stp), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\n",
        "stp_8.run(max_iter = max_iter, init_evals = n_init) # run\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDhy8DkEJLlC",
        "outputId": "026e113d-a370-4e38-aab1-38c7221b00f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [-2.93775508  0.00749837]. \t  -92.35857237145763 \t -1.395407492769129\n",
            "init   \t [-0.02536024 -1.46468188]. \t  -9.867672894921913 \t -1.395407492769129\n",
            "init   \t [-2.14733349 -1.1257653 ]. \t  -10.24680089963123 \t -1.395407492769129\n",
            "init   \t [-0.48895092 -1.00759533]. \t  -1.395407492769129 \t -1.395407492769129\n",
            "init   \t [-2.49564209 -0.61800544]. \t  -24.58298635463645 \t -1.395407492769129\n",
            "1      \t [3. 2.]. \t  -162.89999999999998 \t -1.395407492769129\n",
            "2      \t [ 3. -2.]. \t  -150.89999999999998 \t -1.395407492769129\n",
            "3      \t [-0.45841125  2.        ]. \t  -47.83409991920771 \t -1.395407492769129\n",
            "4      \t [0.85125489 0.04298794]. \t  -1.951888254704305 \t -1.395407492769129\n",
            "5      \t [-1.48234862 -2.        ]. \t  -53.151088293314515 \t -1.395407492769129\n",
            "6      \t [-3.  2.]. \t  -150.89999999999998 \t -1.395407492769129\n",
            "7      \t [-0.41351583  0.08934667]. \t  \u001b[92m-0.5556225416925543\u001b[0m \t -0.5556225416925543\n",
            "8      \t [-3. -2.]. \t  -162.89999999999998 \t -0.5556225416925543\n",
            "9      \t [-1.08976047 -0.2602509 ]. \t  -2.3779303509287013 \t -0.5556225416925543\n",
            "10     \t [0.89741646 1.41078647]. \t  -11.183744938367287 \t -0.5556225416925543\n",
            "11     \t [ 0.90297163 -0.77742482]. \t  \u001b[92m-0.38761518234825054\u001b[0m \t -0.38761518234825054\n",
            "12     \t [ 3.         -0.02667337]. \t  -108.81713605329 \t -0.38761518234825054\n",
            "13     \t [ 1.10775781 -2.        ]. \t  -48.146679681989944 \t -0.38761518234825054\n",
            "14     \t [ 0.23708077 -0.49760489]. \t  \u001b[92m0.6449170508256922\u001b[0m \t 0.6449170508256922\n",
            "15     \t [-1.60033227 -0.83235568]. \t  -2.5503925550269724 \t 0.6449170508256922\n",
            "16     \t [-1.24137132  0.94893589]. \t  -0.860517055965941 \t 0.6449170508256922\n",
            "17     \t [1.62979573 0.72708168]. \t  -2.24358701550847 \t 0.6449170508256922\n",
            "18     \t [1.37172005 2.        ]. \t  -53.05550588279266 \t 0.6449170508256922\n",
            "19     \t [-0.77205273  0.75230705]. \t  -0.1453224071589967 \t 0.6449170508256922\n",
            "20     \t [0.42515875 0.28989647]. \t  -0.4717358738443701 \t 0.6449170508256922\n",
            "21     \t [-0.87093926 -0.20019046]. \t  -1.991806092094759 \t 0.6449170508256922\n",
            "22     \t [0.54720168 0.21296371]. \t  -0.9617331296995641 \t 0.6449170508256922\n",
            "23     \t [-0.84723559 -0.20491393]. \t  -1.92519788933177 \t 0.6449170508256922\n",
            "24     \t [0.59649761 0.15556291]. \t  -1.1707282610224845 \t 0.6449170508256922\n",
            "25     \t [ 1.42910216 -0.15813754]. \t  -1.9260564166540517 \t 0.6449170508256922\n",
            "26     \t [1.08859202 0.46677601]. \t  -2.172306066197844 \t 0.6449170508256922\n",
            "27     \t [-0.92259455 -0.21790422]. \t  -2.108943862855526 \t 0.6449170508256922\n",
            "28     \t [ 0.57600063 -0.03313924]. \t  -1.0846450199900157 \t 0.6449170508256922\n",
            "29     \t [0.64277237 0.03229968]. \t  -1.3342601409643597 \t 0.6449170508256922\n",
            "30     \t [-0.90816396 -0.2204115 ]. \t  -2.072855113780413 \t 0.6449170508256922\n",
            "31     \t [-1.61017125 -0.53386877]. \t  -2.108362163108336 \t 0.6449170508256922\n",
            "32     \t [0.71315038 0.08138373]. \t  -1.5667244971911265 \t 0.6449170508256922\n",
            "33     \t [-0.91546267 -0.24058707]. \t  -2.0756540744262124 \t 0.6449170508256922\n",
            "34     \t [0.7132899  0.08217378]. \t  -1.5672117978395697 \t 0.6449170508256922\n",
            "35     \t [-0.91684166 -0.23907888]. \t  -2.080143613979991 \t 0.6449170508256922\n",
            "36     \t [0.71317645 0.08240995]. \t  -1.5668740934697207 \t 0.6449170508256922\n",
            "37     \t [-0.04159854 -0.2853218 ]. \t  0.28034027634169223 \t 0.6449170508256922\n",
            "38     \t [-0.92940812 -0.22872939]. \t  -2.1173878001984394 \t 0.6449170508256922\n",
            "39     \t [0.71158859 0.08118992]. \t  -1.5618528811223786 \t 0.6449170508256922\n",
            "40     \t [0.69913368 0.06937955]. \t  -1.5217032149331784 \t 0.6449170508256922\n",
            "41     \t [-0.49641284  0.19632543]. \t  -0.6174764411002345 \t 0.6449170508256922\n",
            "42     \t [-0.91414549 -0.38381938]. \t  -1.919082855723656 \t 0.6449170508256922\n",
            "43     \t [0.68771108 0.06947562]. \t  -1.4858889787800715 \t 0.6449170508256922\n",
            "44     \t [-0.93223577 -0.08362505]. \t  -2.159158369497297 \t 0.6449170508256922\n",
            "45     \t [0.68434961 0.06485518]. \t  -1.4746002971244963 \t 0.6449170508256922\n",
            "46     \t [ 0.09388108 -0.34483299]. \t  0.4163625738183651 \t 0.6449170508256922\n",
            "47     \t [0.65901818 0.03266569]. \t  -1.3856861225680945 \t 0.6449170508256922\n",
            "48     \t [-0.8588193  -0.41517626]. \t  -1.7275328228037279 \t 0.6449170508256922\n",
            "49     \t [0.66523321 0.05187226]. \t  -1.4115438045475328 \t 0.6449170508256922\n",
            "50     \t [-0.78734023  0.03389174]. \t  -1.720759225023743 \t 0.6449170508256922\n",
            "51     \t [0.66934078 0.04929696]. \t  -1.4238323251179827 \t 0.6449170508256922\n",
            "52     \t [-0.89018932 -0.38951887]. \t  -1.8488391456368367 \t 0.6449170508256922\n",
            "53     \t [0.66802269 0.05369676]. \t  -1.4208104767481644 \t 0.6449170508256922\n",
            "54     \t [ 0.12123569 -0.31197281]. \t  0.3309004083222678 \t 0.6449170508256922\n",
            "55     \t [0.63184523 0.00561617]. \t  -1.2868411351374351 \t 0.6449170508256922\n",
            "56     \t [-0.87950677 -0.27968318]. \t  -1.9494386209088097 \t 0.6449170508256922\n",
            "57     \t [0.64720227 0.03520583]. \t  -1.349363373380187 \t 0.6449170508256922\n",
            "58     \t [-0.48256646  0.11798016]. \t  -0.7099753127305048 \t 0.6449170508256922\n",
            "59     \t [0.63744677 0.03531295]. \t  -1.318512636950214 \t 0.6449170508256922\n",
            "60     \t [-0.88853558 -0.26898468]. \t  -1.9836081678972677 \t 0.6449170508256922\n",
            "61     \t [0.64096679 0.04179565]. \t  -1.331827686999029 \t 0.6449170508256922\n",
            "62     \t [-0.87832978 -0.21783051]. \t  -1.999605719348054 \t 0.6449170508256922\n",
            "63     \t [0.64280041 0.04324824]. \t  -1.3380876304913203 \t 0.6449170508256922\n",
            "64     \t [ 0.17591862 -0.29722603]. \t  0.25265461367579795 \t 0.6449170508256922\n",
            "65     \t [ 0.60185557 -0.01195862]. \t  -1.1814516087246667 \t 0.6449170508256922\n",
            "66     \t [0.61643612 0.01290198]. \t  -1.2423215791547249 \t 0.6449170508256922\n",
            "67     \t [-0.83142254 -0.2670545 ]. \t  -1.828792377885207 \t 0.6449170508256922\n",
            "68     \t [0.62761686 0.02814681]. \t  -1.2846482764743516 \t 0.6449170508256922\n",
            "69     \t [0.62628298 0.02711809]. \t  -1.2800060605838128 \t 0.6449170508256922\n",
            "70     \t [-0.83109009 -0.17895667]. \t  -1.8955435771265632 \t 0.6449170508256922\n",
            "71     \t [0.63199166 0.03155179]. \t  -1.2998405074448853 \t 0.6449170508256922\n",
            "72     \t [0.62953895 0.02885391]. \t  -1.2910193800615346 \t 0.6449170508256922\n",
            "73     \t [-0.84017585 -0.267208  ]. \t  -1.8537158550497823 \t 0.6449170508256922\n",
            "74     \t [0.63311864 0.03304099]. \t  -1.3039701758570985 \t 0.6449170508256922\n",
            "75     \t [ 0.09673551 -0.29896645]. \t  0.31724119748869417 \t 0.6449170508256922\n",
            "76     \t [ 0.24487667 -0.25515248]. \t  0.07355940786143847 \t 0.6449170508256922\n",
            "77     \t [ 0.51983091 -0.09237472]. \t  -0.8522693884666789 \t 0.6449170508256922\n",
            "78     \t [ 0.5634104  -0.04185225]. \t  -1.0382111982129514 \t 0.6449170508256922\n",
            "79     \t [-0.74313553 -0.2314988 ]. \t  -1.5938409222314425 \t 0.6449170508256922\n",
            "80     \t [ 0.59049125 -0.01189675]. \t  -1.1459461139283387 \t 0.6449170508256922\n",
            "81     \t [ 0.59441776 -0.00503105]. \t  -1.1627698467435186 \t 0.6449170508256922\n",
            "82     \t [ 0.59686728 -0.00061591]. \t  -1.1731838280451208 \t 0.6449170508256922\n",
            "83     \t [-0.78752751 -0.22946602]. \t  -1.7337401860504682 \t 0.6449170508256922\n",
            "84     \t [0.60509475 0.00698201]. \t  -1.203427437795638 \t 0.6449170508256922\n",
            "85     \t [0.60474445 0.00732376]. \t  -1.2025114833644452 \t 0.6449170508256922\n",
            "86     \t [-0.79926411 -0.22232793]. \t  -1.7749462866498242 \t 0.6449170508256922\n",
            "87     \t [0.60966477 0.01107942]. \t  -1.2200211905139615 \t 0.6449170508256922\n",
            "88     \t [0.60851524 0.0102689 ]. \t  -1.2159723102456257 \t 0.6449170508256922\n",
            "89     \t [0.60758028 0.00969094]. \t  -1.212719844321922 \t 0.6449170508256922\n",
            "90     \t [-0.80950924 -0.23046175]. \t  -1.7986242094115703 \t 0.6449170508256922\n",
            "91     \t [0.61121447 0.01238806]. \t  -1.2255850142344735 \t 0.6449170508256922\n",
            "92     \t [0.60992999 0.01131445]. \t  -1.2209798372046772 \t 0.6449170508256922\n",
            "93     \t [0.60888819 0.01053362]. \t  -1.2172872203082312 \t 0.6449170508256922\n",
            "94     \t [-0.81359884 -0.22621639]. \t  -1.8141281015686763 \t 0.6449170508256922\n",
            "95     \t [0.61200722 0.01273845]. \t  -1.2282650729589224 \t 0.6449170508256922\n",
            "96     \t [0.61075883 0.01167672]. \t  -1.223781615655347 \t 0.6449170508256922\n",
            "97     \t [0.60973915 0.01089053]. \t  -1.220157158023106 \t 0.6449170508256922\n",
            "98     \t [0.60890404 0.01031271]. \t  -1.2172210981336133 \t 0.6449170508256922\n",
            "99     \t [-0.81784005 -0.22905375]. \t  -1.8241799440532331 \t 0.6449170508256922\n",
            "100    \t [0.61184332 0.01250634]. \t  -1.2276294042196874 \t 0.6449170508256922\n"
          ]
        }
      ],
      "source": [
        "### Bayesian optimisation runs (x20): 'STP' Acquisition Function run number = 9 \n",
        "\n",
        "np.random.seed(run_num_9)\n",
        "surrogate_stp_9 = tStudentProcess(cov_func, nu = df, optimize=hyperOpt)\n",
        "\n",
        "stp_9 = GPGO(surrogate_stp_9, Acquisition_new(util_stp), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\n",
        "stp_9.run(max_iter = max_iter, init_evals = n_init) # run\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RqwHOur5JLlC",
        "outputId": "a4e8b685-d2cd-4775-a7de-e5e2ca809cbf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 1.62792386 -1.9169922 ]. \t  -38.25414770674631 \t -0.7775687473184012\n",
            "init   \t [0.80188941 0.99521553]. \t  -2.552651714051803 \t -0.7775687473184012\n",
            "init   \t [-0.00895793 -1.10081342]. \t  -1.0367630165263393 \t -0.7775687473184012\n",
            "init   \t [-1.81162281  1.04212285]. \t  -0.7775687473184012 \t -0.7775687473184012\n",
            "init   \t [-1.98533498 -1.64664074]. \t  -25.383481436170044 \t -0.7775687473184012\n",
            "1      \t [3. 2.]. \t  -162.89999999999998 \t -0.7775687473184012\n",
            "2      \t [-3.  2.]. \t  -150.89999999999998 \t -0.7775687473184012\n",
            "3      \t [-0.61174023  2.        ]. \t  -47.996798612026915 \t -0.7775687473184012\n",
            "4      \t [ 3.         -0.33692774]. \t  -107.4866830115488 \t -0.7775687473184012\n",
            "5      \t [-0.96459623  0.00587716]. \t  -2.1664490832063437 \t -0.7775687473184012\n",
            "6      \t [-3.         -0.45082508]. \t  -109.60473351017524 \t -0.7775687473184012\n",
            "7      \t [-0.518975 -2.      ]. \t  -49.96946597892602 \t -0.7775687473184012\n",
            "8      \t [0.25433762 0.02975367]. \t  \u001b[92m-0.2540827836260772\u001b[0m \t -0.2540827836260772\n",
            "9      \t [-0.42321824  0.33501737]. \t  \u001b[92m-0.11065479359004765\u001b[0m \t -0.11065479359004765\n",
            "10     \t [-3. -2.]. \t  -162.89999999999998 \t -0.11065479359004765\n",
            "11     \t [ 0.67870279 -0.15825047]. \t  -1.2244686339399753 \t -0.11065479359004765\n",
            "12     \t [ 3. -2.]. \t  -150.89999999999998 \t -0.11065479359004765\n",
            "13     \t [0.98614185 2.        ]. \t  -52.18275733304595 \t -0.11065479359004765\n",
            "14     \t [-1.27388057 -1.110226  ]. \t  -4.946551221161268 \t -0.11065479359004765\n",
            "15     \t [ 0.77987942 -1.38550583]. \t  -7.711838071048273 \t -0.11065479359004765\n",
            "16     \t [-1.24974409  0.82875132]. \t  -0.498582738173876 \t -0.11065479359004765\n",
            "17     \t [1.65162018 0.56230934]. \t  -2.1149433680897642 \t -0.11065479359004765\n",
            "18     \t [-1.97749158  0.42214887]. \t  -2.041236520239288 \t -0.11065479359004765\n",
            "19     \t [-0.97865149 -0.02201659]. \t  -2.217161029985665 \t -0.11065479359004765\n",
            "20     \t [1.03043827 0.09204058]. \t  -2.3398961868690344 \t -0.11065479359004765\n",
            "21     \t [-1.01852574  0.1383826 ]. \t  -2.0456499345549246 \t -0.11065479359004765\n",
            "22     \t [ 0.47366176 -0.09779545]. \t  -0.7112700082798226 \t -0.11065479359004765\n",
            "23     \t [-0.35865406 -0.28156794]. \t  -0.28949806407415424 \t -0.11065479359004765\n",
            "24     \t [ 1.24452809 -0.68675931]. \t  -0.5446908278042375 \t -0.11065479359004765\n",
            "25     \t [ 0.71388347 -0.05930162]. \t  -1.4808705471497567 \t -0.11065479359004765\n",
            "26     \t [ 0.45661224 -0.74892615]. \t  \u001b[92m0.5814253788941428\u001b[0m \t 0.5814253788941428\n",
            "27     \t [-1.11110105  0.27865669]. \t  -1.768661776173215 \t 0.5814253788941428\n",
            "28     \t [0.0421345  0.92493237]. \t  0.44841312227767827 \t 0.5814253788941428\n",
            "29     \t [-1.67595247 -0.55079031]. \t  -2.131845168529873 \t 0.5814253788941428\n",
            "30     \t [0.6858996  0.10701652]. \t  -1.4798640708870174 \t 0.5814253788941428\n",
            "31     \t [-1.32321149  0.36277951]. \t  -1.4177663544228514 \t 0.5814253788941428\n",
            "32     \t [-0.97274144 -0.05700017]. \t  -2.2295739862703883 \t 0.5814253788941428\n",
            "33     \t [0.66822494 0.05994415]. \t  -1.422802729337523 \t 0.5814253788941428\n",
            "34     \t [-1.06352333  0.17680415]. \t  -2.0108834007878875 \t 0.5814253788941428\n",
            "35     \t [0.65168658 0.0172818 ]. \t  -1.3556142141490775 \t 0.5814253788941428\n",
            "36     \t [ 0.63285063 -0.01654039]. \t  -1.2750110776132253 \t 0.5814253788941428\n",
            "37     \t [-1.06160303  0.15874615]. \t  -2.0510882348929713 \t 0.5814253788941428\n",
            "38     \t [ 0.63022748 -0.03461196]. \t  -1.251743217830364 \t 0.5814253788941428\n",
            "39     \t [-0.84427322 -0.27200399]. \t  -1.860537350618799 \t 0.5814253788941428\n",
            "40     \t [-1.10337669  0.28821201]. \t  -1.736032968678066 \t 0.5814253788941428\n",
            "41     \t [ 0.65193921 -0.00838415]. \t  -1.3405881796704215 \t 0.5814253788941428\n",
            "42     \t [ 0.5782909  -0.16491083]. \t  -0.9141002948178036 \t 0.5814253788941428\n",
            "43     \t [-1.09466026  0.23945592]. \t  -1.8729814506144493 \t 0.5814253788941428\n",
            "44     \t [0.68856269 0.08830423]. \t  -1.4897997274485464 \t 0.5814253788941428\n",
            "45     \t [-1.0803143  0.1932939]. \t  -1.9851598371530386 \t 0.5814253788941428\n",
            "46     \t [ 0.52088835 -0.27925121]. \t  -0.5043015099485797 \t 0.5814253788941428\n",
            "47     \t [0.68907952 0.08959368]. \t  -1.4914202948376916 \t 0.5814253788941428\n",
            "48     \t [-0.83538538 -0.28114716]. \t  -1.8257064813351707 \t 0.5814253788941428\n",
            "49     \t [ 0.56980597 -0.21470779]. \t  -0.7905109852073126 \t 0.5814253788941428\n",
            "50     \t [-1.10128884  0.2564318 ]. \t  -1.8288487677141028 \t 0.5814253788941428\n",
            "51     \t [0.68523386 0.08256426]. \t  -1.479190250924206 \t 0.5814253788941428\n",
            "52     \t [-1.09019583  0.21919052]. \t  -1.9253863813696706 \t 0.5814253788941428\n",
            "53     \t [ 0.54810437 -0.24788404]. \t  -0.6546341311662784 \t 0.5814253788941428\n",
            "54     \t [0.67890683 0.07169951]. \t  -1.4583883340871415 \t 0.5814253788941428\n",
            "55     \t [-1.07736619  0.18330245]. \t  -2.007510949261415 \t 0.5814253788941428\n",
            "56     \t [ 0.55079457 -0.23684081]. \t  -0.68729083090811 \t 0.5814253788941428\n",
            "57     \t [0.6740286  0.06083947]. \t  -1.4413282867507398 \t 0.5814253788941428\n",
            "58     \t [ 0.54707323 -0.23653415]. \t  -0.6773130579187657 \t 0.5814253788941428\n",
            "59     \t [-1.06557921  0.15462592]. \t  -2.0642287477581722 \t 0.5814253788941428\n",
            "60     \t [0.67045408 0.05015369]. \t  -1.4275778890491717 \t 0.5814253788941428\n",
            "61     \t [ 0.56133967 -0.20815949]. \t  -0.7796703181254299 \t 0.5814253788941428\n",
            "62     \t [-0.85494452 -0.24665303]. \t  -1.9142742688168437 \t 0.5814253788941428\n",
            "63     \t [0.67116321 0.04615479]. \t  -1.4286630201444155 \t 0.5814253788941428\n",
            "64     \t [-1.09379958  0.23274876]. \t  -1.891017292171279 \t 0.5814253788941428\n",
            "65     \t [ 0.63990504 -0.03102139]. \t  -1.284991126394304 \t 0.5814253788941428\n",
            "66     \t [ 0.56201476 -0.22726938]. \t  -0.7407712331710907 \t 0.5814253788941428\n",
            "67     \t [0.65883694 0.0246997 ]. \t  -1.381691893965619 \t 0.5814253788941428\n",
            "68     \t [-1.08361416  0.20248024]. \t  -1.9644039552387478 \t 0.5814253788941428\n",
            "69     \t [ 0.62196483 -0.06873799]. \t  -1.1908390442328725 \t 0.5814253788941428\n",
            "70     \t [ 0.62899509 -0.04821423]. \t  -1.234871916714022 \t 0.5814253788941428\n",
            "71     \t [-1.07445725  0.17847711]. \t  -2.0167616328721145 \t 0.5814253788941428\n",
            "72     \t [ 0.55252624 -0.24056542]. \t  -0.6838979595012771 \t 0.5814253788941428\n",
            "73     \t [0.653775   0.01362579]. \t  -1.3602335326752077 \t 0.5814253788941428\n",
            "74     \t [ 0.62642084 -0.05321856]. \t  -1.221760699447877 \t 0.5814253788941428\n",
            "75     \t [-1.06562475  0.1577195 ]. \t  -2.057299101931651 \t 0.5814253788941428\n",
            "76     \t [ 0.56055619 -0.21974978]. \t  -0.7528743177592285 \t 0.5814253788941428\n",
            "77     \t [0.65036635 0.00467945]. \t  -1.3443771545489622 \t 0.5814253788941428\n",
            "78     \t [ 0.62749562 -0.05095911]. \t  -1.2274317815721427 \t 0.5814253788941428\n",
            "79     \t [-1.05955737  0.14482595]. \t  -2.079937559816485 \t 0.5814253788941428\n",
            "80     \t [ 0.56891876 -0.19991634]. \t  -0.8187650350904567 \t 0.5814253788941428\n",
            "81     \t [ 0.64685096 -0.00507767]. \t  -1.3270433224135598 \t 0.5814253788941428\n",
            "82     \t [ 0.62708233 -0.05305463]. \t  -1.2239742432911946 \t 0.5814253788941428\n",
            "83     \t [ 0.56889402 -0.19518627]. \t  -0.8282754999433957 \t 0.5814253788941428\n",
            "84     \t [-1.05681307  0.13998398]. \t  -2.0875449726256945 \t 0.5814253788941428\n",
            "85     \t [ 0.64432593 -0.01284097]. \t  -1.313597414509385 \t 0.5814253788941428\n",
            "86     \t [ 0.62785172 -0.05269039]. \t  -1.2267305022657276 \t 0.5814253788941428\n",
            "87     \t [ 0.61690188 -0.07881912]. \t  -1.1631783321820601 \t 0.5814253788941428\n",
            "88     \t [ 0.62307863 -0.06255136]. \t  -1.2013361851721178 \t 0.5814253788941428\n",
            "89     \t [-1.05577433  0.1382995 ]. \t  -2.0900451393025774 \t 0.5814253788941428\n",
            "90     \t [ 0.61842378 -0.07761741]. \t  -1.1693256391466955 \t 0.5814253788941428\n",
            "91     \t [ 0.62329365 -0.06434283]. \t  -1.1999794158706512 \t 0.5814253788941428\n",
            "92     \t [ 0.61842519 -0.07549356]. \t  -1.1719289034383866 \t 0.5814253788941428\n",
            "93     \t [-0.88078315 -0.19690821]. \t  -2.0192517370169165 \t 0.5814253788941428\n",
            "94     \t [ 0.63654131 -0.0400385 ]. \t  -1.2662578904699862 \t 0.5814253788941428\n",
            "95     \t [ 0.62420418 -0.07030992]. \t  -1.1958707728158753 \t 0.5814253788941428\n",
            "96     \t [-1.08391673  0.20649966]. \t  -1.9542533084889455 \t 0.5814253788941428\n",
            "97     \t [ 0.61903359 -0.08217534]. \t  -1.1654964557156384 \t 0.5814253788941428\n",
            "98     \t [ 0.62522457 -0.06471124]. \t  -1.2054996886455331 \t 0.5814253788941428\n",
            "99     \t [ 0.62185084 -0.07216865]. \t  -1.1864410800741816 \t 0.5814253788941428\n",
            "100    \t [ 0.62259267 -0.06918498]. \t  -1.1922451891044197 \t 0.5814253788941428\n"
          ]
        }
      ],
      "source": [
        "### Bayesian optimisation runs (x20): 'STP' Acquisition Function run number = 10 \n",
        "\n",
        "np.random.seed(run_num_10)\n",
        "surrogate_stp_10 = tStudentProcess(cov_func, nu = df, optimize=hyperOpt)\n",
        "\n",
        "stp_10 = GPGO(surrogate_stp_10, Acquisition_new(util_stp), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\n",
        "stp_10.run(max_iter = max_iter, init_evals = n_init) # run\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iXLW3-5DJLlD",
        "outputId": "23936536-2bf3-4e18-aa8a-2e35fab6cda1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [-1.91838187 -1.92209903]. \t  -46.39910375151002 \t 0.6254688257880329\n",
            "init   \t [-0.22068884  0.89973572]. \t  0.6254688257880329 \t 0.6254688257880329\n",
            "init   \t [-0.47877837 -0.05829161]. \t  -0.8249470187639529 \t 0.6254688257880329\n",
            "init   \t [-2.92331511 -0.05051357]. \t  -88.99028404075307 \t 0.6254688257880329\n",
            "init   \t [2.65083991 1.40318036]. \t  -51.423425402262914 \t 0.6254688257880329\n",
            "1      \t [ 1.80850935 -2.        ]. \t  -46.66382992980821 \t 0.6254688257880329\n",
            "2      \t [-0.9752184  2.       ]. \t  -48.24106256776646 \t 0.6254688257880329\n",
            "3      \t [0.64894496 0.05800598]. \t  -1.3612080143044278 \t 0.6254688257880329\n",
            "4      \t [ 0.02064705 -0.89040825]. \t  \u001b[92m0.673689228431223\u001b[0m \t 0.673689228431223\n",
            "5      \t [0.25095176 0.10304984]. \t  -0.22749617783408294 \t 0.673689228431223\n",
            "6      \t [ 3.         -0.61847937]. \t  -106.09977115149148 \t 0.673689228431223\n",
            "7      \t [0.89265336 2.        ]. \t  -51.807902718956235 \t 0.673689228431223\n",
            "8      \t [-3.  2.]. \t  -150.89999999999998 \t 0.673689228431223\n",
            "9      \t [-0.02803215 -2.        ]. \t  -48.059206209185 \t 0.673689228431223\n",
            "10     \t [-3. -2.]. \t  -162.89999999999998 \t 0.673689228431223\n",
            "11     \t [-1.0876288 -1.1081942]. \t  -4.67070047750041 \t 0.673689228431223\n",
            "12     \t [ 0.97134132 -0.84712376]. \t  -0.5511506422808329 \t 0.673689228431223\n",
            "13     \t [-1.34052567  0.65831692]. \t  -0.4762159523332846 \t 0.673689228431223\n",
            "14     \t [ 3. -2.]. \t  -150.89999999999998 \t 0.673689228431223\n",
            "15     \t [-1.54360903 -0.25339181]. \t  -2.2684131547616104 \t 0.673689228431223\n",
            "16     \t [3. 2.]. \t  -162.89999999999998 \t 0.673689228431223\n",
            "17     \t [2.0332249  0.66871783]. \t  -4.5678768762232895 \t 0.673689228431223\n",
            "18     \t [3.         0.60566589]. \t  -109.78793341356247 \t 0.673689228431223\n",
            "19     \t [1.16914136 0.32319199]. \t  -2.3989252146871474 \t 0.673689228431223\n",
            "20     \t [-0.66342087 -0.05471261]. \t  -1.4064925835545246 \t 0.673689228431223\n",
            "21     \t [-0.63600939 -0.04746423]. \t  -1.3176751182556847 \t 0.673689228431223\n",
            "22     \t [ 0.76641513 -0.02337465]. \t  -1.6724634571806074 \t 0.673689228431223\n",
            "23     \t [-0.64536969 -0.04005231]. \t  -1.3452390433157073 \t 0.673689228431223\n",
            "24     \t [ 0.65131402 -0.01829248]. \t  -1.3311301677869658 \t 0.673689228431223\n",
            "25     \t [1.77822555 1.35290433]. \t  -10.674993603646929 \t 0.673689228431223\n",
            "26     \t [0.95971827 0.46724166]. \t  -1.9289684931623134 \t 0.673689228431223\n",
            "27     \t [ 1.6327988  -0.40044722]. \t  -0.8619547129015381 \t 0.673689228431223\n",
            "28     \t [1.02224261 0.07893477]. \t  -2.3230450980155823 \t 0.673689228431223\n",
            "29     \t [-0.75079377 -0.04561236]. \t  -1.6731393593370643 \t 0.673689228431223\n",
            "30     \t [-0.78171651  0.67266969]. \t  -0.21939865246766943 \t 0.673689228431223\n",
            "31     \t [-0.71997026 -0.0412699 ]. \t  -1.5785093784937863 \t 0.673689228431223\n",
            "32     \t [-1.09735182 -2.        ]. \t  -52.54836033725128 \t 0.673689228431223\n",
            "33     \t [ 0.87292673 -0.14325229]. \t  -1.7706835163788701 \t 0.673689228431223\n",
            "34     \t [-0.70969003  0.05258293]. \t  -1.47616727025756 \t 0.673689228431223\n",
            "35     \t [1.02024247 0.18230926]. \t  -2.321703964476672 \t 0.673689228431223\n",
            "36     \t [-0.69503926  0.04470655]. \t  -1.440776531691677 \t 0.673689228431223\n",
            "37     \t [ 0.74202178 -0.27271727]. \t  -1.1436613502950013 \t 0.673689228431223\n",
            "38     \t [1.02105388 0.21238971]. \t  -2.3099714008828554 \t 0.673689228431223\n",
            "39     \t [-0.6948656  0.0421582]. \t  -1.4429049621141803 \t 0.673689228431223\n",
            "40     \t [-0.68524563  0.03968556]. \t  -1.4162480443636225 \t 0.673689228431223\n",
            "41     \t [ 0.74865517 -0.24707633]. \t  -1.2266737980432227 \t 0.673689228431223\n",
            "42     \t [1.00865235 0.19057216]. \t  -2.299132462522574 \t 0.673689228431223\n",
            "43     \t [-0.69040009  0.03846766]. \t  -1.4331242943956002 \t 0.673689228431223\n",
            "44     \t [-0.6831886   0.03719654]. \t  -1.4124515597191825 \t 0.673689228431223\n",
            "45     \t [ 0.75435552 -0.22764928]. \t  -1.289327326630369 \t 0.673689228431223\n",
            "46     \t [0.99693502 0.16951537]. \t  -2.2857524601442307 \t 0.673689228431223\n",
            "47     \t [-0.6894584   0.03647079]. \t  -1.4322399144977382 \t 0.673689228431223\n",
            "48     \t [-0.68347687  0.03584799]. \t  -1.4146446501321182 \t 0.673689228431223\n",
            "49     \t [ 0.75960818 -0.21192253]. \t  -1.3403365390657846 \t 0.673689228431223\n",
            "50     \t [-0.6896731   0.03804163]. \t  -1.4313418438854049 \t 0.673689228431223\n",
            "51     \t [0.98509512 0.14612552]. \t  -2.2690522531433586 \t 0.673689228431223\n",
            "52     \t [-0.68418906  0.03421416]. \t  -1.4183897960416474 \t 0.673689228431223\n",
            "53     \t [ 0.7655651  -0.19720487]. \t  -1.3896317466764518 \t 0.673689228431223\n",
            "54     \t [-0.68967791  0.03653771]. \t  -1.4328410562605498 \t 0.673689228431223\n",
            "55     \t [0.97688674 0.13377209]. \t  -2.25483233860395 \t 0.673689228431223\n",
            "56     \t [-0.68492349  0.03334281]. \t  -1.4214602411470698 \t 0.673689228431223\n",
            "57     \t [ 0.77102314 -0.18508364]. \t  -1.4307575823573102 \t 0.673689228431223\n",
            "58     \t [-0.68963192  0.03554816]. \t  -1.433668393478869 \t 0.673689228431223\n",
            "59     \t [0.96861549 0.12055741]. \t  -2.239110881675083 \t 0.673689228431223\n",
            "60     \t [-0.6856251   0.03283423]. \t  -1.4240817268544745 \t 0.673689228431223\n",
            "61     \t [-0.6832291   0.03316024]. \t  -1.4164657865452204 \t 0.673689228431223\n",
            "62     \t [ 0.79582841 -0.1553591 ]. \t  -1.557840889412112 \t 0.673689228431223\n",
            "63     \t [-0.68861309  0.03503402]. \t  -1.4310707131136151 \t 0.673689228431223\n",
            "64     \t [0.95931061 0.10487476]. \t  -2.219491041550128 \t 0.673689228431223\n",
            "65     \t [-0.6857402   0.03264702]. \t  -1.4246098345502998 \t 0.673689228431223\n",
            "66     \t [-0.68385621  0.03295073]. \t  -1.4185776009420774 \t 0.673689228431223\n",
            "67     \t [ 0.80196287 -0.14437867]. \t  -1.595191335902589 \t 0.673689228431223\n",
            "68     \t [-0.68856887  0.03457715]. \t  -1.4313777194245232 \t 0.673689228431223\n",
            "69     \t [0.95189558 0.09331842]. \t  -2.202543127687473 \t 0.673689228431223\n",
            "70     \t [-0.68633379  0.03250663]. \t  -1.4265515840570375 \t 0.673689228431223\n",
            "71     \t [-0.68474148  0.0327801 ]. \t  -1.4214391681935374 \t 0.673689228431223\n",
            "72     \t [ 0.80805916 -0.13358041]. \t  -1.6312459256659415 \t 0.673689228431223\n",
            "73     \t [-0.68871729  0.03416682]. \t  -1.4322242494846626 \t 0.673689228431223\n",
            "74     \t [0.94530452 0.08333665]. \t  -2.1865508901745856 \t 0.673689228431223\n",
            "75     \t [-0.68695752  0.03238934]. \t  -1.4285627552468794 \t 0.673689228431223\n",
            "76     \t [-0.68558894  0.03263249]. \t  -1.4241625384042549 \t 0.673689228431223\n",
            "77     \t [ 0.81383996 -0.12339885]. \t  -1.6645409114380723 \t 0.673689228431223\n",
            "78     \t [-0.68891437  0.03380449]. \t  -1.433171505261484 \t 0.673689228431223\n",
            "79     \t [0.93929392 0.07435105]. \t  -2.1712097135209327 \t 0.673689228431223\n",
            "80     \t [-0.68753006  0.03228886]. \t  -1.4304015239719976 \t 0.673689228431223\n",
            "81     \t [-0.68634695  0.03250415]. \t  -1.4265940445067342 \t 0.673689228431223\n",
            "82     \t [ 0.81957915 -0.11350547]. \t  -1.696459070364545 \t 0.673689228431223\n",
            "83     \t [-0.68912753  0.03348648]. \t  -1.4341243362427065 \t 0.673689228431223\n",
            "84     \t [-0.68783545  0.03351166]. \t  -1.4301691930053348 \t 0.673689228431223\n",
            "85     \t [0.93247473 0.06322978]. \t  -2.152501395257538 \t 0.673689228431223\n",
            "86     \t [-0.68709397  0.03224129]. \t  -1.4291183035270976 \t 0.673689228431223\n",
            "87     \t [-0.68625819  0.03242263]. \t  -1.4264006478047737 \t 0.673689228431223\n",
            "88     \t [ 0.84318701 -0.08013637]. \t  -1.8090678634475974 \t 0.673689228431223\n",
            "89     \t [-0.68862995  0.0330315 ]. \t  -1.4330449130075105 \t 0.673689228431223\n",
            "90     \t [-0.68767698  0.03309525]. \t  -1.430083921890521 \t 0.673689228431223\n",
            "91     \t [0.92111337 0.04461944]. \t  -2.1188206068790505 \t 0.673689228431223\n",
            "92     \t [-0.687481    0.03216478]. \t  -1.430369335832408 \t 0.673689228431223\n",
            "93     \t [-0.68678601  0.03232043]. \t  -1.4281054016516803 \t 0.673689228431223\n",
            "94     \t [-0.68621275  0.03245189]. \t  -1.4262345233861402 \t 0.673689228431223\n",
            "95     \t [ 0.85764736 -0.05783666]. \t  -1.8757555196657172 \t 0.673689228431223\n",
            "96     \t [-0.68816958  0.03277933]. \t  -1.4318837457578533 \t 0.673689228431223\n",
            "97     \t [-0.68749184  0.03284687]. \t  -1.4297564251620047 \t 0.673689228431223\n",
            "98     \t [0.90850456 0.02422579]. \t  -2.077984847575206 \t 0.673689228431223\n",
            "99     \t [-0.68779777  0.03222681]. \t  -1.4312753643484821 \t 0.673689228431223\n",
            "100    \t [-0.6872341   0.03234229]. \t  -1.4294496742622524 \t 0.673689228431223\n"
          ]
        }
      ],
      "source": [
        "### Bayesian optimisation runs (x20): 'STP' Acquisition Function run number = 11 \n",
        "\n",
        "np.random.seed(run_num_11)\n",
        "surrogate_stp_11 = tStudentProcess(cov_func, nu = df, optimize=hyperOpt)\n",
        "\n",
        "stp_11 = GPGO(surrogate_stp_11, Acquisition_new(util_stp), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\n",
        "stp_11.run(max_iter = max_iter, init_evals = n_init) # run\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sv5SygMbJLlD",
        "outputId": "9745ebbe-cf54-4635-f0ee-1e46d2b05244"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [-2.07502295  0.96019879]. \t  -2.6185857163917037 \t -1.9967735906956543\n",
            "init   \t [-1.42010991  0.13495757]. \t  -1.9967735906956543 \t -1.9967735906956543\n",
            "init   \t [-2.91255023  1.67498803]. \t  -101.67816714332157 \t -1.9967735906956543\n",
            "init   \t [ 2.40428912 -1.86631429]. \t  -47.44624883788006 \t -1.9967735906956543\n",
            "init   \t [ 2.74169602 -1.45116271]. \t  -58.32400185681089 \t -1.9967735906956543\n",
            "1      \t [-0.39176725  1.5242247 ]. \t  -12.265642885832602 \t -1.9967735906956543\n",
            "2      \t [3. 2.]. \t  -162.89999999999998 \t -1.9967735906956543\n",
            "3      \t [-3. -2.]. \t  -162.89999999999998 \t -1.9967735906956543\n",
            "4      \t [-0.0182726  -1.12851875]. \t  \u001b[92m-1.4155029251986726\u001b[0m \t -1.4155029251986726\n",
            "5      \t [0.67020012 0.18263987]. \t  \u001b[92m-1.396627126354816\u001b[0m \t -1.396627126354816\n",
            "6      \t [-0.06063807 -2.        ]. \t  -48.13595565688664 \t -1.396627126354816\n",
            "7      \t [-0.47122639  0.07034518]. \t  \u001b[92m-0.7354755614644964\u001b[0m \t -0.7354755614644964\n",
            "8      \t [0.55456757 2.        ]. \t  -50.15038571290821 \t -0.7354755614644964\n",
            "9      \t [ 1.06692379 -0.8600088 ]. \t  \u001b[92m-0.6359268924007138\u001b[0m \t -0.6359268924007138\n",
            "10     \t [-1.30938464  2.        ]. \t  -47.74619241043836 \t -0.6359268924007138\n",
            "11     \t [ 0.13702174 -0.1720663 ]. \t  \u001b[92m0.06413602412090168\u001b[0m \t 0.06413602412090168\n",
            "12     \t [-3.         0.1084833]. \t  -108.52802958577361 \t 0.06413602412090168\n",
            "13     \t [-1.27705007  0.86399246]. \t  -0.5235837245540091 \t 0.06413602412090168\n",
            "14     \t [2.07959477 0.09383417]. \t  -5.144394771634976 \t 0.06413602412090168\n",
            "15     \t [-0.98091163 -1.02374583]. \t  -3.4071562954565318 \t 0.06413602412090168\n",
            "16     \t [3.        0.0514614]. \t  -109.04381915343737 \t 0.06413602412090168\n",
            "17     \t [ 1.49193366 -0.08754953]. \t  -2.0140168099308164 \t 0.06413602412090168\n",
            "18     \t [1.49285386 0.76012411]. \t  -2.3329364655540172 \t 0.06413602412090168\n",
            "19     \t [ 1.01799107 -0.0315994 ]. \t  -2.224786014603975 \t 0.06413602412090168\n",
            "20     \t [-0.7588762   0.09231383]. \t  -1.566915253875827 \t 0.06413602412090168\n",
            "21     \t [-1.08252594  0.56073436]. \t  -0.8707707625719912 \t 0.06413602412090168\n",
            "22     \t [ 1.19355285 -2.        ]. \t  -48.01310886031216 \t 0.06413602412090168\n",
            "23     \t [0.77016663 0.00309635]. \t  -1.7056842254910023 \t 0.06413602412090168\n",
            "24     \t [-0.73442996 -0.24057128]. \t  -1.5574701256260572 \t 0.06413602412090168\n",
            "25     \t [ 0.02944159 -0.59610097]. \t  \u001b[92m0.9303742414384724\u001b[0m \t 0.9303742414384724\n",
            "26     \t [ 0.81683183 -0.00694035]. \t  -1.8271370244500993 \t 0.9303742414384724\n",
            "27     \t [-0.70375022  0.05704517]. \t  -1.453329359712619 \t 0.9303742414384724\n",
            "28     \t [1.39563295 0.12028049]. \t  -2.3980651777873683 \t 0.9303742414384724\n",
            "29     \t [ 0.77942829 -0.04960443]. \t  -1.6812498643701856 \t 0.9303742414384724\n",
            "30     \t [0.07449648 0.78955457]. \t  0.8581399887819565 \t 0.9303742414384724\n",
            "31     \t [-1.32299169 -2.        ]. \t  -53.00110340836274 \t 0.9303742414384724\n",
            "32     \t [-0.64969518  0.14853775]. \t  -1.1565129046922908 \t 0.9303742414384724\n",
            "33     \t [-0.65118995  0.1297192 ]. \t  -1.193347202897138 \t 0.9303742414384724\n",
            "34     \t [0.73943458 0.00508059]. \t  -1.6173968671401457 \t 0.9303742414384724\n",
            "35     \t [-0.70544479  0.14778417]. \t  -1.321904155175962 \t 0.9303742414384724\n",
            "36     \t [0.77383899 0.0046375 ]. \t  -1.717341861877607 \t 0.9303742414384724\n",
            "37     \t [-0.71869691  0.14178123]. \t  -1.371071478852588 \t 0.9303742414384724\n",
            "38     \t [0.79503958 0.00350028]. \t  -1.7762422228628103 \t 0.9303742414384724\n",
            "39     \t [-0.72139952  0.13201717]. \t  -1.3961634042786564 \t 0.9303742414384724\n",
            "40     \t [0.80918333 0.00234198]. \t  -1.8142179644160847 \t 0.9303742414384724\n",
            "41     \t [-0.31198676 -0.17001097]. \t  -0.31052237851827685 \t 0.9303742414384724\n",
            "42     \t [-0.80089713  0.22329768]. \t  -1.4213498262403856 \t 0.9303742414384724\n",
            "43     \t [0.82529437 0.00498516]. \t  -1.8595681185494846 \t 0.9303742414384724\n",
            "44     \t [-0.76205019  0.16090715]. \t  -1.4564634091899848 \t 0.9303742414384724\n",
            "45     \t [8.25506676e-01 6.09197717e-05]. \t  -1.8561652970041864 \t 0.9303742414384724\n",
            "46     \t [-0.33530051 -0.1830689 ]. \t  -0.35545506288142426 \t 0.9303742414384724\n",
            "47     \t [-0.78806426  0.19485994]. \t  -1.4543853458429683 \t 0.9303742414384724\n",
            "48     \t [ 8.29668048e-01 -8.02701647e-04]. \t  -1.866415269540358 \t 0.9303742414384724\n",
            "49     \t [-0.74010545  0.12242304]. \t  -1.4660724225304667 \t 0.9303742414384724\n",
            "50     \t [-0.24221034 -0.2052315 ]. \t  -0.11582884718269257 \t 0.9303742414384724\n",
            "51     \t [ 0.82764411 -0.00471826]. \t  -1.857764809242577 \t 0.9303742414384724\n",
            "52     \t [-0.75639607  0.14688751]. \t  -1.4680097230193492 \t 0.9303742414384724\n",
            "53     \t [-0.39651495 -0.16655549]. \t  -0.5364381401175943 \t 0.9303742414384724\n",
            "54     \t [ 0.82851996 -0.00593064]. \t  -1.859011182792043 \t 0.9303742414384724\n",
            "55     \t [-0.77139052  0.1712672 ]. \t  -1.460840703508932 \t 0.9303742414384724\n",
            "56     \t [-0.71732406  0.09433397]. \t  -1.4446726279738047 \t 0.9303742414384724\n",
            "57     \t [ 0.82591433 -0.00972938]. \t  -1.8487787947773553 \t 0.9303742414384724\n",
            "58     \t [-0.3972617  -0.16882345]. \t  -0.536585667696558 \t 0.9303742414384724\n",
            "59     \t [-0.76392908  0.16595556]. \t  -1.4514865478048178 \t 0.9303742414384724\n",
            "60     \t [ 0.82507296 -0.01065123]. \t  -1.8457254984158704 \t 0.9303742414384724\n",
            "61     \t [-0.51275025 -0.10990433]. \t  -0.9211716915634115 \t 0.9303742414384724\n",
            "62     \t [-0.76915299  0.17624869]. \t  -1.4444742919005364 \t 0.9303742414384724\n",
            "63     \t [ 0.82632239 -0.01037162]. \t  -1.8492708093830217 \t 0.9303742414384724\n",
            "64     \t [-0.72702495  0.11197215]. \t  -1.4458554194221476 \t 0.9303742414384724\n",
            "65     \t [-0.28257929 -0.19950025]. \t  -0.2096934393728143 \t 0.9303742414384724\n",
            "66     \t [ 0.81821328 -0.01571783]. \t  -1.8228538036027968 \t 0.9303742414384724\n",
            "67     \t [-0.69557968  0.06972511]. \t  -1.4136326178752214 \t 0.9303742414384724\n",
            "68     \t [-0.46468648 -0.13402633]. \t  -0.7608916149334397 \t 0.9303742414384724\n",
            "69     \t [-0.74449036  0.14526713]. \t  -1.4379010726350467 \t 0.9303742414384724\n",
            "70     \t [ 0.81953758 -0.01547862]. \t  -1.82660130376861 \t 0.9303742414384724\n",
            "71     \t [-0.69714929  0.07743828]. \t  -1.4084607966010563 \t 0.9303742414384724\n",
            "72     \t [-0.34170205 -0.18202657]. \t  -0.37299806502384975 \t 0.9303742414384724\n",
            "73     \t [-0.70237836  0.08803211]. \t  -1.4096763032412944 \t 0.9303742414384724\n",
            "74     \t [ 0.81506688 -0.01864049]. \t  -1.8116724125287078 \t 0.9303742414384724\n",
            "75     \t [-0.50978013 -0.10445015]. \t  -0.9136123772274283 \t 0.9303742414384724\n",
            "76     \t [-0.7311516   0.13067578]. \t  -1.426437564123136 \t 0.9303742414384724\n",
            "77     \t [ 0.81663624 -0.01737607]. \t  -1.8170764870813474 \t 0.9303742414384724\n",
            "78     \t [-0.68507906  0.06664851]. \t  -1.3858703064231448 \t 0.9303742414384724\n",
            "79     \t [-0.37078673 -0.17143361]. \t  -0.4605665746861657 \t 0.9303742414384724\n",
            "80     \t [-0.69445932  0.08172631]. \t  -1.3947567230318034 \t 0.9303742414384724\n",
            "81     \t [ 0.81315016 -0.01971921]. \t  -1.8054986629462935 \t 0.9303742414384724\n",
            "82     \t [-0.52861538 -0.08834325]. \t  -0.9767597459054562 \t 0.9303742414384724\n",
            "83     \t [-0.71915717  0.11715818]. \t  -1.4147421805035942 \t 0.9303742414384724\n",
            "84     \t [ 0.81460719 -0.01857339]. \t  -1.8105078916283723 \t 0.9303742414384724\n",
            "85     \t [-0.67546922  0.05820973]. \t  -1.3667071837973286 \t 0.9303742414384724\n",
            "86     \t [-0.40088372 -0.15897366]. \t  -0.5551721841207687 \t 0.9303742414384724\n",
            "87     \t [-0.69031493  0.07944478]. \t  -1.3854025131870173 \t 0.9303742414384724\n",
            "88     \t [-0.41216283 -0.15167944]. \t  -0.5931511307199606 \t 0.9303742414384724\n",
            "89     \t [ 0.81082163 -0.02090008]. \t  -1.798097156303264 \t 0.9303742414384724\n",
            "90     \t [-0.68800255  0.07611366]. \t  -1.3828156408336452 \t 0.9303742414384724\n",
            "91     \t [-0.64319906  0.02318598]. \t  -1.3019409443053047 \t 0.9303742414384724\n",
            "92     \t [-0.47176899 -0.1198868 ]. \t  -0.7898079100854372 \t 0.9303742414384724\n",
            "93     \t [-0.70079013  0.09683779]. \t  -1.392398085085914 \t 0.9303742414384724\n",
            "94     \t [ 0.81100419 -0.02116003]. \t  -1.7983334680020464 \t 0.9303742414384724\n",
            "95     \t [-0.66617584  0.05181828]. \t  -1.3454694684877506 \t 0.9303742414384724\n",
            "96     \t [-0.43148374 -0.14163255]. \t  -0.6565557083746922 \t 0.9303742414384724\n",
            "97     \t [-0.67794853  0.06792439]. \t  -1.3627866427665187 \t 0.9303742414384724\n",
            "98     \t [ 0.80992073 -0.0217132 ]. \t  -1.7948760134300705 \t 0.9303742414384724\n",
            "99     \t [-0.64871782  0.0321405 ]. \t  -1.3112908145053568 \t 0.9303742414384724\n",
            "100    \t [-0.47909524 -0.11461497]. \t  -0.8145767672965771 \t 0.9303742414384724\n"
          ]
        }
      ],
      "source": [
        "### Bayesian optimisation runs (x20): 'STP' Acquisition Function run number = 12\n",
        "\n",
        "np.random.seed(run_num_12)\n",
        "surrogate_stp_12 = tStudentProcess(cov_func, nu = df, optimize=hyperOpt)\n",
        "\n",
        "stp_12 = GPGO(surrogate_stp_12, Acquisition_new(util_stp), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\n",
        "stp_12.run(max_iter = max_iter, init_evals = n_init) # run\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NSskozWHJLlE",
        "outputId": "1b29c1b0-9c85-4eea-b927-14abbdcb2303"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 1.66621446 -1.04983512]. \t  -0.752930921147986 \t -0.752930921147986\n",
            "init   \t [1.9456712  1.86299679]. \t  -41.05776363102951 \t -0.752930921147986\n",
            "init   \t [ 2.83560668 -0.18620301]. \t  -69.0134544723513 \t -0.752930921147986\n",
            "init   \t [0.65425478 1.10210606]. \t  -3.117452174069064 \t -0.752930921147986\n",
            "init   \t [0.84968007 0.88807292]. \t  -2.006601529383926 \t -0.752930921147986\n",
            "1      \t [ 0.11748268 -1.15392561]. \t  -1.685107104956753 \t -0.752930921147986\n",
            "2      \t [-1.14016576  1.01518233]. \t  -1.3519770527173272 \t -0.752930921147986\n",
            "3      \t [-3. -2.]. \t  -162.89999999999998 \t -0.752930921147986\n",
            "4      \t [-3.  2.]. \t  -150.89999999999998 \t -0.752930921147986\n",
            "5      \t [ 1.08987166 -2.        ]. \t  -48.167250662404584 \t -0.752930921147986\n",
            "6      \t [-0.24488367  0.02810628]. \t  \u001b[92m-0.22235187465038392\u001b[0m \t -0.22235187465038392\n",
            "7      \t [ 3. -2.]. \t  -150.89999999999998 \t -0.22235187465038392\n",
            "8      \t [ 1.04204528 -0.44457769]. \t  -1.1965158300709877 \t -0.22235187465038392\n",
            "9      \t [-0.26872198  2.        ]. \t  -47.740577113506355 \t -0.22235187465038392\n",
            "10     \t [-1.56249404 -0.16251479]. \t  -2.2503678114210324 \t -0.22235187465038392\n",
            "11     \t [-0.80265776 -2.        ]. \t  -51.399843529208574 \t -0.22235187465038392\n",
            "12     \t [ 0.479951   -0.09237158]. \t  -0.7358823265787156 \t -0.22235187465038392\n",
            "13     \t [-3.          0.06801199]. \t  -108.67754710878832 \t -0.22235187465038392\n",
            "14     \t [3. 2.]. \t  -162.89999999999998 \t -0.22235187465038392\n",
            "15     \t [1.08661801 2.        ]. \t  -52.51719523238082 \t -0.22235187465038392\n",
            "16     \t [-0.9587563  -0.83399545]. \t  -2.1139045263374108 \t -0.22235187465038392\n",
            "17     \t [-0.22827887  0.8509874 ]. \t  \u001b[92m0.790447121904849\u001b[0m \t 0.790447121904849\n",
            "18     \t [-1.42277882  2.        ]. \t  -47.411334928627646 \t 0.790447121904849\n",
            "19     \t [-0.84453312  0.12940745]. \t  -1.7304526415084769 \t 0.790447121904849\n",
            "20     \t [1.43650452 0.27904983]. \t  -2.3545656222000266 \t 0.790447121904849\n",
            "21     \t [-0.15618684 -0.01265672]. \t  -0.09766862977243733 \t 0.790447121904849\n",
            "22     \t [ 0.65108039 -0.08658963]. \t  -1.2575094359221441 \t 0.790447121904849\n",
            "23     \t [ 0.92526341 -0.88117243]. \t  -0.5848708853960114 \t 0.790447121904849\n",
            "24     \t [-0.60752467  0.05637096]. \t  -1.1601155914880852 \t 0.790447121904849\n",
            "25     \t [ 0.6690943  -0.05220817]. \t  -1.3539625491347376 \t 0.790447121904849\n",
            "26     \t [-0.89375511  0.1920096 ]. \t  -1.7114830867882138 \t 0.790447121904849\n",
            "27     \t [ 1.15908442 -0.34792039]. \t  -1.562995757721637 \t 0.790447121904849\n",
            "28     \t [-0.38119857 -0.00947772]. \t  -0.541182888702112 \t 0.790447121904849\n",
            "29     \t [0.59472924 0.3148921 ]. \t  -0.9968154300280949 \t 0.790447121904849\n",
            "30     \t [1.48648688 0.89628245]. \t  -2.881815236695898 \t 0.790447121904849\n",
            "31     \t [0.82130365 0.02874911]. \t  -1.8652652726525 \t 0.790447121904849\n",
            "32     \t [-0.23185131 -0.70263296]. \t  0.6279307865656418 \t 0.790447121904849\n",
            "33     \t [-0.61286584  0.00398224]. \t  -1.2213119909921435 \t 0.790447121904849\n",
            "34     \t [ 0.75683098 -0.0352699 ]. \t  -1.6331592926300253 \t 0.790447121904849\n",
            "35     \t [-0.60914249  0.01037379]. \t  -1.2053667422710215 \t 0.790447121904849\n",
            "36     \t [ 0.76559343 -0.03836228]. \t  -1.6549480418237823 \t 0.790447121904849\n",
            "37     \t [-0.60627548  0.01487073]. \t  -1.193207426049749 \t 0.790447121904849\n",
            "38     \t [ 0.77050214 -0.04174923]. \t  -1.6651715055958176 \t 0.790447121904849\n",
            "39     \t [-0.60423065  0.01796671]. \t  -1.1845358877342738 \t 0.790447121904849\n",
            "40     \t [ 0.77317821 -0.0449461 ]. \t  -1.6691375140106082 \t 0.790447121904849\n",
            "41     \t [-0.60287002  0.02006584]. \t  -1.1787009136582218 \t 0.790447121904849\n",
            "42     \t [-0.58652207  0.01850754]. \t  -1.1288606155497969 \t 0.790447121904849\n",
            "43     \t [ 0.79061434 -0.04123676]. \t  -1.7218004263913274 \t 0.790447121904849\n",
            "44     \t [-0.59213626  0.02098194]. \t  -1.1445153804526365 \t 0.790447121904849\n",
            "45     \t [ 0.77911574 -0.05606236]. \t  -1.6726339190303048 \t 0.790447121904849\n",
            "46     \t [-0.59612682  0.02293819]. \t  -1.155450166434193 \t 0.790447121904849\n",
            "47     \t [ 0.56431494 -0.2907208 ]. \t  -0.5980477464060101 \t 0.790447121904849\n",
            "48     \t [0.83410872 0.05787686]. \t  -1.9136223282717566 \t 0.790447121904849\n",
            "49     \t [-0.60111854  0.02428607]. \t  -1.1699489487553685 \t 0.790447121904849\n",
            "50     \t [-0.58937986  0.02122352]. \t  -1.1357401380104009 \t 0.790447121904849\n",
            "51     \t [ 0.81226461 -0.01284639]. \t  -1.8096009479069455 \t 0.790447121904849\n",
            "52     \t [-0.59054907  0.01984854]. \t  -1.1404217719867644 \t 0.790447121904849\n",
            "53     \t [ 0.56786929 -0.31545156]. \t  -0.5451349895718096 \t 0.790447121904849\n",
            "54     \t [0.82232076 0.03452767]. \t  -1.8712941728500823 \t 0.790447121904849\n",
            "55     \t [-0.59249096  0.01920142]. \t  -1.1469621517364528 \t 0.790447121904849\n",
            "56     \t [-0.58476629  0.01811156]. \t  -1.123677088049639 \t 0.790447121904849\n",
            "57     \t [ 0.80123712 -0.05487164]. \t  -1.7346534299098204 \t 0.790447121904849\n",
            "58     \t [-0.58725547  0.01905286]. \t  -1.130745118428506 \t 0.790447121904849\n",
            "59     \t [ 0.63328183 -0.29072424]. \t  -0.7943074420469214 \t 0.790447121904849\n",
            "60     \t [-0.58641542  0.02223458]. \t  -1.1257356431279177 \t 0.790447121904849\n",
            "61     \t [0.81551718 0.03738192]. \t  -1.85437039700384 \t 0.790447121904849\n",
            "62     \t [-0.58689172  0.0172778 ]. \t  -1.1309107273512282 \t 0.790447121904849\n",
            "63     \t [-0.58205806  0.01700882]. \t  -1.1160340388290655 \t 0.790447121904849\n",
            "64     \t [ 0.7997522  -0.05902726]. \t  -1.7254431203086957 \t 0.790447121904849\n",
            "65     \t [-0.58514258  0.01814851]. \t  -1.124823077945842 \t 0.790447121904849\n",
            "66     \t [ 0.69568419 -0.24943051]. \t  -1.0748998868686244 \t 0.790447121904849\n",
            "67     \t [-0.5871023   0.02244418]. \t  -1.1277141405066322 \t 0.790447121904849\n",
            "68     \t [0.80475516 0.03751279]. \t  -1.8248414671196758 \t 0.790447121904849\n",
            "69     \t [-0.58816952  0.01774911]. \t  -1.1345534483432653 \t 0.790447121904849\n",
            "70     \t [-0.5843624   0.01737467]. \t  -1.1229533160252074 \t 0.790447121904849\n",
            "71     \t [ 0.78898184 -0.08279429]. \t  -1.6640760193731823 \t 0.790447121904849\n",
            "72     \t [-0.58696502  0.01891015]. \t  -1.129945110063834 \t 0.790447121904849\n",
            "73     \t [ 0.7845049  -0.06731512]. \t  -1.6732152607918076 \t 0.790447121904849\n",
            "74     \t [-0.58911359  0.01938815]. \t  -1.1362895286314072 \t 0.790447121904849\n",
            "75     \t [-0.58582717  0.01860965]. \t  -1.1266193341971145 \t 0.790447121904849\n",
            "76     \t [ 0.68046194 -0.26415042]. \t  -0.9956023232912584 \t 0.790447121904849\n",
            "77     \t [-0.58635986  0.02091035]. \t  -1.1265674657461464 \t 0.790447121904849\n",
            "78     \t [0.79730176 0.03100579]. \t  -1.800653476838623 \t 0.790447121904849\n",
            "79     \t [-0.58800751  0.01746641]. \t  -1.1342541503871677 \t 0.790447121904849\n",
            "80     \t [-0.58553387  0.01730393]. \t  -1.1266570965819689 \t 0.790447121904849\n",
            "81     \t [ 0.77998096 -0.10175564]. \t  -1.610940993957159 \t 0.790447121904849\n",
            "82     \t [-0.58776415  0.01897223]. \t  -1.1323906202576592 \t 0.790447121904849\n",
            "83     \t [ 0.78648277 -0.04012696]. \t  -1.7116376709234278 \t 0.790447121904849\n",
            "84     \t [-0.58946755  0.01843177]. \t  -1.1381015556194494 \t 0.790447121904849\n",
            "85     \t [-0.58722786  0.01806661]. \t  -1.131384528851991 \t 0.790447121904849\n",
            "86     \t [ 0.69998881 -0.24675316]. \t  -1.0935281698678643 \t 0.790447121904849\n",
            "87     \t [-0.58789328  0.02010928]. \t  -1.1319471442339386 \t 0.790447121904849\n",
            "88     \t [0.79175583 0.0085983 ]. \t  -1.770889174228409 \t 0.790447121904849\n",
            "89     \t [-0.58927498  0.01790286]. \t  -1.137889406590917 \t 0.790447121904849\n",
            "90     \t [-0.58745461  0.01771193]. \t  -1.132350749988613 \t 0.790447121904849\n",
            "91     \t [ 0.76398401 -0.13942544]. \t  -1.5027892536245147 \t 0.790447121904849\n",
            "92     \t [-0.58917301  0.01958398]. \t  -1.1363289180615537 \t 0.790447121904849\n",
            "93     \t [-0.58751168  0.01911775]. \t  -1.1314958426287236 \t 0.790447121904849\n",
            "94     \t [ 0.78720777 -0.02531595]. \t  -1.7291705669756783 \t 0.790447121904849\n",
            "95     \t [-0.58904751  0.01817385]. \t  -1.1369811045657972 \t 0.790447121904849\n",
            "96     \t [-0.58761006  0.01799106]. \t  -1.1326317131432584 \t 0.790447121904849\n",
            "97     \t [-0.58638604  0.01786764]. \t  -1.128904827128808 \t 0.790447121904849\n",
            "98     \t [ 0.75953798 -0.14718366]. \t  -1.4761209942698947 \t 0.790447121904849\n",
            "99     \t [-0.58826571  0.01967974]. \t  -1.13342895014617 \t 0.790447121904849\n",
            "100    \t [-0.58705948  0.01930182]. \t  -1.1299498161202457 \t 0.790447121904849\n"
          ]
        }
      ],
      "source": [
        "### Bayesian optimisation runs (x20): 'STP' Acquisition Function run number = 13 \n",
        "\n",
        "np.random.seed(run_num_13)\n",
        "surrogate_stp_13 = tStudentProcess(cov_func, nu = df, optimize=hyperOpt)\n",
        "\n",
        "stp_13 = GPGO(surrogate_stp_13, Acquisition_new(util_stp), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\n",
        "stp_13.run(max_iter = max_iter, init_evals = n_init) # run\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aM5FQ3ibJLlE",
        "outputId": "f9378df9-5100-46df-8e63-c69cfbe0b72b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.08366006 1.09266021]. \t  -1.0453292732107575 \t 1.029299726828387\n",
            "init   \t [ 2.22256611 -1.96781221]. \t  -48.81113313056442 \t 1.029299726828387\n",
            "init   \t [-1.14158445  1.83041496]. \t  -31.794043287944216 \t 1.029299726828387\n",
            "init   \t [ 0.07870027 -0.7268623 ]. \t  1.029299726828387 \t 1.029299726828387\n",
            "init   \t [ 0.23519962 -1.11498023]. \t  -1.161934062902255 \t 1.029299726828387\n",
            "1      \t [1.89853564 1.50330511]. \t  -16.987634599938588 \t 1.029299726828387\n",
            "2      \t [-1.88208258 -1.63896295]. \t  -23.837190696460535 \t 1.029299726828387\n",
            "3      \t [-3.          0.43461685]. \t  -106.98330266760131 \t 1.029299726828387\n",
            "4      \t [3.         0.23658381]. \t  -109.39839524339403 \t 1.029299726828387\n",
            "5      \t [-0.19979114 -2.        ]. \t  -48.55592348904069 \t 1.029299726828387\n",
            "6      \t [0.32896993 0.1214515 ]. \t  -0.3905348371950145 \t 1.029299726828387\n",
            "7      \t [0.81863235 2.        ]. \t  -51.47508880425528 \t 1.029299726828387\n",
            "8      \t [3. 2.]. \t  -162.89999999999998 \t 1.029299726828387\n",
            "9      \t [-0.5266048   0.01491649]. \t  -0.9461194087019339 \t 1.029299726828387\n",
            "10     \t [-3. -2.]. \t  -162.89999999999998 \t 1.029299726828387\n",
            "11     \t [0.81900658 0.0048974 ]. \t  -1.842740317770158 \t 1.029299726828387\n",
            "12     \t [-0.72852416 -0.34426265]. \t  -1.4141921915869886 \t 1.029299726828387\n",
            "13     \t [1.32052585 0.91327411]. \t  -3.009392639275797 \t 1.029299726828387\n",
            "14     \t [-3.  2.]. \t  -150.89999999999998 \t 1.029299726828387\n",
            "15     \t [ 1.17803222 -1.06057752]. \t  -1.7098109664481562 \t 1.029299726828387\n",
            "16     \t [-1.73842638 -0.65242576]. \t  -2.26559500629751 \t 1.029299726828387\n",
            "17     \t [-1.25953082 -1.18726646]. \t  -6.196312709374964 \t 1.029299726828387\n",
            "18     \t [ 1.03171874 -2.        ]. \t  -48.21697163933103 \t 1.029299726828387\n",
            "19     \t [ 3.        -1.3576928]. \t  -111.045060664572 \t 1.029299726828387\n",
            "20     \t [0.54006981 0.00556466]. \t  -0.9991979059612347 \t 1.029299726828387\n",
            "21     \t [-0.69927574 -0.2705521 ]. \t  -1.4106220702544106 \t 1.029299726828387\n",
            "22     \t [-0.78138674  0.58985915]. \t  -0.36686136202815955 \t 1.029299726828387\n",
            "23     \t [0.39838846 0.02790834]. \t  -0.5912925465725217 \t 1.029299726828387\n",
            "24     \t [ 0.88644479 -0.54166516]. \t  -0.6987830723898883 \t 1.029299726828387\n",
            "25     \t [-0.9784147  -0.39509316]. \t  -2.0567752040169625 \t 1.029299726828387\n",
            "26     \t [-0.25146914  0.63673301]. \t  0.8797104108744997 \t 1.029299726828387\n",
            "27     \t [ 0.28053472 -0.00082211]. \t  -0.30172140906754663 \t 1.029299726828387\n",
            "28     \t [-1.51311357  0.33071535]. \t  -1.2605176325238385 \t 1.029299726828387\n",
            "29     \t [-1.21234111 -0.34762644]. \t  -2.397432446174624 \t 1.029299726828387\n",
            "30     \t [ 0.65635228 -0.58619649]. \t  -0.07316988938939883 \t 1.029299726828387\n",
            "31     \t [-0.52778552 -0.01205727]. \t  -0.9642692137773472 \t 1.029299726828387\n",
            "32     \t [0.67102785 0.14784037]. \t  -1.4194574069715606 \t 1.029299726828387\n",
            "33     \t [-0.62232153 -0.06608993]. \t  -1.277256278820874 \t 1.029299726828387\n",
            "34     \t [0.55735344 0.0321078 ]. \t  -1.0636918153173305 \t 1.029299726828387\n",
            "35     \t [-0.71731471 -0.13277373]. \t  -1.5735594477251542 \t 1.029299726828387\n",
            "36     \t [ 0.51620287 -0.01339949]. \t  -0.9154253764660543 \t 1.029299726828387\n",
            "37     \t [ 0.42951451 -0.0573754 ]. \t  -0.630784650074774 \t 1.029299726828387\n",
            "38     \t [-0.7878461  -0.18353062]. \t  -1.7678490761500278 \t 1.029299726828387\n",
            "39     \t [ 0.55463266 -0.0032574 ]. \t  -1.039603800262228 \t 1.029299726828387\n",
            "40     \t [-0.59420294  0.02640015]. \t  -1.1467142451013712 \t 1.029299726828387\n",
            "41     \t [ 0.51592913 -0.05080779]. \t  -0.8857138614712384 \t 1.029299726828387\n",
            "42     \t [-0.86706274 -0.29140248]. \t  -1.9037551501407617 \t 1.029299726828387\n",
            "43     \t [ 0.50152725 -0.05202277]. \t  -0.8416748582688833 \t 1.029299726828387\n",
            "44     \t [ 0.44798868 -0.07430836]. \t  -0.6656318056705505 \t 1.029299726828387\n",
            "45     \t [-0.52278321  0.13227539]. \t  -0.805242206046511 \t 1.029299726828387\n",
            "46     \t [ 0.57620097 -0.0007861 ]. \t  -1.1082928193032664 \t 1.029299726828387\n",
            "47     \t [-0.87083894 -0.28547672]. \t  -1.9202734229070098 \t 1.029299726828387\n",
            "48     \t [ 0.43669052 -0.09619767]. \t  -0.61005555390861 \t 1.029299726828387\n",
            "49     \t [-0.48330913  0.14692857]. \t  -0.6685167643777148 \t 1.029299726828387\n",
            "50     \t [ 0.53246154 -0.04526436]. \t  -0.9405774511141689 \t 1.029299726828387\n",
            "51     \t [-0.86095788 -0.26341576]. \t  -1.9154069813680472 \t 1.029299726828387\n",
            "52     \t [ 0.49635522 -0.0637896 ]. \t  -0.8151215047765957 \t 1.029299726828387\n",
            "53     \t [ 0.47427621 -0.07169012]. \t  -0.7428384339034454 \t 1.029299726828387\n",
            "54     \t [-0.52026511  0.1308814 ]. \t  -0.8000171935970659 \t 1.029299726828387\n",
            "55     \t [ 0.52845257 -0.03551814]. \t  -0.9367252723529927 \t 1.029299726828387\n",
            "56     \t [-0.85314699 -0.24785977]. \t  -1.908256319672215 \t 1.029299726828387\n",
            "57     \t [ 0.48783831 -0.06421408]. \t  -0.7897473439306127 \t 1.029299726828387\n",
            "58     \t [ 0.47829545 -0.06568077]. \t  -0.7605590147372102 \t 1.029299726828387\n",
            "59     \t [-0.5193915   0.12654546]. \t  -0.8040317964571216 \t 1.029299726828387\n",
            "60     \t [ 0.51634607 -0.03971944]. \t  -0.8966871728036162 \t 1.029299726828387\n",
            "61     \t [-0.84321886 -0.2313353 ]. \t  -1.894699859181014 \t 1.029299726828387\n",
            "62     \t [ 0.49724312 -0.05146467]. \t  -0.8295053000589292 \t 1.029299726828387\n",
            "63     \t [ 0.47621338 -0.06563284]. \t  -0.7545922368796745 \t 1.029299726828387\n",
            "64     \t [ 0.48049239 -0.05843099]. \t  -0.7739731587846866 \t 1.029299726828387\n",
            "65     \t [-0.56060151  0.09652948]. \t  -0.9689907572097438 \t 1.029299726828387\n",
            "66     \t [0.61568513 0.15089208]. \t  -1.2365764637302685 \t 1.029299726828387\n",
            "67     \t [-0.83310201 -0.21980647]. \t  -1.8752742166683867 \t 1.029299726828387\n",
            "68     \t [ 0.4233351 -0.1192549]. \t  -0.5447603151268094 \t 1.029299726828387\n",
            "69     \t [ 0.44574271 -0.10360401]. \t  -0.625805344982503 \t 1.029299726828387\n",
            "70     \t [ 0.46134231 -0.0896267 ]. \t  -0.6862095552013459 \t 1.029299726828387\n",
            "71     \t [ 0.4711496  -0.07842392]. \t  -0.7266950062965774 \t 1.029299726828387\n",
            "72     \t [-0.76477211 -0.12286761]. \t  -1.7223198363896222 \t 1.029299726828387\n",
            "73     \t [ 0.49911437 -0.05598869]. \t  -0.8308469163482353 \t 1.029299726828387\n",
            "74     \t [ 0.49089948 -0.05906409]. \t  -0.8037417054968912 \t 1.029299726828387\n",
            "75     \t [ 0.48625817 -0.05950743]. \t  -0.789738953157713 \t 1.029299726828387\n",
            "76     \t [-0.48698471  0.14442917]. \t  -0.6829206725322132 \t 1.029299726828387\n",
            "77     \t [ 0.48608319 -0.05872591]. \t  -0.7899751016031098 \t 1.029299726828387\n",
            "78     \t [-0.80819818 -0.18253071]. \t  -1.8283577647558682 \t 1.029299726828387\n",
            "79     \t [ 0.49710758 -0.04485632]. \t  -0.8349241500886863 \t 1.029299726828387\n",
            "80     \t [ 0.48921083 -0.05088111]. \t  -0.8063751639549127 \t 1.029299726828387\n",
            "81     \t [ 0.48491661 -0.0532254 ]. \t  -0.7916860490563414 \t 1.029299726828387\n",
            "82     \t [ 0.48232395 -0.05414647]. \t  -0.7832818243390228 \t 1.029299726828387\n",
            "83     \t [-0.53594141  0.10645239]. \t  -0.8817088268713976 \t 1.029299726828387\n",
            "84     \t [ 0.48827148 -0.05352439]. \t  -0.8012304402598044 \t 1.029299726828387\n",
            "85     \t [-0.80386161 -0.17743557]. \t  -1.8184930594717414 \t 1.029299726828387\n",
            "86     \t [ 0.49565271 -0.04330683]. \t  -0.8319313623834411 \t 1.029299726828387\n",
            "87     \t [ 0.48999117 -0.04806325]. \t  -0.8111570338098585 \t 1.029299726828387\n",
            "88     \t [ 0.48645713 -0.0504707 ]. \t  -0.7986669549177022 \t 1.029299726828387\n",
            "89     \t [ 0.48410532 -0.05174469]. \t  -0.7906515104887459 \t 1.029299726828387\n",
            "90     \t [ 0.48247497 -0.05241784]. \t  -0.7852886322497711 \t 1.029299726828387\n",
            "91     \t [-0.73911395 -0.09544355]. \t  -1.6472313708705177 \t 1.029299726828387\n",
            "92     \t [ 0.49440195 -0.04428029]. \t  -0.8274113520315499 \t 1.029299726828387\n",
            "93     \t [ 0.49034913 -0.04760276]. \t  -0.812610864486294 \t 1.029299726828387\n",
            "94     \t [ 0.48756567 -0.04953775]. \t  -0.8027413184519847 \t 1.029299726828387\n",
            "95     \t [ 0.4855777  -0.05070044]. \t  -0.7958883241205078 \t 1.029299726828387\n",
            "96     \t [ 0.48411728 -0.05140457]. \t  -0.7909907059148289 \t 1.029299726828387\n",
            "97     \t [-0.56265002  0.08075489]. \t  -0.9950623474438776 \t 1.029299726828387\n",
            "98     \t [ 0.4892021  -0.05138775]. \t  -0.8058955138033995 \t 1.029299726828387\n",
            "99     \t [ 0.48739198 -0.05211135]. \t  -0.7999366712079775 \t 1.029299726828387\n",
            "100    \t [-0.79573028 -0.16814554]. \t  -1.7993278732697133 \t 1.029299726828387\n"
          ]
        }
      ],
      "source": [
        "### Bayesian optimisation runs (x20): 'STP' Acquisition Function run number = 14 \n",
        "\n",
        "np.random.seed(run_num_14)\n",
        "surrogate_stp_14 = tStudentProcess(cov_func, nu = df, optimize=hyperOpt)\n",
        "\n",
        "stp_14 = GPGO(surrogate_stp_14, Acquisition_new(util_stp), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\n",
        "stp_14.run(max_iter = max_iter, init_evals = n_init) # run\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XmPTh2j_JLlF",
        "outputId": "da2a1ef9-bd66-4007-9ce6-126b7e840e91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 2.09290618 -1.2844163 ]. \t  -6.84252100896936 \t -2.1163170846379233\n",
            "init   \t [-2.67382071 -0.55384622]. \t  -43.69785230561242 \t -2.1163170846379233\n",
            "init   \t [-1.34759443  0.1200009 ]. \t  -2.1163170846379233 \t -2.1163170846379233\n",
            "init   \t [-1.16448651 -0.78210256]. \t  -2.3544087277459513 \t -2.1163170846379233\n",
            "init   \t [-2.32955234 -1.00040394]. \t  -15.469119251600274 \t -2.1163170846379233\n",
            "1      \t [0.05567328 0.77688668]. \t  \u001b[92m0.9014774425222407\u001b[0m \t 0.9014774425222407\n",
            "2      \t [-1.08600029  2.        ]. \t  -48.17137310903507 \t 0.9014774425222407\n",
            "3      \t [1.58656919 1.09777358]. \t  -4.809549206848835 \t 0.9014774425222407\n",
            "4      \t [ 0.14825354 -0.45955491]. \t  0.6475819081358222 \t 0.9014774425222407\n",
            "5      \t [-0.18675767 -2.        ]. \t  -48.51048851682823 \t 0.9014774425222407\n",
            "6      \t [3. 2.]. \t  -162.89999999999998 \t 0.9014774425222407\n",
            "7      \t [1.07136709 0.10966628]. \t  -2.39859849858498 \t 0.9014774425222407\n",
            "8      \t [ 3. -2.]. \t  -150.89999999999998 \t 0.9014774425222407\n",
            "9      \t [-3.  2.]. \t  -150.89999999999998 \t 0.9014774425222407\n",
            "10     \t [0.58954961 2.        ]. \t  -50.32968160796946 \t 0.9014774425222407\n",
            "11     \t [ 1.56915787 -0.24557659]. \t  -1.4812893960835152 \t 0.9014774425222407\n",
            "12     \t [-3. -2.]. \t  -162.89999999999998 \t 0.9014774425222407\n",
            "13     \t [-0.46539652  0.03332691]. \t  -0.7512975408608911 \t 0.9014774425222407\n",
            "14     \t [ 1.19034313 -1.49912564]. \t  -11.828662685477994 \t 0.9014774425222407\n",
            "15     \t [ 0.88969101 -0.05145722]. \t  -1.9594134093274804 \t 0.9014774425222407\n",
            "16     \t [ 3.         -0.14106005]. \t  -108.39881181855044 \t 0.9014774425222407\n",
            "17     \t [-1.4692307 -2.       ]. \t  -53.14048668278344 \t 0.9014774425222407\n",
            "18     \t [0.49470074 0.07731417]. \t  -0.872507839157439 \t 0.9014774425222407\n",
            "19     \t [-0.82492947 -0.03460226]. \t  -1.878348244744711 \t 0.9014774425222407\n",
            "20     \t [ 1.27279488 -0.82731792]. \t  -0.4690232690075947 \t 0.9014774425222407\n",
            "21     \t [-0.94233822  0.88528261]. \t  -0.6172325777842109 \t 0.9014774425222407\n",
            "22     \t [0.6045454  0.09806678]. \t  -1.2188590117533893 \t 0.9014774425222407\n",
            "23     \t [-1.71284362 -0.60745001]. \t  -2.1864925590366484 \t 0.9014774425222407\n",
            "24     \t [0.99738897 0.6581785 ]. \t  -1.9034406743208447 \t 0.9014774425222407\n",
            "25     \t [-0.34212518  0.40828882]. \t  0.25536787718344167 \t 0.9014774425222407\n",
            "26     \t [-1.04061381 -0.03362549]. \t  -2.3227428592670383 \t 0.9014774425222407\n",
            "27     \t [ 1.46316831 -0.89500578]. \t  -0.2622145501791059 \t 0.9014774425222407\n",
            "28     \t [ 1.23592488 -0.75725754]. \t  -0.48383704072233436 \t 0.9014774425222407\n",
            "29     \t [-1.95274169  0.44136222]. \t  -1.7104201538932322 \t 0.9014774425222407\n",
            "30     \t [-1.20353721  0.01119581]. \t  -2.3869622458189665 \t 0.9014774425222407\n",
            "31     \t [ 1.5540355 -2.       ]. \t  -46.99918944260815 \t 0.9014774425222407\n",
            "32     \t [-1.72197506 -0.21382851]. \t  -2.280834320788891 \t 0.9014774425222407\n",
            "33     \t [ 0.86707067 -0.26929594]. \t  -1.4593863317072562 \t 0.9014774425222407\n",
            "34     \t [ 0.87791727 -0.23573988]. \t  -1.5711911073021472 \t 0.9014774425222407\n",
            "35     \t [-1.04704899  0.03227347]. \t  -2.2625230178718376 \t 0.9014774425222407\n",
            "36     \t [ 0.88288598 -0.20440366]. \t  -1.6592550081996145 \t 0.9014774425222407\n",
            "37     \t [ 0.88287793 -0.18141807]. \t  -1.7123548879716572 \t 0.9014774425222407\n",
            "38     \t [-1.0651829   0.02828427]. \t  -2.288579579639126 \t 0.9014774425222407\n",
            "39     \t [ 0.87959011 -0.15759653]. \t  -1.7565691648547275 \t 0.9014774425222407\n",
            "40     \t [-1.07709863  0.02422059]. \t  -2.306172503067966 \t 0.9014774425222407\n",
            "41     \t [ 0.87668753 -0.14368093]. \t  -1.7783213588611024 \t 0.9014774425222407\n",
            "42     \t [-0.17658856  0.16400981]. \t  0.010962727671137734 \t 0.9014774425222407\n",
            "43     \t [-1.10004823  0.01840733]. \t  -2.3343470639561215 \t 0.9014774425222407\n",
            "44     \t [0.75308709 0.094637  ]. \t  -1.689672519942516 \t 0.9014774425222407\n",
            "45     \t [ 0.93332229 -0.33304285]. \t  -1.405916575084788 \t 0.9014774425222407\n",
            "46     \t [-1.08170462  0.02028113]. \t  -2.3156368035680575 \t 0.9014774425222407\n",
            "47     \t [ 0.91615249 -0.25240166]. \t  -1.6051941079148977 \t 0.9014774425222407\n",
            "48     \t [0.59990171 0.21619445]. \t  -1.134557054680978 \t 0.9014774425222407\n",
            "49     \t [-0.38934396  0.15147278]. \t  -0.410614497785436 \t 0.9014774425222407\n",
            "50     \t [-1.12283968  0.01088387]. \t  -2.360364184140846 \t 0.9014774425222407\n",
            "51     \t [ 0.9280922  -0.28432375]. \t  -1.5392862173994801 \t 0.9014774425222407\n",
            "52     \t [0.72745661 0.13123791]. \t  -1.6058395020192728 \t 0.9014774425222407\n",
            "53     \t [ 0.94117702 -0.31914993]. \t  -1.4608420037392378 \t 0.9014774425222407\n",
            "54     \t [-1.07969833  0.01894527]. \t  -2.3153398041384605 \t 0.9014774425222407\n",
            "55     \t [ 0.9216363  -0.24883299]. \t  -1.6251122605998642 \t 0.9014774425222407\n",
            "56     \t [-0.2054057   0.18545894]. \t  0.00588954407509476 \t 0.9014774425222407\n",
            "57     \t [0.64802386 0.17800048]. \t  -1.3267264152128484 \t 0.9014774425222407\n",
            "58     \t [-1.01529123  0.0337337 ]. \t  -2.2181553111882595 \t 0.9014774425222407\n",
            "59     \t [ 0.91814606 -0.25968023]. \t  -1.58934993380468 \t 0.9014774425222407\n",
            "60     \t [-0.29253169  0.17793629]. \t  -0.1524421130392027 \t 0.9014774425222407\n",
            "61     \t [0.67916428 0.14056128]. \t  -1.4489601339937463 \t 0.9014774425222407\n",
            "62     \t [-1.02319699  0.03167049]. \t  -2.2320773671523586 \t 0.9014774425222407\n",
            "63     \t [ 0.91719156 -0.26886498]. \t  -1.5624149397799225 \t 0.9014774425222407\n",
            "64     \t [-0.32105721  0.17789791]. \t  -0.21066367411880818 \t 0.9014774425222407\n",
            "65     \t [0.68043427 0.1223985 ]. \t  -1.4591448305349193 \t 0.9014774425222407\n",
            "66     \t [-1.00894326  0.03546744]. \t  -2.2065433413657205 \t 0.9014774425222407\n",
            "67     \t [ 0.91468475 -0.26849476]. \t  -1.5586884858414936 \t 0.9014774425222407\n",
            "68     \t [0.68873951 0.10790937]. \t  -1.488774008080705 \t 0.9014774425222407\n",
            "69     \t [-0.52215159  0.15666156]. \t  -0.7636605649414063 \t 0.9014774425222407\n",
            "70     \t [-1.05943725  0.02162759]. \t  -2.29060541953657 \t 0.9014774425222407\n",
            "71     \t [ 0.91732017 -0.27205372]. \t  -1.553842294739991 \t 0.9014774425222407\n",
            "72     \t [0.69652973 0.0929301 ]. \t  -1.514876173608034 \t 0.9014774425222407\n",
            "73     \t [ 0.92322875 -0.28025416]. \t  -1.5419286835041346 \t 0.9014774425222407\n",
            "74     \t [-0.34535439  0.18280897]. \t  -0.2554281442646295 \t 0.9014774425222407\n",
            "75     \t [-0.98923776  0.041131  ]. \t  -2.168255049703938 \t 0.9014774425222407\n",
            "76     \t [0.63958678 0.12100204]. \t  -1.3273732115163899 \t 0.9014774425222407\n",
            "77     \t [ 0.91409408 -0.26097273]. \t  -1.5781375255878982 \t 0.9014774425222407\n",
            "78     \t [-0.28860108  0.18945214]. \t  -0.12569498423372483 \t 0.9014774425222407\n",
            "79     \t [-0.53386669  0.15915681]. \t  -0.7934577519366066 \t 0.9014774425222407\n",
            "80     \t [-0.99114162  0.04014083]. \t  -2.172658644344373 \t 0.9014774425222407\n",
            "81     \t [0.60830879 0.12851533]. \t  -1.2226999509797845 \t 0.9014774425222407\n",
            "82     \t [ 0.89699175 -0.22894446]. \t  -1.628485867524093 \t 0.9014774425222407\n",
            "83     \t [-0.08876913  0.19918717]. \t  0.13869759530615322 \t 0.9014774425222407\n",
            "84     \t [-0.1904474   0.19525535]. \t  0.041536379893640396 \t 0.9014774425222407\n",
            "85     \t [0.48100132 0.16331337]. \t  -0.791881722401528 \t 0.9014774425222407\n",
            "86     \t [-0.51852321  0.16278686]. \t  -0.7425387642079776 \t 0.9014774425222407\n",
            "87     \t [0.63166064 0.10114662]. \t  -1.3062260804963934 \t 0.9014774425222407\n",
            "88     \t [-0.73051799  0.11500104]. \t  -1.4510168273410025 \t 0.9014774425222407\n",
            "89     \t [ 0.84704601 -0.15109836]. \t  -1.6947866033756165 \t 0.9014774425222407\n",
            "90     \t [-0.88100375  0.07128421]. \t  -1.9123941921646963 \t 0.9014774425222407\n",
            "91     \t [0.64009307 0.09505336]. \t  -1.3343054969811308 \t 0.9014774425222407\n",
            "92     \t [ 0.87633016 -0.2047116 ]. \t  -1.6443049653694657 \t 0.9014774425222407\n",
            "93     \t [-0.25942407  0.19598465]. \t  -0.061211494715563086 \t 0.9014774425222407\n",
            "94     \t [-0.32053695  0.190795  ]. \t  -0.18770186510357056 \t 0.9014774425222407\n",
            "95     \t [-0.44849384  0.17562398]. \t  -0.5239976551844692 \t 0.9014774425222407\n",
            "96     \t [-0.77463285  0.10296954]. \t  -1.5943782946360303 \t 0.9014774425222407\n",
            "97     \t [0.3216594  0.18289996]. \t  -0.3212460192764711 \t 0.9014774425222407\n",
            "98     \t [0.54435101 0.13300775]. \t  -1.0124461437921397 \t 0.9014774425222407\n",
            "99     \t [-0.18763227  0.19758645]. \t  0.0489034410770145 \t 0.9014774425222407\n",
            "100    \t [-0.22468488  0.19576069]. \t  -0.005225007374964452 \t 0.9014774425222407\n"
          ]
        }
      ],
      "source": [
        "### Bayesian optimisation runs (x20): 'STP' Acquisition Function run number = 15 \n",
        "\n",
        "np.random.seed(run_num_15)\n",
        "surrogate_stp_15 = tStudentProcess(cov_func, nu = df, optimize=hyperOpt)\n",
        "\n",
        "stp_15 = GPGO(surrogate_stp_15, Acquisition_new(util_stp), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\n",
        "stp_15.run(max_iter = max_iter, init_evals = n_init) # run\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6aUP_b73JLlG",
        "outputId": "8bb60960-7d8c-45ef-ae4b-68f050ddf274"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [-1.66025353  0.09265337]. \t  -1.8632773736203017 \t -1.8632773736203017\n",
            "init   \t [ 0.30420874 -1.8175922 ]. \t  -30.24114424375299 \t -1.8632773736203017\n",
            "init   \t [-0.83562699 -1.10767623]. \t  -3.922061281476444 \t -1.8632773736203017\n",
            "init   \t [ 1.13235697 -1.3450743 ]. \t  -6.7121671493737685 \t -1.8632773736203017\n",
            "init   \t [-2.5780508   1.76404344]. \t  -53.42443470756798 \t -1.8632773736203017\n",
            "1      \t [3.         0.30626313]. \t  -109.4787925601704 \t -1.8632773736203017\n",
            "2      \t [-3. -2.]. \t  -162.89999999999998 \t -1.8632773736203017\n",
            "3      \t [0.3339528 2.       ]. \t  -49.08834665210417 \t -1.8632773736203017\n",
            "4      \t [ 3. -2.]. \t  -150.89999999999998 \t -1.8632773736203017\n",
            "5      \t [-0.01428911 -0.00094648]. \t  \u001b[92m-0.0008265685841763482\u001b[0m \t -0.0008265685841763482\n",
            "6      \t [-0.8053902   0.19396115]. \t  -1.5009730929402496 \t -0.0008265685841763482\n",
            "7      \t [ 0.71522002 -0.13513306]. \t  -1.372904619146189 \t -0.0008265685841763482\n",
            "8      \t [3. 2.]. \t  -162.89999999999998 \t -0.0008265685841763482\n",
            "9      \t [-3.          0.22420362]. \t  -108.03642729733238 \t -0.0008265685841763482\n",
            "10     \t [-1.20071201  2.        ]. \t  -47.99938580460215 \t -0.0008265685841763482\n",
            "11     \t [-1.23770886 -0.45927002]. \t  -2.3004940838929 \t -0.0008265685841763482\n",
            "12     \t [ 0.26549162 -0.7768472 ]. \t  \u001b[92m0.8917777828905157\u001b[0m \t 0.8917777828905157\n",
            "13     \t [-1.17675026 -2.        ]. \t  -52.75078230982751 \t 0.8917777828905157\n",
            "14     \t [1.15658631 1.02509908]. \t  -3.790145817081989 \t 0.8917777828905157\n",
            "15     \t [0.39764409 0.83777271]. \t  -0.07742668830978805 \t 0.8917777828905157\n",
            "16     \t [ 1.78364563 -0.57154238]. \t  -0.304915799551972 \t 0.8917777828905157\n",
            "17     \t [-1.58179998  0.92025993]. \t  -0.10844347722028214 \t 0.8917777828905157\n",
            "18     \t [-0.45110933 -0.64548711]. \t  -0.04881396293305773 \t 0.8917777828905157\n",
            "19     \t [1.40135263 2.        ]. \t  -53.083709296427855 \t 0.8917777828905157\n",
            "20     \t [ 0.83919795 -0.10674332]. \t  -1.7572644783892346 \t 0.8917777828905157\n",
            "21     \t [-0.63863781  0.13970123]. \t  -1.1389563272623862 \t 0.8917777828905157\n",
            "22     \t [ 0.79251492 -0.1211011 ]. \t  -1.6127156408952452 \t 0.8917777828905157\n",
            "23     \t [-1.05296014  0.20623697]. \t  -1.9276809281343288 \t 0.8917777828905157\n",
            "24     \t [ 1.19997451 -0.42373537]. \t  -1.3030433381716673 \t 0.8917777828905157\n",
            "25     \t [-0.75742431 -0.03180903]. \t  -1.686598030336129 \t 0.8917777828905157\n",
            "26     \t [ 0.48355009 -0.00392688]. \t  -0.8227719652062555 \t 0.8917777828905157\n",
            "27     \t [-0.56505263  0.00582972]. \t  -1.0704780190002343 \t 0.8917777828905157\n",
            "28     \t [ 0.93561352 -0.03990529]. \t  -2.072205527930118 \t 0.8917777828905157\n",
            "29     \t [-0.56296177  0.88802415]. \t  0.09940767050738197 \t 0.8917777828905157\n",
            "30     \t [-0.95403269  0.24284672]. \t  -1.6986899244746452 \t 0.8917777828905157\n",
            "31     \t [ 1.08140588 -0.62364165]. \t  -0.7138627554671262 \t 0.8917777828905157\n",
            "32     \t [-0.78594429  0.06440427]. \t  -1.6809739861167086 \t 0.8917777828905157\n",
            "33     \t [0.24362793 0.05740169]. \t  -0.23093800562376435 \t 0.8917777828905157\n",
            "34     \t [-0.54292771  0.03707648]. \t  -0.9795302907888002 \t 0.8917777828905157\n",
            "35     \t [ 0.66878721 -0.0845367 ]. \t  -1.3138956755931195 \t 0.8917777828905157\n",
            "36     \t [-0.62586626  0.04679885]. \t  -1.226622355681947 \t 0.8917777828905157\n",
            "37     \t [ 0.7087056  -0.13426084]. \t  -1.3555697158110542 \t 0.8917777828905157\n",
            "38     \t [-0.66020824  0.05330484]. \t  -1.325604972929274 \t 0.8917777828905157\n",
            "39     \t [ 0.72594629 -0.15595008]. \t  -1.3654255859381437 \t 0.8917777828905157\n",
            "40     \t [-0.67926758  0.05753637]. \t  -1.3790031909511038 \t 0.8917777828905157\n",
            "41     \t [ 0.73318812 -0.16193418]. \t  -1.3743225063568243 \t 0.8917777828905157\n",
            "42     \t [-0.69116177  0.0602625 ]. \t  -1.4118078458662093 \t 0.8917777828905157\n",
            "43     \t [-0.69219166  0.05969963]. \t  -1.4155657275331524 \t 0.8917777828905157\n",
            "44     \t [ 0.74841942 -0.17665769]. \t  -1.3870867645754692 \t 0.8917777828905157\n",
            "45     \t [-0.69971649  0.06187003]. \t  -1.4355956901409244 \t 0.8917777828905157\n",
            "46     \t [ 0.73714833 -0.14951881]. \t  -1.4093234922379172 \t 0.8917777828905157\n",
            "47     \t [-0.7055964   0.06308596]. \t  -1.4517026701345517 \t 0.8917777828905157\n",
            "48     \t [ 0.7490371  -0.17937868]. \t  -1.3831227697808246 \t 0.8917777828905157\n",
            "49     \t [-0.70884731  0.06402452]. \t  -1.4602427115202885 \t 0.8917777828905157\n",
            "50     \t [0.61362574 0.03592418]. \t  -1.2430922336189285 \t 0.8917777828905157\n",
            "51     \t [-0.71561342  0.06257646]. \t  -1.4820709347018763 \t 0.8917777828905157\n",
            "52     \t [ 0.80111739 -0.31751407]. \t  -1.1733247532709683 \t 0.8917777828905157\n",
            "53     \t [-0.71355746  0.06322025]. \t  -1.4752011144463673 \t 0.8917777828905157\n",
            "54     \t [ 0.77002741 -0.21123975]. \t  -1.3697540775984813 \t 0.8917777828905157\n",
            "55     \t [-0.71361579  0.06395081]. \t  -1.474483985146134 \t 0.8917777828905157\n",
            "56     \t [0.61741619 0.03715007]. \t  -1.2555374355697775 \t 0.8917777828905157\n",
            "57     \t [-0.71819234  0.06270694]. \t  -1.4895366224652986 \t 0.8917777828905157\n",
            "58     \t [ 0.79925485 -0.29078915]. \t  -1.2431201467606452 \t 0.8917777828905157\n",
            "59     \t [-0.71609407  0.06329126]. \t  -1.4826241953972152 \t 0.8917777828905157\n",
            "60     \t [ 0.76868507 -0.19966521]. \t  -1.3925008741488396 \t 0.8917777828905157\n",
            "61     \t [-0.71572644  0.0638631 ]. \t  -1.4808389974329363 \t 0.8917777828905157\n",
            "62     \t [ 0.65893395 -0.01075961]. \t  -1.3606070723341372 \t 0.8917777828905157\n",
            "63     \t [ 0.79414788 -0.27515602]. \t  -1.2726035454472004 \t 0.8917777828905157\n",
            "64     \t [-0.71918539  0.06422618]. \t  -1.4906104363094634 \t 0.8917777828905157\n",
            "65     \t [ 0.75815859 -0.1799667 ]. \t  -1.4068832282762165 \t 0.8917777828905157\n",
            "66     \t [-0.71861752  0.06445032]. \t  -1.4886596797412883 \t 0.8917777828905157\n",
            "67     \t [0.62116955 0.02222938]. \t  -1.2617366950832527 \t 0.8917777828905157\n",
            "68     \t [-0.72096479  0.06354415]. \t  -1.4966922779743501 \t 0.8917777828905157\n",
            "69     \t [ 0.79451937 -0.26962981]. \t  -1.288178849851716 \t 0.8917777828905157\n",
            "70     \t [-0.71902789  0.06383007]. \t  -1.4906319198249591 \t 0.8917777828905157\n",
            "71     \t [ 0.77058619 -0.2057875 ]. \t  -1.383742571036515 \t 0.8917777828905157\n",
            "72     \t [-0.71812237  0.06414823]. \t  -1.4875694921698026 \t 0.8917777828905157\n",
            "73     \t [ 0.73765324 -0.13777121]. \t  -1.4323536017736822 \t 0.8917777828905157\n",
            "74     \t [-0.71846014  0.06427524]. \t  -1.4884104970597847 \t 0.8917777828905157\n",
            "75     \t [ 0.75697734 -0.17986116]. \t  -1.4038833031622926 \t 0.8917777828905157\n",
            "76     \t [-0.71810826  0.06449331]. \t  -1.4871039436196982 \t 0.8917777828905157\n",
            "77     \t [ 0.68924745 -0.06324652]. \t  -1.4025208850627806 \t 0.8917777828905157\n",
            "78     \t [-0.71963789  0.06424142]. \t  -1.4919260630568105 \t 0.8917777828905157\n",
            "79     \t [ 0.78127808 -0.23794594]. \t  -1.3354133728167359 \t 0.8917777828905157\n",
            "80     \t [-0.71849472  0.06445164]. \t  -1.4882957334255675 \t 0.8917777828905157\n",
            "81     \t [ 0.75437323 -0.17642836]. \t  -1.4039361415959732 \t 0.8917777828905157\n",
            "82     \t [-0.71824978  0.06462692]. \t  -1.4873572377126258 \t 0.8917777828905157\n",
            "83     \t [ 0.735115   -0.14010106]. \t  -1.4209626605702406 \t 0.8917777828905157\n",
            "84     \t [-0.71857729  0.06469882]. \t  -1.4882351212800715 \t 0.8917777828905157\n",
            "85     \t [ 0.75460291 -0.17940609]. \t  -1.3983486591415537 \t 0.8917777828905157\n",
            "86     \t [-0.71832547  0.06483912]. \t  -1.4873192051272182 \t 0.8917777828905157\n",
            "87     \t [ 0.72831754 -0.13014929]. \t  -1.4192550860532722 \t 0.8917777828905157\n",
            "88     \t [-0.71879066  0.06485667]. \t  -1.4886699889780899 \t 0.8917777828905157\n",
            "89     \t [ 0.75918355 -0.1904303 ]. \t  -1.3872929607767723 \t 0.8917777828905157\n",
            "90     \t [-0.7184145   0.06498066]. \t  -1.4874073524585054 \t 0.8917777828905157\n",
            "91     \t [ 0.66150227 -0.03270965]. \t  -1.350248343428767 \t 0.8917777828905157\n",
            "92     \t [-0.71985428  0.06462547]. \t  -1.49209119768795 \t 0.8917777828905157\n",
            "93     \t [ 0.77918228 -0.23354578]. \t  -1.3407848104167965 \t 0.8917777828905157\n",
            "94     \t [-0.71898243  0.06475457]. \t  -1.4893615077616644 \t 0.8917777828905157\n",
            "95     \t [ 0.76159825 -0.19401222]. \t  -1.3860029004746977 \t 0.8917777828905157\n",
            "96     \t [-0.71857165  0.06488236]. \t  -1.4879922376568349 \t 0.8917777828905157\n",
            "97     \t [ 0.74632269 -0.16362236]. \t  -1.4077380129998909 \t 0.8917777828905157\n",
            "98     \t [-0.71855049  0.06496599]. \t  -1.4878266646775549 \t 0.8917777828905157\n",
            "99     \t [ 0.74333906 -0.1585514 ]. \t  -1.4094011582597574 \t 0.8917777828905157\n",
            "100    \t [-0.71859653  0.06503221]. \t  -1.4878807470842406 \t 0.8917777828905157\n"
          ]
        }
      ],
      "source": [
        "### Bayesian optimisation runs (x20): 'STP' Acquisition Function run number = 16 \n",
        "\n",
        "np.random.seed(run_num_16)\n",
        "surrogate_stp_16 = tStudentProcess(cov_func, nu = df, optimize=hyperOpt)\n",
        "\n",
        "stp_16 = GPGO(surrogate_stp_16, Acquisition_new(util_stp), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\n",
        "stp_16.run(max_iter = max_iter, init_evals = n_init) # run\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TV8_B_7cJLlH",
        "outputId": "885a1158-a17d-41bd-db32-f2cdae2b8895"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [-1.23200998  0.12234702]. \t  -2.189206652278967 \t -1.7722768782964888\n",
            "init   \t [-1.85087528 -1.72839857]. \t  -29.406067820453675 \t -1.7722768782964888\n",
            "init   \t [1.72191276 0.62533409]. \t  -2.2113401446731897 \t -1.7722768782964888\n",
            "init   \t [0.82512538 0.30241158]. \t  -1.7722768782964888 \t -1.7722768782964888\n",
            "init   \t [-2.7656225  -0.56874558]. \t  -57.5922315952177 \t -1.7722768782964888\n",
            "1      \t [-0.77676135  1.95670391]. \t  -43.52298341603711 \t -1.7722768782964888\n",
            "2      \t [ 3. -2.]. \t  -150.89999999999998 \t -1.7722768782964888\n",
            "3      \t [3. 2.]. \t  -162.89999999999998 \t -1.7722768782964888\n",
            "4      \t [-3.  2.]. \t  -150.89999999999998 \t -1.7722768782964888\n",
            "5      \t [ 0.16952685 -1.39548835]. \t  -7.256383000688942 \t -1.7722768782964888\n",
            "6      \t [-0.12799561 -0.13157352]. \t  \u001b[92m-0.01376256489419321\u001b[0m \t -0.01376256489419321\n",
            "7      \t [ 1.16909197 -0.47098095]. \t  -1.1541334440580695 \t -0.01376256489419321\n",
            "8      \t [-0.28851477 -2.        ]. \t  -48.895633927747696 \t -0.01376256489419321\n",
            "9      \t [0.60941261 1.21967085]. \t  -4.857638985732331 \t -0.01376256489419321\n",
            "10     \t [0.1373416  0.13155912]. \t  -0.024741478005386966 \t -0.01376256489419321\n",
            "11     \t [-3. -2.]. \t  -162.89999999999998 \t -0.01376256489419321\n",
            "12     \t [ 3.        -0.0121378]. \t  -108.8629973696339 \t -0.01376256489419321\n",
            "13     \t [ 1.13566684 -2.        ]. \t  -48.10955506887359 \t -0.01376256489419321\n",
            "14     \t [-1.37413554 -0.88952228]. \t  -2.871283418855258 \t -0.01376256489419321\n",
            "15     \t [1.20719952 2.        ]. \t  -52.81541420968049 \t -0.01376256489419321\n",
            "16     \t [-0.5155403  0.8249029]. \t  \u001b[92m0.3739589717760775\u001b[0m \t 0.3739589717760775\n",
            "17     \t [ 0.56613358 -0.82790145]. \t  0.25389793506038894 \t 0.3739589717760775\n",
            "18     \t [-0.71833299 -0.46956852]. \t  -1.2004628766859122 \t 0.3739589717760775\n",
            "19     \t [1.00177845 0.28189222]. \t  -2.2259657257142638 \t 0.3739589717760775\n",
            "20     \t [0.36721649 0.01728588]. \t  -0.5071756243748367 \t 0.3739589717760775\n",
            "21     \t [-0.52891503 -0.11386021]. \t  -0.970992893880915 \t 0.3739589717760775\n",
            "22     \t [0.56329903 0.04624168]. \t  -1.0859510758113333 \t 0.3739589717760775\n",
            "23     \t [-1.94420098  0.84705384]. \t  -0.6599272957245939 \t 0.3739589717760775\n",
            "24     \t [-3.          0.50362705]. \t  -106.63189145785357 \t 0.3739589717760775\n",
            "25     \t [-1.19659353  0.58093606]. \t  -0.8110127872749211 \t 0.3739589717760775\n",
            "26     \t [-0.90657758  0.1073248 ]. \t  -1.9112157765068614 \t 0.3739589717760775\n",
            "27     \t [-0.92948325  0.17642668]. \t  -1.8186654737320616 \t 0.3739589717760775\n",
            "28     \t [0.87131727 0.0683451 ]. \t  -2.013200707496039 \t 0.3739589717760775\n",
            "29     \t [0.53412751 0.009524  ]. \t  -0.9827107213941986 \t 0.3739589717760775\n",
            "30     \t [ 1.90854783 -0.94582001]. \t  -0.6346594545769386 \t 0.3739589717760775\n",
            "31     \t [ 1.29309742 -0.50390588]. \t  -0.965942681275828 \t 0.3739589717760775\n",
            "32     \t [ 0.97587964 -0.25423831]. \t  -1.7027289610146439 \t 0.3739589717760775\n",
            "33     \t [-0.88068606  0.07675776]. \t  -1.90363888149468 \t 0.3739589717760775\n",
            "34     \t [ 0.95280834 -0.22561981]. \t  -1.741780724487344 \t 0.3739589717760775\n",
            "35     \t [-0.85390945  0.0990109 ]. \t  -1.8059765802393508 \t 0.3739589717760775\n",
            "36     \t [ 0.93269425 -0.20034182]. \t  -1.7689599913500509 \t 0.3739589717760775\n",
            "37     \t [ 0.91499254 -0.17916322]. \t  -1.7843049339626946 \t 0.3739589717760775\n",
            "38     \t [-0.83469839  0.10844911]. \t  -1.743222619307562 \t 0.3739589717760775\n",
            "39     \t [ 0.8997789  -0.16032741]. \t  -1.7944019622270386 \t 0.3739589717760775\n",
            "40     \t [-0.82889525  0.09687234]. \t  -1.747571051451614 \t 0.3739589717760775\n",
            "41     \t [ 0.88722249 -0.14513688]. \t  -1.798768686864853 \t 0.3739589717760775\n",
            "42     \t [-0.82250361  0.10036588]. \t  -1.725711894301863 \t 0.3739589717760775\n",
            "43     \t [ 0.87721176 -0.13366375]. \t  -1.7989699024759116 \t 0.3739589717760775\n",
            "44     \t [-0.83513059 -0.01544128]. \t  -1.8933029516608284 \t 0.3739589717760775\n",
            "45     \t [ 0.86932083 -0.12380162]. \t  -1.799417536822758 \t 0.3739589717760775\n",
            "46     \t [-0.73438338  0.29272529]. \t  -1.0703939337450896 \t 0.3739589717760775\n",
            "47     \t [ 0.86261249 -0.11919588]. \t  -1.792151582466472 \t 0.3739589717760775\n",
            "48     \t [-0.83402963 -0.14825733]. \t  -1.9161572646339848 \t 0.3739589717760775\n",
            "49     \t [ 0.85781102 -0.11220936]. \t  -1.793117930773913 \t 0.3739589717760775\n",
            "50     \t [-0.78308344  0.27395361]. \t  -1.2478623290887885 \t 0.3739589717760775\n",
            "51     \t [ 0.85505356 -0.11314821]. \t  -1.7849163157535173 \t 0.3739589717760775\n",
            "52     \t [-0.83712716  0.15428353]. \t  -1.6644422346956282 \t 0.3739589717760775\n",
            "53     \t [ 0.85291646 -0.11320124]. \t  -1.7797046800771976 \t 0.3739589717760775\n",
            "54     \t [0.03422565 0.2976914 ]. \t  0.30819516563537375 \t 0.3739589717760775\n",
            "55     \t [-0.77919215  0.16793843]. \t  -1.4885741215766737 \t 0.3739589717760775\n",
            "56     \t [ 0.77856311 -0.01913423]. \t  -1.710917356350657 \t 0.3739589717760775\n",
            "57     \t [-0.79872212  0.0761394 ]. \t  -1.6998294319766598 \t 0.3739589717760775\n",
            "58     \t [ 0.81873043 -0.08708949]. \t  -1.7366755326969598 \t 0.3739589717760775\n",
            "59     \t [-0.79657776  0.1438193 ]. \t  -1.582183172640344 \t 0.3739589717760775\n",
            "60     \t [ 0.82497874 -0.09661494]. \t  -1.7380232842938579 \t 0.3739589717760775\n",
            "61     \t [-0.80262398  0.06002953]. \t  -1.7318919347087864 \t 0.3739589717760775\n",
            "62     \t [ 0.82795411 -0.09860303]. \t  -1.7424247989808288 \t 0.3739589717760775\n",
            "63     \t [-0.7951651   0.17087138]. \t  -1.524607335713426 \t 0.3739589717760775\n",
            "64     \t [ 0.82958573 -0.10088483]. \t  -1.7428783426975114 \t 0.3739589717760775\n",
            "65     \t [-0.77427541 -0.12888905]. \t  -1.749534014616893 \t 0.3739589717760775\n",
            "66     \t [ 0.83046248 -0.09755117]. \t  -1.750453534692692 \t 0.3739589717760775\n",
            "67     \t [-0.7922666   0.23008799]. \t  -1.3829580008647495 \t 0.3739589717760775\n",
            "68     \t [ 0.83128696 -0.10021608]. \t  -1.7482516795524277 \t 0.3739589717760775\n",
            "69     \t [-0.80618733  0.17478774]. \t  -1.5448054511300213 \t 0.3739589717760775\n",
            "70     \t [ 0.83149571 -0.10103734]. \t  -1.7474467048065185 \t 0.3739589717760775\n",
            "71     \t [0.14388739 0.26928527]. \t  0.14836088327504418 \t 0.3739589717760775\n",
            "72     \t [-0.73494961  0.18246703]. \t  -1.3375864499999757 \t 0.3739589717760775\n",
            "73     \t [0.62700266 0.14348881]. \t  -1.2775285683649904 \t 0.3739589717760775\n",
            "74     \t [ 0.80017405 -0.07638925]. \t  -1.7033709465036193 \t 0.3739589717760775\n",
            "75     \t [-0.76352905  0.14003948]. \t  -1.5004105639339091 \t 0.3739589717760775\n",
            "76     \t [ 0.80567024 -0.08259541]. \t  -1.7091284121405501 \t 0.3739589717760775\n",
            "77     \t [-0.77153877  0.1241386 ]. \t  -1.5507976564527768 \t 0.3739589717760775\n",
            "78     \t [ 0.80881481 -0.08510855]. \t  -1.7137422959575117 \t 0.3739589717760775\n",
            "79     \t [-0.77638029  0.11912833]. \t  -1.572629088539991 \t 0.3739589717760775\n",
            "80     \t [ 0.810791   -0.08613899]. \t  -1.7174067024634465 \t 0.3739589717760775\n",
            "81     \t [-0.77952957  0.11795698]. \t  -1.5831860972318985 \t 0.3739589717760775\n",
            "82     \t [ 0.81211224 -0.08652798]. \t  -1.7202890453192508 \t 0.3739589717760775\n",
            "83     \t [-0.7816671   0.11774135]. \t  -1.5893472719247907 \t 0.3739589717760775\n",
            "84     \t [ 0.81303848 -0.08662986]. \t  -1.7225595219060634 \t 0.3739589717760775\n",
            "85     \t [-0.78315995  0.11774483]. \t  -1.5933789840283044 \t 0.3739589717760775\n",
            "86     \t [ 0.81371594 -0.08660876]. \t  -1.7243607871958153 \t 0.3739589717760775\n",
            "87     \t [-0.78422547  0.11779409]. \t  -1.5961720237053716 \t 0.3739589717760775\n",
            "88     \t [ 0.8142261  -0.08653683]. \t  -1.7257997788836432 \t 0.3739589717760775\n",
            "89     \t [-0.78499872  0.11784909]. \t  -1.5981634891768057 \t 0.3739589717760775\n",
            "90     \t [ 0.81462173 -0.0864515 ]. \t  -1.7269592018681221 \t 0.3739589717760775\n",
            "91     \t [-0.78556951  0.11790041]. \t  -1.59961374702389 \t 0.3739589717760775\n",
            "92     \t [ 0.81493437 -0.0863666 ]. \t  -1.7279010576576503 \t 0.3739589717760775\n",
            "93     \t [-0.78599716  0.11794678]. \t  -1.6006859879103006 \t 0.3739589717760775\n",
            "94     \t [ 0.8151871  -0.08629144]. \t  -1.7286718572312487 \t 0.3739589717760775\n",
            "95     \t [-0.78632112  0.11798823]. \t  -1.601486985156533 \t 0.3739589717760775\n",
            "96     \t [ 0.81539308 -0.08622455]. \t  -1.7293083232331992 \t 0.3739589717760775\n",
            "97     \t [-0.78657082  0.11802516]. \t  -1.6020956055140994 \t 0.3739589717760775\n",
            "98     \t [ 0.81556301 -0.08616676]. \t  -1.7298371417890976 \t 0.3739589717760775\n",
            "99     \t [-0.78676593  0.11805844]. \t  -1.602563423413465 \t 0.3739589717760775\n",
            "100    \t [ 0.815705   -0.08611828]. \t  -1.730279181739854 \t 0.3739589717760775\n"
          ]
        }
      ],
      "source": [
        "### Bayesian optimisation runs (x20): 'STP' Acquisition Function run number = 17 \n",
        "\n",
        "np.random.seed(run_num_17)\n",
        "surrogate_stp_17 = tStudentProcess(cov_func, nu = df, optimize=hyperOpt)\n",
        "\n",
        "stp_17 = GPGO(surrogate_stp_17, Acquisition_new(util_stp), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\n",
        "stp_17.run(max_iter = max_iter, init_evals = n_init) # run\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57ABzGR1JLlI",
        "outputId": "53d0695e-8146-45bc-bc38-a924045ebea6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.90224545 0.02181349]. \t  -2.062169771852028 \t -2.062169771852028\n",
            "init   \t [ 2.27160883 -1.2726391 ]. \t  -11.64729291207819 \t -2.062169771852028\n",
            "init   \t [2.11339841 1.00054514]. \t  -7.792128760671214 \t -2.062169771852028\n",
            "init   \t [0.99661    1.95158179]. \t  -46.96206222999227 \t -2.062169771852028\n",
            "init   \t [-1.45818946 -1.8867763 ]. \t  -41.4190528039297 \t -2.062169771852028\n",
            "1      \t [-3.  2.]. \t  -150.89999999999998 \t -2.062169771852028\n",
            "2      \t [ 0.79000945 -2.        ]. \t  -48.179484955485655 \t -2.062169771852028\n",
            "3      \t [3.         0.05148131]. \t  -109.04387073320572 \t -2.062169771852028\n",
            "4      \t [-0.6941088  0.2969202]. \t  \u001b[92m-0.9493245339400505\u001b[0m \t -0.9493245339400505\n",
            "5      \t [-3.        -0.7957435]. \t  -110.3582077061305 \t -0.9493245339400505\n",
            "6      \t [3. 2.]. \t  -162.89999999999998 \t -0.9493245339400505\n",
            "7      \t [ 3. -2.]. \t  -150.89999999999998 \t -0.9493245339400505\n",
            "8      \t [-0.65378509  2.        ]. \t  -48.044529151826964 \t -0.9493245339400505\n",
            "9      \t [-0.03431137 -0.3794106 ]. \t  \u001b[92m0.4751961768204562\u001b[0m \t 0.4751961768204562\n",
            "10     \t [0.80179774 0.27375842]. \t  -1.7343572040012694 \t 0.4751961768204562\n",
            "11     \t [ 1.10502194 -0.45030365]. \t  -1.2158120668921915 \t 0.4751961768204562\n",
            "12     \t [-0.23819143 -0.10715717]. \t  -0.20036255669415698 \t 0.4751961768204562\n",
            "13     \t [1.53966388 0.68937705]. \t  -2.185531702571205 \t 0.4751961768204562\n",
            "14     \t [-1.87357724  0.46514208]. \t  -1.0331008171473812 \t 0.4751961768204562\n",
            "15     \t [-1.34121014 -0.43018873]. \t  -2.314085715785525 \t 0.4751961768204562\n",
            "16     \t [ 1.6793283  -1.26013247]. \t  -3.673455663205934 \t 0.4751961768204562\n",
            "17     \t [-0.99750728  0.19777503]. \t  -1.8817006890408368 \t 0.4751961768204562\n",
            "18     \t [-0.41025111 -2.        ]. \t  -49.43582881356825 \t 0.4751961768204562\n",
            "19     \t [-3. -2.]. \t  -162.89999999999998 \t 0.4751961768204562\n",
            "20     \t [ 1.62177426 -0.46120795]. \t  -0.6404666933461182 \t 0.4751961768204562\n",
            "21     \t [-1.09079848  0.03580662]. \t  -2.3036636166352498 \t 0.4751961768204562\n",
            "22     \t [ 1.07962844 -0.12817809]. \t  -2.134136805062025 \t 0.4751961768204562\n",
            "23     \t [ 1.16412683 -0.38829592]. \t  -1.4294567936587552 \t 0.4751961768204562\n",
            "24     \t [0.93656568 0.20602829]. \t  -2.1482153084250575 \t 0.4751961768204562\n",
            "25     \t [-0.78856964  0.06894499]. \t  -1.6821860788680159 \t 0.4751961768204562\n",
            "26     \t [ 1.68729965 -0.90823842]. \t  0.05156674937836614 \t 0.4751961768204562\n",
            "27     \t [0.06174803 0.81450964]. \t  \u001b[92m0.8276526965860922\u001b[0m \t 0.8276526965860922\n",
            "28     \t [ 1.0310005  -0.01621777]. \t  -2.261653197606658 \t 0.8276526965860922\n",
            "29     \t [-0.67304789  0.16552338]. \t  -1.1940380903635783 \t 0.8276526965860922\n",
            "30     \t [0.09783472 0.28747737]. \t  0.23703363709929048 \t 0.8276526965860922\n",
            "31     \t [ 1.0782171  -0.15366664]. \t  -2.077831864200404 \t 0.8276526965860922\n",
            "32     \t [-0.79881736  0.15747182]. \t  -1.5614397939200069 \t 0.8276526965860922\n",
            "33     \t [0.98334528 0.10312966]. \t  -2.265017069631843 \t 0.8276526965860922\n",
            "34     \t [-0.74724566  0.12018056]. \t  -1.4900456943239215 \t 0.8276526965860922\n",
            "35     \t [ 1.12384449 -0.33760309]. \t  -1.5903641412199239 \t 0.8276526965860922\n",
            "36     \t [-0.72228092  0.10905895]. \t  -1.436769525580101 \t 0.8276526965860922\n",
            "37     \t [0.93366745 0.17190404]. \t  -2.1577109801050254 \t 0.8276526965860922\n",
            "38     \t [-0.78227425  0.12622175]. \t  -1.576327350160499 \t 0.8276526965860922\n",
            "39     \t [ 1.13723473 -0.33805704]. \t  -1.5924185605688586 \t 0.8276526965860922\n",
            "40     \t [0.0287229  0.08981264]. \t  0.026126711638177064 \t 0.8276526965860922\n",
            "41     \t [0.95725915 0.1205432 ]. \t  -2.2166292747776444 \t 0.8276526965860922\n",
            "42     \t [-0.75310189  0.11079125]. \t  -1.5220164396228493 \t 0.8276526965860922\n",
            "43     \t [ 1.13001571 -0.32595446]. \t  -1.6294330307386498 \t 0.8276526965860922\n",
            "44     \t [-0.70235627  0.09704412]. \t  -1.396724109300467 \t 0.8276526965860922\n",
            "45     \t [0.04811644 0.10036795]. \t  0.025810117685482387 \t 0.8276526965860922\n",
            "46     \t [0.94256569 0.11145007]. \t  -2.1859034977028213 \t 0.8276526965860922\n",
            "47     \t [-0.73296362  0.10769161]. \t  -1.4697362048261287 \t 0.8276526965860922\n",
            "48     \t [ 1.11723069 -0.30016999]. \t  -1.705934078278874 \t 0.8276526965860922\n",
            "49     \t [-0.69458724  0.09916636]. \t  -1.3706139984102788 \t 0.8276526965860922\n",
            "50     \t [0.92746774 0.11062129]. \t  -2.153328481431556 \t 0.8276526965860922\n",
            "51     \t [-0.71612106  0.10573515]. \t  -1.424048278160878 \t 0.8276526965860922\n",
            "52     \t [ 1.12079628 -0.29637828]. \t  -1.7190153475788388 \t 0.8276526965860922\n",
            "53     \t [-0.18684952  0.08850772]. \t  -0.08947884098780395 \t 0.8276526965860922\n",
            "54     \t [-0.73430374  0.1116304 ]. \t  -1.467317290978221 \t 0.8276526965860922\n",
            "55     \t [0.9068503  0.10265874]. \t  -2.1060477027951645 \t 0.8276526965860922\n",
            "56     \t [-0.70590415  0.10360617]. \t  -1.3973964128247238 \t 0.8276526965860922\n",
            "57     \t [ 1.11035757 -0.27349517]. \t  -1.7836996805565644 \t 0.8276526965860922\n",
            "58     \t [-0.67744632  0.09936804]. \t  -1.3192297521235299 \t 0.8276526965860922\n",
            "59     \t [-0.00864559  0.10775896]. \t  0.04654128529297223 \t 0.8276526965860922\n",
            "60     \t [-0.61772997  0.09147551]. \t  -1.1494009255000313 \t 0.8276526965860922\n",
            "61     \t [0.89127635 0.09530493]. \t  -2.0683644911925385 \t 0.8276526965860922\n",
            "62     \t [-0.67111597  0.10151092]. \t  -1.2971232429159425 \t 0.8276526965860922\n",
            "63     \t [ 1.08528142 -0.22742356]. \t  -1.8996845093808765 \t 0.8276526965860922\n",
            "64     \t [-0.66004002  0.10137783]. \t  -1.26400576638396 \t 0.8276526965860922\n",
            "65     \t [-0.65702449  0.10152763]. \t  -1.2546944087827125 \t 0.8276526965860922\n",
            "66     \t [0.90216321 0.08067407]. \t  -2.0911238620258787 \t 0.8276526965860922\n",
            "67     \t [-0.68088013  0.10572018]. \t  -1.3200754299957094 \t 0.8276526965860922\n",
            "68     \t [-0.07725488  0.10646336]. \t  0.02925018933715303 \t 0.8276526965860922\n",
            "69     \t [-0.58145512  0.09302247]. \t  -1.036800150369443 \t 0.8276526965860922\n",
            "70     \t [ 1.05280135 -0.17302583]. \t  -2.0092185102577056 \t 0.8276526965860922\n",
            "71     \t [-0.62534616  0.100099  ]. \t  -1.1607463825873 \t 0.8276526965860922\n",
            "72     \t [-0.63366998  0.10165306]. \t  -1.1838219076002408 \t 0.8276526965860922\n",
            "73     \t [0.87948124 0.07949521]. \t  -2.0366066734589157 \t 0.8276526965860922\n",
            "74     \t [-0.65972677  0.10521743]. \t  -1.2574232363900355 \t 0.8276526965860922\n",
            "75     \t [-0.64856308  0.10366934]. \t  -1.2260215221090252 \t 0.8276526965860922\n",
            "76     \t [ 1.08514889 -0.2301255 ]. \t  -1.8922284656757942 \t 0.8276526965860922\n",
            "77     \t [-0.63995784  0.10351973]. \t  -1.200198633110344 \t 0.8276526965860922\n",
            "78     \t [-0.00972094  0.11855203]. \t  0.05620268022848432 \t 0.8276526965860922\n",
            "79     \t [-0.15854218  0.10871962]. \t  -0.03526338944139568 \t 0.8276526965860922\n",
            "80     \t [-0.45588097  0.09453695]. \t  -0.6650712553479244 \t 0.8276526965860922\n",
            "81     \t [-0.5230793   0.09622961]. \t  -0.8570290348090276 \t 0.8276526965860922\n",
            "82     \t [0.81544493 0.09819723]. \t  -1.8711478614301849 \t 0.8276526965860922\n",
            "83     \t [-0.58522233  0.0998657 ]. \t  -1.039071223105134 \t 0.8276526965860922\n",
            "84     \t [-0.59181858  0.10075446]. \t  -1.057880645973021 \t 0.8276526965860922\n",
            "85     \t [-0.59650151  0.101426  ]. \t  -1.071177968115149 \t 0.8276526965860922\n",
            "86     \t [-0.59978447  0.10192861]. \t  -1.0804538141716917 \t 0.8276526965860922\n",
            "87     \t [0.92104294 0.01105364]. \t  -2.095210924101485 \t 0.8276526965860922\n",
            "88     \t [-0.61480866  0.10372771]. \t  -1.1235732638118634 \t 0.8276526965860922\n",
            "89     \t [-0.61274828  0.10359571]. \t  -1.117500933409797 \t 0.8276526965860922\n",
            "90     \t [-0.61123671  0.10352242]. \t  -1.1130120331001292 \t 0.8276526965860922\n",
            "91     \t [ 1.03437062 -0.1507177 ]. \t  -2.0393100413769054 \t 0.8276526965860922\n",
            "92     \t [-0.61082366  0.10438164]. \t  -1.110532943773672 \t 0.8276526965860922\n",
            "93     \t [-0.60984141  0.10430698]. \t  -1.10765545229287 \t 0.8276526965860922\n",
            "94     \t [-0.6091347   0.10426018]. \t  -1.1055751971789256 \t 0.8276526965860922\n",
            "95     \t [-0.60863325  0.10423316]. \t  -1.1040902733488458 \t 0.8276526965860922\n",
            "96     \t [0.90869112 0.02637892]. \t  -2.0799222558101 \t 0.8276526965860922\n",
            "97     \t [-0.62129306  0.10543312]. \t  -1.140816864592552 \t 0.8276526965860922\n",
            "98     \t [-0.61780075  0.10507875]. \t  -1.130725225982009 \t 0.8276526965860922\n",
            "99     \t [-0.61522001  0.10483207]. \t  -1.123242365047132 \t 0.8276526965860922\n",
            "100    \t [-0.61333569  0.10466197]. \t  -1.1177629265508897 \t 0.8276526965860922\n"
          ]
        }
      ],
      "source": [
        "### Bayesian optimisation runs (x20): 'STP' Acquisition Function run number = 18 \n",
        "\n",
        "np.random.seed(run_num_18)\n",
        "surrogate_stp_18 = tStudentProcess(cov_func, nu = df, optimize=hyperOpt)\n",
        "\n",
        "stp_18 = GPGO(surrogate_stp_18, Acquisition_new(util_stp), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\n",
        "stp_18.run(max_iter = max_iter, init_evals = n_init) # run\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x2CyIorrJLlJ",
        "outputId": "087cc24a-c5c5-4824-8550-4f72c9eae7b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [-2.41479839  1.04499887]. \t  -15.890475442873509 \t -6.578088852480828\n",
            "init   \t [-1.51837216 -1.44747325]. \t  -13.520839509777993 \t -6.578088852480828\n",
            "init   \t [-1.01132062 -1.66800174]. \t  -23.772158573571232 \t -6.578088852480828\n",
            "init   \t [1.03186249 1.22637519]. \t  -6.578088852480828 \t -6.578088852480828\n",
            "init   \t [2.89645149 0.54264294]. \t  -83.31828503667734 \t -6.578088852480828\n",
            "1      \t [ 1.61725746 -2.        ]. \t  -46.82578999540443 \t -6.578088852480828\n",
            "2      \t [-0.39225792  2.        ]. \t  -47.78244637178001 \t -6.578088852480828\n",
            "3      \t [-3. -2.]. \t  -162.89999999999998 \t -6.578088852480828\n",
            "4      \t [-0.13355883 -0.20505081]. \t  \u001b[92m0.0630400595018401\u001b[0m \t 0.0630400595018401\n",
            "5      \t [-3.  2.]. \t  -150.89999999999998 \t 0.0630400595018401\n",
            "6      \t [-1.38848961  0.07338664]. \t  -2.171537630726725 \t 0.0630400595018401\n",
            "7      \t [ 0.69845401 -0.16048588]. \t  -1.2778196664900316 \t 0.0630400595018401\n",
            "8      \t [ 3. -2.]. \t  -150.89999999999998 \t 0.0630400595018401\n",
            "9      \t [ 0.10886708 -2.        ]. \t  -47.82937956918763 \t 0.0630400595018401\n",
            "10     \t [1.79594533 2.        ]. \t  -53.831609295223586 \t 0.0630400595018401\n",
            "11     \t [-0.41443875  0.33391092]. \t  -0.09212844337325882 \t 0.0630400595018401\n",
            "12     \t [-1.61861167  0.00466456]. \t  -2.052045625442223 \t 0.0630400595018401\n",
            "13     \t [-3.          0.22139955]. \t  -108.04934127957556 \t 0.0630400595018401\n",
            "14     \t [-1.66339256  1.07190913]. \t  -0.9531814229686446 \t 0.0630400595018401\n",
            "15     \t [0.43573061 0.60216779]. \t  -0.023918053718083532 \t 0.0630400595018401\n",
            "16     \t [ 1.74480779 -0.62780424]. \t  -0.06897052795832181 \t 0.0630400595018401\n",
            "17     \t [ 1.07551145 -1.04084787]. \t  -1.5747892117680191 \t 0.0630400595018401\n",
            "18     \t [0.69161926 2.        ]. \t  -50.852575939391684 \t 0.0630400595018401\n",
            "19     \t [1.50099809 0.39176326]. \t  -2.2328103269908004 \t 0.0630400595018401\n",
            "20     \t [ 0.91505756 -0.11268549]. \t  -1.9193943787377912 \t 0.0630400595018401\n",
            "21     \t [-1.07026518  0.62656858]. \t  -0.7030112097270681 \t 0.0630400595018401\n",
            "22     \t [-0.8835566  -0.50009879]. \t  -1.6931071566959746 \t 0.0630400595018401\n",
            "23     \t [ 0.82354149 -0.10550166]. \t  -1.7199958783823792 \t 0.0630400595018401\n",
            "24     \t [3. 2.]. \t  -162.89999999999998 \t 0.0630400595018401\n",
            "25     \t [-0.89350289  0.25888913]. \t  -1.5431039444982038 \t 0.0630400595018401\n",
            "26     \t [-1.52695942  2.        ]. \t  -47.0812642649012 \t 0.0630400595018401\n",
            "27     \t [ 0.91758324 -0.06398722]. \t  -2.003086087252968 \t 0.0630400595018401\n",
            "28     \t [-1.23422301  0.48889183]. \t  -1.0675636713719583 \t 0.0630400595018401\n",
            "29     \t [ 0.17122212 -0.83383932]. \t  \u001b[92m0.8747505683211554\u001b[0m \t 0.8747505683211554\n",
            "30     \t [-0.78737962 -0.29061144]. \t  -1.6716753872462375 \t 0.8747505683211554\n",
            "31     \t [-1.70490824  0.73009172]. \t  0.17012783402751663 \t 0.8747505683211554\n",
            "32     \t [-0.91832888  0.19639001]. \t  -1.7510365567231303 \t 0.8747505683211554\n",
            "33     \t [ 0.84743006 -0.13086251]. \t  -1.7347644567408416 \t 0.8747505683211554\n",
            "34     \t [-0.94695765  0.20073209]. \t  -1.7938537586770893 \t 0.8747505683211554\n",
            "35     \t [ 0.84328052 -0.12762634]. \t  -1.7306822810831004 \t 0.8747505683211554\n",
            "36     \t [-0.96664731  0.20482485]. \t  -1.8172662320313782 \t 0.8747505683211554\n",
            "37     \t [ 0.83980372 -0.12522363]. \t  -1.726559923068641 \t 0.8747505683211554\n",
            "38     \t [-0.98031483  0.20805117]. \t  -1.830853348051687 \t 0.8747505683211554\n",
            "39     \t [ 0.83723962 -0.12359388]. \t  -1.723189656378171 \t 0.8747505683211554\n",
            "40     \t [-0.98984262  0.21028163]. \t  -1.8395138382712353 \t 0.8747505683211554\n",
            "41     \t [ 0.83558589 -0.12260925]. \t  -1.720865959438099 \t 0.8747505683211554\n",
            "42     \t [-0.99648549  0.21162232]. \t  -1.8456735496961498 \t 0.8747505683211554\n",
            "43     \t [ 0.83463957 -0.12208548]. \t  -1.7194551134768705 \t 0.8747505683211554\n",
            "44     \t [-1.00111103  0.2122719 ]. \t  -1.8504827415343832 \t 0.8747505683211554\n",
            "45     \t [ 0.22779158 -0.03619529]. \t  -0.18846989621517074 \t 0.8747505683211554\n",
            "46     \t [ 0.88221695 -0.14143158]. \t  -1.7950996823070742 \t 0.8747505683211554\n",
            "47     \t [-0.98871487  0.19805216]. \t  -1.8682597378344623 \t 0.8747505683211554\n",
            "48     \t [ 0.84660816 -0.12354783]. \t  -1.746176745136187 \t 0.8747505683211554\n",
            "49     \t [-0.99361998  0.2030516 ]. \t  -1.863102937702903 \t 0.8747505683211554\n",
            "50     \t [ 0.82609553 -0.11492313]. \t  -1.7106029029418481 \t 0.8747505683211554\n",
            "51     \t [-0.99697964  0.20570123]. \t  -1.861297607540938 \t 0.8747505683211554\n",
            "52     \t [ 0.81842932 -0.11316988]. \t  -1.6940856165607239 \t 0.8747505683211554\n",
            "53     \t [-0.56634227 -0.1513327 ]. \t  -1.0741304365674382 \t 0.8747505683211554\n",
            "54     \t [-1.03234488  0.25197188]. \t  -1.7833060757823251 \t 0.8747505683211554\n",
            "55     \t [ 0.80940737 -0.11118095]. \t  -1.6741290552586157 \t 0.8747505683211554\n",
            "56     \t [-1.02131635  0.23293925]. \t  -1.8226169642560515 \t 0.8747505683211554\n",
            "57     \t [ 0.80900303 -0.11291048]. \t  -1.6701650006723485 \t 0.8747505683211554\n",
            "58     \t [-1.01198519  0.21779734]. \t  -1.8508397757538229 \t 0.8747505683211554\n",
            "59     \t [ 0.80926101 -0.1143784 ]. \t  -1.6683487593299064 \t 0.8747505683211554\n",
            "60     \t [ 0.15948234 -0.05244906]. \t  -0.08104738280511121 \t 0.8747505683211554\n",
            "61     \t [ 0.76957691 -0.09744939]. \t  -1.5890275807490737 \t 0.8747505683211554\n",
            "62     \t [-0.96337151  0.16135039]. \t  -1.9131229860680334 \t 0.8747505683211554\n",
            "63     \t [ 0.78887392 -0.10939449]. \t  -1.6227346713363782 \t 0.8747505683211554\n",
            "64     \t [-0.98308718  0.18974594]. \t  -1.8798858072493552 \t 0.8747505683211554\n",
            "65     \t [ 0.79158445 -0.11191854]. \t  -1.625830949913082 \t 0.8747505683211554\n",
            "66     \t [-0.98476148  0.19190581]. \t  -1.8772543675790097 \t 0.8747505683211554\n",
            "67     \t [ 0.79206208 -0.11292045]. \t  -1.6254367131001213 \t 0.8747505683211554\n",
            "68     \t [-0.68880283 -0.12151451]. \t  -1.4861911863098491 \t 0.8747505683211554\n",
            "69     \t [-1.02376031  0.24756397]. \t  -1.7857221317098733 \t 0.8747505683211554\n",
            "70     \t [ 0.79503625 -0.11418359]. \t  -1.6312474062163353 \t 0.8747505683211554\n",
            "71     \t [ 0.79253649 -0.11292492]. \t  -1.6266969237280127 \t 0.8747505683211554\n",
            "72     \t [-1.01243927  0.22937504]. \t  -1.8210684040305072 \t 0.8747505683211554\n",
            "73     \t [ 0.78968291 -0.11229776]. \t  -1.6201046985326284 \t 0.8747505683211554\n",
            "74     \t [-1.00334855  0.21541259]. \t  -1.8455191295882722 \t 0.8747505683211554\n",
            "75     \t [ 0.7889604  -0.11262085]. \t  -1.6176271386591385 \t 0.8747505683211554\n",
            "76     \t [-0.99596864  0.20449027]. \t  -1.8628881917299758 \t 0.8747505683211554\n",
            "77     \t [ 0.78901375 -0.1131655 ]. \t  -1.6168612779215221 \t 0.8747505683211554\n",
            "78     \t [-0.99060463  0.19682249]. \t  -1.8740576345460545 \t 0.8747505683211554\n",
            "79     \t [ 0.78928056 -0.11367393]. \t  -1.6167266413389643 \t 0.8747505683211554\n",
            "80     \t [-0.98720506  0.19214101]. \t  -1.8803723359964828 \t 0.8747505683211554\n",
            "81     \t [ 0.78953544 -0.11407256]. \t  -1.6167418790536072 \t 0.8747505683211554\n",
            "82     \t [ 0.78941742 -0.11383543]. \t  -1.6168231521419227 \t 0.8747505683211554\n",
            "83     \t [-0.985536    0.18984828]. \t  -1.88336757014888 \t 0.8747505683211554\n",
            "84     \t [ 0.78969724 -0.11421549]. \t  -1.6169357248509364 \t 0.8747505683211554\n",
            "85     \t [-0.6843393 -0.1149983]. \t  -1.4734378934058656 \t 0.8747505683211554\n",
            "86     \t [-1.01055776  0.22459656]. \t  -1.8312584333201656 \t 0.8747505683211554\n",
            "87     \t [ 0.78919194 -0.1141106 ]. \t  -1.6157567007452556 \t 0.8747505683211554\n",
            "88     \t [-1.00302752  0.21356235]. \t  -1.8498205677084303 \t 0.8747505683211554\n",
            "89     \t [ 0.78795001 -0.1138364 ]. \t  -1.6128814172620503 \t 0.8747505683211554\n",
            "90     \t [ 0.78838517 -0.11388789]. \t  -1.6139644211582782 \t 0.8747505683211554\n",
            "91     \t [-0.996445    0.20410032]. \t  -1.8645386237555703 \t 0.8747505683211554\n",
            "92     \t [ 0.78781607 -0.11390925]. \t  -1.6123993315024152 \t 0.8747505683211554\n",
            "93     \t [-0.99158447  0.19738392]. \t  -1.8741217424848766 \t 0.8747505683211554\n",
            "94     \t [ 0.78772106 -0.11410095]. \t  -1.6118225909037875 \t 0.8747505683211554\n",
            "95     \t [-0.98794236  0.19249507]. \t  -1.8806214910745223 \t 0.8747505683211554\n",
            "96     \t [ 0.78781691 -0.11433295]. \t  -1.611691028132959 \t 0.8747505683211554\n",
            "97     \t [ 0.78813107 -0.11430639]. \t  -1.6125798815498205 \t 0.8747505683211554\n",
            "98     \t [-0.98539117  0.18910975]. \t  -1.8849151903378616 \t 0.8747505683211554\n",
            "99     \t [ 0.78817326 -0.11449405]. \t  -1.6123780523115425 \t 0.8747505683211554\n",
            "100    \t [-0.98369997  0.18702087]. \t  -1.8873183670422202 \t 0.8747505683211554\n"
          ]
        }
      ],
      "source": [
        "### Bayesian optimisation runs (x20): 'STP' Acquisition Function run number = 19 \n",
        "\n",
        "np.random.seed(run_num_19)\n",
        "surrogate_stp_19 = tStudentProcess(cov_func, nu = df, optimize=hyperOpt)\n",
        "\n",
        "stp_19 = GPGO(surrogate_stp_19, Acquisition_new(util_stp), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\n",
        "stp_19.run(max_iter = max_iter, init_evals = n_init) # run\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4O6_IplWJLlJ",
        "outputId": "d9f1e837-a4d6-4e72-c868-774cf8e87f61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.52878481 1.59085491]. \t  -17.29968374481291 \t -1.5037392797834441\n",
            "init   \t [2.34918438 1.26334991]. \t  -20.91583049569433 \t -1.5037392797834441\n",
            "init   \t [-2.78466249  0.76703033]. \t  -57.06253405225224 \t -1.5037392797834441\n",
            "init   \t [-0.72791435  0.07404378]. \t  -1.5037392797834441 \t -1.5037392797834441\n",
            "init   \t [ 0.94770879 -1.22459913]. \t  -3.9766737661914173 \t -1.5037392797834441\n",
            "1      \t [ 3. -2.]. \t  -150.89999999999998 \t -1.5037392797834441\n",
            "2      \t [-0.9827712 -2.       ]. \t  -52.17025017918145 \t -1.5037392797834441\n",
            "3      \t [-3. -2.]. \t  -162.89999999999998 \t -1.5037392797834441\n",
            "4      \t [-1.07753905  2.        ]. \t  -48.17997586334706 \t -1.5037392797834441\n",
            "5      \t [ 0.67479424 -0.040508  ]. \t  \u001b[92m-1.3835560332132117\u001b[0m \t -1.3835560332132117\n",
            "6      \t [3. 2.]. \t  -162.89999999999998 \t -1.3835560332132117\n",
            "7      \t [1.67537931 0.09628876]. \t  -2.1784963369694106 \t -1.3835560332132117\n",
            "8      \t [ 0.07514876 -0.54555344]. \t  \u001b[92m0.8546584269275503\u001b[0m \t 0.8546584269275503\n",
            "9      \t [ 0.56881185 -2.        ]. \t  -47.94802041961625 \t 0.8546584269275503\n",
            "10     \t [0.91509636 0.3572201 ]. \t  -1.9543386954758457 \t 0.8546584269275503\n",
            "11     \t [3.       0.221162]. \t  -109.37740525834035 \t 0.8546584269275503\n",
            "12     \t [1.57816152 1.28315648]. \t  -8.368510544738166 \t 0.8546584269275503\n",
            "13     \t [-3.  2.]. \t  -150.89999999999998 \t 0.8546584269275503\n",
            "14     \t [-1.8341046  -0.33628178]. \t  -2.5964384073957163 \t 0.8546584269275503\n",
            "15     \t [-3.         -0.25013356]. \t  -109.41579190521777 \t 0.8546584269275503\n",
            "16     \t [-1.63148344  0.47916795]. \t  -0.5654786954817681 \t 0.8546584269275503\n",
            "17     \t [-1.07498332 -0.6487463 ]. \t  -2.0548679348615835 \t 0.8546584269275503\n",
            "18     \t [-1.00340894  0.06986816]. \t  -2.1492084765973987 \t 0.8546584269275503\n",
            "19     \t [-0.26336826  1.03665354]. \t  -0.31533050973566756 \t 0.8546584269275503\n",
            "20     \t [ 1.18127165 -0.5194229 ]. \t  -0.996672393907724 \t 0.8546584269275503\n",
            "21     \t [1.37471006 0.73819376]. \t  -2.3319532362851607 \t 0.8546584269275503\n",
            "22     \t [-0.40130099  0.07854833]. \t  -0.5350506912761889 \t 0.8546584269275503\n",
            "23     \t [0.659444   0.14447119]. \t  -1.3832749703931333 \t 0.8546584269275503\n",
            "24     \t [-1.14858225  0.11300829]. \t  -2.207234578890782 \t 0.8546584269275503\n",
            "25     \t [ 1.77877581 -1.13073542]. \t  -1.6046221030901238 \t 0.8546584269275503\n",
            "26     \t [ 1.23835267 -0.65627298]. \t  -0.6041783978664936 \t 0.8546584269275503\n",
            "27     \t [ 0.91029947 -0.14759882]. \t  -1.8426712088681922 \t 0.8546584269275503\n",
            "28     \t [1.83670032 0.80308992]. \t  -2.9513628478670633 \t 0.8546584269275503\n",
            "29     \t [-1.80047478 -1.14672036]. \t  -5.975301786883221 \t 0.8546584269275503\n",
            "30     \t [1.38362709 2.        ]. \t  -53.067210047371304 \t 0.8546584269275503\n",
            "31     \t [0.10925814 0.60360413]. \t  0.8129838859292806 \t 0.8546584269275503\n",
            "32     \t [-1.07480376 -0.33362285]. \t  -2.2951619695342296 \t 0.8546584269275503\n",
            "33     \t [1.03040987 0.1702193 ]. \t  -2.3414690901488493 \t 0.8546584269275503\n",
            "34     \t [-0.8829293  -0.08335796]. \t  -2.045961129720295 \t 0.8546584269275503\n",
            "35     \t [1.02721385 0.1286811 ]. \t  -2.3412205292847195 \t 0.8546584269275503\n",
            "36     \t [-0.89483297 -0.07568405]. \t  -2.0725388362883725 \t 0.8546584269275503\n",
            "37     \t [1.02393093 0.08620347]. \t  -2.328301476347592 \t 0.8546584269275503\n",
            "38     \t [-0.9038128  -0.07152776]. \t  -2.0921887876998424 \t 0.8546584269275503\n",
            "39     \t [1.0201587 0.0494391]. \t  -2.304793325348824 \t 0.8546584269275503\n",
            "40     \t [-0.91065358 -0.06939386]. \t  -2.1070753926289325 \t 0.8546584269275503\n",
            "41     \t [0.9886734  0.23806632]. \t  -2.2362675204232043 \t 0.8546584269275503\n",
            "42     \t [ 1.02041787 -0.24525464]. \t  -1.7880973285434043 \t 0.8546584269275503\n",
            "43     \t [-0.91631499 -0.06791656]. \t  -2.1192432706187345 \t 0.8546584269275503\n",
            "44     \t [0.96299581 0.33735612]. \t  -2.090736256144263 \t 0.8546584269275503\n",
            "45     \t [-0.92002996 -0.06857476]. \t  -2.127726434876487 \t 0.8546584269275503\n",
            "46     \t [ 1.02175915 -0.24144373]. \t  -1.8001419574068132 \t 0.8546584269275503\n",
            "47     \t [-0.92228241 -0.06664918]. \t  -2.1319348002265643 \t 0.8546584269275503\n",
            "48     \t [0.97404496 0.31300496]. \t  -2.1407982866726063 \t 0.8546584269275503\n",
            "49     \t [ 1.02085905 -0.24075512]. \t  -1.8009359736963675 \t 0.8546584269275503\n",
            "50     \t [-0.92441849 -0.06658331]. \t  -2.1365719454380883 \t 0.8546584269275503\n",
            "51     \t [0.97875583 0.29950343]. \t  -2.1642526496976253 \t 0.8546584269275503\n",
            "52     \t [ 1.01984754 -0.2369363 ]. \t  -1.810070284170886 \t 0.8546584269275503\n",
            "53     \t [-0.92575081 -0.06632308]. \t  -2.139362256760608 \t 0.8546584269275503\n",
            "54     \t [-0.228889    0.28746775]. \t  0.16518836293263628 \t 0.8546584269275503\n",
            "55     \t [0.94728546 0.30611904]. \t  -2.089533853121439 \t 0.8546584269275503\n",
            "56     \t [-0.8824099  -0.01173368]. \t  -2.0085424423158056 \t 0.8546584269275503\n",
            "57     \t [ 0.99937562 -0.20405952]. \t  -1.868775314117431 \t 0.8546584269275503\n",
            "58     \t [-0.90168261 -0.0427121 ]. \t  -2.0743557774161774 \t 0.8546584269275503\n",
            "59     \t [0.96015697 0.28098745]. \t  -2.1428975154716112 \t 0.8546584269275503\n",
            "60     \t [-0.90527207 -0.04915336]. \t  -2.086012653466119 \t 0.8546584269275503\n",
            "61     \t [ 1.00193809 -0.19837939]. \t  -1.8864344238210564 \t 0.8546584269275503\n",
            "62     \t [0.96508139 0.26979412]. \t  -2.163562746949382 \t 0.8546584269275503\n",
            "63     \t [-0.90634686 -0.04991321]. \t  -2.088843928852483 \t 0.8546584269275503\n",
            "64     \t [ 1.00304408 -0.19744781]. \t  -1.8902585603544326 \t 0.8546584269275503\n",
            "65     \t [-0.25789259  0.28493907]. \t  0.11503402258764228 \t 0.8546584269275503\n",
            "66     \t [-0.83578923  0.03607135]. \t  -1.8477271520138308 \t 0.8546584269275503\n",
            "67     \t [0.93185992 0.27869272]. \t  -2.0813565049175113 \t 0.8546584269275503\n",
            "68     \t [-0.88035268 -0.02820141]. \t  -2.0155254509019946 \t 0.8546584269275503\n",
            "69     \t [ 0.98394454 -0.16233865]. \t  -1.944354487260908 \t 0.8546584269275503\n",
            "70     \t [-0.8847054 -0.0336305]. \t  -2.0293708523039893 \t 0.8546584269275503\n",
            "71     \t [0.94443382 0.25855249]. \t  -2.128299580471982 \t 0.8546584269275503\n",
            "72     \t [-0.88639663 -0.03627055]. \t  -2.0349893215728048 \t 0.8546584269275503\n",
            "73     \t [ 0.98817286 -0.16134823]. \t  -1.9530472397696899 \t 0.8546584269275503\n",
            "74     \t [-0.12826844  0.27917663]. \t  0.2580254040506986 \t 0.8546584269275503\n",
            "75     \t [-0.56833427  0.22525763]. \t  -0.7634653920342709 \t 0.8546584269275503\n",
            "76     \t [-0.82200578  0.0264741 ]. \t  -1.822262939231876 \t 0.8546584269275503\n",
            "77     \t [0.89445246 0.27393219]. \t  -1.9941117846219347 \t 0.8546584269275503\n",
            "78     \t [-0.84534433 -0.00331343]. \t  -1.9104336469332097 \t 0.8546584269275503\n",
            "79     \t [ 0.95594659 -0.08508156]. \t  -2.045940817143901 \t 0.8546584269275503\n",
            "80     \t [-0.85309394 -0.01181248]. \t  -1.936822346968464 \t 0.8546584269275503\n",
            "81     \t [0.91552191 0.25111571]. \t  -2.067232371582296 \t 0.8546584269275503\n",
            "82     \t [-0.85680887 -0.01629543]. \t  -1.9495050123094895 \t 0.8546584269275503\n",
            "83     \t [ 0.96743707 -0.12294004]. \t  -1.9989984413119894 \t 0.8546584269275503\n",
            "84     \t [0.92565803 0.24145525]. \t  -2.099184521777558 \t 0.8546584269275503\n",
            "85     \t [-0.85918344 -0.01767301]. \t  -1.9564488845518655 \t 0.8546584269275503\n",
            "86     \t [ 0.97308375 -0.13257581]. \t  -1.9896174484211393 \t 0.8546584269275503\n",
            "87     \t [-0.86038322 -0.01818508]. \t  -1.9598116407313884 \t 0.8546584269275503\n",
            "88     \t [-0.0561653  0.2827342]. \t  0.2974763567465529 \t 0.8546584269275503\n",
            "89     \t [-0.09278863  0.27954191]. \t  0.2798038287275688 \t 0.8546584269275503\n",
            "90     \t [-0.16352211  0.27662531]. \t  0.22243561645801715 \t 0.8546584269275503\n",
            "91     \t [-0.31637649  0.26742429]. \t  -0.029459328483648073 \t 0.8546584269275503\n",
            "92     \t [-0.40622527  0.25116746]. \t  -0.2659361166150988 \t 0.8546584269275503\n",
            "93     \t [-0.46585197  0.23265991]. \t  -0.45938869803905946 \t 0.8546584269275503\n",
            "94     \t [-0.51444515  0.21235097]. \t  -0.6362255790579809 \t 0.8546584269275503\n",
            "95     \t [0.15199966 0.26585099]. \t  0.13101818096602164 \t 0.8546584269275503\n",
            "96     \t [0.13548251 0.26434589]. \t  0.1514520324030303 \t 0.8546584269275503\n",
            "97     \t [-0.37403801  0.23343172]. \t  -0.2260296896405396 \t 0.8546584269275503\n",
            "98     \t [0.17627398 0.26520396]. \t  0.09252448877655295 \t 0.8546584269275503\n",
            "99     \t [-0.35427772  0.23232672]. \t  -0.18307019077411346 \t 0.8546584269275503\n",
            "100    \t [-0.38604688  0.22443019]. \t  -0.2726217836886983 \t 0.8546584269275503\n"
          ]
        }
      ],
      "source": [
        "### Bayesian optimisation runs (x20): 'STP' Acquisition Function run number = 20 \n",
        "\n",
        "np.random.seed(run_num_20)\n",
        "surrogate_stp_20 = tStudentProcess(cov_func, nu = df, optimize=hyperOpt)\n",
        "\n",
        "stp_20 = GPGO(surrogate_stp_20, Acquisition_new(util_stp), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\n",
        "stp_20.run(max_iter = max_iter, init_evals = n_init) # run\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9S2UvZ9JLlK",
        "outputId": "5c761a57-acf0-4c0f-f6c0-d17833565bb8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-0.2658009358573259, -2.460963545356269)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "### Simple regret minimisation: run number = 1\n",
        "\n",
        "gp_output_1 = np.append(np.max(gp_1.GP.y[0:n_init]),gp_1.GP.y[n_init:(n_init+max_iter)]) \n",
        "stp_output_1 = np.append(np.max(stp_1.GP.y[0:n_init]),stp_1.GP.y[n_init:(n_init+max_iter)]) \n",
        "\n",
        "regret_gp_1 = np.log(y_global_orig - gp_output_1)\n",
        "regret_stp_1 = np.log(y_global_orig - stp_output_1)\n",
        "\n",
        "simple_regret_gp_1 = min_max_array(regret_gp_1)\n",
        "simple_regret_stp_1 = min_max_array(regret_stp_1)\n",
        "\n",
        "min_simple_regret_gp_1 = min(simple_regret_gp_1)\n",
        "min_simple_regret_stp_1 = min(simple_regret_stp_1)\n",
        "\n",
        "min_simple_regret_gp_1, min_simple_regret_stp_1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adGcU8l5JLlK",
        "outputId": "a86658ce-0b67-49bb-abf6-e88ac6aeafe8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.04261840449610358, -1.0102027023780198)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "### Simple regret minimisation: run number = 2\n",
        "\n",
        "gp_output_2 = np.append(np.max(gp_2.GP.y[0:n_init]),gp_2.GP.y[n_init:(n_init+max_iter)]) \n",
        "stp_output_2 = np.append(np.max(stp_2.GP.y[0:n_init]),stp_2.GP.y[n_init:(n_init+max_iter)]) \n",
        "\n",
        "regret_gp_2 = np.log(y_global_orig - gp_output_2)\n",
        "regret_stp_2 = np.log(y_global_orig - stp_output_2)\n",
        "\n",
        "simple_regret_gp_2 = min_max_array(regret_gp_2)\n",
        "simple_regret_stp_2 = min_max_array(regret_stp_2)\n",
        "\n",
        "min_simple_regret_gp_2 = min(simple_regret_gp_2)\n",
        "min_simple_regret_stp_2 = min(simple_regret_stp_2)\n",
        "\n",
        "min_simple_regret_gp_2, min_simple_regret_stp_2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1F9LaViaJLlL",
        "outputId": "c51b989d-cb10-45bc-d07d-d0761d2b350a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-1.9224366800906934, -0.23773993035753282)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "### Simple regret minimisation: run number = 3\n",
        "\n",
        "gp_output_3 = np.append(np.max(gp_3.GP.y[0:n_init]),gp_3.GP.y[n_init:(n_init+max_iter)]) \n",
        "stp_output_3 = np.append(np.max(stp_3.GP.y[0:n_init]),stp_3.GP.y[n_init:(n_init+max_iter)]) \n",
        "\n",
        "regret_gp_3 = np.log(y_global_orig - gp_output_3)\n",
        "regret_stp_3 = np.log(y_global_orig - stp_output_3)\n",
        "\n",
        "simple_regret_gp_3 = min_max_array(regret_gp_3)\n",
        "simple_regret_stp_3 = min_max_array(regret_stp_3)\n",
        "\n",
        "min_simple_regret_gp_3 = min(simple_regret_gp_3)\n",
        "min_simple_regret_stp_3 = min(simple_regret_stp_3)\n",
        "\n",
        "min_simple_regret_gp_3, min_simple_regret_stp_3\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vThMylZmJLlL",
        "outputId": "f7322b98-b7b9-443b-c649-53122fd4e523"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-3.9755567928573337, -1.2300875975311583)"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "### Simple regret minimisation: run number = 4\n",
        "\n",
        "gp_output_4 = np.append(np.max(gp_4.GP.y[0:n_init]),gp_4.GP.y[n_init:(n_init+max_iter)]) \n",
        "stp_output_4 = np.append(np.max(stp_4.GP.y[0:n_init]),stp_4.GP.y[n_init:(n_init+max_iter)]) \n",
        "\n",
        "regret_gp_4 = np.log(y_global_orig - gp_output_4)\n",
        "regret_stp_4 = np.log(y_global_orig - stp_output_4)\n",
        "\n",
        "simple_regret_gp_4 = min_max_array(regret_gp_4)\n",
        "simple_regret_stp_4 = min_max_array(regret_stp_4)\n",
        "\n",
        "min_simple_regret_gp_4 = min(simple_regret_gp_4)\n",
        "min_simple_regret_stp_4 = min(simple_regret_stp_4)\n",
        "\n",
        "min_simple_regret_gp_4, min_simple_regret_stp_4\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Um6_WG7JLlM",
        "outputId": "49a3ed0a-4e35-471d-c22b-c7b20459a7e6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-0.9667370327122197, -0.9667370327122197)"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "### Simple regret minimisation: run number = 5\n",
        "\n",
        "gp_output_5 = np.append(np.max(gp_5.GP.y[0:n_init]),gp_5.GP.y[n_init:(n_init+max_iter)]) \n",
        "stp_output_5 = np.append(np.max(stp_5.GP.y[0:n_init]),stp_5.GP.y[n_init:(n_init+max_iter)]) \n",
        "\n",
        "regret_gp_5 = np.log(y_global_orig - gp_output_5)\n",
        "regret_stp_5 = np.log(y_global_orig - stp_output_5)\n",
        "\n",
        "simple_regret_gp_5 = min_max_array(regret_gp_5)\n",
        "simple_regret_stp_5 = min_max_array(regret_stp_5)\n",
        "\n",
        "min_simple_regret_gp_5 = min(simple_regret_gp_5)\n",
        "min_simple_regret_stp_5 = min(simple_regret_stp_5)\n",
        "\n",
        "min_simple_regret_gp_5, min_simple_regret_stp_5\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7F8Y3b9JLlM",
        "outputId": "10edb071-25ec-443c-e0a9-7d87de99185a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-3.3342191318798085, -0.47886295590108363)"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "### Simple regret minimisation: run number = 6\n",
        "\n",
        "gp_output_6 = np.append(np.max(gp_6.GP.y[0:n_init]),gp_6.GP.y[n_init:(n_init+max_iter)]) \n",
        "stp_output_6 = np.append(np.max(stp_6.GP.y[0:n_init]),stp_6.GP.y[n_init:(n_init+max_iter)]) \n",
        "\n",
        "regret_gp_6 = np.log(y_global_orig - gp_output_6)\n",
        "regret_stp_6 = np.log(y_global_orig - stp_output_6)\n",
        "\n",
        "simple_regret_gp_6 = min_max_array(regret_gp_6)\n",
        "simple_regret_stp_6 = min_max_array(regret_stp_6)\n",
        "\n",
        "min_simple_regret_gp_6 = min(simple_regret_gp_6)\n",
        "min_simple_regret_stp_6 = min(simple_regret_stp_6)\n",
        "\n",
        "min_simple_regret_gp_6, min_simple_regret_stp_6\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FbMNex-gJLlN",
        "outputId": "c9f3736b-27ad-4500-c002-904f423cb9d9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-0.567767694400235, -0.567767694400235)"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "### Simple regret minimisation: run number = 7\n",
        "\n",
        "gp_output_7 = np.append(np.max(gp_7.GP.y[0:n_init]),gp_7.GP.y[n_init:(n_init+max_iter)]) \n",
        "stp_output_7 = np.append(np.max(stp_7.GP.y[0:n_init]),stp_7.GP.y[n_init:(n_init+max_iter)]) \n",
        "\n",
        "regret_gp_7 = np.log(y_global_orig - gp_output_7)\n",
        "regret_stp_7 = np.log(y_global_orig - stp_output_7)\n",
        "\n",
        "simple_regret_gp_7 = min_max_array(regret_gp_7)\n",
        "simple_regret_stp_7 = min_max_array(regret_stp_7)\n",
        "\n",
        "min_simple_regret_gp_7 = min(simple_regret_gp_7)\n",
        "min_simple_regret_stp_7 = min(simple_regret_stp_7)\n",
        "\n",
        "min_simple_regret_gp_7, min_simple_regret_stp_7\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yTxbjos2JLlN",
        "outputId": "d4774843-c55b-4501-9f40-5ee2c123f8a2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-0.5580913127468999, -0.3524920481389185)"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "### Simple regret minimisation: run number = 8\n",
        "\n",
        "gp_output_8 = np.append(np.max(gp_8.GP.y[0:n_init]),gp_8.GP.y[n_init:(n_init+max_iter)]) \n",
        "stp_output_8 = np.append(np.max(stp_8.GP.y[0:n_init]),stp_8.GP.y[n_init:(n_init+max_iter)]) \n",
        "\n",
        "regret_gp_8 = np.log(y_global_orig - gp_output_8)\n",
        "regret_stp_8 = np.log(y_global_orig - stp_output_8)\n",
        "\n",
        "simple_regret_gp_8 = min_max_array(regret_gp_8)\n",
        "simple_regret_stp_8 = min_max_array(regret_stp_8)\n",
        "\n",
        "min_simple_regret_gp_8 = min(simple_regret_gp_8)\n",
        "min_simple_regret_stp_8 = min(simple_regret_stp_8)\n",
        "\n",
        "min_simple_regret_gp_8, min_simple_regret_stp_8\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iBuMpq59JLlO",
        "outputId": "8cc8624e-7a29-4a26-bb7b-cf4b283d7585"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-0.03604981995597414, -0.9501501745028799)"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "### Simple regret minimisation: run number = 9\n",
        "\n",
        "gp_output_9 = np.append(np.max(gp_9.GP.y[0:n_init]),gp_9.GP.y[n_init:(n_init+max_iter)]) \n",
        "stp_output_9 = np.append(np.max(stp_9.GP.y[0:n_init]),stp_9.GP.y[n_init:(n_init+max_iter)]) \n",
        "\n",
        "regret_gp_9 = np.log(y_global_orig - gp_output_9)\n",
        "regret_stp_9 = np.log(y_global_orig - stp_output_9)\n",
        "\n",
        "simple_regret_gp_9 = min_max_array(regret_gp_9)\n",
        "simple_regret_stp_9 = min_max_array(regret_stp_9)\n",
        "\n",
        "min_simple_regret_gp_9 = min(simple_regret_gp_9)\n",
        "min_simple_regret_stp_9 = min(simple_regret_stp_9)\n",
        "\n",
        "min_simple_regret_gp_9, min_simple_regret_stp_9\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MT-MYaKEJLlO",
        "outputId": "68d78da1-e640-4153-dfc3-5edbed8a867b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-0.15837762539473393, -0.7981197245865939)"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "source": [
        "### Simple regret minimisation: run number = 10\n",
        "\n",
        "gp_output_10 = np.append(np.max(gp_10.GP.y[0:n_init]),gp_10.GP.y[n_init:(n_init+max_iter)]) \n",
        "stp_output_10 = np.append(np.max(stp_10.GP.y[0:n_init]),stp_10.GP.y[n_init:(n_init+max_iter)]) \n",
        "\n",
        "regret_gp_10 = np.log(y_global_orig - gp_output_10)\n",
        "regret_stp_10 = np.log(y_global_orig - stp_output_10)\n",
        "\n",
        "simple_regret_gp_10 = min_max_array(regret_gp_10)\n",
        "simple_regret_stp_10 = min_max_array(regret_stp_10)\n",
        "\n",
        "min_simple_regret_gp_10 = min(simple_regret_gp_10)\n",
        "min_simple_regret_stp_10 = min(simple_regret_stp_10)\n",
        "\n",
        "min_simple_regret_gp_10, min_simple_regret_stp_10\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JgXNMHBOJLlP",
        "outputId": "4ec82308-0d28-4351-cc78-10621181466e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-1.9196861805080783, -1.0274715650752406)"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ],
      "source": [
        "### Simple regret minimisation: run number = 11\n",
        "\n",
        "gp_output_11 = np.append(np.max(gp_11.GP.y[0:n_init]),gp_11.GP.y[n_init:(n_init+max_iter)]) \n",
        "stp_output_11 = np.append(np.max(stp_11.GP.y[0:n_init]),stp_11.GP.y[n_init:(n_init+max_iter)]) \n",
        "\n",
        "regret_gp_11 = np.log(y_global_orig - gp_output_11)\n",
        "regret_stp_11 = np.log(y_global_orig - stp_output_11)\n",
        "\n",
        "simple_regret_gp_11 = min_max_array(regret_gp_11)\n",
        "simple_regret_stp_11 = min_max_array(regret_stp_11)\n",
        "\n",
        "min_simple_regret_gp_11 = min(simple_regret_gp_11)\n",
        "min_simple_regret_stp_11 = min(simple_regret_stp_11)\n",
        "\n",
        "min_simple_regret_gp_11, min_simple_regret_stp_11\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNvnLAXOJLlQ",
        "outputId": "25a85b56-6139-49ab-abe9-63fd21ab15b3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.5644002217234239, -2.29040202327596)"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "### Simple regret minimisation: run number = 12\n",
        "\n",
        "gp_output_12 = np.append(np.max(gp_12.GP.y[0:n_init]),gp_12.GP.y[n_init:(n_init+max_iter)]) \n",
        "stp_output_12 = np.append(np.max(stp_12.GP.y[0:n_init]),stp_12.GP.y[n_init:(n_init+max_iter)]) \n",
        "\n",
        "regret_gp_12 = np.log(y_global_orig - gp_output_12)\n",
        "regret_stp_12 = np.log(y_global_orig - stp_output_12)\n",
        "\n",
        "simple_regret_gp_12 = min_max_array(regret_gp_12)\n",
        "simple_regret_stp_12 = min_max_array(regret_stp_12)\n",
        "\n",
        "min_simple_regret_gp_12 = min(simple_regret_gp_12)\n",
        "min_simple_regret_stp_12 = min(simple_regret_stp_12)\n",
        "\n",
        "min_simple_regret_gp_12, min_simple_regret_stp_12\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LccPP2SJJLlQ",
        "outputId": "0a5c1856-671b-4efe-b043-49963bc94cab"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.3315796636621878, -1.4223241976631904)"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "### Simple regret minimisation: run number = 13\n",
        "\n",
        "gp_output_13 = np.append(np.max(gp_13.GP.y[0:n_init]),gp_13.GP.y[n_init:(n_init+max_iter)]) \n",
        "stp_output_13 = np.append(np.max(stp_13.GP.y[0:n_init]),stp_13.GP.y[n_init:(n_init+max_iter)]) \n",
        "\n",
        "regret_gp_13 = np.log(y_global_orig - gp_output_13)\n",
        "regret_stp_13 = np.log(y_global_orig - stp_output_13)\n",
        "\n",
        "simple_regret_gp_13 = min_max_array(regret_gp_13)\n",
        "simple_regret_stp_13 = min_max_array(regret_stp_13)\n",
        "\n",
        "min_simple_regret_gp_13 = min(simple_regret_gp_13)\n",
        "min_simple_regret_stp_13 = min(simple_regret_stp_13)\n",
        "\n",
        "min_simple_regret_gp_13, min_simple_regret_stp_13\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OsCDbV_CJLlR",
        "outputId": "39fbb0f6-dd54-4144-95ab-42c2a70d4a69"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-6.074727392833108, -6.074727392833108)"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "### Simple regret minimisation: run number = 14\n",
        "\n",
        "gp_output_14 = np.append(np.max(gp_14.GP.y[0:n_init]),gp_14.GP.y[n_init:(n_init+max_iter)]) \n",
        "stp_output_14 = np.append(np.max(stp_14.GP.y[0:n_init]),stp_14.GP.y[n_init:(n_init+max_iter)]) \n",
        "\n",
        "regret_gp_14 = np.log(y_global_orig - gp_output_14)\n",
        "regret_stp_14 = np.log(y_global_orig - stp_output_14)\n",
        "\n",
        "simple_regret_gp_14 = min_max_array(regret_gp_14)\n",
        "simple_regret_stp_14 = min_max_array(regret_stp_14)\n",
        "\n",
        "min_simple_regret_gp_14 = min(simple_regret_gp_14)\n",
        "min_simple_regret_stp_14 = min(simple_regret_stp_14)\n",
        "\n",
        "min_simple_regret_gp_14, min_simple_regret_stp_14\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVNGSKzNJLlR",
        "outputId": "2654a090-2f92-47b3-f075-f8bbf718c4f3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-0.5140068510069826, -2.0392785228071557)"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "source": [
        "### Simple regret minimisation: run number = 15\n",
        "\n",
        "gp_output_15 = np.append(np.max(gp_15.GP.y[0:n_init]),gp_15.GP.y[n_init:(n_init+max_iter)]) \n",
        "stp_output_15 = np.append(np.max(stp_15.GP.y[0:n_init]),stp_15.GP.y[n_init:(n_init+max_iter)]) \n",
        "\n",
        "regret_gp_15 = np.log(y_global_orig - gp_output_15)\n",
        "regret_stp_15 = np.log(y_global_orig - stp_output_15)\n",
        "\n",
        "simple_regret_gp_15 = min_max_array(regret_gp_15)\n",
        "simple_regret_stp_15 = min_max_array(regret_stp_15)\n",
        "\n",
        "min_simple_regret_gp_15 = min(simple_regret_gp_15)\n",
        "min_simple_regret_stp_15 = min(simple_regret_stp_15)\n",
        "\n",
        "min_simple_regret_gp_15, min_simple_regret_stp_15\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFT0-DcpJLlS",
        "outputId": "fcb362ea-3bbd-41bf-817a-8bba81034602"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1.0208365910396675, -1.967383541140278)"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ],
      "source": [
        "### Simple regret minimisation: run number = 16\n",
        "\n",
        "gp_output_16 = np.append(np.max(gp_16.GP.y[0:n_init]),gp_16.GP.y[n_init:(n_init+max_iter)]) \n",
        "stp_output_16 = np.append(np.max(stp_16.GP.y[0:n_init]),stp_16.GP.y[n_init:(n_init+max_iter)]) \n",
        "\n",
        "regret_gp_16 = np.log(y_global_orig - gp_output_16)\n",
        "regret_stp_16 = np.log(y_global_orig - stp_output_16)\n",
        "\n",
        "simple_regret_gp_16 = min_max_array(regret_gp_16)\n",
        "simple_regret_stp_16 = min_max_array(regret_stp_16)\n",
        "\n",
        "min_simple_regret_gp_16 = min(simple_regret_gp_16)\n",
        "min_simple_regret_stp_16 = min(simple_regret_stp_16)\n",
        "\n",
        "min_simple_regret_gp_16, min_simple_regret_stp_16\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TPbl73U3JLlS",
        "outputId": "a34b1953-9f0b-4d07-ea82-ad52815f4af9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-0.3022326539436522, -0.41909604633493136)"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ],
      "source": [
        "### Simple regret minimisation: run number = 17\n",
        "\n",
        "gp_output_17 = np.append(np.max(gp_17.GP.y[0:n_init]),gp_17.GP.y[n_init:(n_init+max_iter)]) \n",
        "stp_output_17 = np.append(np.max(stp_17.GP.y[0:n_init]),stp_17.GP.y[n_init:(n_init+max_iter)]) \n",
        "\n",
        "regret_gp_17 = np.log(y_global_orig - gp_output_17)\n",
        "regret_stp_17 = np.log(y_global_orig - stp_output_17)\n",
        "\n",
        "simple_regret_gp_17 = min_max_array(regret_gp_17)\n",
        "simple_regret_stp_17 = min_max_array(regret_stp_17)\n",
        "\n",
        "min_simple_regret_gp_17 = min(simple_regret_gp_17)\n",
        "min_simple_regret_stp_17 = min(simple_regret_stp_17)\n",
        "\n",
        "min_simple_regret_gp_17, min_simple_regret_stp_17\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANjpLP7uJLlT",
        "outputId": "7dacca65-428c-47c9-f037-450972a24aaf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-0.08454162260698546, -1.5898936351058908)"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ],
      "source": [
        "### Simple regret minimisation: run number = 18\n",
        "\n",
        "gp_output_18 = np.append(np.max(gp_18.GP.y[0:n_init]),gp_18.GP.y[n_init:(n_init+max_iter)]) \n",
        "stp_output_18 = np.append(np.max(stp_18.GP.y[0:n_init]),stp_18.GP.y[n_init:(n_init+max_iter)]) \n",
        "\n",
        "regret_gp_18 = np.log(y_global_orig - gp_output_18)\n",
        "regret_stp_18 = np.log(y_global_orig - stp_output_18)\n",
        "\n",
        "simple_regret_gp_18 = min_max_array(regret_gp_18)\n",
        "simple_regret_stp_18 = min_max_array(regret_stp_18)\n",
        "\n",
        "min_simple_regret_gp_18 = min(simple_regret_gp_18)\n",
        "min_simple_regret_stp_18 = min(simple_regret_stp_18)\n",
        "\n",
        "min_simple_regret_gp_18, min_simple_regret_stp_18\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yYy7bHMOJLlT",
        "outputId": "5b426b2d-ddf9-4535-858f-3d45c603fdfd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-0.0637058568208816, -1.8524689676937758)"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ],
      "source": [
        "### Simple regret minimisation: run number = 19\n",
        "\n",
        "gp_output_19 = np.append(np.max(gp_19.GP.y[0:n_init]),gp_19.GP.y[n_init:(n_init+max_iter)]) \n",
        "stp_output_19 = np.append(np.max(stp_19.GP.y[0:n_init]),stp_19.GP.y[n_init:(n_init+max_iter)]) \n",
        "\n",
        "regret_gp_19 = np.log(y_global_orig - gp_output_19)\n",
        "regret_stp_19 = np.log(y_global_orig - stp_output_19)\n",
        "\n",
        "simple_regret_gp_19 = min_max_array(regret_gp_19)\n",
        "simple_regret_stp_19 = min_max_array(regret_stp_19)\n",
        "\n",
        "min_simple_regret_gp_19 = min(simple_regret_gp_19)\n",
        "min_simple_regret_stp_19 = min(simple_regret_stp_19)\n",
        "\n",
        "min_simple_regret_gp_19, min_simple_regret_stp_19\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7h8DTQ7MJLlU",
        "outputId": "f5986054-20dd-4e2c-9c7e-35cb1d96e374"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.21916839298683835, -1.731935696537742)"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ],
      "source": [
        "### Simple regret minimisation: run number = 20\n",
        "\n",
        "gp_output_20 = np.append(np.max(gp_20.GP.y[0:n_init]),gp_20.GP.y[n_init:(n_init+max_iter)]) \n",
        "stp_output_20 = np.append(np.max(stp_20.GP.y[0:n_init]),stp_20.GP.y[n_init:(n_init+max_iter)]) \n",
        "\n",
        "regret_gp_20 = np.log(y_global_orig - gp_output_20)\n",
        "regret_stp_20 = np.log(y_global_orig - stp_output_20)\n",
        "\n",
        "simple_regret_gp_20 = min_max_array(regret_gp_20)\n",
        "simple_regret_stp_20 = min_max_array(regret_stp_20)\n",
        "\n",
        "min_simple_regret_gp_20 = min(simple_regret_gp_20)\n",
        "min_simple_regret_stp_20 = min(simple_regret_stp_20)\n",
        "\n",
        "min_simple_regret_gp_20, min_simple_regret_stp_20\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "FuTVzVQkJLlU"
      },
      "outputs": [],
      "source": [
        "# Iteration1 :\n",
        "\n",
        "slice1 = 0\n",
        "\n",
        "gp1 = [simple_regret_gp_1[slice1],\n",
        "       simple_regret_gp_2[slice1],\n",
        "       simple_regret_gp_3[slice1],\n",
        "       simple_regret_gp_4[slice1],\n",
        "       simple_regret_gp_5[slice1],\n",
        "       simple_regret_gp_6[slice1],\n",
        "       simple_regret_gp_7[slice1],\n",
        "       simple_regret_gp_8[slice1],\n",
        "       simple_regret_gp_9[slice1],\n",
        "       simple_regret_gp_10[slice1],\n",
        "       simple_regret_gp_11[slice1],\n",
        "       simple_regret_gp_12[slice1],\n",
        "       simple_regret_gp_13[slice1],\n",
        "       simple_regret_gp_14[slice1],\n",
        "       simple_regret_gp_15[slice1],\n",
        "       simple_regret_gp_16[slice1],\n",
        "       simple_regret_gp_17[slice1],\n",
        "       simple_regret_gp_18[slice1],\n",
        "       simple_regret_gp_19[slice1],\n",
        "       simple_regret_gp_20[slice1]]\n",
        "\n",
        "stp1 = [simple_regret_stp_1[slice1],\n",
        "       simple_regret_stp_2[slice1],\n",
        "       simple_regret_stp_3[slice1],\n",
        "       simple_regret_stp_4[slice1],\n",
        "       simple_regret_stp_5[slice1],\n",
        "       simple_regret_stp_6[slice1],\n",
        "       simple_regret_stp_7[slice1],\n",
        "       simple_regret_stp_8[slice1],\n",
        "       simple_regret_stp_9[slice1],\n",
        "       simple_regret_stp_10[slice1],\n",
        "       simple_regret_stp_11[slice1],\n",
        "       simple_regret_stp_12[slice1],\n",
        "       simple_regret_stp_13[slice1],\n",
        "       simple_regret_stp_14[slice1],\n",
        "       simple_regret_stp_15[slice1],\n",
        "       simple_regret_stp_16[slice1],\n",
        "       simple_regret_stp_17[slice1],\n",
        "       simple_regret_stp_18[slice1],\n",
        "       simple_regret_stp_19[slice1],\n",
        "       simple_regret_stp_20[slice1]]\n",
        "\n",
        "gp1_results = pd.DataFrame(gp1).sort_values(by=[0], ascending=False)\n",
        "stp1_results = pd.DataFrame(stp1).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - gp:\n",
        "lower_gp1 = np.asarray(gp1_results[4:5][0])[0]\n",
        "median_gp1 = np.asarray(gp1_results[9:10][0])[0]\n",
        "upper_gp1 = np.asarray(gp1_results[14:15][0])[0]\n",
        "\n",
        "lower_stp1 = np.asarray(stp1_results[4:5][0])[0]\n",
        "median_stp1 = np.asarray(stp1_results[9:10][0])[0]\n",
        "upper_stp1 = np.asarray(stp1_results[14:15][0])[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "OCTtqlBHJLlV"
      },
      "outputs": [],
      "source": [
        "# Iteration11 :\n",
        "\n",
        "slice11 = 10\n",
        "\n",
        "gp11 = [simple_regret_gp_1[slice11],\n",
        "       simple_regret_gp_2[slice11],\n",
        "       simple_regret_gp_3[slice11],\n",
        "       simple_regret_gp_4[slice11],\n",
        "       simple_regret_gp_5[slice11],\n",
        "       simple_regret_gp_6[slice11],\n",
        "       simple_regret_gp_7[slice11],\n",
        "       simple_regret_gp_8[slice11],\n",
        "       simple_regret_gp_9[slice11],\n",
        "       simple_regret_gp_10[slice11],\n",
        "       simple_regret_gp_11[slice11],\n",
        "       simple_regret_gp_12[slice11],\n",
        "       simple_regret_gp_13[slice11],\n",
        "       simple_regret_gp_14[slice11],\n",
        "       simple_regret_gp_15[slice11],\n",
        "       simple_regret_gp_16[slice11],\n",
        "       simple_regret_gp_17[slice11],\n",
        "       simple_regret_gp_18[slice11],\n",
        "       simple_regret_gp_19[slice11],\n",
        "       simple_regret_gp_20[slice11]]\n",
        "\n",
        "stp11 = [simple_regret_stp_1[slice11],\n",
        "       simple_regret_stp_2[slice11],\n",
        "       simple_regret_stp_3[slice11],\n",
        "       simple_regret_stp_4[slice11],\n",
        "       simple_regret_stp_5[slice11],\n",
        "       simple_regret_stp_6[slice11],\n",
        "       simple_regret_stp_7[slice11],\n",
        "       simple_regret_stp_8[slice11],\n",
        "       simple_regret_stp_9[slice11],\n",
        "       simple_regret_stp_10[slice11],\n",
        "       simple_regret_stp_11[slice11],\n",
        "       simple_regret_stp_12[slice11],\n",
        "       simple_regret_stp_13[slice11],\n",
        "       simple_regret_stp_14[slice11],\n",
        "       simple_regret_stp_15[slice11],\n",
        "       simple_regret_stp_16[slice11],\n",
        "       simple_regret_stp_17[slice11],\n",
        "       simple_regret_stp_18[slice11],\n",
        "       simple_regret_stp_19[slice11],\n",
        "       simple_regret_stp_20[slice11]]\n",
        "\n",
        "gp11_results = pd.DataFrame(gp11).sort_values(by=[0], ascending=False)\n",
        "stp11_results = pd.DataFrame(stp11).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - gp:\n",
        "lower_gp11 = np.asarray(gp11_results[4:5][0])[0]\n",
        "median_gp11 = np.asarray(gp11_results[9:10][0])[0]\n",
        "upper_gp11 = np.asarray(gp11_results[14:15][0])[0]\n",
        "\n",
        "lower_stp11 = np.asarray(stp11_results[4:5][0])[0]\n",
        "median_stp11 = np.asarray(stp11_results[9:10][0])[0]\n",
        "upper_stp11 = np.asarray(stp11_results[14:15][0])[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "OhneK6K5JLlV"
      },
      "outputs": [],
      "source": [
        "# Iteration21 :\n",
        "\n",
        "slice21 = 20\n",
        "\n",
        "gp21 = [simple_regret_gp_1[slice21],\n",
        "       simple_regret_gp_2[slice21],\n",
        "       simple_regret_gp_3[slice21],\n",
        "       simple_regret_gp_4[slice21],\n",
        "       simple_regret_gp_5[slice21],\n",
        "       simple_regret_gp_6[slice21],\n",
        "       simple_regret_gp_7[slice21],\n",
        "       simple_regret_gp_8[slice21],\n",
        "       simple_regret_gp_9[slice21],\n",
        "       simple_regret_gp_10[slice21],\n",
        "       simple_regret_gp_11[slice21],\n",
        "       simple_regret_gp_12[slice21],\n",
        "       simple_regret_gp_13[slice21],\n",
        "       simple_regret_gp_14[slice21],\n",
        "       simple_regret_gp_15[slice21],\n",
        "       simple_regret_gp_16[slice21],\n",
        "       simple_regret_gp_17[slice21],\n",
        "       simple_regret_gp_18[slice21],\n",
        "       simple_regret_gp_19[slice21],\n",
        "       simple_regret_gp_20[slice21]]\n",
        "\n",
        "stp21 = [simple_regret_stp_1[slice21],\n",
        "       simple_regret_stp_2[slice21],\n",
        "       simple_regret_stp_3[slice21],\n",
        "       simple_regret_stp_4[slice21],\n",
        "       simple_regret_stp_5[slice21],\n",
        "       simple_regret_stp_6[slice21],\n",
        "       simple_regret_stp_7[slice21],\n",
        "       simple_regret_stp_8[slice21],\n",
        "       simple_regret_stp_9[slice21],\n",
        "       simple_regret_stp_10[slice21],\n",
        "       simple_regret_stp_11[slice21],\n",
        "       simple_regret_stp_12[slice21],\n",
        "       simple_regret_stp_13[slice21],\n",
        "       simple_regret_stp_14[slice21],\n",
        "       simple_regret_stp_15[slice21],\n",
        "       simple_regret_stp_16[slice21],\n",
        "       simple_regret_stp_17[slice21],\n",
        "       simple_regret_stp_18[slice21],\n",
        "       simple_regret_stp_19[slice21],\n",
        "       simple_regret_stp_20[slice21]]\n",
        "\n",
        "gp21_results = pd.DataFrame(gp21).sort_values(by=[0], ascending=False)\n",
        "stp21_results = pd.DataFrame(stp21).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - gp:\n",
        "lower_gp21 = np.asarray(gp21_results[4:5][0])[0]\n",
        "median_gp21 = np.asarray(gp21_results[9:10][0])[0]\n",
        "upper_gp21 = np.asarray(gp21_results[14:15][0])[0]\n",
        "\n",
        "lower_stp21 = np.asarray(stp21_results[4:5][0])[0]\n",
        "median_stp21 = np.asarray(stp21_results[9:10][0])[0]\n",
        "upper_stp21 = np.asarray(stp21_results[14:15][0])[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "YQ1yImxkJLlX"
      },
      "outputs": [],
      "source": [
        "# Iteration31 :\n",
        "\n",
        "slice31 = 30\n",
        "\n",
        "gp31 = [simple_regret_gp_1[slice31],\n",
        "       simple_regret_gp_2[slice31],\n",
        "       simple_regret_gp_3[slice31],\n",
        "       simple_regret_gp_4[slice31],\n",
        "       simple_regret_gp_5[slice31],\n",
        "       simple_regret_gp_6[slice31],\n",
        "       simple_regret_gp_7[slice31],\n",
        "       simple_regret_gp_8[slice31],\n",
        "       simple_regret_gp_9[slice31],\n",
        "       simple_regret_gp_10[slice31],\n",
        "       simple_regret_gp_11[slice31],\n",
        "       simple_regret_gp_12[slice31],\n",
        "       simple_regret_gp_13[slice31],\n",
        "       simple_regret_gp_14[slice31],\n",
        "       simple_regret_gp_15[slice31],\n",
        "       simple_regret_gp_16[slice31],\n",
        "       simple_regret_gp_17[slice31],\n",
        "       simple_regret_gp_18[slice31],\n",
        "       simple_regret_gp_19[slice31],\n",
        "       simple_regret_gp_20[slice31]]\n",
        "\n",
        "stp31 = [simple_regret_stp_1[slice31],\n",
        "       simple_regret_stp_2[slice31],\n",
        "       simple_regret_stp_3[slice31],\n",
        "       simple_regret_stp_4[slice31],\n",
        "       simple_regret_stp_5[slice31],\n",
        "       simple_regret_stp_6[slice31],\n",
        "       simple_regret_stp_7[slice31],\n",
        "       simple_regret_stp_8[slice31],\n",
        "       simple_regret_stp_9[slice31],\n",
        "       simple_regret_stp_10[slice31],\n",
        "       simple_regret_stp_11[slice31],\n",
        "       simple_regret_stp_12[slice31],\n",
        "       simple_regret_stp_13[slice31],\n",
        "       simple_regret_stp_14[slice31],\n",
        "       simple_regret_stp_15[slice31],\n",
        "       simple_regret_stp_16[slice31],\n",
        "       simple_regret_stp_17[slice31],\n",
        "       simple_regret_stp_18[slice31],\n",
        "       simple_regret_stp_19[slice31],\n",
        "       simple_regret_stp_20[slice31]]\n",
        "\n",
        "gp31_results = pd.DataFrame(gp31).sort_values(by=[0], ascending=False)\n",
        "stp31_results = pd.DataFrame(stp31).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - gp:\n",
        "lower_gp31 = np.asarray(gp31_results[4:5][0])[0]\n",
        "median_gp31 = np.asarray(gp31_results[9:10][0])[0]\n",
        "upper_gp31 = np.asarray(gp31_results[14:15][0])[0]\n",
        "\n",
        "lower_stp31 = np.asarray(stp31_results[4:5][0])[0]\n",
        "median_stp31 = np.asarray(stp31_results[9:10][0])[0]\n",
        "upper_stp31 = np.asarray(stp31_results[14:15][0])[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "QLs3tfatJLlX"
      },
      "outputs": [],
      "source": [
        "# Iteration41 :\n",
        "\n",
        "slice41 = 40\n",
        "\n",
        "gp41 = [simple_regret_gp_1[slice41],\n",
        "       simple_regret_gp_2[slice41],\n",
        "       simple_regret_gp_3[slice41],\n",
        "       simple_regret_gp_4[slice41],\n",
        "       simple_regret_gp_5[slice41],\n",
        "       simple_regret_gp_6[slice41],\n",
        "       simple_regret_gp_7[slice41],\n",
        "       simple_regret_gp_8[slice41],\n",
        "       simple_regret_gp_9[slice41],\n",
        "       simple_regret_gp_10[slice41],\n",
        "       simple_regret_gp_11[slice41],\n",
        "       simple_regret_gp_12[slice41],\n",
        "       simple_regret_gp_13[slice41],\n",
        "       simple_regret_gp_14[slice41],\n",
        "       simple_regret_gp_15[slice41],\n",
        "       simple_regret_gp_16[slice41],\n",
        "       simple_regret_gp_17[slice41],\n",
        "       simple_regret_gp_18[slice41],\n",
        "       simple_regret_gp_19[slice41],\n",
        "       simple_regret_gp_20[slice41]]\n",
        "\n",
        "stp41 = [simple_regret_stp_1[slice41],\n",
        "       simple_regret_stp_2[slice41],\n",
        "       simple_regret_stp_3[slice41],\n",
        "       simple_regret_stp_4[slice41],\n",
        "       simple_regret_stp_5[slice41],\n",
        "       simple_regret_stp_6[slice41],\n",
        "       simple_regret_stp_7[slice41],\n",
        "       simple_regret_stp_8[slice41],\n",
        "       simple_regret_stp_9[slice41],\n",
        "       simple_regret_stp_10[slice41],\n",
        "       simple_regret_stp_11[slice41],\n",
        "       simple_regret_stp_12[slice41],\n",
        "       simple_regret_stp_13[slice41],\n",
        "       simple_regret_stp_14[slice41],\n",
        "       simple_regret_stp_15[slice41],\n",
        "       simple_regret_stp_16[slice41],\n",
        "       simple_regret_stp_17[slice41],\n",
        "       simple_regret_stp_18[slice41],\n",
        "       simple_regret_stp_19[slice41],\n",
        "       simple_regret_stp_20[slice41]]\n",
        "\n",
        "gp41_results = pd.DataFrame(gp41).sort_values(by=[0], ascending=False)\n",
        "stp41_results = pd.DataFrame(stp41).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - gp:\n",
        "lower_gp41 = np.asarray(gp41_results[4:5][0])[0]\n",
        "median_gp41 = np.asarray(gp41_results[9:10][0])[0]\n",
        "upper_gp41 = np.asarray(gp41_results[14:15][0])[0]\n",
        "\n",
        "lower_stp41 = np.asarray(stp41_results[4:5][0])[0]\n",
        "median_stp41 = np.asarray(stp41_results[9:10][0])[0]\n",
        "upper_stp41 = np.asarray(stp41_results[14:15][0])[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "nHXvSh0YJLlY"
      },
      "outputs": [],
      "source": [
        "# Iteration51 :\n",
        "\n",
        "slice51 = 50\n",
        "\n",
        "gp51 = [simple_regret_gp_1[slice51],\n",
        "       simple_regret_gp_2[slice51],\n",
        "       simple_regret_gp_3[slice51],\n",
        "       simple_regret_gp_4[slice51],\n",
        "       simple_regret_gp_5[slice51],\n",
        "       simple_regret_gp_6[slice51],\n",
        "       simple_regret_gp_7[slice51],\n",
        "       simple_regret_gp_8[slice51],\n",
        "       simple_regret_gp_9[slice51],\n",
        "       simple_regret_gp_10[slice51],\n",
        "       simple_regret_gp_11[slice51],\n",
        "       simple_regret_gp_12[slice51],\n",
        "       simple_regret_gp_13[slice51],\n",
        "       simple_regret_gp_14[slice51],\n",
        "       simple_regret_gp_15[slice51],\n",
        "       simple_regret_gp_16[slice51],\n",
        "       simple_regret_gp_17[slice51],\n",
        "       simple_regret_gp_18[slice51],\n",
        "       simple_regret_gp_19[slice51],\n",
        "       simple_regret_gp_20[slice51]]\n",
        "\n",
        "stp51 = [simple_regret_stp_1[slice51],\n",
        "       simple_regret_stp_2[slice51],\n",
        "       simple_regret_stp_3[slice51],\n",
        "       simple_regret_stp_4[slice51],\n",
        "       simple_regret_stp_5[slice51],\n",
        "       simple_regret_stp_6[slice51],\n",
        "       simple_regret_stp_7[slice51],\n",
        "       simple_regret_stp_8[slice51],\n",
        "       simple_regret_stp_9[slice51],\n",
        "       simple_regret_stp_10[slice51],\n",
        "       simple_regret_stp_11[slice51],\n",
        "       simple_regret_stp_12[slice51],\n",
        "       simple_regret_stp_13[slice51],\n",
        "       simple_regret_stp_14[slice51],\n",
        "       simple_regret_stp_15[slice51],\n",
        "       simple_regret_stp_16[slice51],\n",
        "       simple_regret_stp_17[slice51],\n",
        "       simple_regret_stp_18[slice51],\n",
        "       simple_regret_stp_19[slice51],\n",
        "       simple_regret_stp_20[slice51]]\n",
        "\n",
        "gp51_results = pd.DataFrame(gp51).sort_values(by=[0], ascending=False)\n",
        "stp51_results = pd.DataFrame(stp51).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - gp:\n",
        "lower_gp51 = np.asarray(gp51_results[4:5][0])[0]\n",
        "median_gp51 = np.asarray(gp51_results[9:10][0])[0]\n",
        "upper_gp51 = np.asarray(gp51_results[14:15][0])[0]\n",
        "\n",
        "lower_stp51 = np.asarray(stp51_results[4:5][0])[0]\n",
        "median_stp51 = np.asarray(stp51_results[9:10][0])[0]\n",
        "upper_stp51 = np.asarray(stp51_results[14:15][0])[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "4GBJgoM5JLlY"
      },
      "outputs": [],
      "source": [
        "# Iteration61 :\n",
        "\n",
        "slice61 = 60\n",
        "\n",
        "gp61 = [simple_regret_gp_1[slice61],\n",
        "       simple_regret_gp_2[slice61],\n",
        "       simple_regret_gp_3[slice61],\n",
        "       simple_regret_gp_4[slice61],\n",
        "       simple_regret_gp_5[slice61],\n",
        "       simple_regret_gp_6[slice61],\n",
        "       simple_regret_gp_7[slice61],\n",
        "       simple_regret_gp_8[slice61],\n",
        "       simple_regret_gp_9[slice61],\n",
        "       simple_regret_gp_10[slice61],\n",
        "       simple_regret_gp_11[slice61],\n",
        "       simple_regret_gp_12[slice61],\n",
        "       simple_regret_gp_13[slice61],\n",
        "       simple_regret_gp_14[slice61],\n",
        "       simple_regret_gp_15[slice61],\n",
        "       simple_regret_gp_16[slice61],\n",
        "       simple_regret_gp_17[slice61],\n",
        "       simple_regret_gp_18[slice61],\n",
        "       simple_regret_gp_19[slice61],\n",
        "       simple_regret_gp_20[slice61]]\n",
        "\n",
        "stp61 = [simple_regret_stp_1[slice61],\n",
        "       simple_regret_stp_2[slice61],\n",
        "       simple_regret_stp_3[slice61],\n",
        "       simple_regret_stp_4[slice61],\n",
        "       simple_regret_stp_5[slice61],\n",
        "       simple_regret_stp_6[slice61],\n",
        "       simple_regret_stp_7[slice61],\n",
        "       simple_regret_stp_8[slice61],\n",
        "       simple_regret_stp_9[slice61],\n",
        "       simple_regret_stp_10[slice61],\n",
        "       simple_regret_stp_11[slice61],\n",
        "       simple_regret_stp_12[slice61],\n",
        "       simple_regret_stp_13[slice61],\n",
        "       simple_regret_stp_14[slice61],\n",
        "       simple_regret_stp_15[slice61],\n",
        "       simple_regret_stp_16[slice61],\n",
        "       simple_regret_stp_17[slice61],\n",
        "       simple_regret_stp_18[slice61],\n",
        "       simple_regret_stp_19[slice61],\n",
        "       simple_regret_stp_20[slice61]]\n",
        "\n",
        "gp61_results = pd.DataFrame(gp61).sort_values(by=[0], ascending=False)\n",
        "stp61_results = pd.DataFrame(stp61).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - gp:\n",
        "lower_gp61 = np.asarray(gp61_results[4:5][0])[0]\n",
        "median_gp61 = np.asarray(gp61_results[9:10][0])[0]\n",
        "upper_gp61 = np.asarray(gp61_results[14:15][0])[0]\n",
        "\n",
        "lower_stp61 = np.asarray(stp61_results[4:5][0])[0]\n",
        "median_stp61 = np.asarray(stp61_results[9:10][0])[0]\n",
        "upper_stp61 = np.asarray(stp61_results[14:15][0])[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "tUi0f4UzJLlZ"
      },
      "outputs": [],
      "source": [
        "# Iteration71 :\n",
        "\n",
        "slice71 = 70\n",
        "\n",
        "gp71 = [simple_regret_gp_1[slice71],\n",
        "       simple_regret_gp_2[slice71],\n",
        "       simple_regret_gp_3[slice71],\n",
        "       simple_regret_gp_4[slice71],\n",
        "       simple_regret_gp_5[slice71],\n",
        "       simple_regret_gp_6[slice71],\n",
        "       simple_regret_gp_7[slice71],\n",
        "       simple_regret_gp_8[slice71],\n",
        "       simple_regret_gp_9[slice71],\n",
        "       simple_regret_gp_10[slice71],\n",
        "       simple_regret_gp_11[slice71],\n",
        "       simple_regret_gp_12[slice71],\n",
        "       simple_regret_gp_13[slice71],\n",
        "       simple_regret_gp_14[slice71],\n",
        "       simple_regret_gp_15[slice71],\n",
        "       simple_regret_gp_16[slice71],\n",
        "       simple_regret_gp_17[slice71],\n",
        "       simple_regret_gp_18[slice71],\n",
        "       simple_regret_gp_19[slice71],\n",
        "       simple_regret_gp_20[slice71]]\n",
        "\n",
        "stp71 = [simple_regret_stp_1[slice71],\n",
        "       simple_regret_stp_2[slice71],\n",
        "       simple_regret_stp_3[slice71],\n",
        "       simple_regret_stp_4[slice71],\n",
        "       simple_regret_stp_5[slice71],\n",
        "       simple_regret_stp_6[slice71],\n",
        "       simple_regret_stp_7[slice71],\n",
        "       simple_regret_stp_8[slice71],\n",
        "       simple_regret_stp_9[slice71],\n",
        "       simple_regret_stp_10[slice71],\n",
        "       simple_regret_stp_11[slice71],\n",
        "       simple_regret_stp_12[slice71],\n",
        "       simple_regret_stp_13[slice71],\n",
        "       simple_regret_stp_14[slice71],\n",
        "       simple_regret_stp_15[slice71],\n",
        "       simple_regret_stp_16[slice71],\n",
        "       simple_regret_stp_17[slice71],\n",
        "       simple_regret_stp_18[slice71],\n",
        "       simple_regret_stp_19[slice71],\n",
        "       simple_regret_stp_20[slice71]]\n",
        "\n",
        "gp71_results = pd.DataFrame(gp71).sort_values(by=[0], ascending=False)\n",
        "stp71_results = pd.DataFrame(stp71).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - gp:\n",
        "lower_gp71 = np.asarray(gp71_results[4:5][0])[0]\n",
        "median_gp71 = np.asarray(gp71_results[9:10][0])[0]\n",
        "upper_gp71 = np.asarray(gp71_results[14:15][0])[0]\n",
        "\n",
        "lower_stp71 = np.asarray(stp71_results[4:5][0])[0]\n",
        "median_stp71 = np.asarray(stp71_results[9:10][0])[0]\n",
        "upper_stp71 = np.asarray(stp71_results[14:15][0])[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "SlifUQq8JLla"
      },
      "outputs": [],
      "source": [
        "# Iteration81 :\n",
        "\n",
        "slice81 = 80\n",
        "\n",
        "gp81 = [simple_regret_gp_1[slice81],\n",
        "       simple_regret_gp_2[slice81],\n",
        "       simple_regret_gp_3[slice81],\n",
        "       simple_regret_gp_4[slice81],\n",
        "       simple_regret_gp_5[slice81],\n",
        "       simple_regret_gp_6[slice81],\n",
        "       simple_regret_gp_7[slice81],\n",
        "       simple_regret_gp_8[slice81],\n",
        "       simple_regret_gp_9[slice81],\n",
        "       simple_regret_gp_10[slice81],\n",
        "       simple_regret_gp_11[slice81],\n",
        "       simple_regret_gp_12[slice81],\n",
        "       simple_regret_gp_13[slice81],\n",
        "       simple_regret_gp_14[slice81],\n",
        "       simple_regret_gp_15[slice81],\n",
        "       simple_regret_gp_16[slice81],\n",
        "       simple_regret_gp_17[slice81],\n",
        "       simple_regret_gp_18[slice81],\n",
        "       simple_regret_gp_19[slice81],\n",
        "       simple_regret_gp_20[slice81]]\n",
        "\n",
        "stp81 = [simple_regret_stp_1[slice81],\n",
        "       simple_regret_stp_2[slice81],\n",
        "       simple_regret_stp_3[slice81],\n",
        "       simple_regret_stp_4[slice81],\n",
        "       simple_regret_stp_5[slice81],\n",
        "       simple_regret_stp_6[slice81],\n",
        "       simple_regret_stp_7[slice81],\n",
        "       simple_regret_stp_8[slice81],\n",
        "       simple_regret_stp_9[slice81],\n",
        "       simple_regret_stp_10[slice81],\n",
        "       simple_regret_stp_11[slice81],\n",
        "       simple_regret_stp_12[slice81],\n",
        "       simple_regret_stp_13[slice81],\n",
        "       simple_regret_stp_14[slice81],\n",
        "       simple_regret_stp_15[slice81],\n",
        "       simple_regret_stp_16[slice81],\n",
        "       simple_regret_stp_17[slice81],\n",
        "       simple_regret_stp_18[slice81],\n",
        "       simple_regret_stp_19[slice81],\n",
        "       simple_regret_stp_20[slice81]]\n",
        "\n",
        "gp81_results = pd.DataFrame(gp81).sort_values(by=[0], ascending=False)\n",
        "stp81_results = pd.DataFrame(stp81).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - gp:\n",
        "lower_gp81 = np.asarray(gp81_results[4:5][0])[0]\n",
        "median_gp81 = np.asarray(gp81_results[9:10][0])[0]\n",
        "upper_gp81 = np.asarray(gp81_results[14:15][0])[0]\n",
        "\n",
        "lower_stp81 = np.asarray(stp81_results[4:5][0])[0]\n",
        "median_stp81 = np.asarray(stp81_results[9:10][0])[0]\n",
        "upper_stp81 = np.asarray(stp81_results[14:15][0])[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "B7HHBL3XJLla"
      },
      "outputs": [],
      "source": [
        "# Iteration91 :\n",
        "\n",
        "slice91 = 90\n",
        "\n",
        "gp91 = [simple_regret_gp_1[slice91],\n",
        "       simple_regret_gp_2[slice91],\n",
        "       simple_regret_gp_3[slice91],\n",
        "       simple_regret_gp_4[slice91],\n",
        "       simple_regret_gp_5[slice91],\n",
        "       simple_regret_gp_6[slice91],\n",
        "       simple_regret_gp_7[slice91],\n",
        "       simple_regret_gp_8[slice91],\n",
        "       simple_regret_gp_9[slice91],\n",
        "       simple_regret_gp_10[slice91],\n",
        "       simple_regret_gp_11[slice91],\n",
        "       simple_regret_gp_12[slice91],\n",
        "       simple_regret_gp_13[slice91],\n",
        "       simple_regret_gp_14[slice91],\n",
        "       simple_regret_gp_15[slice91],\n",
        "       simple_regret_gp_16[slice91],\n",
        "       simple_regret_gp_17[slice91],\n",
        "       simple_regret_gp_18[slice91],\n",
        "       simple_regret_gp_19[slice91],\n",
        "       simple_regret_gp_20[slice91]]\n",
        "\n",
        "stp91 = [simple_regret_stp_1[slice91],\n",
        "       simple_regret_stp_2[slice91],\n",
        "       simple_regret_stp_3[slice91],\n",
        "       simple_regret_stp_4[slice91],\n",
        "       simple_regret_stp_5[slice91],\n",
        "       simple_regret_stp_6[slice91],\n",
        "       simple_regret_stp_7[slice91],\n",
        "       simple_regret_stp_8[slice91],\n",
        "       simple_regret_stp_9[slice91],\n",
        "       simple_regret_stp_10[slice91],\n",
        "       simple_regret_stp_11[slice91],\n",
        "       simple_regret_stp_12[slice91],\n",
        "       simple_regret_stp_13[slice91],\n",
        "       simple_regret_stp_14[slice91],\n",
        "       simple_regret_stp_15[slice91],\n",
        "       simple_regret_stp_16[slice91],\n",
        "       simple_regret_stp_17[slice91],\n",
        "       simple_regret_stp_18[slice91],\n",
        "       simple_regret_stp_19[slice91],\n",
        "       simple_regret_stp_20[slice91]]\n",
        "\n",
        "gp91_results = pd.DataFrame(gp91).sort_values(by=[0], ascending=False)\n",
        "stp91_results = pd.DataFrame(stp91).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - gp:\n",
        "lower_gp91 = np.asarray(gp91_results[4:5][0])[0]\n",
        "median_gp91 = np.asarray(gp91_results[9:10][0])[0]\n",
        "upper_gp91 = np.asarray(gp91_results[14:15][0])[0]\n",
        "\n",
        "lower_stp91 = np.asarray(stp91_results[4:5][0])[0]\n",
        "median_stp91 = np.asarray(stp91_results[9:10][0])[0]\n",
        "upper_stp91 = np.asarray(stp91_results[14:15][0])[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "B5tPijA1JLlb"
      },
      "outputs": [],
      "source": [
        "# Iteration101 :\n",
        "\n",
        "slice101 = 100\n",
        "\n",
        "gp101 = [simple_regret_gp_1[slice101],\n",
        "       simple_regret_gp_2[slice101],\n",
        "       simple_regret_gp_3[slice101],\n",
        "       simple_regret_gp_4[slice101],\n",
        "       simple_regret_gp_5[slice101],\n",
        "       simple_regret_gp_6[slice101],\n",
        "       simple_regret_gp_7[slice101],\n",
        "       simple_regret_gp_8[slice101],\n",
        "       simple_regret_gp_9[slice101],\n",
        "       simple_regret_gp_10[slice101],\n",
        "       simple_regret_gp_11[slice101],\n",
        "       simple_regret_gp_12[slice101],\n",
        "       simple_regret_gp_13[slice101],\n",
        "       simple_regret_gp_14[slice101],\n",
        "       simple_regret_gp_15[slice101],\n",
        "       simple_regret_gp_16[slice101],\n",
        "       simple_regret_gp_17[slice101],\n",
        "       simple_regret_gp_18[slice101],\n",
        "       simple_regret_gp_19[slice101],\n",
        "       simple_regret_gp_20[slice101]]\n",
        "\n",
        "stp101 = [simple_regret_stp_1[slice101],\n",
        "       simple_regret_stp_2[slice101],\n",
        "       simple_regret_stp_3[slice101],\n",
        "       simple_regret_stp_4[slice101],\n",
        "       simple_regret_stp_5[slice101],\n",
        "       simple_regret_stp_6[slice101],\n",
        "       simple_regret_stp_7[slice101],\n",
        "       simple_regret_stp_8[slice101],\n",
        "       simple_regret_stp_9[slice101],\n",
        "       simple_regret_stp_10[slice101],\n",
        "       simple_regret_stp_11[slice101],\n",
        "       simple_regret_stp_12[slice101],\n",
        "       simple_regret_stp_13[slice101],\n",
        "       simple_regret_stp_14[slice101],\n",
        "       simple_regret_stp_15[slice101],\n",
        "       simple_regret_stp_16[slice101],\n",
        "       simple_regret_stp_17[slice101],\n",
        "       simple_regret_stp_18[slice101],\n",
        "       simple_regret_stp_19[slice101],\n",
        "       simple_regret_stp_20[slice101]]\n",
        "\n",
        "gp101_results = pd.DataFrame(gp101).sort_values(by=[0], ascending=False)\n",
        "stp101_results = pd.DataFrame(stp101).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - gp:\n",
        "lower_gp101 = np.asarray(gp101_results[4:5][0])[0]\n",
        "median_gp101 = np.asarray(gp101_results[9:10][0])[0]\n",
        "upper_gp101 = np.asarray(gp101_results[14:15][0])[0]\n",
        "\n",
        "lower_stp101 = np.asarray(stp101_results[4:5][0])[0]\n",
        "median_stp101 = np.asarray(stp101_results[9:10][0])[0]\n",
        "upper_stp101 = np.asarray(stp101_results[14:15][0])[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "wetKUCmLJLlb"
      },
      "outputs": [],
      "source": [
        "# Iteration2 :\n",
        "\n",
        "slice2 = 1\n",
        "\n",
        "gp2 = [simple_regret_gp_1[slice2],\n",
        "       simple_regret_gp_2[slice2],\n",
        "       simple_regret_gp_3[slice2],\n",
        "       simple_regret_gp_4[slice2],\n",
        "       simple_regret_gp_5[slice2],\n",
        "       simple_regret_gp_6[slice2],\n",
        "       simple_regret_gp_7[slice2],\n",
        "       simple_regret_gp_8[slice2],\n",
        "       simple_regret_gp_9[slice2],\n",
        "       simple_regret_gp_10[slice2],\n",
        "       simple_regret_gp_11[slice2],\n",
        "       simple_regret_gp_12[slice2],\n",
        "       simple_regret_gp_13[slice2],\n",
        "       simple_regret_gp_14[slice2],\n",
        "       simple_regret_gp_15[slice2],\n",
        "       simple_regret_gp_16[slice2],\n",
        "       simple_regret_gp_17[slice2],\n",
        "       simple_regret_gp_18[slice2],\n",
        "       simple_regret_gp_19[slice2],\n",
        "       simple_regret_gp_20[slice2]]\n",
        "\n",
        "stp2 = [simple_regret_stp_1[slice2],\n",
        "       simple_regret_stp_2[slice2],\n",
        "       simple_regret_stp_3[slice2],\n",
        "       simple_regret_stp_4[slice2],\n",
        "       simple_regret_stp_5[slice2],\n",
        "       simple_regret_stp_6[slice2],\n",
        "       simple_regret_stp_7[slice2],\n",
        "       simple_regret_stp_8[slice2],\n",
        "       simple_regret_stp_9[slice2],\n",
        "       simple_regret_stp_10[slice2],\n",
        "       simple_regret_stp_11[slice2],\n",
        "       simple_regret_stp_12[slice2],\n",
        "       simple_regret_stp_13[slice2],\n",
        "       simple_regret_stp_14[slice2],\n",
        "       simple_regret_stp_15[slice2],\n",
        "       simple_regret_stp_16[slice2],\n",
        "       simple_regret_stp_17[slice2],\n",
        "       simple_regret_stp_18[slice2],\n",
        "       simple_regret_stp_19[slice2],\n",
        "       simple_regret_stp_20[slice2]]\n",
        "\n",
        "gp2_results = pd.DataFrame(gp2).sort_values(by=[0], ascending=False)\n",
        "stp2_results = pd.DataFrame(stp2).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - gp:\n",
        "lower_gp2 = np.asarray(gp2_results[4:5][0])[0]\n",
        "median_gp2 = np.asarray(gp2_results[9:10][0])[0]\n",
        "upper_gp2 = np.asarray(gp2_results[14:15][0])[0]\n",
        "\n",
        "lower_stp2 = np.asarray(stp2_results[4:5][0])[0]\n",
        "median_stp2 = np.asarray(stp2_results[9:10][0])[0]\n",
        "upper_stp2 = np.asarray(stp2_results[14:15][0])[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "8dIyaTLKJLlc"
      },
      "outputs": [],
      "source": [
        "# Iteration12 :\n",
        "\n",
        "slice12 = 11\n",
        "\n",
        "gp12 = [simple_regret_gp_1[slice12],\n",
        "       simple_regret_gp_2[slice12],\n",
        "       simple_regret_gp_3[slice12],\n",
        "       simple_regret_gp_4[slice12],\n",
        "       simple_regret_gp_5[slice12],\n",
        "       simple_regret_gp_6[slice12],\n",
        "       simple_regret_gp_7[slice12],\n",
        "       simple_regret_gp_8[slice12],\n",
        "       simple_regret_gp_9[slice12],\n",
        "       simple_regret_gp_10[slice12],\n",
        "       simple_regret_gp_11[slice12],\n",
        "       simple_regret_gp_12[slice12],\n",
        "       simple_regret_gp_13[slice12],\n",
        "       simple_regret_gp_14[slice12],\n",
        "       simple_regret_gp_15[slice12],\n",
        "       simple_regret_gp_16[slice12],\n",
        "       simple_regret_gp_17[slice12],\n",
        "       simple_regret_gp_18[slice12],\n",
        "       simple_regret_gp_19[slice12],\n",
        "       simple_regret_gp_20[slice12]]\n",
        "\n",
        "stp12 = [simple_regret_stp_1[slice12],\n",
        "       simple_regret_stp_2[slice12],\n",
        "       simple_regret_stp_3[slice12],\n",
        "       simple_regret_stp_4[slice12],\n",
        "       simple_regret_stp_5[slice12],\n",
        "       simple_regret_stp_6[slice12],\n",
        "       simple_regret_stp_7[slice12],\n",
        "       simple_regret_stp_8[slice12],\n",
        "       simple_regret_stp_9[slice12],\n",
        "       simple_regret_stp_10[slice12],\n",
        "       simple_regret_stp_11[slice12],\n",
        "       simple_regret_stp_12[slice12],\n",
        "       simple_regret_stp_13[slice12],\n",
        "       simple_regret_stp_14[slice12],\n",
        "       simple_regret_stp_15[slice12],\n",
        "       simple_regret_stp_16[slice12],\n",
        "       simple_regret_stp_17[slice12],\n",
        "       simple_regret_stp_18[slice12],\n",
        "       simple_regret_stp_19[slice12],\n",
        "       simple_regret_stp_20[slice12]]\n",
        "\n",
        "gp12_results = pd.DataFrame(gp12).sort_values(by=[0], ascending=False)\n",
        "stp12_results = pd.DataFrame(stp12).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - gp:\n",
        "lower_gp12 = np.asarray(gp12_results[4:5][0])[0]\n",
        "median_gp12 = np.asarray(gp12_results[9:10][0])[0]\n",
        "upper_gp12 = np.asarray(gp12_results[14:15][0])[0]\n",
        "\n",
        "lower_stp12 = np.asarray(stp12_results[4:5][0])[0]\n",
        "median_stp12 = np.asarray(stp12_results[9:10][0])[0]\n",
        "upper_stp12 = np.asarray(stp12_results[14:15][0])[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "qbnFhjNQJLld"
      },
      "outputs": [],
      "source": [
        "# Iteration22 :\n",
        "\n",
        "slice22 = 21\n",
        "\n",
        "gp22 = [simple_regret_gp_1[slice22],\n",
        "       simple_regret_gp_2[slice22],\n",
        "       simple_regret_gp_3[slice22],\n",
        "       simple_regret_gp_4[slice22],\n",
        "       simple_regret_gp_5[slice22],\n",
        "       simple_regret_gp_6[slice22],\n",
        "       simple_regret_gp_7[slice22],\n",
        "       simple_regret_gp_8[slice22],\n",
        "       simple_regret_gp_9[slice22],\n",
        "       simple_regret_gp_10[slice22],\n",
        "       simple_regret_gp_11[slice22],\n",
        "       simple_regret_gp_12[slice22],\n",
        "       simple_regret_gp_13[slice22],\n",
        "       simple_regret_gp_14[slice22],\n",
        "       simple_regret_gp_15[slice22],\n",
        "       simple_regret_gp_16[slice22],\n",
        "       simple_regret_gp_17[slice22],\n",
        "       simple_regret_gp_18[slice22],\n",
        "       simple_regret_gp_19[slice22],\n",
        "       simple_regret_gp_20[slice22]]\n",
        "\n",
        "stp22 = [simple_regret_stp_1[slice22],\n",
        "       simple_regret_stp_2[slice22],\n",
        "       simple_regret_stp_3[slice22],\n",
        "       simple_regret_stp_4[slice22],\n",
        "       simple_regret_stp_5[slice22],\n",
        "       simple_regret_stp_6[slice22],\n",
        "       simple_regret_stp_7[slice22],\n",
        "       simple_regret_stp_8[slice22],\n",
        "       simple_regret_stp_9[slice22],\n",
        "       simple_regret_stp_10[slice22],\n",
        "       simple_regret_stp_11[slice22],\n",
        "       simple_regret_stp_12[slice22],\n",
        "       simple_regret_stp_13[slice22],\n",
        "       simple_regret_stp_14[slice22],\n",
        "       simple_regret_stp_15[slice22],\n",
        "       simple_regret_stp_16[slice22],\n",
        "       simple_regret_stp_17[slice22],\n",
        "       simple_regret_stp_18[slice22],\n",
        "       simple_regret_stp_19[slice22],\n",
        "       simple_regret_stp_20[slice22]]\n",
        "\n",
        "gp22_results = pd.DataFrame(gp22).sort_values(by=[0], ascending=False)\n",
        "stp22_results = pd.DataFrame(stp22).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - gp:\n",
        "lower_gp22 = np.asarray(gp22_results[4:5][0])[0]\n",
        "median_gp22 = np.asarray(gp22_results[9:10][0])[0]\n",
        "upper_gp22 = np.asarray(gp22_results[14:15][0])[0]\n",
        "\n",
        "lower_stp22 = np.asarray(stp22_results[4:5][0])[0]\n",
        "median_stp22 = np.asarray(stp22_results[9:10][0])[0]\n",
        "upper_stp22 = np.asarray(stp22_results[14:15][0])[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "tDPQgdwzJLld"
      },
      "outputs": [],
      "source": [
        "# Iteration32 :\n",
        "\n",
        "slice32 = 31\n",
        "\n",
        "gp32 = [simple_regret_gp_1[slice32],\n",
        "       simple_regret_gp_2[slice32],\n",
        "       simple_regret_gp_3[slice32],\n",
        "       simple_regret_gp_4[slice32],\n",
        "       simple_regret_gp_5[slice32],\n",
        "       simple_regret_gp_6[slice32],\n",
        "       simple_regret_gp_7[slice32],\n",
        "       simple_regret_gp_8[slice32],\n",
        "       simple_regret_gp_9[slice32],\n",
        "       simple_regret_gp_10[slice32],\n",
        "       simple_regret_gp_11[slice32],\n",
        "       simple_regret_gp_12[slice32],\n",
        "       simple_regret_gp_13[slice32],\n",
        "       simple_regret_gp_14[slice32],\n",
        "       simple_regret_gp_15[slice32],\n",
        "       simple_regret_gp_16[slice32],\n",
        "       simple_regret_gp_17[slice32],\n",
        "       simple_regret_gp_18[slice32],\n",
        "       simple_regret_gp_19[slice32],\n",
        "       simple_regret_gp_20[slice32]]\n",
        "\n",
        "stp32 = [simple_regret_stp_1[slice32],\n",
        "       simple_regret_stp_2[slice32],\n",
        "       simple_regret_stp_3[slice32],\n",
        "       simple_regret_stp_4[slice32],\n",
        "       simple_regret_stp_5[slice32],\n",
        "       simple_regret_stp_6[slice32],\n",
        "       simple_regret_stp_7[slice32],\n",
        "       simple_regret_stp_8[slice32],\n",
        "       simple_regret_stp_9[slice32],\n",
        "       simple_regret_stp_10[slice32],\n",
        "       simple_regret_stp_11[slice32],\n",
        "       simple_regret_stp_12[slice32],\n",
        "       simple_regret_stp_13[slice32],\n",
        "       simple_regret_stp_14[slice32],\n",
        "       simple_regret_stp_15[slice32],\n",
        "       simple_regret_stp_16[slice32],\n",
        "       simple_regret_stp_17[slice32],\n",
        "       simple_regret_stp_18[slice32],\n",
        "       simple_regret_stp_19[slice32],\n",
        "       simple_regret_stp_20[slice32]]\n",
        "\n",
        "gp32_results = pd.DataFrame(gp32).sort_values(by=[0], ascending=False)\n",
        "stp32_results = pd.DataFrame(stp32).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - gp:\n",
        "lower_gp32 = np.asarray(gp32_results[4:5][0])[0]\n",
        "median_gp32 = np.asarray(gp32_results[9:10][0])[0]\n",
        "upper_gp32 = np.asarray(gp32_results[14:15][0])[0]\n",
        "\n",
        "lower_stp32 = np.asarray(stp32_results[4:5][0])[0]\n",
        "median_stp32 = np.asarray(stp32_results[9:10][0])[0]\n",
        "upper_stp32 = np.asarray(stp32_results[14:15][0])[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "9TcH0KpuJLle"
      },
      "outputs": [],
      "source": [
        "# Iteration42 :\n",
        "\n",
        "slice42 = 41\n",
        "\n",
        "gp42 = [simple_regret_gp_1[slice42],\n",
        "       simple_regret_gp_2[slice42],\n",
        "       simple_regret_gp_3[slice42],\n",
        "       simple_regret_gp_4[slice42],\n",
        "       simple_regret_gp_5[slice42],\n",
        "       simple_regret_gp_6[slice42],\n",
        "       simple_regret_gp_7[slice42],\n",
        "       simple_regret_gp_8[slice42],\n",
        "       simple_regret_gp_9[slice42],\n",
        "       simple_regret_gp_10[slice42],\n",
        "       simple_regret_gp_11[slice42],\n",
        "       simple_regret_gp_12[slice42],\n",
        "       simple_regret_gp_13[slice42],\n",
        "       simple_regret_gp_14[slice42],\n",
        "       simple_regret_gp_15[slice42],\n",
        "       simple_regret_gp_16[slice42],\n",
        "       simple_regret_gp_17[slice42],\n",
        "       simple_regret_gp_18[slice42],\n",
        "       simple_regret_gp_19[slice42],\n",
        "       simple_regret_gp_20[slice42]]\n",
        "\n",
        "stp42 = [simple_regret_stp_1[slice42],\n",
        "       simple_regret_stp_2[slice42],\n",
        "       simple_regret_stp_3[slice42],\n",
        "       simple_regret_stp_4[slice42],\n",
        "       simple_regret_stp_5[slice42],\n",
        "       simple_regret_stp_6[slice42],\n",
        "       simple_regret_stp_7[slice42],\n",
        "       simple_regret_stp_8[slice42],\n",
        "       simple_regret_stp_9[slice42],\n",
        "       simple_regret_stp_10[slice42],\n",
        "       simple_regret_stp_11[slice42],\n",
        "       simple_regret_stp_12[slice42],\n",
        "       simple_regret_stp_13[slice42],\n",
        "       simple_regret_stp_14[slice42],\n",
        "       simple_regret_stp_15[slice42],\n",
        "       simple_regret_stp_16[slice42],\n",
        "       simple_regret_stp_17[slice42],\n",
        "       simple_regret_stp_18[slice42],\n",
        "       simple_regret_stp_19[slice42],\n",
        "       simple_regret_stp_20[slice42]]\n",
        "\n",
        "gp42_results = pd.DataFrame(gp42).sort_values(by=[0], ascending=False)\n",
        "stp42_results = pd.DataFrame(stp42).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - gp:\n",
        "lower_gp42 = np.asarray(gp42_results[4:5][0])[0]\n",
        "median_gp42 = np.asarray(gp42_results[9:10][0])[0]\n",
        "upper_gp42 = np.asarray(gp42_results[14:15][0])[0]\n",
        "\n",
        "lower_stp42 = np.asarray(stp42_results[4:5][0])[0]\n",
        "median_stp42 = np.asarray(stp42_results[9:10][0])[0]\n",
        "upper_stp42 = np.asarray(stp42_results[14:15][0])[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "vOAnq-c1JLle"
      },
      "outputs": [],
      "source": [
        "# Iteration52 :\n",
        "\n",
        "slice52 = 51\n",
        "\n",
        "gp52 = [simple_regret_gp_1[slice52],\n",
        "       simple_regret_gp_2[slice52],\n",
        "       simple_regret_gp_3[slice52],\n",
        "       simple_regret_gp_4[slice52],\n",
        "       simple_regret_gp_5[slice52],\n",
        "       simple_regret_gp_6[slice52],\n",
        "       simple_regret_gp_7[slice52],\n",
        "       simple_regret_gp_8[slice52],\n",
        "       simple_regret_gp_9[slice52],\n",
        "       simple_regret_gp_10[slice52],\n",
        "       simple_regret_gp_11[slice52],\n",
        "       simple_regret_gp_12[slice52],\n",
        "       simple_regret_gp_13[slice52],\n",
        "       simple_regret_gp_14[slice52],\n",
        "       simple_regret_gp_15[slice52],\n",
        "       simple_regret_gp_16[slice52],\n",
        "       simple_regret_gp_17[slice52],\n",
        "       simple_regret_gp_18[slice52],\n",
        "       simple_regret_gp_19[slice52],\n",
        "       simple_regret_gp_20[slice52]]\n",
        "\n",
        "stp52 = [simple_regret_stp_1[slice52],\n",
        "       simple_regret_stp_2[slice52],\n",
        "       simple_regret_stp_3[slice52],\n",
        "       simple_regret_stp_4[slice52],\n",
        "       simple_regret_stp_5[slice52],\n",
        "       simple_regret_stp_6[slice52],\n",
        "       simple_regret_stp_7[slice52],\n",
        "       simple_regret_stp_8[slice52],\n",
        "       simple_regret_stp_9[slice52],\n",
        "       simple_regret_stp_10[slice52],\n",
        "       simple_regret_stp_11[slice52],\n",
        "       simple_regret_stp_12[slice52],\n",
        "       simple_regret_stp_13[slice52],\n",
        "       simple_regret_stp_14[slice52],\n",
        "       simple_regret_stp_15[slice52],\n",
        "       simple_regret_stp_16[slice52],\n",
        "       simple_regret_stp_17[slice52],\n",
        "       simple_regret_stp_18[slice52],\n",
        "       simple_regret_stp_19[slice52],\n",
        "       simple_regret_stp_20[slice52]]\n",
        "\n",
        "gp52_results = pd.DataFrame(gp52).sort_values(by=[0], ascending=False)\n",
        "stp52_results = pd.DataFrame(stp52).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - gp:\n",
        "lower_gp52 = np.asarray(gp52_results[4:5][0])[0]\n",
        "median_gp52 = np.asarray(gp52_results[9:10][0])[0]\n",
        "upper_gp52 = np.asarray(gp52_results[14:15][0])[0]\n",
        "\n",
        "lower_stp52 = np.asarray(stp52_results[4:5][0])[0]\n",
        "median_stp52 = np.asarray(stp52_results[9:10][0])[0]\n",
        "upper_stp52 = np.asarray(stp52_results[14:15][0])[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "KSZeGTx1JLlf"
      },
      "outputs": [],
      "source": [
        "# Iteration62 :\n",
        "\n",
        "slice62 = 61\n",
        "\n",
        "gp62 = [simple_regret_gp_1[slice62],\n",
        "       simple_regret_gp_2[slice62],\n",
        "       simple_regret_gp_3[slice62],\n",
        "       simple_regret_gp_4[slice62],\n",
        "       simple_regret_gp_5[slice62],\n",
        "       simple_regret_gp_6[slice62],\n",
        "       simple_regret_gp_7[slice62],\n",
        "       simple_regret_gp_8[slice62],\n",
        "       simple_regret_gp_9[slice62],\n",
        "       simple_regret_gp_10[slice62],\n",
        "       simple_regret_gp_11[slice62],\n",
        "       simple_regret_gp_12[slice62],\n",
        "       simple_regret_gp_13[slice62],\n",
        "       simple_regret_gp_14[slice62],\n",
        "       simple_regret_gp_15[slice62],\n",
        "       simple_regret_gp_16[slice62],\n",
        "       simple_regret_gp_17[slice62],\n",
        "       simple_regret_gp_18[slice62],\n",
        "       simple_regret_gp_19[slice62],\n",
        "       simple_regret_gp_20[slice62]]\n",
        "\n",
        "stp62 = [simple_regret_stp_1[slice62],\n",
        "       simple_regret_stp_2[slice62],\n",
        "       simple_regret_stp_3[slice62],\n",
        "       simple_regret_stp_4[slice62],\n",
        "       simple_regret_stp_5[slice62],\n",
        "       simple_regret_stp_6[slice62],\n",
        "       simple_regret_stp_7[slice62],\n",
        "       simple_regret_stp_8[slice62],\n",
        "       simple_regret_stp_9[slice62],\n",
        "       simple_regret_stp_10[slice62],\n",
        "       simple_regret_stp_11[slice62],\n",
        "       simple_regret_stp_12[slice62],\n",
        "       simple_regret_stp_13[slice62],\n",
        "       simple_regret_stp_14[slice62],\n",
        "       simple_regret_stp_15[slice62],\n",
        "       simple_regret_stp_16[slice62],\n",
        "       simple_regret_stp_17[slice62],\n",
        "       simple_regret_stp_18[slice62],\n",
        "       simple_regret_stp_19[slice62],\n",
        "       simple_regret_stp_20[slice62]]\n",
        "\n",
        "gp62_results = pd.DataFrame(gp62).sort_values(by=[0], ascending=False)\n",
        "stp62_results = pd.DataFrame(stp62).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - gp:\n",
        "lower_gp62 = np.asarray(gp62_results[4:5][0])[0]\n",
        "median_gp62 = np.asarray(gp62_results[9:10][0])[0]\n",
        "upper_gp62 = np.asarray(gp62_results[14:15][0])[0]\n",
        "\n",
        "lower_stp62 = np.asarray(stp62_results[4:5][0])[0]\n",
        "median_stp62 = np.asarray(stp62_results[9:10][0])[0]\n",
        "upper_stp62 = np.asarray(stp62_results[14:15][0])[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "-Eld0MsuJLlg"
      },
      "outputs": [],
      "source": [
        "# Iteration72 :\n",
        "\n",
        "slice72 = 71\n",
        "\n",
        "gp72 = [simple_regret_gp_1[slice72],\n",
        "       simple_regret_gp_2[slice72],\n",
        "       simple_regret_gp_3[slice72],\n",
        "       simple_regret_gp_4[slice72],\n",
        "       simple_regret_gp_5[slice72],\n",
        "       simple_regret_gp_6[slice72],\n",
        "       simple_regret_gp_7[slice72],\n",
        "       simple_regret_gp_8[slice72],\n",
        "       simple_regret_gp_9[slice72],\n",
        "       simple_regret_gp_10[slice72],\n",
        "       simple_regret_gp_11[slice72],\n",
        "       simple_regret_gp_12[slice72],\n",
        "       simple_regret_gp_13[slice72],\n",
        "       simple_regret_gp_14[slice72],\n",
        "       simple_regret_gp_15[slice72],\n",
        "       simple_regret_gp_16[slice72],\n",
        "       simple_regret_gp_17[slice72],\n",
        "       simple_regret_gp_18[slice72],\n",
        "       simple_regret_gp_19[slice72],\n",
        "       simple_regret_gp_20[slice72]]\n",
        "\n",
        "stp72 = [simple_regret_stp_1[slice72],\n",
        "       simple_regret_stp_2[slice72],\n",
        "       simple_regret_stp_3[slice72],\n",
        "       simple_regret_stp_4[slice72],\n",
        "       simple_regret_stp_5[slice72],\n",
        "       simple_regret_stp_6[slice72],\n",
        "       simple_regret_stp_7[slice72],\n",
        "       simple_regret_stp_8[slice72],\n",
        "       simple_regret_stp_9[slice72],\n",
        "       simple_regret_stp_10[slice72],\n",
        "       simple_regret_stp_11[slice72],\n",
        "       simple_regret_stp_12[slice72],\n",
        "       simple_regret_stp_13[slice72],\n",
        "       simple_regret_stp_14[slice72],\n",
        "       simple_regret_stp_15[slice72],\n",
        "       simple_regret_stp_16[slice72],\n",
        "       simple_regret_stp_17[slice72],\n",
        "       simple_regret_stp_18[slice72],\n",
        "       simple_regret_stp_19[slice72],\n",
        "       simple_regret_stp_20[slice72]]\n",
        "\n",
        "gp72_results = pd.DataFrame(gp72).sort_values(by=[0], ascending=False)\n",
        "stp72_results = pd.DataFrame(stp72).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - gp:\n",
        "lower_gp72 = np.asarray(gp72_results[4:5][0])[0]\n",
        "median_gp72 = np.asarray(gp72_results[9:10][0])[0]\n",
        "upper_gp72 = np.asarray(gp72_results[14:15][0])[0]\n",
        "\n",
        "lower_stp72 = np.asarray(stp72_results[4:5][0])[0]\n",
        "median_stp72 = np.asarray(stp72_results[9:10][0])[0]\n",
        "upper_stp72 = np.asarray(stp72_results[14:15][0])[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "jqls7rj0JLlh"
      },
      "outputs": [],
      "source": [
        "# Iteration82 :\n",
        "\n",
        "slice82 = 81\n",
        "\n",
        "gp82 = [simple_regret_gp_1[slice82],\n",
        "       simple_regret_gp_2[slice82],\n",
        "       simple_regret_gp_3[slice82],\n",
        "       simple_regret_gp_4[slice82],\n",
        "       simple_regret_gp_5[slice82],\n",
        "       simple_regret_gp_6[slice82],\n",
        "       simple_regret_gp_7[slice82],\n",
        "       simple_regret_gp_8[slice82],\n",
        "       simple_regret_gp_9[slice82],\n",
        "       simple_regret_gp_10[slice82],\n",
        "       simple_regret_gp_11[slice82],\n",
        "       simple_regret_gp_12[slice82],\n",
        "       simple_regret_gp_13[slice82],\n",
        "       simple_regret_gp_14[slice82],\n",
        "       simple_regret_gp_15[slice82],\n",
        "       simple_regret_gp_16[slice82],\n",
        "       simple_regret_gp_17[slice82],\n",
        "       simple_regret_gp_18[slice82],\n",
        "       simple_regret_gp_19[slice82],\n",
        "       simple_regret_gp_20[slice82]]\n",
        "\n",
        "stp82 = [simple_regret_stp_1[slice82],\n",
        "       simple_regret_stp_2[slice82],\n",
        "       simple_regret_stp_3[slice82],\n",
        "       simple_regret_stp_4[slice82],\n",
        "       simple_regret_stp_5[slice82],\n",
        "       simple_regret_stp_6[slice82],\n",
        "       simple_regret_stp_7[slice82],\n",
        "       simple_regret_stp_8[slice82],\n",
        "       simple_regret_stp_9[slice82],\n",
        "       simple_regret_stp_10[slice82],\n",
        "       simple_regret_stp_11[slice82],\n",
        "       simple_regret_stp_12[slice82],\n",
        "       simple_regret_stp_13[slice82],\n",
        "       simple_regret_stp_14[slice82],\n",
        "       simple_regret_stp_15[slice82],\n",
        "       simple_regret_stp_16[slice82],\n",
        "       simple_regret_stp_17[slice82],\n",
        "       simple_regret_stp_18[slice82],\n",
        "       simple_regret_stp_19[slice82],\n",
        "       simple_regret_stp_20[slice82]]\n",
        "\n",
        "gp82_results = pd.DataFrame(gp82).sort_values(by=[0], ascending=False)\n",
        "stp82_results = pd.DataFrame(stp82).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - gp:\n",
        "lower_gp82 = np.asarray(gp82_results[4:5][0])[0]\n",
        "median_gp82 = np.asarray(gp82_results[9:10][0])[0]\n",
        "upper_gp82 = np.asarray(gp82_results[14:15][0])[0]\n",
        "\n",
        "lower_stp82 = np.asarray(stp82_results[4:5][0])[0]\n",
        "median_stp82 = np.asarray(stp82_results[9:10][0])[0]\n",
        "upper_stp82 = np.asarray(stp82_results[14:15][0])[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "ePbYzuu6JLli"
      },
      "outputs": [],
      "source": [
        "# Iteration92 :\n",
        "\n",
        "slice92 = 91\n",
        "\n",
        "gp92 = [simple_regret_gp_1[slice92],\n",
        "       simple_regret_gp_2[slice92],\n",
        "       simple_regret_gp_3[slice92],\n",
        "       simple_regret_gp_4[slice92],\n",
        "       simple_regret_gp_5[slice92],\n",
        "       simple_regret_gp_6[slice92],\n",
        "       simple_regret_gp_7[slice92],\n",
        "       simple_regret_gp_8[slice92],\n",
        "       simple_regret_gp_9[slice92],\n",
        "       simple_regret_gp_10[slice92],\n",
        "       simple_regret_gp_11[slice92],\n",
        "       simple_regret_gp_12[slice92],\n",
        "       simple_regret_gp_13[slice92],\n",
        "       simple_regret_gp_14[slice92],\n",
        "       simple_regret_gp_15[slice92],\n",
        "       simple_regret_gp_16[slice92],\n",
        "       simple_regret_gp_17[slice92],\n",
        "       simple_regret_gp_18[slice92],\n",
        "       simple_regret_gp_19[slice92],\n",
        "       simple_regret_gp_20[slice92]]\n",
        "\n",
        "stp92 = [simple_regret_stp_1[slice92],\n",
        "       simple_regret_stp_2[slice92],\n",
        "       simple_regret_stp_3[slice92],\n",
        "       simple_regret_stp_4[slice92],\n",
        "       simple_regret_stp_5[slice92],\n",
        "       simple_regret_stp_6[slice92],\n",
        "       simple_regret_stp_7[slice92],\n",
        "       simple_regret_stp_8[slice92],\n",
        "       simple_regret_stp_9[slice92],\n",
        "       simple_regret_stp_10[slice92],\n",
        "       simple_regret_stp_11[slice92],\n",
        "       simple_regret_stp_12[slice92],\n",
        "       simple_regret_stp_13[slice92],\n",
        "       simple_regret_stp_14[slice92],\n",
        "       simple_regret_stp_15[slice92],\n",
        "       simple_regret_stp_16[slice92],\n",
        "       simple_regret_stp_17[slice92],\n",
        "       simple_regret_stp_18[slice92],\n",
        "       simple_regret_stp_19[slice92],\n",
        "       simple_regret_stp_20[slice92]]\n",
        "\n",
        "gp92_results = pd.DataFrame(gp92).sort_values(by=[0], ascending=False)\n",
        "stp92_results = pd.DataFrame(stp92).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - gp:\n",
        "lower_gp92 = np.asarray(gp92_results[4:5][0])[0]\n",
        "median_gp92 = np.asarray(gp92_results[9:10][0])[0]\n",
        "upper_gp92 = np.asarray(gp92_results[14:15][0])[0]\n",
        "\n",
        "lower_stp92 = np.asarray(stp92_results[4:5][0])[0]\n",
        "median_stp92 = np.asarray(stp92_results[9:10][0])[0]\n",
        "upper_stp92 = np.asarray(stp92_results[14:15][0])[0]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "1_6u8LF1JLlt"
      },
      "outputs": [],
      "source": [
        "# Iteration3 :\n",
        "\n",
        "slice3 = 2\n",
        "\n",
        "gp3 = [simple_regret_gp_1[slice3],\n",
        "       simple_regret_gp_2[slice3],\n",
        "       simple_regret_gp_3[slice3],\n",
        "       simple_regret_gp_4[slice3],\n",
        "       simple_regret_gp_5[slice3],\n",
        "       simple_regret_gp_6[slice3],\n",
        "       simple_regret_gp_7[slice3],\n",
        "       simple_regret_gp_8[slice3],\n",
        "       simple_regret_gp_9[slice3],\n",
        "       simple_regret_gp_10[slice3],\n",
        "       simple_regret_gp_11[slice3],\n",
        "       simple_regret_gp_12[slice3],\n",
        "       simple_regret_gp_13[slice3],\n",
        "       simple_regret_gp_14[slice3],\n",
        "       simple_regret_gp_15[slice3],\n",
        "       simple_regret_gp_16[slice3],\n",
        "       simple_regret_gp_17[slice3],\n",
        "       simple_regret_gp_18[slice3],\n",
        "       simple_regret_gp_19[slice3],\n",
        "       simple_regret_gp_20[slice3]]\n",
        "\n",
        "stp3 = [simple_regret_stp_1[slice3],\n",
        "       simple_regret_stp_2[slice3],\n",
        "       simple_regret_stp_3[slice3],\n",
        "       simple_regret_stp_4[slice3],\n",
        "       simple_regret_stp_5[slice3],\n",
        "       simple_regret_stp_6[slice3],\n",
        "       simple_regret_stp_7[slice3],\n",
        "       simple_regret_stp_8[slice3],\n",
        "       simple_regret_stp_9[slice3],\n",
        "       simple_regret_stp_10[slice3],\n",
        "       simple_regret_stp_11[slice3],\n",
        "       simple_regret_stp_12[slice3],\n",
        "       simple_regret_stp_13[slice3],\n",
        "       simple_regret_stp_14[slice3],\n",
        "       simple_regret_stp_15[slice3],\n",
        "       simple_regret_stp_16[slice3],\n",
        "       simple_regret_stp_17[slice3],\n",
        "       simple_regret_stp_18[slice3],\n",
        "       simple_regret_stp_19[slice3],\n",
        "       simple_regret_stp_20[slice3]]\n",
        "\n",
        "gp3_results = pd.DataFrame(gp3).sort_values(by=[0], ascending=False)\n",
        "stp3_results = pd.DataFrame(stp3).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - gp:\n",
        "lower_gp3 = np.asarray(gp3_results[4:5][0])[0]\n",
        "median_gp3 = np.asarray(gp3_results[9:10][0])[0]\n",
        "upper_gp3 = np.asarray(gp3_results[14:15][0])[0]\n",
        "\n",
        "lower_stp3 = np.asarray(stp3_results[4:5][0])[0]\n",
        "median_stp3 = np.asarray(stp3_results[9:10][0])[0]\n",
        "upper_stp3 = np.asarray(stp3_results[14:15][0])[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "GGEAa73pJLlu"
      },
      "outputs": [],
      "source": [
        "# Iteration13 :\n",
        "\n",
        "slice13 = 12\n",
        "\n",
        "gp13 = [simple_regret_gp_1[slice13],\n",
        "       simple_regret_gp_2[slice13],\n",
        "       simple_regret_gp_3[slice13],\n",
        "       simple_regret_gp_4[slice13],\n",
        "       simple_regret_gp_5[slice13],\n",
        "       simple_regret_gp_6[slice13],\n",
        "       simple_regret_gp_7[slice13],\n",
        "       simple_regret_gp_8[slice13],\n",
        "       simple_regret_gp_9[slice13],\n",
        "       simple_regret_gp_10[slice13],\n",
        "       simple_regret_gp_11[slice13],\n",
        "       simple_regret_gp_12[slice13],\n",
        "       simple_regret_gp_13[slice13],\n",
        "       simple_regret_gp_14[slice13],\n",
        "       simple_regret_gp_15[slice13],\n",
        "       simple_regret_gp_16[slice13],\n",
        "       simple_regret_gp_17[slice13],\n",
        "       simple_regret_gp_18[slice13],\n",
        "       simple_regret_gp_19[slice13],\n",
        "       simple_regret_gp_20[slice13]]\n",
        "\n",
        "stp13 = [simple_regret_stp_1[slice13],\n",
        "       simple_regret_stp_2[slice13],\n",
        "       simple_regret_stp_3[slice13],\n",
        "       simple_regret_stp_4[slice13],\n",
        "       simple_regret_stp_5[slice13],\n",
        "       simple_regret_stp_6[slice13],\n",
        "       simple_regret_stp_7[slice13],\n",
        "       simple_regret_stp_8[slice13],\n",
        "       simple_regret_stp_9[slice13],\n",
        "       simple_regret_stp_10[slice13],\n",
        "       simple_regret_stp_11[slice13],\n",
        "       simple_regret_stp_12[slice13],\n",
        "       simple_regret_stp_13[slice13],\n",
        "       simple_regret_stp_14[slice13],\n",
        "       simple_regret_stp_15[slice13],\n",
        "       simple_regret_stp_16[slice13],\n",
        "       simple_regret_stp_17[slice13],\n",
        "       simple_regret_stp_18[slice13],\n",
        "       simple_regret_stp_19[slice13],\n",
        "       simple_regret_stp_20[slice13]]\n",
        "\n",
        "gp13_results = pd.DataFrame(gp12).sort_values(by=[0], ascending=False)\n",
        "stp13_results = pd.DataFrame(stp12).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - gp:\n",
        "lower_gp13 = np.asarray(gp13_results[4:5][0])[0]\n",
        "median_gp13 = np.asarray(gp13_results[9:10][0])[0]\n",
        "upper_gp13 = np.asarray(gp13_results[14:15][0])[0]\n",
        "\n",
        "lower_stp13 = np.asarray(stp13_results[4:5][0])[0]\n",
        "median_stp13 = np.asarray(stp13_results[9:10][0])[0]\n",
        "upper_stp13 = np.asarray(stp13_results[14:15][0])[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "Gzw6RMXBJLlv"
      },
      "outputs": [],
      "source": [
        "# Iteration23 :\n",
        "\n",
        "slice23 = 22\n",
        "\n",
        "gp23 = [simple_regret_gp_1[slice23],\n",
        "       simple_regret_gp_2[slice23],\n",
        "       simple_regret_gp_3[slice23],\n",
        "       simple_regret_gp_4[slice23],\n",
        "       simple_regret_gp_5[slice23],\n",
        "       simple_regret_gp_6[slice23],\n",
        "       simple_regret_gp_7[slice23],\n",
        "       simple_regret_gp_8[slice23],\n",
        "       simple_regret_gp_9[slice23],\n",
        "       simple_regret_gp_10[slice23],\n",
        "       simple_regret_gp_11[slice23],\n",
        "       simple_regret_gp_12[slice23],\n",
        "       simple_regret_gp_13[slice23],\n",
        "       simple_regret_gp_14[slice23],\n",
        "       simple_regret_gp_15[slice23],\n",
        "       simple_regret_gp_16[slice23],\n",
        "       simple_regret_gp_17[slice23],\n",
        "       simple_regret_gp_18[slice23],\n",
        "       simple_regret_gp_19[slice23],\n",
        "       simple_regret_gp_20[slice23]]\n",
        "\n",
        "stp23 = [simple_regret_stp_1[slice23],\n",
        "       simple_regret_stp_2[slice23],\n",
        "       simple_regret_stp_3[slice23],\n",
        "       simple_regret_stp_4[slice23],\n",
        "       simple_regret_stp_5[slice23],\n",
        "       simple_regret_stp_6[slice23],\n",
        "       simple_regret_stp_7[slice23],\n",
        "       simple_regret_stp_8[slice23],\n",
        "       simple_regret_stp_9[slice23],\n",
        "       simple_regret_stp_10[slice23],\n",
        "       simple_regret_stp_11[slice23],\n",
        "       simple_regret_stp_12[slice23],\n",
        "       simple_regret_stp_13[slice23],\n",
        "       simple_regret_stp_14[slice23],\n",
        "       simple_regret_stp_15[slice23],\n",
        "       simple_regret_stp_16[slice23],\n",
        "       simple_regret_stp_17[slice23],\n",
        "       simple_regret_stp_18[slice23],\n",
        "       simple_regret_stp_19[slice23],\n",
        "       simple_regret_stp_20[slice23]]\n",
        "\n",
        "gp23_results = pd.DataFrame(gp23).sort_values(by=[0], ascending=False)\n",
        "stp23_results = pd.DataFrame(stp23).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - gp:\n",
        "lower_gp23 = np.asarray(gp23_results[4:5][0])[0]\n",
        "median_gp23 = np.asarray(gp23_results[9:10][0])[0]\n",
        "upper_gp23 = np.asarray(gp23_results[14:15][0])[0]\n",
        "\n",
        "lower_stp23 = np.asarray(stp23_results[4:5][0])[0]\n",
        "median_stp23 = np.asarray(stp23_results[9:10][0])[0]\n",
        "upper_stp23 = np.asarray(stp23_results[14:15][0])[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "Vp3Y90TyJLlw"
      },
      "outputs": [],
      "source": [
        "# Iteration33 :\n",
        "\n",
        "slice33 = 32\n",
        "\n",
        "gp33 = [simple_regret_gp_1[slice33],\n",
        "       simple_regret_gp_2[slice33],\n",
        "       simple_regret_gp_3[slice33],\n",
        "       simple_regret_gp_4[slice33],\n",
        "       simple_regret_gp_5[slice33],\n",
        "       simple_regret_gp_6[slice33],\n",
        "       simple_regret_gp_7[slice33],\n",
        "       simple_regret_gp_8[slice33],\n",
        "       simple_regret_gp_9[slice33],\n",
        "       simple_regret_gp_10[slice33],\n",
        "       simple_regret_gp_11[slice33],\n",
        "       simple_regret_gp_12[slice33],\n",
        "       simple_regret_gp_13[slice33],\n",
        "       simple_regret_gp_14[slice33],\n",
        "       simple_regret_gp_15[slice33],\n",
        "       simple_regret_gp_16[slice33],\n",
        "       simple_regret_gp_17[slice33],\n",
        "       simple_regret_gp_18[slice33],\n",
        "       simple_regret_gp_19[slice33],\n",
        "       simple_regret_gp_20[slice33]]\n",
        "\n",
        "stp33 = [simple_regret_stp_1[slice33],\n",
        "       simple_regret_stp_2[slice33],\n",
        "       simple_regret_stp_3[slice33],\n",
        "       simple_regret_stp_4[slice33],\n",
        "       simple_regret_stp_5[slice33],\n",
        "       simple_regret_stp_6[slice33],\n",
        "       simple_regret_stp_7[slice33],\n",
        "       simple_regret_stp_8[slice33],\n",
        "       simple_regret_stp_9[slice33],\n",
        "       simple_regret_stp_10[slice33],\n",
        "       simple_regret_stp_11[slice33],\n",
        "       simple_regret_stp_12[slice33],\n",
        "       simple_regret_stp_13[slice33],\n",
        "       simple_regret_stp_14[slice33],\n",
        "       simple_regret_stp_15[slice33],\n",
        "       simple_regret_stp_16[slice33],\n",
        "       simple_regret_stp_17[slice33],\n",
        "       simple_regret_stp_18[slice33],\n",
        "       simple_regret_stp_19[slice33],\n",
        "       simple_regret_stp_20[slice33]]\n",
        "\n",
        "gp33_results = pd.DataFrame(gp33).sort_values(by=[0], ascending=False)\n",
        "stp33_results = pd.DataFrame(stp33).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - gp:\n",
        "lower_gp33 = np.asarray(gp33_results[4:5][0])[0]\n",
        "median_gp33 = np.asarray(gp33_results[9:10][0])[0]\n",
        "upper_gp33 = np.asarray(gp33_results[14:15][0])[0]\n",
        "\n",
        "lower_stp33 = np.asarray(stp33_results[4:5][0])[0]\n",
        "median_stp33 = np.asarray(stp33_results[9:10][0])[0]\n",
        "upper_stp33 = np.asarray(stp33_results[14:15][0])[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "CqmTtBgVJLlx"
      },
      "outputs": [],
      "source": [
        "# Iteration43 :\n",
        "\n",
        "slice43 = 42\n",
        "\n",
        "gp43 = [simple_regret_gp_1[slice43],\n",
        "       simple_regret_gp_2[slice43],\n",
        "       simple_regret_gp_3[slice43],\n",
        "       simple_regret_gp_4[slice43],\n",
        "       simple_regret_gp_5[slice43],\n",
        "       simple_regret_gp_6[slice43],\n",
        "       simple_regret_gp_7[slice43],\n",
        "       simple_regret_gp_8[slice43],\n",
        "       simple_regret_gp_9[slice43],\n",
        "       simple_regret_gp_10[slice43],\n",
        "       simple_regret_gp_11[slice43],\n",
        "       simple_regret_gp_12[slice43],\n",
        "       simple_regret_gp_13[slice43],\n",
        "       simple_regret_gp_14[slice43],\n",
        "       simple_regret_gp_15[slice43],\n",
        "       simple_regret_gp_16[slice43],\n",
        "       simple_regret_gp_17[slice43],\n",
        "       simple_regret_gp_18[slice43],\n",
        "       simple_regret_gp_19[slice43],\n",
        "       simple_regret_gp_20[slice43]]\n",
        "\n",
        "stp43 = [simple_regret_stp_1[slice43],\n",
        "       simple_regret_stp_2[slice43],\n",
        "       simple_regret_stp_3[slice43],\n",
        "       simple_regret_stp_4[slice43],\n",
        "       simple_regret_stp_5[slice43],\n",
        "       simple_regret_stp_6[slice43],\n",
        "       simple_regret_stp_7[slice43],\n",
        "       simple_regret_stp_8[slice43],\n",
        "       simple_regret_stp_9[slice43],\n",
        "       simple_regret_stp_10[slice43],\n",
        "       simple_regret_stp_11[slice43],\n",
        "       simple_regret_stp_12[slice43],\n",
        "       simple_regret_stp_13[slice43],\n",
        "       simple_regret_stp_14[slice43],\n",
        "       simple_regret_stp_15[slice43],\n",
        "       simple_regret_stp_16[slice43],\n",
        "       simple_regret_stp_17[slice43],\n",
        "       simple_regret_stp_18[slice43],\n",
        "       simple_regret_stp_19[slice43],\n",
        "       simple_regret_stp_20[slice43]]\n",
        "\n",
        "gp43_results = pd.DataFrame(gp43).sort_values(by=[0], ascending=False)\n",
        "stp43_results = pd.DataFrame(stp43).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - gp:\n",
        "lower_gp43 = np.asarray(gp43_results[4:5][0])[0]\n",
        "median_gp43 = np.asarray(gp43_results[9:10][0])[0]\n",
        "upper_gp43 = np.asarray(gp43_results[14:15][0])[0]\n",
        "\n",
        "lower_stp43 = np.asarray(stp43_results[4:5][0])[0]\n",
        "median_stp43 = np.asarray(stp43_results[9:10][0])[0]\n",
        "upper_stp43 = np.asarray(stp43_results[14:15][0])[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "c4w_cxaNJLlx"
      },
      "outputs": [],
      "source": [
        "# Iteration53 :\n",
        "\n",
        "slice53 = 52\n",
        "\n",
        "gp53 = [simple_regret_gp_1[slice53],\n",
        "       simple_regret_gp_2[slice53],\n",
        "       simple_regret_gp_3[slice53],\n",
        "       simple_regret_gp_4[slice53],\n",
        "       simple_regret_gp_5[slice53],\n",
        "       simple_regret_gp_6[slice53],\n",
        "       simple_regret_gp_7[slice53],\n",
        "       simple_regret_gp_8[slice53],\n",
        "       simple_regret_gp_9[slice53],\n",
        "       simple_regret_gp_10[slice53],\n",
        "       simple_regret_gp_11[slice53],\n",
        "       simple_regret_gp_12[slice53],\n",
        "       simple_regret_gp_13[slice53],\n",
        "       simple_regret_gp_14[slice53],\n",
        "       simple_regret_gp_15[slice53],\n",
        "       simple_regret_gp_16[slice53],\n",
        "       simple_regret_gp_17[slice53],\n",
        "       simple_regret_gp_18[slice53],\n",
        "       simple_regret_gp_19[slice53],\n",
        "       simple_regret_gp_20[slice53]]\n",
        "\n",
        "stp53 = [simple_regret_stp_1[slice53],\n",
        "       simple_regret_stp_2[slice53],\n",
        "       simple_regret_stp_3[slice53],\n",
        "       simple_regret_stp_4[slice53],\n",
        "       simple_regret_stp_5[slice53],\n",
        "       simple_regret_stp_6[slice53],\n",
        "       simple_regret_stp_7[slice53],\n",
        "       simple_regret_stp_8[slice53],\n",
        "       simple_regret_stp_9[slice53],\n",
        "       simple_regret_stp_10[slice53],\n",
        "       simple_regret_stp_11[slice53],\n",
        "       simple_regret_stp_12[slice53],\n",
        "       simple_regret_stp_13[slice53],\n",
        "       simple_regret_stp_14[slice53],\n",
        "       simple_regret_stp_15[slice53],\n",
        "       simple_regret_stp_16[slice53],\n",
        "       simple_regret_stp_17[slice53],\n",
        "       simple_regret_stp_18[slice53],\n",
        "       simple_regret_stp_19[slice53],\n",
        "       simple_regret_stp_20[slice53]]\n",
        "\n",
        "gp53_results = pd.DataFrame(gp53).sort_values(by=[0], ascending=False)\n",
        "stp53_results = pd.DataFrame(stp53).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - gp:\n",
        "lower_gp53 = np.asarray(gp53_results[4:5][0])[0]\n",
        "median_gp53 = np.asarray(gp53_results[9:10][0])[0]\n",
        "upper_gp53 = np.asarray(gp53_results[14:15][0])[0]\n",
        "\n",
        "lower_stp53 = np.asarray(stp53_results[4:5][0])[0]\n",
        "median_stp53 = np.asarray(stp53_results[9:10][0])[0]\n",
        "upper_stp53 = np.asarray(stp53_results[14:15][0])[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "NLh7sC2vJLly"
      },
      "outputs": [],
      "source": [
        "# Iteration63 :\n",
        "\n",
        "slice63 = 62\n",
        "\n",
        "gp63 = [simple_regret_gp_1[slice63],\n",
        "       simple_regret_gp_2[slice63],\n",
        "       simple_regret_gp_3[slice63],\n",
        "       simple_regret_gp_4[slice63],\n",
        "       simple_regret_gp_5[slice63],\n",
        "       simple_regret_gp_6[slice63],\n",
        "       simple_regret_gp_7[slice63],\n",
        "       simple_regret_gp_8[slice63],\n",
        "       simple_regret_gp_9[slice63],\n",
        "       simple_regret_gp_10[slice63],\n",
        "       simple_regret_gp_11[slice63],\n",
        "       simple_regret_gp_12[slice63],\n",
        "       simple_regret_gp_13[slice63],\n",
        "       simple_regret_gp_14[slice63],\n",
        "       simple_regret_gp_15[slice63],\n",
        "       simple_regret_gp_16[slice63],\n",
        "       simple_regret_gp_17[slice63],\n",
        "       simple_regret_gp_18[slice63],\n",
        "       simple_regret_gp_19[slice63],\n",
        "       simple_regret_gp_20[slice63]]\n",
        "\n",
        "stp63 = [simple_regret_stp_1[slice63],\n",
        "       simple_regret_stp_2[slice63],\n",
        "       simple_regret_stp_3[slice63],\n",
        "       simple_regret_stp_4[slice63],\n",
        "       simple_regret_stp_5[slice63],\n",
        "       simple_regret_stp_6[slice63],\n",
        "       simple_regret_stp_7[slice63],\n",
        "       simple_regret_stp_8[slice63],\n",
        "       simple_regret_stp_9[slice63],\n",
        "       simple_regret_stp_10[slice63],\n",
        "       simple_regret_stp_11[slice63],\n",
        "       simple_regret_stp_12[slice63],\n",
        "       simple_regret_stp_13[slice63],\n",
        "       simple_regret_stp_14[slice63],\n",
        "       simple_regret_stp_15[slice63],\n",
        "       simple_regret_stp_16[slice63],\n",
        "       simple_regret_stp_17[slice63],\n",
        "       simple_regret_stp_18[slice63],\n",
        "       simple_regret_stp_19[slice63],\n",
        "       simple_regret_stp_20[slice63]]\n",
        "\n",
        "gp63_results = pd.DataFrame(gp63).sort_values(by=[0], ascending=False)\n",
        "stp63_results = pd.DataFrame(stp63).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - gp:\n",
        "lower_gp63 = np.asarray(gp63_results[4:5][0])[0]\n",
        "median_gp63 = np.asarray(gp63_results[9:10][0])[0]\n",
        "upper_gp63 = np.asarray(gp63_results[14:15][0])[0]\n",
        "\n",
        "lower_stp63 = np.asarray(stp63_results[4:5][0])[0]\n",
        "median_stp63 = np.asarray(stp63_results[9:10][0])[0]\n",
        "upper_stp63 = np.asarray(stp63_results[14:15][0])[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "CoZWTkawJLlz"
      },
      "outputs": [],
      "source": [
        "# Iteration73 :\n",
        "\n",
        "slice73 = 72\n",
        "\n",
        "gp73 = [simple_regret_gp_1[slice73],\n",
        "       simple_regret_gp_2[slice73],\n",
        "       simple_regret_gp_3[slice73],\n",
        "       simple_regret_gp_4[slice73],\n",
        "       simple_regret_gp_5[slice73],\n",
        "       simple_regret_gp_6[slice73],\n",
        "       simple_regret_gp_7[slice73],\n",
        "       simple_regret_gp_8[slice73],\n",
        "       simple_regret_gp_9[slice73],\n",
        "       simple_regret_gp_10[slice73],\n",
        "       simple_regret_gp_11[slice73],\n",
        "       simple_regret_gp_12[slice73],\n",
        "       simple_regret_gp_13[slice73],\n",
        "       simple_regret_gp_14[slice73],\n",
        "       simple_regret_gp_15[slice73],\n",
        "       simple_regret_gp_16[slice73],\n",
        "       simple_regret_gp_17[slice73],\n",
        "       simple_regret_gp_18[slice73],\n",
        "       simple_regret_gp_19[slice73],\n",
        "       simple_regret_gp_20[slice73]]\n",
        "\n",
        "stp73 = [simple_regret_stp_1[slice73],\n",
        "       simple_regret_stp_2[slice73],\n",
        "       simple_regret_stp_3[slice73],\n",
        "       simple_regret_stp_4[slice73],\n",
        "       simple_regret_stp_5[slice73],\n",
        "       simple_regret_stp_6[slice73],\n",
        "       simple_regret_stp_7[slice73],\n",
        "       simple_regret_stp_8[slice73],\n",
        "       simple_regret_stp_9[slice73],\n",
        "       simple_regret_stp_10[slice73],\n",
        "       simple_regret_stp_11[slice73],\n",
        "       simple_regret_stp_12[slice73],\n",
        "       simple_regret_stp_13[slice73],\n",
        "       simple_regret_stp_14[slice73],\n",
        "       simple_regret_stp_15[slice73],\n",
        "       simple_regret_stp_16[slice73],\n",
        "       simple_regret_stp_17[slice73],\n",
        "       simple_regret_stp_18[slice73],\n",
        "       simple_regret_stp_19[slice73],\n",
        "       simple_regret_stp_20[slice73]]\n",
        "\n",
        "gp73_results = pd.DataFrame(gp73).sort_values(by=[0], ascending=False)\n",
        "stp73_results = pd.DataFrame(stp73).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - gp:\n",
        "lower_gp73 = np.asarray(gp73_results[4:5][0])[0]\n",
        "median_gp73 = np.asarray(gp73_results[9:10][0])[0]\n",
        "upper_gp73 = np.asarray(gp73_results[14:15][0])[0]\n",
        "\n",
        "lower_stp73 = np.asarray(stp73_results[4:5][0])[0]\n",
        "median_stp73 = np.asarray(stp73_results[9:10][0])[0]\n",
        "upper_stp73 = np.asarray(stp73_results[14:15][0])[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "ujz05uLmJLlz"
      },
      "outputs": [],
      "source": [
        "# Iteration83 :\n",
        "\n",
        "slice83 = 82\n",
        "\n",
        "gp83 = [simple_regret_gp_1[slice83],\n",
        "       simple_regret_gp_2[slice83],\n",
        "       simple_regret_gp_3[slice83],\n",
        "       simple_regret_gp_4[slice83],\n",
        "       simple_regret_gp_5[slice83],\n",
        "       simple_regret_gp_6[slice83],\n",
        "       simple_regret_gp_7[slice83],\n",
        "       simple_regret_gp_8[slice83],\n",
        "       simple_regret_gp_9[slice83],\n",
        "       simple_regret_gp_10[slice83],\n",
        "       simple_regret_gp_11[slice83],\n",
        "       simple_regret_gp_12[slice83],\n",
        "       simple_regret_gp_13[slice83],\n",
        "       simple_regret_gp_14[slice83],\n",
        "       simple_regret_gp_15[slice83],\n",
        "       simple_regret_gp_16[slice83],\n",
        "       simple_regret_gp_17[slice83],\n",
        "       simple_regret_gp_18[slice83],\n",
        "       simple_regret_gp_19[slice83],\n",
        "       simple_regret_gp_20[slice83]]\n",
        "\n",
        "stp83 = [simple_regret_stp_1[slice83],\n",
        "       simple_regret_stp_2[slice83],\n",
        "       simple_regret_stp_3[slice83],\n",
        "       simple_regret_stp_4[slice83],\n",
        "       simple_regret_stp_5[slice83],\n",
        "       simple_regret_stp_6[slice83],\n",
        "       simple_regret_stp_7[slice83],\n",
        "       simple_regret_stp_8[slice83],\n",
        "       simple_regret_stp_9[slice83],\n",
        "       simple_regret_stp_10[slice83],\n",
        "       simple_regret_stp_11[slice83],\n",
        "       simple_regret_stp_12[slice83],\n",
        "       simple_regret_stp_13[slice83],\n",
        "       simple_regret_stp_14[slice83],\n",
        "       simple_regret_stp_15[slice83],\n",
        "       simple_regret_stp_16[slice83],\n",
        "       simple_regret_stp_17[slice83],\n",
        "       simple_regret_stp_18[slice83],\n",
        "       simple_regret_stp_19[slice83],\n",
        "       simple_regret_stp_20[slice83]]\n",
        "\n",
        "gp83_results = pd.DataFrame(gp83).sort_values(by=[0], ascending=False)\n",
        "stp83_results = pd.DataFrame(stp83).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - gp:\n",
        "lower_gp83 = np.asarray(gp83_results[4:5][0])[0]\n",
        "median_gp83 = np.asarray(gp83_results[9:10][0])[0]\n",
        "upper_gp83 = np.asarray(gp83_results[14:15][0])[0]\n",
        "\n",
        "lower_stp83 = np.asarray(stp83_results[4:5][0])[0]\n",
        "median_stp83 = np.asarray(stp83_results[9:10][0])[0]\n",
        "upper_stp83 = np.asarray(stp83_results[14:15][0])[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "Pfl6TM-4JLl0"
      },
      "outputs": [],
      "source": [
        "# Iteration93 :\n",
        "\n",
        "slice93 = 92\n",
        "\n",
        "gp93 = [simple_regret_gp_1[slice93],\n",
        "       simple_regret_gp_2[slice93],\n",
        "       simple_regret_gp_3[slice93],\n",
        "       simple_regret_gp_4[slice93],\n",
        "       simple_regret_gp_5[slice93],\n",
        "       simple_regret_gp_6[slice93],\n",
        "       simple_regret_gp_7[slice93],\n",
        "       simple_regret_gp_8[slice93],\n",
        "       simple_regret_gp_9[slice93],\n",
        "       simple_regret_gp_10[slice93],\n",
        "       simple_regret_gp_11[slice93],\n",
        "       simple_regret_gp_12[slice93],\n",
        "       simple_regret_gp_13[slice93],\n",
        "       simple_regret_gp_14[slice93],\n",
        "       simple_regret_gp_15[slice93],\n",
        "       simple_regret_gp_16[slice93],\n",
        "       simple_regret_gp_17[slice93],\n",
        "       simple_regret_gp_18[slice93],\n",
        "       simple_regret_gp_19[slice93],\n",
        "       simple_regret_gp_20[slice93]]\n",
        "\n",
        "stp93 = [simple_regret_stp_1[slice93],\n",
        "       simple_regret_stp_2[slice93],\n",
        "       simple_regret_stp_3[slice93],\n",
        "       simple_regret_stp_4[slice93],\n",
        "       simple_regret_stp_5[slice93],\n",
        "       simple_regret_stp_6[slice93],\n",
        "       simple_regret_stp_7[slice93],\n",
        "       simple_regret_stp_8[slice93],\n",
        "       simple_regret_stp_9[slice93],\n",
        "       simple_regret_stp_10[slice93],\n",
        "       simple_regret_stp_11[slice93],\n",
        "       simple_regret_stp_12[slice93],\n",
        "       simple_regret_stp_13[slice93],\n",
        "       simple_regret_stp_14[slice93],\n",
        "       simple_regret_stp_15[slice93],\n",
        "       simple_regret_stp_16[slice93],\n",
        "       simple_regret_stp_17[slice93],\n",
        "       simple_regret_stp_18[slice93],\n",
        "       simple_regret_stp_19[slice93],\n",
        "       simple_regret_stp_20[slice93]]\n",
        "\n",
        "gp93_results = pd.DataFrame(gp93).sort_values(by=[0], ascending=False)\n",
        "stp93_results = pd.DataFrame(stp93).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - gp:\n",
        "lower_gp93 = np.asarray(gp93_results[4:5][0])[0]\n",
        "median_gp93 = np.asarray(gp93_results[9:10][0])[0]\n",
        "upper_gp93 = np.asarray(gp93_results[14:15][0])[0]\n",
        "\n",
        "lower_stp93 = np.asarray(stp93_results[4:5][0])[0]\n",
        "median_stp93 = np.asarray(stp93_results[9:10][0])[0]\n",
        "upper_stp93 = np.asarray(stp93_results[14:15][0])[0]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "T30xLxygJLl0"
      },
      "outputs": [],
      "source": [
        "# Iteration4 :\n",
        "\n",
        "slice4 = 3\n",
        "\n",
        "gp4 = [simple_regret_gp_1[slice4],\n",
        "       simple_regret_gp_2[slice4],\n",
        "       simple_regret_gp_3[slice4],\n",
        "       simple_regret_gp_4[slice4],\n",
        "       simple_regret_gp_5[slice4],\n",
        "       simple_regret_gp_6[slice4],\n",
        "       simple_regret_gp_7[slice4],\n",
        "       simple_regret_gp_8[slice4],\n",
        "       simple_regret_gp_9[slice4],\n",
        "       simple_regret_gp_10[slice4],\n",
        "       simple_regret_gp_11[slice4],\n",
        "       simple_regret_gp_12[slice4],\n",
        "       simple_regret_gp_13[slice4],\n",
        "       simple_regret_gp_14[slice4],\n",
        "       simple_regret_gp_15[slice4],\n",
        "       simple_regret_gp_16[slice4],\n",
        "       simple_regret_gp_17[slice4],\n",
        "       simple_regret_gp_18[slice4],\n",
        "       simple_regret_gp_19[slice4],\n",
        "       simple_regret_gp_20[slice4]]\n",
        "\n",
        "stp4 = [simple_regret_stp_1[slice4],\n",
        "       simple_regret_stp_2[slice4],\n",
        "       simple_regret_stp_3[slice4],\n",
        "       simple_regret_stp_4[slice4],\n",
        "       simple_regret_stp_5[slice4],\n",
        "       simple_regret_stp_6[slice4],\n",
        "       simple_regret_stp_7[slice4],\n",
        "       simple_regret_stp_8[slice4],\n",
        "       simple_regret_stp_9[slice4],\n",
        "       simple_regret_stp_10[slice4],\n",
        "       simple_regret_stp_11[slice4],\n",
        "       simple_regret_stp_12[slice4],\n",
        "       simple_regret_stp_13[slice4],\n",
        "       simple_regret_stp_14[slice4],\n",
        "       simple_regret_stp_15[slice4],\n",
        "       simple_regret_stp_16[slice4],\n",
        "       simple_regret_stp_17[slice4],\n",
        "       simple_regret_stp_18[slice4],\n",
        "       simple_regret_stp_19[slice4],\n",
        "       simple_regret_stp_20[slice4]]\n",
        "\n",
        "gp4_results = pd.DataFrame(gp4).sort_values(by=[0], ascending=False)\n",
        "stp4_results = pd.DataFrame(stp4).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - gp:\n",
        "lower_gp4 = np.asarray(gp4_results[4:5][0])[0]\n",
        "median_gp4 = np.asarray(gp4_results[9:10][0])[0]\n",
        "upper_gp4 = np.asarray(gp4_results[14:15][0])[0]\n",
        "\n",
        "lower_stp4 = np.asarray(stp4_results[4:5][0])[0]\n",
        "median_stp4 = np.asarray(stp4_results[9:10][0])[0]\n",
        "upper_stp4 = np.asarray(stp4_results[14:15][0])[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "MQ-jpNrnJLl1"
      },
      "outputs": [],
      "source": [
        "# Iteration14 :\n",
        "\n",
        "slice14 = 13\n",
        "\n",
        "gp14 = [simple_regret_gp_1[slice14],\n",
        "       simple_regret_gp_2[slice14],\n",
        "       simple_regret_gp_3[slice14],\n",
        "       simple_regret_gp_4[slice14],\n",
        "       simple_regret_gp_5[slice14],\n",
        "       simple_regret_gp_6[slice14],\n",
        "       simple_regret_gp_7[slice14],\n",
        "       simple_regret_gp_8[slice14],\n",
        "       simple_regret_gp_9[slice14],\n",
        "       simple_regret_gp_10[slice14],\n",
        "       simple_regret_gp_11[slice14],\n",
        "       simple_regret_gp_12[slice14],\n",
        "       simple_regret_gp_13[slice14],\n",
        "       simple_regret_gp_14[slice14],\n",
        "       simple_regret_gp_15[slice14],\n",
        "       simple_regret_gp_16[slice14],\n",
        "       simple_regret_gp_17[slice14],\n",
        "       simple_regret_gp_18[slice14],\n",
        "       simple_regret_gp_19[slice14],\n",
        "       simple_regret_gp_20[slice14]]\n",
        "\n",
        "stp14 = [simple_regret_stp_1[slice14],\n",
        "       simple_regret_stp_2[slice14],\n",
        "       simple_regret_stp_3[slice14],\n",
        "       simple_regret_stp_4[slice14],\n",
        "       simple_regret_stp_5[slice14],\n",
        "       simple_regret_stp_6[slice14],\n",
        "       simple_regret_stp_7[slice14],\n",
        "       simple_regret_stp_8[slice14],\n",
        "       simple_regret_stp_9[slice14],\n",
        "       simple_regret_stp_10[slice14],\n",
        "       simple_regret_stp_11[slice14],\n",
        "       simple_regret_stp_12[slice14],\n",
        "       simple_regret_stp_13[slice14],\n",
        "       simple_regret_stp_14[slice14],\n",
        "       simple_regret_stp_15[slice14],\n",
        "       simple_regret_stp_16[slice14],\n",
        "       simple_regret_stp_17[slice14],\n",
        "       simple_regret_stp_18[slice14],\n",
        "       simple_regret_stp_19[slice14],\n",
        "       simple_regret_stp_20[slice14]]\n",
        "\n",
        "gp14_results = pd.DataFrame(gp14).sort_values(by=[0], ascending=False)\n",
        "stp14_results = pd.DataFrame(stp14).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - gp:\n",
        "lower_gp14 = np.asarray(gp14_results[4:5][0])[0]\n",
        "median_gp14 = np.asarray(gp14_results[9:10][0])[0]\n",
        "upper_gp14 = np.asarray(gp14_results[14:15][0])[0]\n",
        "\n",
        "lower_stp14 = np.asarray(stp14_results[4:5][0])[0]\n",
        "median_stp14 = np.asarray(stp14_results[9:10][0])[0]\n",
        "upper_stp14 = np.asarray(stp14_results[14:15][0])[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "tATrQA5rJLl1"
      },
      "outputs": [],
      "source": [
        "# Iteration24 :\n",
        "\n",
        "slice24 = 23\n",
        "\n",
        "gp24 = [simple_regret_gp_1[slice24],\n",
        "       simple_regret_gp_2[slice24],\n",
        "       simple_regret_gp_3[slice24],\n",
        "       simple_regret_gp_4[slice24],\n",
        "       simple_regret_gp_5[slice24],\n",
        "       simple_regret_gp_6[slice24],\n",
        "       simple_regret_gp_7[slice24],\n",
        "       simple_regret_gp_8[slice24],\n",
        "       simple_regret_gp_9[slice24],\n",
        "       simple_regret_gp_10[slice24],\n",
        "       simple_regret_gp_11[slice24],\n",
        "       simple_regret_gp_12[slice24],\n",
        "       simple_regret_gp_13[slice24],\n",
        "       simple_regret_gp_14[slice24],\n",
        "       simple_regret_gp_15[slice24],\n",
        "       simple_regret_gp_16[slice24],\n",
        "       simple_regret_gp_17[slice24],\n",
        "       simple_regret_gp_18[slice24],\n",
        "       simple_regret_gp_19[slice24],\n",
        "       simple_regret_gp_20[slice24]]\n",
        "\n",
        "stp24 = [simple_regret_stp_1[slice24],\n",
        "       simple_regret_stp_2[slice24],\n",
        "       simple_regret_stp_3[slice24],\n",
        "       simple_regret_stp_4[slice24],\n",
        "       simple_regret_stp_5[slice24],\n",
        "       simple_regret_stp_6[slice24],\n",
        "       simple_regret_stp_7[slice24],\n",
        "       simple_regret_stp_8[slice24],\n",
        "       simple_regret_stp_9[slice24],\n",
        "       simple_regret_stp_10[slice24],\n",
        "       simple_regret_stp_11[slice24],\n",
        "       simple_regret_stp_12[slice24],\n",
        "       simple_regret_stp_13[slice24],\n",
        "       simple_regret_stp_14[slice24],\n",
        "       simple_regret_stp_15[slice24],\n",
        "       simple_regret_stp_16[slice24],\n",
        "       simple_regret_stp_17[slice24],\n",
        "       simple_regret_stp_18[slice24],\n",
        "       simple_regret_stp_19[slice24],\n",
        "       simple_regret_stp_20[slice24]]\n",
        "\n",
        "gp24_results = pd.DataFrame(gp24).sort_values(by=[0], ascending=False)\n",
        "stp24_results = pd.DataFrame(stp24).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - gp:\n",
        "lower_gp24 = np.asarray(gp24_results[4:5][0])[0]\n",
        "median_gp24 = np.asarray(gp24_results[9:10][0])[0]\n",
        "upper_gp24 = np.asarray(gp24_results[14:15][0])[0]\n",
        "\n",
        "lower_stp24 = np.asarray(stp24_results[4:5][0])[0]\n",
        "median_stp24 = np.asarray(stp24_results[9:10][0])[0]\n",
        "upper_stp24 = np.asarray(stp24_results[14:15][0])[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "09J0MKvuJLl2"
      },
      "outputs": [],
      "source": [
        "# Iteration34 :\n",
        "\n",
        "slice34 = 33\n",
        "\n",
        "gp34 = [simple_regret_gp_1[slice34],\n",
        "       simple_regret_gp_2[slice34],\n",
        "       simple_regret_gp_3[slice34],\n",
        "       simple_regret_gp_4[slice34],\n",
        "       simple_regret_gp_5[slice34],\n",
        "       simple_regret_gp_6[slice34],\n",
        "       simple_regret_gp_7[slice34],\n",
        "       simple_regret_gp_8[slice34],\n",
        "       simple_regret_gp_9[slice34],\n",
        "       simple_regret_gp_10[slice34],\n",
        "       simple_regret_gp_11[slice34],\n",
        "       simple_regret_gp_12[slice34],\n",
        "       simple_regret_gp_13[slice34],\n",
        "       simple_regret_gp_14[slice34],\n",
        "       simple_regret_gp_15[slice34],\n",
        "       simple_regret_gp_16[slice34],\n",
        "       simple_regret_gp_17[slice34],\n",
        "       simple_regret_gp_18[slice34],\n",
        "       simple_regret_gp_19[slice34],\n",
        "       simple_regret_gp_20[slice34]]\n",
        "\n",
        "stp34 = [simple_regret_stp_1[slice34],\n",
        "       simple_regret_stp_2[slice34],\n",
        "       simple_regret_stp_3[slice34],\n",
        "       simple_regret_stp_4[slice34],\n",
        "       simple_regret_stp_5[slice34],\n",
        "       simple_regret_stp_6[slice34],\n",
        "       simple_regret_stp_7[slice34],\n",
        "       simple_regret_stp_8[slice34],\n",
        "       simple_regret_stp_9[slice34],\n",
        "       simple_regret_stp_10[slice34],\n",
        "       simple_regret_stp_11[slice34],\n",
        "       simple_regret_stp_12[slice34],\n",
        "       simple_regret_stp_13[slice34],\n",
        "       simple_regret_stp_14[slice34],\n",
        "       simple_regret_stp_15[slice34],\n",
        "       simple_regret_stp_16[slice34],\n",
        "       simple_regret_stp_17[slice34],\n",
        "       simple_regret_stp_18[slice34],\n",
        "       simple_regret_stp_19[slice34],\n",
        "       simple_regret_stp_20[slice34]]\n",
        "\n",
        "gp34_results = pd.DataFrame(gp34).sort_values(by=[0], ascending=False)\n",
        "stp34_results = pd.DataFrame(stp34).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - gp:\n",
        "lower_gp34 = np.asarray(gp34_results[4:5][0])[0]\n",
        "median_gp34 = np.asarray(gp34_results[9:10][0])[0]\n",
        "upper_gp34 = np.asarray(gp34_results[14:15][0])[0]\n",
        "\n",
        "lower_stp34 = np.asarray(stp34_results[4:5][0])[0]\n",
        "median_stp34 = np.asarray(stp34_results[9:10][0])[0]\n",
        "upper_stp34 = np.asarray(stp34_results[14:15][0])[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "YIG08d9XJLl3"
      },
      "outputs": [],
      "source": [
        "# Iteration44 :\n",
        "\n",
        "slice44 = 43\n",
        "\n",
        "gp44 = [simple_regret_gp_1[slice44],\n",
        "       simple_regret_gp_2[slice44],\n",
        "       simple_regret_gp_3[slice44],\n",
        "       simple_regret_gp_4[slice44],\n",
        "       simple_regret_gp_5[slice44],\n",
        "       simple_regret_gp_6[slice44],\n",
        "       simple_regret_gp_7[slice44],\n",
        "       simple_regret_gp_8[slice44],\n",
        "       simple_regret_gp_9[slice44],\n",
        "       simple_regret_gp_10[slice44],\n",
        "       simple_regret_gp_11[slice44],\n",
        "       simple_regret_gp_12[slice44],\n",
        "       simple_regret_gp_13[slice44],\n",
        "       simple_regret_gp_14[slice44],\n",
        "       simple_regret_gp_15[slice44],\n",
        "       simple_regret_gp_16[slice44],\n",
        "       simple_regret_gp_17[slice44],\n",
        "       simple_regret_gp_18[slice44],\n",
        "       simple_regret_gp_19[slice44],\n",
        "       simple_regret_gp_20[slice44]]\n",
        "\n",
        "stp44 = [simple_regret_stp_1[slice44],\n",
        "       simple_regret_stp_2[slice44],\n",
        "       simple_regret_stp_3[slice44],\n",
        "       simple_regret_stp_4[slice44],\n",
        "       simple_regret_stp_5[slice44],\n",
        "       simple_regret_stp_6[slice44],\n",
        "       simple_regret_stp_7[slice44],\n",
        "       simple_regret_stp_8[slice44],\n",
        "       simple_regret_stp_9[slice44],\n",
        "       simple_regret_stp_10[slice44],\n",
        "       simple_regret_stp_11[slice44],\n",
        "       simple_regret_stp_12[slice44],\n",
        "       simple_regret_stp_13[slice44],\n",
        "       simple_regret_stp_14[slice44],\n",
        "       simple_regret_stp_15[slice44],\n",
        "       simple_regret_stp_16[slice44],\n",
        "       simple_regret_stp_17[slice44],\n",
        "       simple_regret_stp_18[slice44],\n",
        "       simple_regret_stp_19[slice44],\n",
        "       simple_regret_stp_20[slice44]]\n",
        "\n",
        "gp44_results = pd.DataFrame(gp44).sort_values(by=[0], ascending=False)\n",
        "stp44_results = pd.DataFrame(stp44).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - gp:\n",
        "lower_gp44 = np.asarray(gp44_results[4:5][0])[0]\n",
        "median_gp44 = np.asarray(gp44_results[9:10][0])[0]\n",
        "upper_gp44 = np.asarray(gp44_results[14:15][0])[0]\n",
        "\n",
        "lower_stp44 = np.asarray(stp44_results[4:5][0])[0]\n",
        "median_stp44 = np.asarray(stp44_results[9:10][0])[0]\n",
        "upper_stp44 = np.asarray(stp44_results[14:15][0])[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "Ee553zQgJLl3"
      },
      "outputs": [],
      "source": [
        "# Iteration54 :\n",
        "\n",
        "slice54 = 53\n",
        "\n",
        "gp54 = [simple_regret_gp_1[slice54],\n",
        "       simple_regret_gp_2[slice54],\n",
        "       simple_regret_gp_3[slice54],\n",
        "       simple_regret_gp_4[slice54],\n",
        "       simple_regret_gp_5[slice54],\n",
        "       simple_regret_gp_6[slice54],\n",
        "       simple_regret_gp_7[slice54],\n",
        "       simple_regret_gp_8[slice54],\n",
        "       simple_regret_gp_9[slice54],\n",
        "       simple_regret_gp_10[slice54],\n",
        "       simple_regret_gp_11[slice54],\n",
        "       simple_regret_gp_12[slice54],\n",
        "       simple_regret_gp_13[slice54],\n",
        "       simple_regret_gp_14[slice54],\n",
        "       simple_regret_gp_15[slice54],\n",
        "       simple_regret_gp_16[slice54],\n",
        "       simple_regret_gp_17[slice54],\n",
        "       simple_regret_gp_18[slice54],\n",
        "       simple_regret_gp_19[slice54],\n",
        "       simple_regret_gp_20[slice54]]\n",
        "\n",
        "stp54 = [simple_regret_stp_1[slice54],\n",
        "       simple_regret_stp_2[slice54],\n",
        "       simple_regret_stp_3[slice54],\n",
        "       simple_regret_stp_4[slice54],\n",
        "       simple_regret_stp_5[slice54],\n",
        "       simple_regret_stp_6[slice54],\n",
        "       simple_regret_stp_7[slice54],\n",
        "       simple_regret_stp_8[slice54],\n",
        "       simple_regret_stp_9[slice54],\n",
        "       simple_regret_stp_10[slice54],\n",
        "       simple_regret_stp_11[slice54],\n",
        "       simple_regret_stp_12[slice54],\n",
        "       simple_regret_stp_13[slice54],\n",
        "       simple_regret_stp_14[slice54],\n",
        "       simple_regret_stp_15[slice54],\n",
        "       simple_regret_stp_16[slice54],\n",
        "       simple_regret_stp_17[slice54],\n",
        "       simple_regret_stp_18[slice54],\n",
        "       simple_regret_stp_19[slice54],\n",
        "       simple_regret_stp_20[slice54]]\n",
        "\n",
        "gp54_results = pd.DataFrame(gp54).sort_values(by=[0], ascending=False)\n",
        "stp54_results = pd.DataFrame(stp54).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - gp:\n",
        "lower_gp54 = np.asarray(gp54_results[4:5][0])[0]\n",
        "median_gp54 = np.asarray(gp54_results[9:10][0])[0]\n",
        "upper_gp54 = np.asarray(gp54_results[14:15][0])[0]\n",
        "\n",
        "lower_stp54 = np.asarray(stp54_results[4:5][0])[0]\n",
        "median_stp54 = np.asarray(stp54_results[9:10][0])[0]\n",
        "upper_stp54 = np.asarray(stp54_results[14:15][0])[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "SEJti-2AJLl4"
      },
      "outputs": [],
      "source": [
        "# Iteration64 :\n",
        "\n",
        "slice64 = 63\n",
        "\n",
        "gp64 = [simple_regret_gp_1[slice64],\n",
        "       simple_regret_gp_2[slice64],\n",
        "       simple_regret_gp_3[slice64],\n",
        "       simple_regret_gp_4[slice64],\n",
        "       simple_regret_gp_5[slice64],\n",
        "       simple_regret_gp_6[slice64],\n",
        "       simple_regret_gp_7[slice64],\n",
        "       simple_regret_gp_8[slice64],\n",
        "       simple_regret_gp_9[slice64],\n",
        "       simple_regret_gp_10[slice64],\n",
        "       simple_regret_gp_11[slice64],\n",
        "       simple_regret_gp_12[slice64],\n",
        "       simple_regret_gp_13[slice64],\n",
        "       simple_regret_gp_14[slice64],\n",
        "       simple_regret_gp_15[slice64],\n",
        "       simple_regret_gp_16[slice64],\n",
        "       simple_regret_gp_17[slice64],\n",
        "       simple_regret_gp_18[slice64],\n",
        "       simple_regret_gp_19[slice64],\n",
        "       simple_regret_gp_20[slice64]]\n",
        "\n",
        "stp64 = [simple_regret_stp_1[slice64],\n",
        "       simple_regret_stp_2[slice64],\n",
        "       simple_regret_stp_3[slice64],\n",
        "       simple_regret_stp_4[slice64],\n",
        "       simple_regret_stp_5[slice64],\n",
        "       simple_regret_stp_6[slice64],\n",
        "       simple_regret_stp_7[slice64],\n",
        "       simple_regret_stp_8[slice64],\n",
        "       simple_regret_stp_9[slice64],\n",
        "       simple_regret_stp_10[slice64],\n",
        "       simple_regret_stp_11[slice64],\n",
        "       simple_regret_stp_12[slice64],\n",
        "       simple_regret_stp_13[slice64],\n",
        "       simple_regret_stp_14[slice64],\n",
        "       simple_regret_stp_15[slice64],\n",
        "       simple_regret_stp_16[slice64],\n",
        "       simple_regret_stp_17[slice64],\n",
        "       simple_regret_stp_18[slice64],\n",
        "       simple_regret_stp_19[slice64],\n",
        "       simple_regret_stp_20[slice64]]\n",
        "\n",
        "gp64_results = pd.DataFrame(gp64).sort_values(by=[0], ascending=False)\n",
        "stp64_results = pd.DataFrame(stp64).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - gp:\n",
        "lower_gp64 = np.asarray(gp64_results[4:5][0])[0]\n",
        "median_gp64 = np.asarray(gp64_results[9:10][0])[0]\n",
        "upper_gp64 = np.asarray(gp64_results[14:15][0])[0]\n",
        "\n",
        "lower_stp64 = np.asarray(stp64_results[4:5][0])[0]\n",
        "median_stp64 = np.asarray(stp64_results[9:10][0])[0]\n",
        "upper_stp64 = np.asarray(stp64_results[14:15][0])[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "m_9u_8JJJLl5"
      },
      "outputs": [],
      "source": [
        "# Iteration74 :\n",
        "\n",
        "slice74 = 73\n",
        "\n",
        "gp74 = [simple_regret_gp_1[slice74],\n",
        "       simple_regret_gp_2[slice74],\n",
        "       simple_regret_gp_3[slice74],\n",
        "       simple_regret_gp_4[slice74],\n",
        "       simple_regret_gp_5[slice74],\n",
        "       simple_regret_gp_6[slice74],\n",
        "       simple_regret_gp_7[slice74],\n",
        "       simple_regret_gp_8[slice74],\n",
        "       simple_regret_gp_9[slice74],\n",
        "       simple_regret_gp_10[slice74],\n",
        "       simple_regret_gp_11[slice74],\n",
        "       simple_regret_gp_12[slice74],\n",
        "       simple_regret_gp_13[slice74],\n",
        "       simple_regret_gp_14[slice74],\n",
        "       simple_regret_gp_15[slice74],\n",
        "       simple_regret_gp_16[slice74],\n",
        "       simple_regret_gp_17[slice74],\n",
        "       simple_regret_gp_18[slice74],\n",
        "       simple_regret_gp_19[slice74],\n",
        "       simple_regret_gp_20[slice74]]\n",
        "\n",
        "stp74 = [simple_regret_stp_1[slice74],\n",
        "       simple_regret_stp_2[slice74],\n",
        "       simple_regret_stp_3[slice74],\n",
        "       simple_regret_stp_4[slice74],\n",
        "       simple_regret_stp_5[slice74],\n",
        "       simple_regret_stp_6[slice74],\n",
        "       simple_regret_stp_7[slice74],\n",
        "       simple_regret_stp_8[slice74],\n",
        "       simple_regret_stp_9[slice74],\n",
        "       simple_regret_stp_10[slice74],\n",
        "       simple_regret_stp_11[slice74],\n",
        "       simple_regret_stp_12[slice74],\n",
        "       simple_regret_stp_13[slice74],\n",
        "       simple_regret_stp_14[slice74],\n",
        "       simple_regret_stp_15[slice74],\n",
        "       simple_regret_stp_16[slice74],\n",
        "       simple_regret_stp_17[slice74],\n",
        "       simple_regret_stp_18[slice74],\n",
        "       simple_regret_stp_19[slice74],\n",
        "       simple_regret_stp_20[slice74]]\n",
        "\n",
        "gp74_results = pd.DataFrame(gp74).sort_values(by=[0], ascending=False)\n",
        "stp74_results = pd.DataFrame(stp74).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - gp:\n",
        "lower_gp74 = np.asarray(gp74_results[4:5][0])[0]\n",
        "median_gp74 = np.asarray(gp74_results[9:10][0])[0]\n",
        "upper_gp74 = np.asarray(gp74_results[14:15][0])[0]\n",
        "\n",
        "lower_stp74 = np.asarray(stp74_results[4:5][0])[0]\n",
        "median_stp74 = np.asarray(stp74_results[9:10][0])[0]\n",
        "upper_stp74 = np.asarray(stp74_results[14:15][0])[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "vtMrs9cLJLl8"
      },
      "outputs": [],
      "source": [
        "# Iteration84 :\n",
        "\n",
        "slice84 = 83\n",
        "\n",
        "gp84 = [simple_regret_gp_1[slice84],\n",
        "       simple_regret_gp_2[slice84],\n",
        "       simple_regret_gp_3[slice84],\n",
        "       simple_regret_gp_4[slice84],\n",
        "       simple_regret_gp_5[slice84],\n",
        "       simple_regret_gp_6[slice84],\n",
        "       simple_regret_gp_7[slice84],\n",
        "       simple_regret_gp_8[slice84],\n",
        "       simple_regret_gp_9[slice84],\n",
        "       simple_regret_gp_10[slice84],\n",
        "       simple_regret_gp_11[slice84],\n",
        "       simple_regret_gp_12[slice84],\n",
        "       simple_regret_gp_13[slice84],\n",
        "       simple_regret_gp_14[slice84],\n",
        "       simple_regret_gp_15[slice84],\n",
        "       simple_regret_gp_16[slice84],\n",
        "       simple_regret_gp_17[slice84],\n",
        "       simple_regret_gp_18[slice84],\n",
        "       simple_regret_gp_19[slice84],\n",
        "       simple_regret_gp_20[slice84]]\n",
        "\n",
        "stp84 = [simple_regret_stp_1[slice84],\n",
        "       simple_regret_stp_2[slice84],\n",
        "       simple_regret_stp_3[slice84],\n",
        "       simple_regret_stp_4[slice84],\n",
        "       simple_regret_stp_5[slice84],\n",
        "       simple_regret_stp_6[slice84],\n",
        "       simple_regret_stp_7[slice84],\n",
        "       simple_regret_stp_8[slice84],\n",
        "       simple_regret_stp_9[slice84],\n",
        "       simple_regret_stp_10[slice84],\n",
        "       simple_regret_stp_11[slice84],\n",
        "       simple_regret_stp_12[slice84],\n",
        "       simple_regret_stp_13[slice84],\n",
        "       simple_regret_stp_14[slice84],\n",
        "       simple_regret_stp_15[slice84],\n",
        "       simple_regret_stp_16[slice84],\n",
        "       simple_regret_stp_17[slice84],\n",
        "       simple_regret_stp_18[slice84],\n",
        "       simple_regret_stp_19[slice84],\n",
        "       simple_regret_stp_20[slice84]]\n",
        "\n",
        "gp84_results = pd.DataFrame(gp84).sort_values(by=[0], ascending=False)\n",
        "stp84_results = pd.DataFrame(stp84).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - gp:\n",
        "lower_gp84 = np.asarray(gp84_results[4:5][0])[0]\n",
        "median_gp84 = np.asarray(gp84_results[9:10][0])[0]\n",
        "upper_gp84 = np.asarray(gp84_results[14:15][0])[0]\n",
        "\n",
        "lower_stp84 = np.asarray(stp84_results[4:5][0])[0]\n",
        "median_stp84 = np.asarray(stp84_results[9:10][0])[0]\n",
        "upper_stp84 = np.asarray(stp84_results[14:15][0])[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "Zsl2NUabJLl9"
      },
      "outputs": [],
      "source": [
        "# Iteration94 :\n",
        "\n",
        "slice94 = 93\n",
        "\n",
        "gp94 = [simple_regret_gp_1[slice94],\n",
        "       simple_regret_gp_2[slice94],\n",
        "       simple_regret_gp_3[slice94],\n",
        "       simple_regret_gp_4[slice94],\n",
        "       simple_regret_gp_5[slice94],\n",
        "       simple_regret_gp_6[slice94],\n",
        "       simple_regret_gp_7[slice94],\n",
        "       simple_regret_gp_8[slice94],\n",
        "       simple_regret_gp_9[slice94],\n",
        "       simple_regret_gp_10[slice94],\n",
        "       simple_regret_gp_11[slice94],\n",
        "       simple_regret_gp_12[slice94],\n",
        "       simple_regret_gp_13[slice94],\n",
        "       simple_regret_gp_14[slice94],\n",
        "       simple_regret_gp_15[slice94],\n",
        "       simple_regret_gp_16[slice94],\n",
        "       simple_regret_gp_17[slice94],\n",
        "       simple_regret_gp_18[slice94],\n",
        "       simple_regret_gp_19[slice94],\n",
        "       simple_regret_gp_20[slice94]]\n",
        "\n",
        "stp94 = [simple_regret_stp_1[slice94],\n",
        "       simple_regret_stp_2[slice94],\n",
        "       simple_regret_stp_3[slice94],\n",
        "       simple_regret_stp_4[slice94],\n",
        "       simple_regret_stp_5[slice94],\n",
        "       simple_regret_stp_6[slice94],\n",
        "       simple_regret_stp_7[slice94],\n",
        "       simple_regret_stp_8[slice94],\n",
        "       simple_regret_stp_9[slice94],\n",
        "       simple_regret_stp_10[slice94],\n",
        "       simple_regret_stp_11[slice94],\n",
        "       simple_regret_stp_12[slice94],\n",
        "       simple_regret_stp_13[slice94],\n",
        "       simple_regret_stp_14[slice94],\n",
        "       simple_regret_stp_15[slice94],\n",
        "       simple_regret_stp_16[slice94],\n",
        "       simple_regret_stp_17[slice94],\n",
        "       simple_regret_stp_18[slice94],\n",
        "       simple_regret_stp_19[slice94],\n",
        "       simple_regret_stp_20[slice94]]\n",
        "\n",
        "gp94_results = pd.DataFrame(gp94).sort_values(by=[0], ascending=False)\n",
        "stp94_results = pd.DataFrame(stp94).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - gp:\n",
        "lower_gp94 = np.asarray(gp94_results[4:5][0])[0]\n",
        "median_gp94 = np.asarray(gp94_results[9:10][0])[0]\n",
        "upper_gp94 = np.asarray(gp94_results[14:15][0])[0]\n",
        "\n",
        "lower_stp94 = np.asarray(stp94_results[4:5][0])[0]\n",
        "median_stp94 = np.asarray(stp94_results[9:10][0])[0]\n",
        "upper_stp94 = np.asarray(stp94_results[14:15][0])[0]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "Xhy_AN9jJLl9"
      },
      "outputs": [],
      "source": [
        "# Iteration5 :\n",
        "\n",
        "slice5 = 4\n",
        "\n",
        "gp5 = [simple_regret_gp_1[slice5],\n",
        "       simple_regret_gp_2[slice5],\n",
        "       simple_regret_gp_3[slice5],\n",
        "       simple_regret_gp_4[slice5],\n",
        "       simple_regret_gp_5[slice5],\n",
        "       simple_regret_gp_6[slice5],\n",
        "       simple_regret_gp_7[slice5],\n",
        "       simple_regret_gp_8[slice5],\n",
        "       simple_regret_gp_9[slice5],\n",
        "       simple_regret_gp_10[slice5],\n",
        "       simple_regret_gp_11[slice5],\n",
        "       simple_regret_gp_12[slice5],\n",
        "       simple_regret_gp_13[slice5],\n",
        "       simple_regret_gp_14[slice5],\n",
        "       simple_regret_gp_15[slice5],\n",
        "       simple_regret_gp_16[slice5],\n",
        "       simple_regret_gp_17[slice5],\n",
        "       simple_regret_gp_18[slice5],\n",
        "       simple_regret_gp_19[slice5],\n",
        "       simple_regret_gp_20[slice5]]\n",
        "\n",
        "stp5 = [simple_regret_stp_1[slice5],\n",
        "       simple_regret_stp_2[slice5],\n",
        "       simple_regret_stp_3[slice5],\n",
        "       simple_regret_stp_4[slice5],\n",
        "       simple_regret_stp_5[slice5],\n",
        "       simple_regret_stp_6[slice5],\n",
        "       simple_regret_stp_7[slice5],\n",
        "       simple_regret_stp_8[slice5],\n",
        "       simple_regret_stp_9[slice5],\n",
        "       simple_regret_stp_10[slice5],\n",
        "       simple_regret_stp_11[slice5],\n",
        "       simple_regret_stp_12[slice5],\n",
        "       simple_regret_stp_13[slice5],\n",
        "       simple_regret_stp_14[slice5],\n",
        "       simple_regret_stp_15[slice5],\n",
        "       simple_regret_stp_16[slice5],\n",
        "       simple_regret_stp_17[slice5],\n",
        "       simple_regret_stp_18[slice5],\n",
        "       simple_regret_stp_19[slice5],\n",
        "       simple_regret_stp_20[slice5]]\n",
        "\n",
        "gp5_results = pd.DataFrame(gp5).sort_values(by=[0], ascending=False)\n",
        "stp5_results = pd.DataFrame(stp5).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - gp:\n",
        "lower_gp5 = np.asarray(gp5_results[4:5][0])[0]\n",
        "median_gp5 = np.asarray(gp5_results[9:10][0])[0]\n",
        "upper_gp5 = np.asarray(gp5_results[14:15][0])[0]\n",
        "\n",
        "lower_stp5 = np.asarray(stp5_results[4:5][0])[0]\n",
        "median_stp5 = np.asarray(stp5_results[9:10][0])[0]\n",
        "upper_stp5 = np.asarray(stp5_results[14:15][0])[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "WHbtLHnbJLl-"
      },
      "outputs": [],
      "source": [
        "# Iteration15 :\n",
        "\n",
        "slice15 = 14\n",
        "\n",
        "gp15 = [simple_regret_gp_1[slice15],\n",
        "       simple_regret_gp_2[slice15],\n",
        "       simple_regret_gp_3[slice15],\n",
        "       simple_regret_gp_4[slice15],\n",
        "       simple_regret_gp_5[slice15],\n",
        "       simple_regret_gp_6[slice15],\n",
        "       simple_regret_gp_7[slice15],\n",
        "       simple_regret_gp_8[slice15],\n",
        "       simple_regret_gp_9[slice15],\n",
        "       simple_regret_gp_10[slice15],\n",
        "       simple_regret_gp_11[slice15],\n",
        "       simple_regret_gp_12[slice15],\n",
        "       simple_regret_gp_13[slice15],\n",
        "       simple_regret_gp_14[slice15],\n",
        "       simple_regret_gp_15[slice15],\n",
        "       simple_regret_gp_16[slice15],\n",
        "       simple_regret_gp_17[slice15],\n",
        "       simple_regret_gp_18[slice15],\n",
        "       simple_regret_gp_19[slice15],\n",
        "       simple_regret_gp_20[slice15]]\n",
        "\n",
        "stp15 = [simple_regret_stp_1[slice15],\n",
        "       simple_regret_stp_2[slice15],\n",
        "       simple_regret_stp_3[slice15],\n",
        "       simple_regret_stp_4[slice15],\n",
        "       simple_regret_stp_5[slice15],\n",
        "       simple_regret_stp_6[slice15],\n",
        "       simple_regret_stp_7[slice15],\n",
        "       simple_regret_stp_8[slice15],\n",
        "       simple_regret_stp_9[slice15],\n",
        "       simple_regret_stp_10[slice15],\n",
        "       simple_regret_stp_11[slice15],\n",
        "       simple_regret_stp_12[slice15],\n",
        "       simple_regret_stp_13[slice15],\n",
        "       simple_regret_stp_14[slice15],\n",
        "       simple_regret_stp_15[slice15],\n",
        "       simple_regret_stp_16[slice15],\n",
        "       simple_regret_stp_17[slice15],\n",
        "       simple_regret_stp_18[slice15],\n",
        "       simple_regret_stp_19[slice15],\n",
        "       simple_regret_stp_20[slice15]]\n",
        "\n",
        "gp15_results = pd.DataFrame(gp15).sort_values(by=[0], ascending=False)\n",
        "stp15_results = pd.DataFrame(stp15).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - gp:\n",
        "lower_gp15 = np.asarray(gp15_results[4:5][0])[0]\n",
        "median_gp15 = np.asarray(gp15_results[9:10][0])[0]\n",
        "upper_gp15 = np.asarray(gp15_results[14:15][0])[0]\n",
        "\n",
        "lower_stp15 = np.asarray(stp15_results[4:5][0])[0]\n",
        "median_stp15 = np.asarray(stp15_results[9:10][0])[0]\n",
        "upper_stp15 = np.asarray(stp15_results[14:15][0])[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "lcLpIkETJLl-"
      },
      "outputs": [],
      "source": [
        "# Iteration25 :\n",
        "\n",
        "slice25 = 24\n",
        "\n",
        "gp25 = [simple_regret_gp_1[slice25],\n",
        "       simple_regret_gp_2[slice25],\n",
        "       simple_regret_gp_3[slice25],\n",
        "       simple_regret_gp_4[slice25],\n",
        "       simple_regret_gp_5[slice25],\n",
        "       simple_regret_gp_6[slice25],\n",
        "       simple_regret_gp_7[slice25],\n",
        "       simple_regret_gp_8[slice25],\n",
        "       simple_regret_gp_9[slice25],\n",
        "       simple_regret_gp_10[slice25],\n",
        "       simple_regret_gp_11[slice25],\n",
        "       simple_regret_gp_12[slice25],\n",
        "       simple_regret_gp_13[slice25],\n",
        "       simple_regret_gp_14[slice25],\n",
        "       simple_regret_gp_15[slice25],\n",
        "       simple_regret_gp_16[slice25],\n",
        "       simple_regret_gp_17[slice25],\n",
        "       simple_regret_gp_18[slice25],\n",
        "       simple_regret_gp_19[slice25],\n",
        "       simple_regret_gp_20[slice25]]\n",
        "\n",
        "stp25 = [simple_regret_stp_1[slice25],\n",
        "       simple_regret_stp_2[slice25],\n",
        "       simple_regret_stp_3[slice25],\n",
        "       simple_regret_stp_4[slice25],\n",
        "       simple_regret_stp_5[slice25],\n",
        "       simple_regret_stp_6[slice25],\n",
        "       simple_regret_stp_7[slice25],\n",
        "       simple_regret_stp_8[slice25],\n",
        "       simple_regret_stp_9[slice25],\n",
        "       simple_regret_stp_10[slice25],\n",
        "       simple_regret_stp_11[slice25],\n",
        "       simple_regret_stp_12[slice25],\n",
        "       simple_regret_stp_13[slice25],\n",
        "       simple_regret_stp_14[slice25],\n",
        "       simple_regret_stp_15[slice25],\n",
        "       simple_regret_stp_16[slice25],\n",
        "       simple_regret_stp_17[slice25],\n",
        "       simple_regret_stp_18[slice25],\n",
        "       simple_regret_stp_19[slice25],\n",
        "       simple_regret_stp_20[slice25]]\n",
        "\n",
        "gp25_results = pd.DataFrame(gp25).sort_values(by=[0], ascending=False)\n",
        "stp25_results = pd.DataFrame(stp25).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - gp:\n",
        "lower_gp25 = np.asarray(gp25_results[4:5][0])[0]\n",
        "median_gp25 = np.asarray(gp25_results[9:10][0])[0]\n",
        "upper_gp25 = np.asarray(gp25_results[14:15][0])[0]\n",
        "\n",
        "lower_stp25 = np.asarray(stp25_results[4:5][0])[0]\n",
        "median_stp25 = np.asarray(stp25_results[9:10][0])[0]\n",
        "upper_stp25= np.asarray(stp25_results[14:15][0])[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "ArKvr7kMJLl_"
      },
      "outputs": [],
      "source": [
        "# Iteration35 :\n",
        "\n",
        "slice35 = 34\n",
        "\n",
        "gp35 = [simple_regret_gp_1[slice35],\n",
        "       simple_regret_gp_2[slice35],\n",
        "       simple_regret_gp_3[slice35],\n",
        "       simple_regret_gp_4[slice35],\n",
        "       simple_regret_gp_5[slice35],\n",
        "       simple_regret_gp_6[slice35],\n",
        "       simple_regret_gp_7[slice35],\n",
        "       simple_regret_gp_8[slice35],\n",
        "       simple_regret_gp_9[slice35],\n",
        "       simple_regret_gp_10[slice35],\n",
        "       simple_regret_gp_11[slice35],\n",
        "       simple_regret_gp_12[slice35],\n",
        "       simple_regret_gp_13[slice35],\n",
        "       simple_regret_gp_14[slice35],\n",
        "       simple_regret_gp_15[slice35],\n",
        "       simple_regret_gp_16[slice35],\n",
        "       simple_regret_gp_17[slice35],\n",
        "       simple_regret_gp_18[slice35],\n",
        "       simple_regret_gp_19[slice35],\n",
        "       simple_regret_gp_20[slice35]]\n",
        "\n",
        "stp35 = [simple_regret_stp_1[slice35],\n",
        "       simple_regret_stp_2[slice35],\n",
        "       simple_regret_stp_3[slice35],\n",
        "       simple_regret_stp_4[slice35],\n",
        "       simple_regret_stp_5[slice35],\n",
        "       simple_regret_stp_6[slice35],\n",
        "       simple_regret_stp_7[slice35],\n",
        "       simple_regret_stp_8[slice35],\n",
        "       simple_regret_stp_9[slice35],\n",
        "       simple_regret_stp_10[slice35],\n",
        "       simple_regret_stp_11[slice35],\n",
        "       simple_regret_stp_12[slice35],\n",
        "       simple_regret_stp_13[slice35],\n",
        "       simple_regret_stp_14[slice35],\n",
        "       simple_regret_stp_15[slice35],\n",
        "       simple_regret_stp_16[slice35],\n",
        "       simple_regret_stp_17[slice35],\n",
        "       simple_regret_stp_18[slice35],\n",
        "       simple_regret_stp_19[slice35],\n",
        "       simple_regret_stp_20[slice35]]\n",
        "\n",
        "gp35_results = pd.DataFrame(gp35).sort_values(by=[0], ascending=False)\n",
        "stp35_results = pd.DataFrame(stp35).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - gp:\n",
        "lower_gp35 = np.asarray(gp35_results[4:5][0])[0]\n",
        "median_gp35 = np.asarray(gp35_results[9:10][0])[0]\n",
        "upper_gp35 = np.asarray(gp35_results[14:15][0])[0]\n",
        "\n",
        "lower_stp35 = np.asarray(stp35_results[4:5][0])[0]\n",
        "median_stp35 = np.asarray(stp35_results[9:10][0])[0]\n",
        "upper_stp35 = np.asarray(stp35_results[14:15][0])[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "KnUohI0LJLl_"
      },
      "outputs": [],
      "source": [
        "# Iteration45 :\n",
        "\n",
        "slice45 = 44\n",
        "\n",
        "gp45 = [simple_regret_gp_1[slice45],\n",
        "       simple_regret_gp_2[slice45],\n",
        "       simple_regret_gp_3[slice45],\n",
        "       simple_regret_gp_4[slice45],\n",
        "       simple_regret_gp_5[slice45],\n",
        "       simple_regret_gp_6[slice45],\n",
        "       simple_regret_gp_7[slice45],\n",
        "       simple_regret_gp_8[slice45],\n",
        "       simple_regret_gp_9[slice45],\n",
        "       simple_regret_gp_10[slice45],\n",
        "       simple_regret_gp_11[slice45],\n",
        "       simple_regret_gp_12[slice45],\n",
        "       simple_regret_gp_13[slice45],\n",
        "       simple_regret_gp_14[slice45],\n",
        "       simple_regret_gp_15[slice45],\n",
        "       simple_regret_gp_16[slice45],\n",
        "       simple_regret_gp_17[slice45],\n",
        "       simple_regret_gp_18[slice45],\n",
        "       simple_regret_gp_19[slice45],\n",
        "       simple_regret_gp_20[slice45]]\n",
        "\n",
        "stp45 = [simple_regret_stp_1[slice45],\n",
        "       simple_regret_stp_2[slice45],\n",
        "       simple_regret_stp_3[slice45],\n",
        "       simple_regret_stp_4[slice45],\n",
        "       simple_regret_stp_5[slice45],\n",
        "       simple_regret_stp_6[slice45],\n",
        "       simple_regret_stp_7[slice45],\n",
        "       simple_regret_stp_8[slice45],\n",
        "       simple_regret_stp_9[slice45],\n",
        "       simple_regret_stp_10[slice45],\n",
        "       simple_regret_stp_11[slice45],\n",
        "       simple_regret_stp_12[slice45],\n",
        "       simple_regret_stp_13[slice45],\n",
        "       simple_regret_stp_14[slice45],\n",
        "       simple_regret_stp_15[slice45],\n",
        "       simple_regret_stp_16[slice45],\n",
        "       simple_regret_stp_17[slice45],\n",
        "       simple_regret_stp_18[slice45],\n",
        "       simple_regret_stp_19[slice45],\n",
        "       simple_regret_stp_20[slice45]]\n",
        "\n",
        "gp45_results = pd.DataFrame(gp45).sort_values(by=[0], ascending=False)\n",
        "stp45_results = pd.DataFrame(stp45).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - gp:\n",
        "lower_gp45 = np.asarray(gp45_results[4:5][0])[0]\n",
        "median_gp45 = np.asarray(gp45_results[9:10][0])[0]\n",
        "upper_gp45 = np.asarray(gp45_results[14:15][0])[0]\n",
        "\n",
        "lower_stp45 = np.asarray(stp45_results[4:5][0])[0]\n",
        "median_stp45 = np.asarray(stp45_results[9:10][0])[0]\n",
        "upper_stp45 = np.asarray(stp45_results[14:15][0])[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "0_by53ZHJLmA"
      },
      "outputs": [],
      "source": [
        "# Iteration55 :\n",
        "\n",
        "slice55 = 54\n",
        "\n",
        "gp55 = [simple_regret_gp_1[slice55],\n",
        "       simple_regret_gp_2[slice55],\n",
        "       simple_regret_gp_3[slice55],\n",
        "       simple_regret_gp_4[slice55],\n",
        "       simple_regret_gp_5[slice55],\n",
        "       simple_regret_gp_6[slice55],\n",
        "       simple_regret_gp_7[slice55],\n",
        "       simple_regret_gp_8[slice55],\n",
        "       simple_regret_gp_9[slice55],\n",
        "       simple_regret_gp_10[slice55],\n",
        "       simple_regret_gp_11[slice55],\n",
        "       simple_regret_gp_12[slice55],\n",
        "       simple_regret_gp_13[slice55],\n",
        "       simple_regret_gp_14[slice55],\n",
        "       simple_regret_gp_15[slice55],\n",
        "       simple_regret_gp_16[slice55],\n",
        "       simple_regret_gp_17[slice55],\n",
        "       simple_regret_gp_18[slice55],\n",
        "       simple_regret_gp_19[slice55],\n",
        "       simple_regret_gp_20[slice55]]\n",
        "\n",
        "stp55 = [simple_regret_stp_1[slice55],\n",
        "       simple_regret_stp_2[slice55],\n",
        "       simple_regret_stp_3[slice55],\n",
        "       simple_regret_stp_4[slice55],\n",
        "       simple_regret_stp_5[slice55],\n",
        "       simple_regret_stp_6[slice55],\n",
        "       simple_regret_stp_7[slice55],\n",
        "       simple_regret_stp_8[slice55],\n",
        "       simple_regret_stp_9[slice55],\n",
        "       simple_regret_stp_10[slice55],\n",
        "       simple_regret_stp_11[slice55],\n",
        "       simple_regret_stp_12[slice55],\n",
        "       simple_regret_stp_13[slice55],\n",
        "       simple_regret_stp_14[slice55],\n",
        "       simple_regret_stp_15[slice55],\n",
        "       simple_regret_stp_16[slice55],\n",
        "       simple_regret_stp_17[slice55],\n",
        "       simple_regret_stp_18[slice55],\n",
        "       simple_regret_stp_19[slice55],\n",
        "       simple_regret_stp_20[slice55]]\n",
        "\n",
        "gp55_results = pd.DataFrame(gp55).sort_values(by=[0], ascending=False)\n",
        "stp55_results = pd.DataFrame(stp55).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - gp:\n",
        "lower_gp55 = np.asarray(gp55_results[4:5][0])[0]\n",
        "median_gp55 = np.asarray(gp55_results[9:10][0])[0]\n",
        "upper_gp55 = np.asarray(gp55_results[14:15][0])[0]\n",
        "\n",
        "lower_stp55 = np.asarray(stp55_results[4:5][0])[0]\n",
        "median_stp55 = np.asarray(stp55_results[9:10][0])[0]\n",
        "upper_stp55 = np.asarray(stp55_results[14:15][0])[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "o8Dgj0tyJLmA"
      },
      "outputs": [],
      "source": [
        "# Iteration65 :\n",
        "\n",
        "slice65 = 64\n",
        "\n",
        "gp65 = [simple_regret_gp_1[slice65],\n",
        "       simple_regret_gp_2[slice65],\n",
        "       simple_regret_gp_3[slice65],\n",
        "       simple_regret_gp_4[slice65],\n",
        "       simple_regret_gp_5[slice65],\n",
        "       simple_regret_gp_6[slice65],\n",
        "       simple_regret_gp_7[slice65],\n",
        "       simple_regret_gp_8[slice65],\n",
        "       simple_regret_gp_9[slice65],\n",
        "       simple_regret_gp_10[slice65],\n",
        "       simple_regret_gp_11[slice65],\n",
        "       simple_regret_gp_12[slice65],\n",
        "       simple_regret_gp_13[slice65],\n",
        "       simple_regret_gp_14[slice65],\n",
        "       simple_regret_gp_15[slice65],\n",
        "       simple_regret_gp_16[slice65],\n",
        "       simple_regret_gp_17[slice65],\n",
        "       simple_regret_gp_18[slice65],\n",
        "       simple_regret_gp_19[slice65],\n",
        "       simple_regret_gp_20[slice65]]\n",
        "\n",
        "stp65 = [simple_regret_stp_1[slice65],\n",
        "       simple_regret_stp_2[slice65],\n",
        "       simple_regret_stp_3[slice65],\n",
        "       simple_regret_stp_4[slice65],\n",
        "       simple_regret_stp_5[slice65],\n",
        "       simple_regret_stp_6[slice65],\n",
        "       simple_regret_stp_7[slice65],\n",
        "       simple_regret_stp_8[slice65],\n",
        "       simple_regret_stp_9[slice65],\n",
        "       simple_regret_stp_10[slice65],\n",
        "       simple_regret_stp_11[slice65],\n",
        "       simple_regret_stp_12[slice65],\n",
        "       simple_regret_stp_13[slice65],\n",
        "       simple_regret_stp_14[slice65],\n",
        "       simple_regret_stp_15[slice65],\n",
        "       simple_regret_stp_16[slice65],\n",
        "       simple_regret_stp_17[slice65],\n",
        "       simple_regret_stp_18[slice65],\n",
        "       simple_regret_stp_19[slice65],\n",
        "       simple_regret_stp_20[slice65]]\n",
        "\n",
        "gp65_results = pd.DataFrame(gp65).sort_values(by=[0], ascending=False)\n",
        "stp65_results = pd.DataFrame(stp65).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - gp:\n",
        "lower_gp65 = np.asarray(gp65_results[4:5][0])[0]\n",
        "median_gp65 = np.asarray(gp65_results[9:10][0])[0]\n",
        "upper_gp65 = np.asarray(gp65_results[14:15][0])[0]\n",
        "\n",
        "lower_stp65 = np.asarray(stp65_results[4:5][0])[0]\n",
        "median_stp65 = np.asarray(stp65_results[9:10][0])[0]\n",
        "upper_stp65 = np.asarray(stp65_results[14:15][0])[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "V-r7jv0nJLmB"
      },
      "outputs": [],
      "source": [
        "# Iteration75 :\n",
        "\n",
        "slice75 = 74\n",
        "\n",
        "gp75 = [simple_regret_gp_1[slice75],\n",
        "       simple_regret_gp_2[slice75],\n",
        "       simple_regret_gp_3[slice75],\n",
        "       simple_regret_gp_4[slice75],\n",
        "       simple_regret_gp_5[slice75],\n",
        "       simple_regret_gp_6[slice75],\n",
        "       simple_regret_gp_7[slice75],\n",
        "       simple_regret_gp_8[slice75],\n",
        "       simple_regret_gp_9[slice75],\n",
        "       simple_regret_gp_10[slice75],\n",
        "       simple_regret_gp_11[slice75],\n",
        "       simple_regret_gp_12[slice75],\n",
        "       simple_regret_gp_13[slice75],\n",
        "       simple_regret_gp_14[slice75],\n",
        "       simple_regret_gp_15[slice75],\n",
        "       simple_regret_gp_16[slice75],\n",
        "       simple_regret_gp_17[slice75],\n",
        "       simple_regret_gp_18[slice75],\n",
        "       simple_regret_gp_19[slice75],\n",
        "       simple_regret_gp_20[slice75]]\n",
        "\n",
        "stp75 = [simple_regret_stp_1[slice75],\n",
        "       simple_regret_stp_2[slice75],\n",
        "       simple_regret_stp_3[slice75],\n",
        "       simple_regret_stp_4[slice75],\n",
        "       simple_regret_stp_5[slice75],\n",
        "       simple_regret_stp_6[slice75],\n",
        "       simple_regret_stp_7[slice75],\n",
        "       simple_regret_stp_8[slice75],\n",
        "       simple_regret_stp_9[slice75],\n",
        "       simple_regret_stp_10[slice75],\n",
        "       simple_regret_stp_11[slice75],\n",
        "       simple_regret_stp_12[slice75],\n",
        "       simple_regret_stp_13[slice75],\n",
        "       simple_regret_stp_14[slice75],\n",
        "       simple_regret_stp_15[slice75],\n",
        "       simple_regret_stp_16[slice75],\n",
        "       simple_regret_stp_17[slice75],\n",
        "       simple_regret_stp_18[slice75],\n",
        "       simple_regret_stp_19[slice75],\n",
        "       simple_regret_stp_20[slice75]]\n",
        "\n",
        "gp75_results = pd.DataFrame(gp75).sort_values(by=[0], ascending=False)\n",
        "stp75_results = pd.DataFrame(stp75).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - gp:\n",
        "lower_gp75 = np.asarray(gp75_results[4:5][0])[0]\n",
        "median_gp75 = np.asarray(gp75_results[9:10][0])[0]\n",
        "upper_gp75 = np.asarray(gp75_results[14:15][0])[0]\n",
        "\n",
        "lower_stp75 = np.asarray(stp75_results[4:5][0])[0]\n",
        "median_stp75 = np.asarray(stp75_results[9:10][0])[0]\n",
        "upper_stp75 = np.asarray(stp75_results[14:15][0])[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "0hweuF60JLmB"
      },
      "outputs": [],
      "source": [
        "# Iteration85 :\n",
        "\n",
        "slice85 = 84\n",
        "\n",
        "gp85 = [simple_regret_gp_1[slice85],\n",
        "       simple_regret_gp_2[slice85],\n",
        "       simple_regret_gp_3[slice85],\n",
        "       simple_regret_gp_4[slice85],\n",
        "       simple_regret_gp_5[slice85],\n",
        "       simple_regret_gp_6[slice85],\n",
        "       simple_regret_gp_7[slice85],\n",
        "       simple_regret_gp_8[slice85],\n",
        "       simple_regret_gp_9[slice85],\n",
        "       simple_regret_gp_10[slice85],\n",
        "       simple_regret_gp_11[slice85],\n",
        "       simple_regret_gp_12[slice85],\n",
        "       simple_regret_gp_13[slice85],\n",
        "       simple_regret_gp_14[slice85],\n",
        "       simple_regret_gp_15[slice85],\n",
        "       simple_regret_gp_16[slice85],\n",
        "       simple_regret_gp_17[slice85],\n",
        "       simple_regret_gp_18[slice85],\n",
        "       simple_regret_gp_19[slice85],\n",
        "       simple_regret_gp_20[slice85]]\n",
        "\n",
        "stp85 = [simple_regret_stp_1[slice85],\n",
        "       simple_regret_stp_2[slice85],\n",
        "       simple_regret_stp_3[slice85],\n",
        "       simple_regret_stp_4[slice85],\n",
        "       simple_regret_stp_5[slice85],\n",
        "       simple_regret_stp_6[slice85],\n",
        "       simple_regret_stp_7[slice85],\n",
        "       simple_regret_stp_8[slice85],\n",
        "       simple_regret_stp_9[slice85],\n",
        "       simple_regret_stp_10[slice85],\n",
        "       simple_regret_stp_11[slice85],\n",
        "       simple_regret_stp_12[slice85],\n",
        "       simple_regret_stp_13[slice85],\n",
        "       simple_regret_stp_14[slice85],\n",
        "       simple_regret_stp_15[slice85],\n",
        "       simple_regret_stp_16[slice85],\n",
        "       simple_regret_stp_17[slice85],\n",
        "       simple_regret_stp_18[slice85],\n",
        "       simple_regret_stp_19[slice85],\n",
        "       simple_regret_stp_20[slice85]]\n",
        "\n",
        "gp85_results = pd.DataFrame(gp85).sort_values(by=[0], ascending=False)\n",
        "stp85_results = pd.DataFrame(stp85).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - gp:\n",
        "lower_gp85 = np.asarray(gp85_results[4:5][0])[0]\n",
        "median_gp85 = np.asarray(gp85_results[9:10][0])[0]\n",
        "upper_gp85 = np.asarray(gp85_results[14:15][0])[0]\n",
        "\n",
        "lower_stp85 = np.asarray(stp85_results[4:5][0])[0]\n",
        "median_stp85 = np.asarray(stp85_results[9:10][0])[0]\n",
        "upper_stp85 = np.asarray(stp85_results[14:15][0])[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "ex3pcd3lJLmC"
      },
      "outputs": [],
      "source": [
        "# Iteration95 :\n",
        "\n",
        "slice95 = 94\n",
        "\n",
        "gp95 = [simple_regret_gp_1[slice95],\n",
        "       simple_regret_gp_2[slice95],\n",
        "       simple_regret_gp_3[slice95],\n",
        "       simple_regret_gp_4[slice95],\n",
        "       simple_regret_gp_5[slice95],\n",
        "       simple_regret_gp_6[slice95],\n",
        "       simple_regret_gp_7[slice95],\n",
        "       simple_regret_gp_8[slice95],\n",
        "       simple_regret_gp_9[slice95],\n",
        "       simple_regret_gp_10[slice95],\n",
        "       simple_regret_gp_11[slice95],\n",
        "       simple_regret_gp_12[slice95],\n",
        "       simple_regret_gp_13[slice95],\n",
        "       simple_regret_gp_14[slice95],\n",
        "       simple_regret_gp_15[slice95],\n",
        "       simple_regret_gp_16[slice95],\n",
        "       simple_regret_gp_17[slice95],\n",
        "       simple_regret_gp_18[slice95],\n",
        "       simple_regret_gp_19[slice95],\n",
        "       simple_regret_gp_20[slice95]]\n",
        "\n",
        "stp95 = [simple_regret_stp_1[slice95],\n",
        "       simple_regret_stp_2[slice95],\n",
        "       simple_regret_stp_3[slice95],\n",
        "       simple_regret_stp_4[slice95],\n",
        "       simple_regret_stp_5[slice95],\n",
        "       simple_regret_stp_6[slice95],\n",
        "       simple_regret_stp_7[slice95],\n",
        "       simple_regret_stp_8[slice95],\n",
        "       simple_regret_stp_9[slice95],\n",
        "       simple_regret_stp_10[slice95],\n",
        "       simple_regret_stp_11[slice95],\n",
        "       simple_regret_stp_12[slice95],\n",
        "       simple_regret_stp_13[slice95],\n",
        "       simple_regret_stp_14[slice95],\n",
        "       simple_regret_stp_15[slice95],\n",
        "       simple_regret_stp_16[slice95],\n",
        "       simple_regret_stp_17[slice95],\n",
        "       simple_regret_stp_18[slice95],\n",
        "       simple_regret_stp_19[slice95],\n",
        "       simple_regret_stp_20[slice95]]\n",
        "\n",
        "gp95_results = pd.DataFrame(gp95).sort_values(by=[0], ascending=False)\n",
        "stp95_results = pd.DataFrame(stp95).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - gp:\n",
        "lower_gp95 = np.asarray(gp95_results[4:5][0])[0]\n",
        "median_gp95 = np.asarray(gp95_results[9:10][0])[0]\n",
        "upper_gp95 = np.asarray(gp95_results[14:15][0])[0]\n",
        "\n",
        "lower_stp95 = np.asarray(stp95_results[4:5][0])[0]\n",
        "median_stp95 = np.asarray(stp95_results[9:10][0])[0]\n",
        "upper_stp95 = np.asarray(stp95_results[14:15][0])[0]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "id": "XqsNyHzqJLmC"
      },
      "outputs": [],
      "source": [
        "# Iteration6 :\n",
        "\n",
        "slice6 = 5\n",
        "\n",
        "gp6 = [simple_regret_gp_1[slice6],\n",
        "       simple_regret_gp_2[slice6],\n",
        "       simple_regret_gp_3[slice6],\n",
        "       simple_regret_gp_4[slice6],\n",
        "       simple_regret_gp_5[slice6],\n",
        "       simple_regret_gp_6[slice6],\n",
        "       simple_regret_gp_7[slice6],\n",
        "       simple_regret_gp_8[slice6],\n",
        "       simple_regret_gp_9[slice6],\n",
        "       simple_regret_gp_10[slice6],\n",
        "       simple_regret_gp_11[slice6],\n",
        "       simple_regret_gp_12[slice6],\n",
        "       simple_regret_gp_13[slice6],\n",
        "       simple_regret_gp_14[slice6],\n",
        "       simple_regret_gp_15[slice6],\n",
        "       simple_regret_gp_16[slice6],\n",
        "       simple_regret_gp_17[slice6],\n",
        "       simple_regret_gp_18[slice6],\n",
        "       simple_regret_gp_19[slice6],\n",
        "       simple_regret_gp_20[slice6]]\n",
        "\n",
        "stp6 = [simple_regret_stp_1[slice6],\n",
        "       simple_regret_stp_2[slice6],\n",
        "       simple_regret_stp_3[slice6],\n",
        "       simple_regret_stp_4[slice6],\n",
        "       simple_regret_stp_5[slice6],\n",
        "       simple_regret_stp_6[slice6],\n",
        "       simple_regret_stp_7[slice6],\n",
        "       simple_regret_stp_8[slice6],\n",
        "       simple_regret_stp_9[slice6],\n",
        "       simple_regret_stp_10[slice6],\n",
        "       simple_regret_stp_11[slice6],\n",
        "       simple_regret_stp_12[slice6],\n",
        "       simple_regret_stp_13[slice6],\n",
        "       simple_regret_stp_14[slice6],\n",
        "       simple_regret_stp_15[slice6],\n",
        "       simple_regret_stp_16[slice6],\n",
        "       simple_regret_stp_17[slice6],\n",
        "       simple_regret_stp_18[slice6],\n",
        "       simple_regret_stp_19[slice6],\n",
        "       simple_regret_stp_20[slice6]]\n",
        "\n",
        "gp6_results = pd.DataFrame(gp6).sort_values(by=[0], ascending=False)\n",
        "stp6_results = pd.DataFrame(stp6).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - gp:\n",
        "lower_gp6 = np.asarray(gp6_results[4:5][0])[0]\n",
        "median_gp6 = np.asarray(gp6_results[9:10][0])[0]\n",
        "upper_gp6 = np.asarray(gp6_results[14:15][0])[0]\n",
        "\n",
        "lower_stp6 = np.asarray(stp6_results[4:5][0])[0]\n",
        "median_stp6 = np.asarray(stp6_results[9:10][0])[0]\n",
        "upper_stp6 = np.asarray(stp6_results[14:15][0])[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "V0-8P_clJLmD"
      },
      "outputs": [],
      "source": [
        "# Iteration16 :\n",
        "\n",
        "slice16 = 15\n",
        "\n",
        "gp16 = [simple_regret_gp_1[slice16],\n",
        "       simple_regret_gp_2[slice16],\n",
        "       simple_regret_gp_3[slice16],\n",
        "       simple_regret_gp_4[slice16],\n",
        "       simple_regret_gp_5[slice16],\n",
        "       simple_regret_gp_6[slice16],\n",
        "       simple_regret_gp_7[slice16],\n",
        "       simple_regret_gp_8[slice16],\n",
        "       simple_regret_gp_9[slice16],\n",
        "       simple_regret_gp_10[slice16],\n",
        "       simple_regret_gp_11[slice16],\n",
        "       simple_regret_gp_12[slice16],\n",
        "       simple_regret_gp_13[slice16],\n",
        "       simple_regret_gp_14[slice16],\n",
        "       simple_regret_gp_15[slice16],\n",
        "       simple_regret_gp_16[slice16],\n",
        "       simple_regret_gp_17[slice16],\n",
        "       simple_regret_gp_18[slice16],\n",
        "       simple_regret_gp_19[slice16],\n",
        "       simple_regret_gp_20[slice16]]\n",
        "\n",
        "stp16 = [simple_regret_stp_1[slice16],\n",
        "       simple_regret_stp_2[slice16],\n",
        "       simple_regret_stp_3[slice16],\n",
        "       simple_regret_stp_4[slice16],\n",
        "       simple_regret_stp_5[slice16],\n",
        "       simple_regret_stp_6[slice16],\n",
        "       simple_regret_stp_7[slice16],\n",
        "       simple_regret_stp_8[slice16],\n",
        "       simple_regret_stp_9[slice16],\n",
        "       simple_regret_stp_10[slice16],\n",
        "       simple_regret_stp_11[slice16],\n",
        "       simple_regret_stp_12[slice16],\n",
        "       simple_regret_stp_13[slice16],\n",
        "       simple_regret_stp_14[slice16],\n",
        "       simple_regret_stp_15[slice16],\n",
        "       simple_regret_stp_16[slice16],\n",
        "       simple_regret_stp_17[slice16],\n",
        "       simple_regret_stp_18[slice16],\n",
        "       simple_regret_stp_19[slice16],\n",
        "       simple_regret_stp_20[slice16]]\n",
        "\n",
        "gp16_results = pd.DataFrame(gp16).sort_values(by=[0], ascending=False)\n",
        "stp16_results = pd.DataFrame(stp16).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - gp:\n",
        "lower_gp16 = np.asarray(gp16_results[4:5][0])[0]\n",
        "median_gp16 = np.asarray(gp16_results[9:10][0])[0]\n",
        "upper_gp16 = np.asarray(gp16_results[14:15][0])[0]\n",
        "\n",
        "lower_stp16 = np.asarray(stp16_results[4:5][0])[0]\n",
        "median_stp16 = np.asarray(stp16_results[9:10][0])[0]\n",
        "upper_stp16 = np.asarray(stp16_results[14:15][0])[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "id": "tuACzf45JLmE"
      },
      "outputs": [],
      "source": [
        "# Iteration26 :\n",
        "\n",
        "slice26 = 25\n",
        "\n",
        "gp26 = [simple_regret_gp_1[slice26],\n",
        "       simple_regret_gp_2[slice26],\n",
        "       simple_regret_gp_3[slice26],\n",
        "       simple_regret_gp_4[slice26],\n",
        "       simple_regret_gp_5[slice26],\n",
        "       simple_regret_gp_6[slice26],\n",
        "       simple_regret_gp_7[slice26],\n",
        "       simple_regret_gp_8[slice26],\n",
        "       simple_regret_gp_9[slice26],\n",
        "       simple_regret_gp_10[slice26],\n",
        "       simple_regret_gp_11[slice26],\n",
        "       simple_regret_gp_12[slice26],\n",
        "       simple_regret_gp_13[slice26],\n",
        "       simple_regret_gp_14[slice26],\n",
        "       simple_regret_gp_15[slice26],\n",
        "       simple_regret_gp_16[slice26],\n",
        "       simple_regret_gp_17[slice26],\n",
        "       simple_regret_gp_18[slice26],\n",
        "       simple_regret_gp_19[slice26],\n",
        "       simple_regret_gp_20[slice26]]\n",
        "\n",
        "stp26 = [simple_regret_stp_1[slice26],\n",
        "       simple_regret_stp_2[slice26],\n",
        "       simple_regret_stp_3[slice26],\n",
        "       simple_regret_stp_4[slice26],\n",
        "       simple_regret_stp_5[slice26],\n",
        "       simple_regret_stp_6[slice26],\n",
        "       simple_regret_stp_7[slice26],\n",
        "       simple_regret_stp_8[slice26],\n",
        "       simple_regret_stp_9[slice26],\n",
        "       simple_regret_stp_10[slice26],\n",
        "       simple_regret_stp_11[slice26],\n",
        "       simple_regret_stp_12[slice26],\n",
        "       simple_regret_stp_13[slice26],\n",
        "       simple_regret_stp_14[slice26],\n",
        "       simple_regret_stp_15[slice26],\n",
        "       simple_regret_stp_16[slice26],\n",
        "       simple_regret_stp_17[slice26],\n",
        "       simple_regret_stp_18[slice26],\n",
        "       simple_regret_stp_19[slice26],\n",
        "       simple_regret_stp_20[slice26]]\n",
        "\n",
        "gp26_results = pd.DataFrame(gp26).sort_values(by=[0], ascending=False)\n",
        "stp26_results = pd.DataFrame(stp26).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - gp:\n",
        "lower_gp26 = np.asarray(gp26_results[4:5][0])[0]\n",
        "median_gp26 = np.asarray(gp26_results[9:10][0])[0]\n",
        "upper_gp26 = np.asarray(gp26_results[14:15][0])[0]\n",
        "\n",
        "lower_stp26 = np.asarray(stp26_results[4:5][0])[0]\n",
        "median_stp26 = np.asarray(stp26_results[9:10][0])[0]\n",
        "upper_stp26 = np.asarray(stp26_results[14:15][0])[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "id": "Lm90naVoJLmE"
      },
      "outputs": [],
      "source": [
        "# Iteration36 :\n",
        "\n",
        "slice36 = 35\n",
        "\n",
        "gp36 = [simple_regret_gp_1[slice36],\n",
        "       simple_regret_gp_2[slice36],\n",
        "       simple_regret_gp_3[slice36],\n",
        "       simple_regret_gp_4[slice36],\n",
        "       simple_regret_gp_5[slice36],\n",
        "       simple_regret_gp_6[slice36],\n",
        "       simple_regret_gp_7[slice36],\n",
        "       simple_regret_gp_8[slice36],\n",
        "       simple_regret_gp_9[slice36],\n",
        "       simple_regret_gp_10[slice36],\n",
        "       simple_regret_gp_11[slice36],\n",
        "       simple_regret_gp_12[slice36],\n",
        "       simple_regret_gp_13[slice36],\n",
        "       simple_regret_gp_14[slice36],\n",
        "       simple_regret_gp_15[slice36],\n",
        "       simple_regret_gp_16[slice36],\n",
        "       simple_regret_gp_17[slice36],\n",
        "       simple_regret_gp_18[slice36],\n",
        "       simple_regret_gp_19[slice36],\n",
        "       simple_regret_gp_20[slice36]]\n",
        "\n",
        "stp36 = [simple_regret_stp_1[slice36],\n",
        "       simple_regret_stp_2[slice36],\n",
        "       simple_regret_stp_3[slice36],\n",
        "       simple_regret_stp_4[slice36],\n",
        "       simple_regret_stp_5[slice36],\n",
        "       simple_regret_stp_6[slice36],\n",
        "       simple_regret_stp_7[slice36],\n",
        "       simple_regret_stp_8[slice36],\n",
        "       simple_regret_stp_9[slice36],\n",
        "       simple_regret_stp_10[slice36],\n",
        "       simple_regret_stp_11[slice36],\n",
        "       simple_regret_stp_12[slice36],\n",
        "       simple_regret_stp_13[slice36],\n",
        "       simple_regret_stp_14[slice36],\n",
        "       simple_regret_stp_15[slice36],\n",
        "       simple_regret_stp_16[slice36],\n",
        "       simple_regret_stp_17[slice36],\n",
        "       simple_regret_stp_18[slice36],\n",
        "       simple_regret_stp_19[slice36],\n",
        "       simple_regret_stp_20[slice36]]\n",
        "\n",
        "gp36_results = pd.DataFrame(gp36).sort_values(by=[0], ascending=False)\n",
        "stp36_results = pd.DataFrame(stp36).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - gp:\n",
        "lower_gp36 = np.asarray(gp36_results[4:5][0])[0]\n",
        "median_gp36 = np.asarray(gp36_results[9:10][0])[0]\n",
        "upper_gp36 = np.asarray(gp36_results[14:15][0])[0]\n",
        "\n",
        "lower_stp36 = np.asarray(stp36_results[4:5][0])[0]\n",
        "median_stp36 = np.asarray(stp36_results[9:10][0])[0]\n",
        "upper_stp36 = np.asarray(stp36_results[14:15][0])[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "id": "U4gEwbURJLmF"
      },
      "outputs": [],
      "source": [
        "# Iteration46 :\n",
        "\n",
        "slice46 = 45\n",
        "\n",
        "gp46 = [simple_regret_gp_1[slice46],\n",
        "       simple_regret_gp_2[slice46],\n",
        "       simple_regret_gp_3[slice46],\n",
        "       simple_regret_gp_4[slice46],\n",
        "       simple_regret_gp_5[slice46],\n",
        "       simple_regret_gp_6[slice46],\n",
        "       simple_regret_gp_7[slice46],\n",
        "       simple_regret_gp_8[slice46],\n",
        "       simple_regret_gp_9[slice46],\n",
        "       simple_regret_gp_10[slice46],\n",
        "       simple_regret_gp_11[slice46],\n",
        "       simple_regret_gp_12[slice46],\n",
        "       simple_regret_gp_13[slice46],\n",
        "       simple_regret_gp_14[slice46],\n",
        "       simple_regret_gp_15[slice46],\n",
        "       simple_regret_gp_16[slice46],\n",
        "       simple_regret_gp_17[slice46],\n",
        "       simple_regret_gp_18[slice46],\n",
        "       simple_regret_gp_19[slice46],\n",
        "       simple_regret_gp_20[slice46]]\n",
        "\n",
        "stp46 = [simple_regret_stp_1[slice46],\n",
        "       simple_regret_stp_2[slice46],\n",
        "       simple_regret_stp_3[slice46],\n",
        "       simple_regret_stp_4[slice46],\n",
        "       simple_regret_stp_5[slice46],\n",
        "       simple_regret_stp_6[slice46],\n",
        "       simple_regret_stp_7[slice46],\n",
        "       simple_regret_stp_8[slice46],\n",
        "       simple_regret_stp_9[slice46],\n",
        "       simple_regret_stp_10[slice46],\n",
        "       simple_regret_stp_11[slice46],\n",
        "       simple_regret_stp_12[slice46],\n",
        "       simple_regret_stp_13[slice46],\n",
        "       simple_regret_stp_14[slice46],\n",
        "       simple_regret_stp_15[slice46],\n",
        "       simple_regret_stp_16[slice46],\n",
        "       simple_regret_stp_17[slice46],\n",
        "       simple_regret_stp_18[slice46],\n",
        "       simple_regret_stp_19[slice46],\n",
        "       simple_regret_stp_20[slice46]]\n",
        "\n",
        "gp46_results = pd.DataFrame(gp46).sort_values(by=[0], ascending=False)\n",
        "stp46_results = pd.DataFrame(stp46).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - gp:\n",
        "lower_gp46 = np.asarray(gp46_results[4:5][0])[0]\n",
        "median_gp46 = np.asarray(gp46_results[9:10][0])[0]\n",
        "upper_gp46 = np.asarray(gp46_results[14:15][0])[0]\n",
        "\n",
        "lower_stp46 = np.asarray(stp46_results[4:5][0])[0]\n",
        "median_stp46 = np.asarray(stp46_results[9:10][0])[0]\n",
        "upper_stp46 = np.asarray(stp46_results[14:15][0])[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "id": "70OQjxwNJLmF"
      },
      "outputs": [],
      "source": [
        "# Iteration56 :\n",
        "\n",
        "slice56 = 55\n",
        "\n",
        "gp56 = [simple_regret_gp_1[slice56],\n",
        "       simple_regret_gp_2[slice56],\n",
        "       simple_regret_gp_3[slice56],\n",
        "       simple_regret_gp_4[slice56],\n",
        "       simple_regret_gp_5[slice56],\n",
        "       simple_regret_gp_6[slice56],\n",
        "       simple_regret_gp_7[slice56],\n",
        "       simple_regret_gp_8[slice56],\n",
        "       simple_regret_gp_9[slice56],\n",
        "       simple_regret_gp_10[slice56],\n",
        "       simple_regret_gp_11[slice56],\n",
        "       simple_regret_gp_12[slice56],\n",
        "       simple_regret_gp_13[slice56],\n",
        "       simple_regret_gp_14[slice56],\n",
        "       simple_regret_gp_15[slice56],\n",
        "       simple_regret_gp_16[slice56],\n",
        "       simple_regret_gp_17[slice56],\n",
        "       simple_regret_gp_18[slice56],\n",
        "       simple_regret_gp_19[slice56],\n",
        "       simple_regret_gp_20[slice56]]\n",
        "\n",
        "stp56 = [simple_regret_stp_1[slice56],\n",
        "       simple_regret_stp_2[slice56],\n",
        "       simple_regret_stp_3[slice56],\n",
        "       simple_regret_stp_4[slice56],\n",
        "       simple_regret_stp_5[slice56],\n",
        "       simple_regret_stp_6[slice56],\n",
        "       simple_regret_stp_7[slice56],\n",
        "       simple_regret_stp_8[slice56],\n",
        "       simple_regret_stp_9[slice56],\n",
        "       simple_regret_stp_10[slice56],\n",
        "       simple_regret_stp_11[slice56],\n",
        "       simple_regret_stp_12[slice56],\n",
        "       simple_regret_stp_13[slice56],\n",
        "       simple_regret_stp_14[slice56],\n",
        "       simple_regret_stp_15[slice56],\n",
        "       simple_regret_stp_16[slice56],\n",
        "       simple_regret_stp_17[slice56],\n",
        "       simple_regret_stp_18[slice56],\n",
        "       simple_regret_stp_19[slice56],\n",
        "       simple_regret_stp_20[slice56]]\n",
        "\n",
        "gp56_results = pd.DataFrame(gp56).sort_values(by=[0], ascending=False)\n",
        "stp56_results = pd.DataFrame(stp56).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - gp:\n",
        "lower_gp56 = np.asarray(gp56_results[4:5][0])[0]\n",
        "median_gp56 = np.asarray(gp56_results[9:10][0])[0]\n",
        "upper_gp56 = np.asarray(gp56_results[14:15][0])[0]\n",
        "\n",
        "lower_stp56 = np.asarray(stp56_results[4:5][0])[0]\n",
        "median_stp56 = np.asarray(stp56_results[9:10][0])[0]\n",
        "upper_stp56 = np.asarray(stp56_results[14:15][0])[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "id": "e6XJxXwXJLmG"
      },
      "outputs": [],
      "source": [
        "# Iteration66 :\n",
        "\n",
        "slice66 = 65\n",
        "\n",
        "gp66 = [simple_regret_gp_1[slice66],\n",
        "       simple_regret_gp_2[slice66],\n",
        "       simple_regret_gp_3[slice66],\n",
        "       simple_regret_gp_4[slice66],\n",
        "       simple_regret_gp_5[slice66],\n",
        "       simple_regret_gp_6[slice66],\n",
        "       simple_regret_gp_7[slice66],\n",
        "       simple_regret_gp_8[slice66],\n",
        "       simple_regret_gp_9[slice66],\n",
        "       simple_regret_gp_10[slice66],\n",
        "       simple_regret_gp_11[slice66],\n",
        "       simple_regret_gp_12[slice66],\n",
        "       simple_regret_gp_13[slice66],\n",
        "       simple_regret_gp_14[slice66],\n",
        "       simple_regret_gp_15[slice66],\n",
        "       simple_regret_gp_16[slice66],\n",
        "       simple_regret_gp_17[slice66],\n",
        "       simple_regret_gp_18[slice66],\n",
        "       simple_regret_gp_19[slice66],\n",
        "       simple_regret_gp_20[slice66]]\n",
        "\n",
        "stp66 = [simple_regret_stp_1[slice66],\n",
        "       simple_regret_stp_2[slice66],\n",
        "       simple_regret_stp_3[slice66],\n",
        "       simple_regret_stp_4[slice66],\n",
        "       simple_regret_stp_5[slice66],\n",
        "       simple_regret_stp_6[slice66],\n",
        "       simple_regret_stp_7[slice66],\n",
        "       simple_regret_stp_8[slice66],\n",
        "       simple_regret_stp_9[slice66],\n",
        "       simple_regret_stp_10[slice66],\n",
        "       simple_regret_stp_11[slice66],\n",
        "       simple_regret_stp_12[slice66],\n",
        "       simple_regret_stp_13[slice66],\n",
        "       simple_regret_stp_14[slice66],\n",
        "       simple_regret_stp_15[slice66],\n",
        "       simple_regret_stp_16[slice66],\n",
        "       simple_regret_stp_17[slice66],\n",
        "       simple_regret_stp_18[slice66],\n",
        "       simple_regret_stp_19[slice66],\n",
        "       simple_regret_stp_20[slice66]]\n",
        "\n",
        "gp66_results = pd.DataFrame(gp66).sort_values(by=[0], ascending=False)\n",
        "stp66_results = pd.DataFrame(stp66).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - gp:\n",
        "lower_gp66 = np.asarray(gp66_results[4:5][0])[0]\n",
        "median_gp66 = np.asarray(gp66_results[9:10][0])[0]\n",
        "upper_gp66 = np.asarray(gp66_results[14:15][0])[0]\n",
        "\n",
        "lower_stp66 = np.asarray(stp66_results[4:5][0])[0]\n",
        "median_stp66 = np.asarray(stp66_results[9:10][0])[0]\n",
        "upper_stp66 = np.asarray(stp66_results[14:15][0])[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "id": "wZPNYi0CJLmH"
      },
      "outputs": [],
      "source": [
        "# Iteration76 :\n",
        "\n",
        "slice76 = 75\n",
        "\n",
        "gp76 = [simple_regret_gp_1[slice76],\n",
        "       simple_regret_gp_2[slice76],\n",
        "       simple_regret_gp_3[slice76],\n",
        "       simple_regret_gp_4[slice76],\n",
        "       simple_regret_gp_5[slice76],\n",
        "       simple_regret_gp_6[slice76],\n",
        "       simple_regret_gp_7[slice76],\n",
        "       simple_regret_gp_8[slice76],\n",
        "       simple_regret_gp_9[slice76],\n",
        "       simple_regret_gp_10[slice76],\n",
        "       simple_regret_gp_11[slice76],\n",
        "       simple_regret_gp_12[slice76],\n",
        "       simple_regret_gp_13[slice76],\n",
        "       simple_regret_gp_14[slice76],\n",
        "       simple_regret_gp_15[slice76],\n",
        "       simple_regret_gp_16[slice76],\n",
        "       simple_regret_gp_17[slice76],\n",
        "       simple_regret_gp_18[slice76],\n",
        "       simple_regret_gp_19[slice76],\n",
        "       simple_regret_gp_20[slice76]]\n",
        "\n",
        "stp76 = [simple_regret_stp_1[slice76],\n",
        "       simple_regret_stp_2[slice76],\n",
        "       simple_regret_stp_3[slice76],\n",
        "       simple_regret_stp_4[slice76],\n",
        "       simple_regret_stp_5[slice76],\n",
        "       simple_regret_stp_6[slice76],\n",
        "       simple_regret_stp_7[slice76],\n",
        "       simple_regret_stp_8[slice76],\n",
        "       simple_regret_stp_9[slice76],\n",
        "       simple_regret_stp_10[slice76],\n",
        "       simple_regret_stp_11[slice76],\n",
        "       simple_regret_stp_12[slice76],\n",
        "       simple_regret_stp_13[slice76],\n",
        "       simple_regret_stp_14[slice76],\n",
        "       simple_regret_stp_15[slice76],\n",
        "       simple_regret_stp_16[slice76],\n",
        "       simple_regret_stp_17[slice76],\n",
        "       simple_regret_stp_18[slice76],\n",
        "       simple_regret_stp_19[slice76],\n",
        "       simple_regret_stp_20[slice76]]\n",
        "\n",
        "gp76_results = pd.DataFrame(gp76).sort_values(by=[0], ascending=False)\n",
        "stp76_results = pd.DataFrame(stp76).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - gp:\n",
        "lower_gp76 = np.asarray(gp76_results[4:5][0])[0]\n",
        "median_gp76 = np.asarray(gp76_results[9:10][0])[0]\n",
        "upper_gp76 = np.asarray(gp76_results[14:15][0])[0]\n",
        "\n",
        "lower_stp76 = np.asarray(stp76_results[4:5][0])[0]\n",
        "median_stp76 = np.asarray(stp76_results[9:10][0])[0]\n",
        "upper_stp76 = np.asarray(stp76_results[14:15][0])[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "id": "x09OxfBAJLmJ"
      },
      "outputs": [],
      "source": [
        "# Iteration86 :\n",
        "\n",
        "slice86 = 85\n",
        "\n",
        "gp86 = [simple_regret_gp_1[slice86],\n",
        "       simple_regret_gp_2[slice86],\n",
        "       simple_regret_gp_3[slice86],\n",
        "       simple_regret_gp_4[slice86],\n",
        "       simple_regret_gp_5[slice86],\n",
        "       simple_regret_gp_6[slice86],\n",
        "       simple_regret_gp_7[slice86],\n",
        "       simple_regret_gp_8[slice86],\n",
        "       simple_regret_gp_9[slice86],\n",
        "       simple_regret_gp_10[slice86],\n",
        "       simple_regret_gp_11[slice86],\n",
        "       simple_regret_gp_12[slice86],\n",
        "       simple_regret_gp_13[slice86],\n",
        "       simple_regret_gp_14[slice86],\n",
        "       simple_regret_gp_15[slice86],\n",
        "       simple_regret_gp_16[slice86],\n",
        "       simple_regret_gp_17[slice86],\n",
        "       simple_regret_gp_18[slice86],\n",
        "       simple_regret_gp_19[slice86],\n",
        "       simple_regret_gp_20[slice86]]\n",
        "\n",
        "stp86 = [simple_regret_stp_1[slice86],\n",
        "       simple_regret_stp_2[slice86],\n",
        "       simple_regret_stp_3[slice86],\n",
        "       simple_regret_stp_4[slice86],\n",
        "       simple_regret_stp_5[slice86],\n",
        "       simple_regret_stp_6[slice86],\n",
        "       simple_regret_stp_7[slice86],\n",
        "       simple_regret_stp_8[slice86],\n",
        "       simple_regret_stp_9[slice86],\n",
        "       simple_regret_stp_10[slice86],\n",
        "       simple_regret_stp_11[slice86],\n",
        "       simple_regret_stp_12[slice86],\n",
        "       simple_regret_stp_13[slice86],\n",
        "       simple_regret_stp_14[slice86],\n",
        "       simple_regret_stp_15[slice86],\n",
        "       simple_regret_stp_16[slice86],\n",
        "       simple_regret_stp_17[slice86],\n",
        "       simple_regret_stp_18[slice86],\n",
        "       simple_regret_stp_19[slice86],\n",
        "       simple_regret_stp_20[slice86]]\n",
        "\n",
        "gp86_results = pd.DataFrame(gp86).sort_values(by=[0], ascending=False)\n",
        "stp86_results = pd.DataFrame(stp86).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - gp:\n",
        "lower_gp86 = np.asarray(gp86_results[4:5][0])[0]\n",
        "median_gp86 = np.asarray(gp86_results[9:10][0])[0]\n",
        "upper_gp86 = np.asarray(gp86_results[14:15][0])[0]\n",
        "\n",
        "lower_stp86 = np.asarray(stp86_results[4:5][0])[0]\n",
        "median_stp86 = np.asarray(stp86_results[9:10][0])[0]\n",
        "upper_stp86 = np.asarray(stp86_results[14:15][0])[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "id": "jqojuKpiJLmL"
      },
      "outputs": [],
      "source": [
        "# Iteration96 :\n",
        "\n",
        "slice96 = 95\n",
        "\n",
        "gp96 = [simple_regret_gp_1[slice96],\n",
        "       simple_regret_gp_2[slice96],\n",
        "       simple_regret_gp_3[slice96],\n",
        "       simple_regret_gp_4[slice96],\n",
        "       simple_regret_gp_5[slice96],\n",
        "       simple_regret_gp_6[slice96],\n",
        "       simple_regret_gp_7[slice96],\n",
        "       simple_regret_gp_8[slice96],\n",
        "       simple_regret_gp_9[slice96],\n",
        "       simple_regret_gp_10[slice96],\n",
        "       simple_regret_gp_11[slice96],\n",
        "       simple_regret_gp_12[slice96],\n",
        "       simple_regret_gp_13[slice96],\n",
        "       simple_regret_gp_14[slice96],\n",
        "       simple_regret_gp_15[slice96],\n",
        "       simple_regret_gp_16[slice96],\n",
        "       simple_regret_gp_17[slice96],\n",
        "       simple_regret_gp_18[slice96],\n",
        "       simple_regret_gp_19[slice96],\n",
        "       simple_regret_gp_20[slice96]]\n",
        "\n",
        "stp96 = [simple_regret_stp_1[slice96],\n",
        "       simple_regret_stp_2[slice96],\n",
        "       simple_regret_stp_3[slice96],\n",
        "       simple_regret_stp_4[slice96],\n",
        "       simple_regret_stp_5[slice96],\n",
        "       simple_regret_stp_6[slice96],\n",
        "       simple_regret_stp_7[slice96],\n",
        "       simple_regret_stp_8[slice96],\n",
        "       simple_regret_stp_9[slice96],\n",
        "       simple_regret_stp_10[slice96],\n",
        "       simple_regret_stp_11[slice96],\n",
        "       simple_regret_stp_12[slice96],\n",
        "       simple_regret_stp_13[slice96],\n",
        "       simple_regret_stp_14[slice96],\n",
        "       simple_regret_stp_15[slice96],\n",
        "       simple_regret_stp_16[slice96],\n",
        "       simple_regret_stp_17[slice96],\n",
        "       simple_regret_stp_18[slice96],\n",
        "       simple_regret_stp_19[slice96],\n",
        "       simple_regret_stp_20[slice96]]\n",
        "\n",
        "gp96_results = pd.DataFrame(gp96).sort_values(by=[0], ascending=False)\n",
        "stp96_results = pd.DataFrame(stp96).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - gp:\n",
        "lower_gp96 = np.asarray(gp96_results[4:5][0])[0]\n",
        "median_gp96 = np.asarray(gp96_results[9:10][0])[0]\n",
        "upper_gp96 = np.asarray(gp96_results[14:15][0])[0]\n",
        "\n",
        "lower_stp96 = np.asarray(stp96_results[4:5][0])[0]\n",
        "median_stp96 = np.asarray(stp96_results[9:10][0])[0]\n",
        "upper_stp96 = np.asarray(stp96_results[14:15][0])[0]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "id": "OcLUACB0JLmM"
      },
      "outputs": [],
      "source": [
        "# Iteration7 :\n",
        "\n",
        "slice7 = 6\n",
        "\n",
        "gp7 = [simple_regret_gp_1[slice7],\n",
        "       simple_regret_gp_2[slice7],\n",
        "       simple_regret_gp_3[slice7],\n",
        "       simple_regret_gp_4[slice7],\n",
        "       simple_regret_gp_5[slice7],\n",
        "       simple_regret_gp_6[slice7],\n",
        "       simple_regret_gp_7[slice7],\n",
        "       simple_regret_gp_8[slice7],\n",
        "       simple_regret_gp_9[slice7],\n",
        "       simple_regret_gp_10[slice7],\n",
        "       simple_regret_gp_11[slice7],\n",
        "       simple_regret_gp_12[slice7],\n",
        "       simple_regret_gp_13[slice7],\n",
        "       simple_regret_gp_14[slice7],\n",
        "       simple_regret_gp_15[slice7],\n",
        "       simple_regret_gp_16[slice7],\n",
        "       simple_regret_gp_17[slice7],\n",
        "       simple_regret_gp_18[slice7],\n",
        "       simple_regret_gp_19[slice7],\n",
        "       simple_regret_gp_20[slice7]]\n",
        "\n",
        "stp7 = [simple_regret_stp_1[slice7],\n",
        "       simple_regret_stp_2[slice7],\n",
        "       simple_regret_stp_3[slice7],\n",
        "       simple_regret_stp_4[slice7],\n",
        "       simple_regret_stp_5[slice7],\n",
        "       simple_regret_stp_6[slice7],\n",
        "       simple_regret_stp_7[slice7],\n",
        "       simple_regret_stp_8[slice7],\n",
        "       simple_regret_stp_9[slice7],\n",
        "       simple_regret_stp_10[slice7],\n",
        "       simple_regret_stp_11[slice7],\n",
        "       simple_regret_stp_12[slice7],\n",
        "       simple_regret_stp_13[slice7],\n",
        "       simple_regret_stp_14[slice7],\n",
        "       simple_regret_stp_15[slice7],\n",
        "       simple_regret_stp_16[slice7],\n",
        "       simple_regret_stp_17[slice7],\n",
        "       simple_regret_stp_18[slice7],\n",
        "       simple_regret_stp_19[slice7],\n",
        "       simple_regret_stp_20[slice7]]\n",
        "\n",
        "gp7_results = pd.DataFrame(gp7).sort_values(by=[0], ascending=False)\n",
        "stp7_results = pd.DataFrame(stp7).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - gp:\n",
        "lower_gp7 = np.asarray(gp7_results[4:5][0])[0]\n",
        "median_gp7 = np.asarray(gp7_results[9:10][0])[0]\n",
        "upper_gp7 = np.asarray(gp7_results[14:15][0])[0]\n",
        "\n",
        "lower_stp7 = np.asarray(stp7_results[4:5][0])[0]\n",
        "median_stp7 = np.asarray(stp7_results[9:10][0])[0]\n",
        "upper_stp7 = np.asarray(stp7_results[14:15][0])[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "id": "q-Fd0t3kJLmN"
      },
      "outputs": [],
      "source": [
        "# Iteration17 :\n",
        "\n",
        "slice17 = 16\n",
        "\n",
        "gp17 = [simple_regret_gp_1[slice17],\n",
        "       simple_regret_gp_2[slice17],\n",
        "       simple_regret_gp_3[slice17],\n",
        "       simple_regret_gp_4[slice17],\n",
        "       simple_regret_gp_5[slice17],\n",
        "       simple_regret_gp_6[slice17],\n",
        "       simple_regret_gp_7[slice17],\n",
        "       simple_regret_gp_8[slice17],\n",
        "       simple_regret_gp_9[slice17],\n",
        "       simple_regret_gp_10[slice17],\n",
        "       simple_regret_gp_11[slice17],\n",
        "       simple_regret_gp_12[slice17],\n",
        "       simple_regret_gp_13[slice17],\n",
        "       simple_regret_gp_14[slice17],\n",
        "       simple_regret_gp_15[slice17],\n",
        "       simple_regret_gp_16[slice17],\n",
        "       simple_regret_gp_17[slice17],\n",
        "       simple_regret_gp_18[slice17],\n",
        "       simple_regret_gp_19[slice17],\n",
        "       simple_regret_gp_20[slice17]]\n",
        "\n",
        "stp17 = [simple_regret_stp_1[slice17],\n",
        "       simple_regret_stp_2[slice17],\n",
        "       simple_regret_stp_3[slice17],\n",
        "       simple_regret_stp_4[slice17],\n",
        "       simple_regret_stp_5[slice17],\n",
        "       simple_regret_stp_6[slice17],\n",
        "       simple_regret_stp_7[slice17],\n",
        "       simple_regret_stp_8[slice17],\n",
        "       simple_regret_stp_9[slice17],\n",
        "       simple_regret_stp_10[slice17],\n",
        "       simple_regret_stp_11[slice17],\n",
        "       simple_regret_stp_12[slice17],\n",
        "       simple_regret_stp_13[slice17],\n",
        "       simple_regret_stp_14[slice17],\n",
        "       simple_regret_stp_15[slice17],\n",
        "       simple_regret_stp_16[slice17],\n",
        "       simple_regret_stp_17[slice17],\n",
        "       simple_regret_stp_18[slice17],\n",
        "       simple_regret_stp_19[slice17],\n",
        "       simple_regret_stp_20[slice17]]\n",
        "\n",
        "gp17_results = pd.DataFrame(gp17).sort_values(by=[0], ascending=False)\n",
        "stp17_results = pd.DataFrame(stp17).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - gp:\n",
        "lower_gp17 = np.asarray(gp17_results[4:5][0])[0]\n",
        "median_gp17 = np.asarray(gp17_results[9:10][0])[0]\n",
        "upper_gp17 = np.asarray(gp17_results[14:15][0])[0]\n",
        "\n",
        "lower_stp17 = np.asarray(stp17_results[4:5][0])[0]\n",
        "median_stp17 = np.asarray(stp17_results[9:10][0])[0]\n",
        "upper_stp17 = np.asarray(stp17_results[14:15][0])[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "id": "_MeHFwdpJLmP"
      },
      "outputs": [],
      "source": [
        "# Iteration27 :\n",
        "\n",
        "slice27 = 26\n",
        "\n",
        "gp27 = [simple_regret_gp_1[slice27],\n",
        "       simple_regret_gp_2[slice27],\n",
        "       simple_regret_gp_3[slice27],\n",
        "       simple_regret_gp_4[slice27],\n",
        "       simple_regret_gp_5[slice27],\n",
        "       simple_regret_gp_6[slice27],\n",
        "       simple_regret_gp_7[slice27],\n",
        "       simple_regret_gp_8[slice27],\n",
        "       simple_regret_gp_9[slice27],\n",
        "       simple_regret_gp_10[slice27],\n",
        "       simple_regret_gp_11[slice27],\n",
        "       simple_regret_gp_12[slice27],\n",
        "       simple_regret_gp_13[slice27],\n",
        "       simple_regret_gp_14[slice27],\n",
        "       simple_regret_gp_15[slice27],\n",
        "       simple_regret_gp_16[slice27],\n",
        "       simple_regret_gp_17[slice27],\n",
        "       simple_regret_gp_18[slice27],\n",
        "       simple_regret_gp_19[slice27],\n",
        "       simple_regret_gp_20[slice27]]\n",
        "\n",
        "stp27 = [simple_regret_stp_1[slice27],\n",
        "       simple_regret_stp_2[slice27],\n",
        "       simple_regret_stp_3[slice27],\n",
        "       simple_regret_stp_4[slice27],\n",
        "       simple_regret_stp_5[slice27],\n",
        "       simple_regret_stp_6[slice27],\n",
        "       simple_regret_stp_7[slice27],\n",
        "       simple_regret_stp_8[slice27],\n",
        "       simple_regret_stp_9[slice27],\n",
        "       simple_regret_stp_10[slice27],\n",
        "       simple_regret_stp_11[slice27],\n",
        "       simple_regret_stp_12[slice27],\n",
        "       simple_regret_stp_13[slice27],\n",
        "       simple_regret_stp_14[slice27],\n",
        "       simple_regret_stp_15[slice27],\n",
        "       simple_regret_stp_16[slice27],\n",
        "       simple_regret_stp_17[slice27],\n",
        "       simple_regret_stp_18[slice27],\n",
        "       simple_regret_stp_19[slice27],\n",
        "       simple_regret_stp_20[slice27]]\n",
        "\n",
        "gp27_results = pd.DataFrame(gp27).sort_values(by=[0], ascending=False)\n",
        "stp27_results = pd.DataFrame(stp27).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - gp:\n",
        "lower_gp27 = np.asarray(gp27_results[4:5][0])[0]\n",
        "median_gp27 = np.asarray(gp27_results[9:10][0])[0]\n",
        "upper_gp27 = np.asarray(gp27_results[14:15][0])[0]\n",
        "\n",
        "lower_stp27 = np.asarray(stp27_results[4:5][0])[0]\n",
        "median_stp27 = np.asarray(stp27_results[9:10][0])[0]\n",
        "upper_stp27 = np.asarray(stp27_results[14:15][0])[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "id": "D_rcRCQIJLmQ"
      },
      "outputs": [],
      "source": [
        "# Iteration37 :\n",
        "\n",
        "slice37 = 36\n",
        "\n",
        "gp37 = [simple_regret_gp_1[slice37],\n",
        "       simple_regret_gp_2[slice37],\n",
        "       simple_regret_gp_3[slice37],\n",
        "       simple_regret_gp_4[slice37],\n",
        "       simple_regret_gp_5[slice37],\n",
        "       simple_regret_gp_6[slice37],\n",
        "       simple_regret_gp_7[slice37],\n",
        "       simple_regret_gp_8[slice37],\n",
        "       simple_regret_gp_9[slice37],\n",
        "       simple_regret_gp_10[slice37],\n",
        "       simple_regret_gp_11[slice37],\n",
        "       simple_regret_gp_12[slice37],\n",
        "       simple_regret_gp_13[slice37],\n",
        "       simple_regret_gp_14[slice37],\n",
        "       simple_regret_gp_15[slice37],\n",
        "       simple_regret_gp_16[slice37],\n",
        "       simple_regret_gp_17[slice37],\n",
        "       simple_regret_gp_18[slice37],\n",
        "       simple_regret_gp_19[slice37],\n",
        "       simple_regret_gp_20[slice37]]\n",
        "\n",
        "stp37 = [simple_regret_stp_1[slice37],\n",
        "       simple_regret_stp_2[slice37],\n",
        "       simple_regret_stp_3[slice37],\n",
        "       simple_regret_stp_4[slice37],\n",
        "       simple_regret_stp_5[slice37],\n",
        "       simple_regret_stp_6[slice37],\n",
        "       simple_regret_stp_7[slice37],\n",
        "       simple_regret_stp_8[slice37],\n",
        "       simple_regret_stp_9[slice37],\n",
        "       simple_regret_stp_10[slice37],\n",
        "       simple_regret_stp_11[slice37],\n",
        "       simple_regret_stp_12[slice37],\n",
        "       simple_regret_stp_13[slice37],\n",
        "       simple_regret_stp_14[slice37],\n",
        "       simple_regret_stp_15[slice37],\n",
        "       simple_regret_stp_16[slice37],\n",
        "       simple_regret_stp_17[slice37],\n",
        "       simple_regret_stp_18[slice37],\n",
        "       simple_regret_stp_19[slice37],\n",
        "       simple_regret_stp_20[slice37]]\n",
        "\n",
        "gp37_results = pd.DataFrame(gp37).sort_values(by=[0], ascending=False)\n",
        "stp37_results = pd.DataFrame(stp37).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - gp:\n",
        "lower_gp37 = np.asarray(gp37_results[4:5][0])[0]\n",
        "median_gp37 = np.asarray(gp37_results[9:10][0])[0]\n",
        "upper_gp37 = np.asarray(gp37_results[14:15][0])[0]\n",
        "\n",
        "lower_stp37 = np.asarray(stp37_results[4:5][0])[0]\n",
        "median_stp37 = np.asarray(stp37_results[9:10][0])[0]\n",
        "upper_stp37 = np.asarray(stp37_results[14:15][0])[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "id": "ToQHXp6pJLmR"
      },
      "outputs": [],
      "source": [
        "# Iteration47 :\n",
        "\n",
        "slice47 = 46\n",
        "\n",
        "gp47 = [simple_regret_gp_1[slice47],\n",
        "       simple_regret_gp_2[slice47],\n",
        "       simple_regret_gp_3[slice47],\n",
        "       simple_regret_gp_4[slice47],\n",
        "       simple_regret_gp_5[slice47],\n",
        "       simple_regret_gp_6[slice47],\n",
        "       simple_regret_gp_7[slice47],\n",
        "       simple_regret_gp_8[slice47],\n",
        "       simple_regret_gp_9[slice47],\n",
        "       simple_regret_gp_10[slice47],\n",
        "       simple_regret_gp_11[slice47],\n",
        "       simple_regret_gp_12[slice47],\n",
        "       simple_regret_gp_13[slice47],\n",
        "       simple_regret_gp_14[slice47],\n",
        "       simple_regret_gp_15[slice47],\n",
        "       simple_regret_gp_16[slice47],\n",
        "       simple_regret_gp_17[slice47],\n",
        "       simple_regret_gp_18[slice47],\n",
        "       simple_regret_gp_19[slice47],\n",
        "       simple_regret_gp_20[slice47]]\n",
        "\n",
        "stp47 = [simple_regret_stp_1[slice47],\n",
        "       simple_regret_stp_2[slice47],\n",
        "       simple_regret_stp_3[slice47],\n",
        "       simple_regret_stp_4[slice47],\n",
        "       simple_regret_stp_5[slice47],\n",
        "       simple_regret_stp_6[slice47],\n",
        "       simple_regret_stp_7[slice47],\n",
        "       simple_regret_stp_8[slice47],\n",
        "       simple_regret_stp_9[slice47],\n",
        "       simple_regret_stp_10[slice47],\n",
        "       simple_regret_stp_11[slice47],\n",
        "       simple_regret_stp_12[slice47],\n",
        "       simple_regret_stp_13[slice47],\n",
        "       simple_regret_stp_14[slice47],\n",
        "       simple_regret_stp_15[slice47],\n",
        "       simple_regret_stp_16[slice47],\n",
        "       simple_regret_stp_17[slice47],\n",
        "       simple_regret_stp_18[slice47],\n",
        "       simple_regret_stp_19[slice47],\n",
        "       simple_regret_stp_20[slice47]]\n",
        "\n",
        "gp47_results = pd.DataFrame(gp47).sort_values(by=[0], ascending=False)\n",
        "stp47_results = pd.DataFrame(stp47).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - gp:\n",
        "lower_gp47 = np.asarray(gp47_results[4:5][0])[0]\n",
        "median_gp47 = np.asarray(gp47_results[9:10][0])[0]\n",
        "upper_gp47 = np.asarray(gp47_results[14:15][0])[0]\n",
        "\n",
        "lower_stp47 = np.asarray(stp47_results[4:5][0])[0]\n",
        "median_stp47 = np.asarray(stp47_results[9:10][0])[0]\n",
        "upper_stp47 = np.asarray(stp47_results[14:15][0])[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "id": "ufa7nJb_JLmR"
      },
      "outputs": [],
      "source": [
        "# Iteration57 :\n",
        "\n",
        "slice57 = 56\n",
        "\n",
        "gp57 = [simple_regret_gp_1[slice57],\n",
        "       simple_regret_gp_2[slice57],\n",
        "       simple_regret_gp_3[slice57],\n",
        "       simple_regret_gp_4[slice57],\n",
        "       simple_regret_gp_5[slice57],\n",
        "       simple_regret_gp_6[slice57],\n",
        "       simple_regret_gp_7[slice57],\n",
        "       simple_regret_gp_8[slice57],\n",
        "       simple_regret_gp_9[slice57],\n",
        "       simple_regret_gp_10[slice57],\n",
        "       simple_regret_gp_11[slice57],\n",
        "       simple_regret_gp_12[slice57],\n",
        "       simple_regret_gp_13[slice57],\n",
        "       simple_regret_gp_14[slice57],\n",
        "       simple_regret_gp_15[slice57],\n",
        "       simple_regret_gp_16[slice57],\n",
        "       simple_regret_gp_17[slice57],\n",
        "       simple_regret_gp_18[slice57],\n",
        "       simple_regret_gp_19[slice57],\n",
        "       simple_regret_gp_20[slice57]]\n",
        "\n",
        "stp57 = [simple_regret_stp_1[slice57],\n",
        "       simple_regret_stp_2[slice57],\n",
        "       simple_regret_stp_3[slice57],\n",
        "       simple_regret_stp_4[slice57],\n",
        "       simple_regret_stp_5[slice57],\n",
        "       simple_regret_stp_6[slice57],\n",
        "       simple_regret_stp_7[slice57],\n",
        "       simple_regret_stp_8[slice57],\n",
        "       simple_regret_stp_9[slice57],\n",
        "       simple_regret_stp_10[slice57],\n",
        "       simple_regret_stp_11[slice57],\n",
        "       simple_regret_stp_12[slice57],\n",
        "       simple_regret_stp_13[slice57],\n",
        "       simple_regret_stp_14[slice57],\n",
        "       simple_regret_stp_15[slice57],\n",
        "       simple_regret_stp_16[slice57],\n",
        "       simple_regret_stp_17[slice57],\n",
        "       simple_regret_stp_18[slice57],\n",
        "       simple_regret_stp_19[slice57],\n",
        "       simple_regret_stp_20[slice57]]\n",
        "\n",
        "gp57_results = pd.DataFrame(gp57).sort_values(by=[0], ascending=False)\n",
        "stp57_results = pd.DataFrame(stp57).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - gp:\n",
        "lower_gp57 = np.asarray(gp57_results[4:5][0])[0]\n",
        "median_gp57 = np.asarray(gp57_results[9:10][0])[0]\n",
        "upper_gp57 = np.asarray(gp57_results[14:15][0])[0]\n",
        "\n",
        "lower_stp57 = np.asarray(stp57_results[4:5][0])[0]\n",
        "median_stp57 = np.asarray(stp57_results[9:10][0])[0]\n",
        "upper_stp57 = np.asarray(stp57_results[14:15][0])[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "id": "YHrg_OcVJLmS"
      },
      "outputs": [],
      "source": [
        "# Iteration67 :\n",
        "\n",
        "slice67 = 66\n",
        "\n",
        "gp67 = [simple_regret_gp_1[slice67],\n",
        "       simple_regret_gp_2[slice67],\n",
        "       simple_regret_gp_3[slice67],\n",
        "       simple_regret_gp_4[slice67],\n",
        "       simple_regret_gp_5[slice67],\n",
        "       simple_regret_gp_6[slice67],\n",
        "       simple_regret_gp_7[slice67],\n",
        "       simple_regret_gp_8[slice67],\n",
        "       simple_regret_gp_9[slice67],\n",
        "       simple_regret_gp_10[slice67],\n",
        "       simple_regret_gp_11[slice67],\n",
        "       simple_regret_gp_12[slice67],\n",
        "       simple_regret_gp_13[slice67],\n",
        "       simple_regret_gp_14[slice67],\n",
        "       simple_regret_gp_15[slice67],\n",
        "       simple_regret_gp_16[slice67],\n",
        "       simple_regret_gp_17[slice67],\n",
        "       simple_regret_gp_18[slice67],\n",
        "       simple_regret_gp_19[slice67],\n",
        "       simple_regret_gp_20[slice67]]\n",
        "\n",
        "stp67 = [simple_regret_stp_1[slice67],\n",
        "       simple_regret_stp_2[slice67],\n",
        "       simple_regret_stp_3[slice67],\n",
        "       simple_regret_stp_4[slice67],\n",
        "       simple_regret_stp_5[slice67],\n",
        "       simple_regret_stp_6[slice67],\n",
        "       simple_regret_stp_7[slice67],\n",
        "       simple_regret_stp_8[slice67],\n",
        "       simple_regret_stp_9[slice67],\n",
        "       simple_regret_stp_10[slice67],\n",
        "       simple_regret_stp_11[slice67],\n",
        "       simple_regret_stp_12[slice67],\n",
        "       simple_regret_stp_13[slice67],\n",
        "       simple_regret_stp_14[slice67],\n",
        "       simple_regret_stp_15[slice67],\n",
        "       simple_regret_stp_16[slice67],\n",
        "       simple_regret_stp_17[slice67],\n",
        "       simple_regret_stp_18[slice67],\n",
        "       simple_regret_stp_19[slice67],\n",
        "       simple_regret_stp_20[slice67]]\n",
        "\n",
        "gp67_results = pd.DataFrame(gp67).sort_values(by=[0], ascending=False)\n",
        "stp67_results = pd.DataFrame(stp67).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - gp:\n",
        "lower_gp67 = np.asarray(gp67_results[4:5][0])[0]\n",
        "median_gp67 = np.asarray(gp67_results[9:10][0])[0]\n",
        "upper_gp67 = np.asarray(gp67_results[14:15][0])[0]\n",
        "\n",
        "lower_stp67 = np.asarray(stp67_results[4:5][0])[0]\n",
        "median_stp67 = np.asarray(stp67_results[9:10][0])[0]\n",
        "upper_stp67 = np.asarray(stp67_results[14:15][0])[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "id": "RwcGAjF9JLmS"
      },
      "outputs": [],
      "source": [
        "# Iteration77 :\n",
        "\n",
        "slice77 = 76\n",
        "\n",
        "gp77 = [simple_regret_gp_1[slice77],\n",
        "       simple_regret_gp_2[slice77],\n",
        "       simple_regret_gp_3[slice77],\n",
        "       simple_regret_gp_4[slice77],\n",
        "       simple_regret_gp_5[slice77],\n",
        "       simple_regret_gp_6[slice77],\n",
        "       simple_regret_gp_7[slice77],\n",
        "       simple_regret_gp_8[slice77],\n",
        "       simple_regret_gp_9[slice77],\n",
        "       simple_regret_gp_10[slice77],\n",
        "       simple_regret_gp_11[slice77],\n",
        "       simple_regret_gp_12[slice77],\n",
        "       simple_regret_gp_13[slice77],\n",
        "       simple_regret_gp_14[slice77],\n",
        "       simple_regret_gp_15[slice77],\n",
        "       simple_regret_gp_16[slice77],\n",
        "       simple_regret_gp_17[slice77],\n",
        "       simple_regret_gp_18[slice77],\n",
        "       simple_regret_gp_19[slice77],\n",
        "       simple_regret_gp_20[slice77]]\n",
        "\n",
        "stp77 = [simple_regret_stp_1[slice77],\n",
        "       simple_regret_stp_2[slice77],\n",
        "       simple_regret_stp_3[slice77],\n",
        "       simple_regret_stp_4[slice77],\n",
        "       simple_regret_stp_5[slice77],\n",
        "       simple_regret_stp_6[slice77],\n",
        "       simple_regret_stp_7[slice77],\n",
        "       simple_regret_stp_8[slice77],\n",
        "       simple_regret_stp_9[slice77],\n",
        "       simple_regret_stp_10[slice77],\n",
        "       simple_regret_stp_11[slice77],\n",
        "       simple_regret_stp_12[slice77],\n",
        "       simple_regret_stp_13[slice77],\n",
        "       simple_regret_stp_14[slice77],\n",
        "       simple_regret_stp_15[slice77],\n",
        "       simple_regret_stp_16[slice77],\n",
        "       simple_regret_stp_17[slice77],\n",
        "       simple_regret_stp_18[slice77],\n",
        "       simple_regret_stp_19[slice77],\n",
        "       simple_regret_stp_20[slice77]]\n",
        "\n",
        "gp77_results = pd.DataFrame(gp77).sort_values(by=[0], ascending=False)\n",
        "stp77_results = pd.DataFrame(stp77).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - gp:\n",
        "lower_gp77 = np.asarray(gp77_results[4:5][0])[0]\n",
        "median_gp77 = np.asarray(gp77_results[9:10][0])[0]\n",
        "upper_gp77 = np.asarray(gp77_results[14:15][0])[0]\n",
        "\n",
        "lower_stp77 = np.asarray(stp77_results[4:5][0])[0]\n",
        "median_stp77 = np.asarray(stp77_results[9:10][0])[0]\n",
        "upper_stp77 = np.asarray(stp77_results[14:15][0])[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "id": "NGqmrg2IJLmT"
      },
      "outputs": [],
      "source": [
        "# Iteration87 :\n",
        "\n",
        "slice87 = 86\n",
        "\n",
        "gp87 = [simple_regret_gp_1[slice87],\n",
        "       simple_regret_gp_2[slice87],\n",
        "       simple_regret_gp_3[slice87],\n",
        "       simple_regret_gp_4[slice87],\n",
        "       simple_regret_gp_5[slice87],\n",
        "       simple_regret_gp_6[slice87],\n",
        "       simple_regret_gp_7[slice87],\n",
        "       simple_regret_gp_8[slice87],\n",
        "       simple_regret_gp_9[slice87],\n",
        "       simple_regret_gp_10[slice87],\n",
        "       simple_regret_gp_11[slice87],\n",
        "       simple_regret_gp_12[slice87],\n",
        "       simple_regret_gp_13[slice87],\n",
        "       simple_regret_gp_14[slice87],\n",
        "       simple_regret_gp_15[slice87],\n",
        "       simple_regret_gp_16[slice87],\n",
        "       simple_regret_gp_17[slice87],\n",
        "       simple_regret_gp_18[slice87],\n",
        "       simple_regret_gp_19[slice87],\n",
        "       simple_regret_gp_20[slice87]]\n",
        "\n",
        "stp87 = [simple_regret_stp_1[slice87],\n",
        "       simple_regret_stp_2[slice87],\n",
        "       simple_regret_stp_3[slice87],\n",
        "       simple_regret_stp_4[slice87],\n",
        "       simple_regret_stp_5[slice87],\n",
        "       simple_regret_stp_6[slice87],\n",
        "       simple_regret_stp_7[slice87],\n",
        "       simple_regret_stp_8[slice87],\n",
        "       simple_regret_stp_9[slice87],\n",
        "       simple_regret_stp_10[slice87],\n",
        "       simple_regret_stp_11[slice87],\n",
        "       simple_regret_stp_12[slice87],\n",
        "       simple_regret_stp_13[slice87],\n",
        "       simple_regret_stp_14[slice87],\n",
        "       simple_regret_stp_15[slice87],\n",
        "       simple_regret_stp_16[slice87],\n",
        "       simple_regret_stp_17[slice87],\n",
        "       simple_regret_stp_18[slice87],\n",
        "       simple_regret_stp_19[slice87],\n",
        "       simple_regret_stp_20[slice87]]\n",
        "\n",
        "gp87_results = pd.DataFrame(gp87).sort_values(by=[0], ascending=False)\n",
        "stp87_results = pd.DataFrame(stp87).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - gp:\n",
        "lower_gp87 = np.asarray(gp87_results[4:5][0])[0]\n",
        "median_gp87 = np.asarray(gp87_results[9:10][0])[0]\n",
        "upper_gp87 = np.asarray(gp87_results[14:15][0])[0]\n",
        "\n",
        "lower_stp87 = np.asarray(stp87_results[4:5][0])[0]\n",
        "median_stp87 = np.asarray(stp87_results[9:10][0])[0]\n",
        "upper_stp87 = np.asarray(stp87_results[14:15][0])[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "id": "Wg6fanrsJLmT"
      },
      "outputs": [],
      "source": [
        "# Iteration97 :\n",
        "\n",
        "slice97 = 96\n",
        "\n",
        "gp97 = [simple_regret_gp_1[slice97],\n",
        "       simple_regret_gp_2[slice97],\n",
        "       simple_regret_gp_3[slice97],\n",
        "       simple_regret_gp_4[slice97],\n",
        "       simple_regret_gp_5[slice97],\n",
        "       simple_regret_gp_6[slice97],\n",
        "       simple_regret_gp_7[slice97],\n",
        "       simple_regret_gp_8[slice97],\n",
        "       simple_regret_gp_9[slice97],\n",
        "       simple_regret_gp_10[slice97],\n",
        "       simple_regret_gp_11[slice97],\n",
        "       simple_regret_gp_12[slice97],\n",
        "       simple_regret_gp_13[slice97],\n",
        "       simple_regret_gp_14[slice97],\n",
        "       simple_regret_gp_15[slice97],\n",
        "       simple_regret_gp_16[slice97],\n",
        "       simple_regret_gp_17[slice97],\n",
        "       simple_regret_gp_18[slice97],\n",
        "       simple_regret_gp_19[slice97],\n",
        "       simple_regret_gp_20[slice97]]\n",
        "\n",
        "stp97 = [simple_regret_stp_1[slice97],\n",
        "       simple_regret_stp_2[slice97],\n",
        "       simple_regret_stp_3[slice97],\n",
        "       simple_regret_stp_4[slice97],\n",
        "       simple_regret_stp_5[slice97],\n",
        "       simple_regret_stp_6[slice97],\n",
        "       simple_regret_stp_7[slice97],\n",
        "       simple_regret_stp_8[slice97],\n",
        "       simple_regret_stp_9[slice97],\n",
        "       simple_regret_stp_10[slice97],\n",
        "       simple_regret_stp_11[slice97],\n",
        "       simple_regret_stp_12[slice97],\n",
        "       simple_regret_stp_13[slice97],\n",
        "       simple_regret_stp_14[slice97],\n",
        "       simple_regret_stp_15[slice97],\n",
        "       simple_regret_stp_16[slice97],\n",
        "       simple_regret_stp_17[slice97],\n",
        "       simple_regret_stp_18[slice97],\n",
        "       simple_regret_stp_19[slice97],\n",
        "       simple_regret_stp_20[slice97]]\n",
        "\n",
        "gp97_results = pd.DataFrame(gp97).sort_values(by=[0], ascending=False)\n",
        "stp97_results = pd.DataFrame(stp97).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - gp:\n",
        "lower_gp97 = np.asarray(gp97_results[4:5][0])[0]\n",
        "median_gp97 = np.asarray(gp97_results[9:10][0])[0]\n",
        "upper_gp97 = np.asarray(gp97_results[14:15][0])[0]\n",
        "\n",
        "lower_stp97 = np.asarray(stp97_results[4:5][0])[0]\n",
        "median_stp97 = np.asarray(stp97_results[9:10][0])[0]\n",
        "upper_stp97 = np.asarray(stp97_results[14:15][0])[0]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "id": "JueXVbnGJLmU"
      },
      "outputs": [],
      "source": [
        "# Iteration8 :\n",
        "\n",
        "slice8 = 7\n",
        "\n",
        "gp8 = [simple_regret_gp_1[slice8],\n",
        "       simple_regret_gp_2[slice8],\n",
        "       simple_regret_gp_3[slice8],\n",
        "       simple_regret_gp_4[slice8],\n",
        "       simple_regret_gp_5[slice8],\n",
        "       simple_regret_gp_6[slice8],\n",
        "       simple_regret_gp_7[slice8],\n",
        "       simple_regret_gp_8[slice8],\n",
        "       simple_regret_gp_9[slice8],\n",
        "       simple_regret_gp_10[slice8],\n",
        "       simple_regret_gp_11[slice8],\n",
        "       simple_regret_gp_12[slice8],\n",
        "       simple_regret_gp_13[slice8],\n",
        "       simple_regret_gp_14[slice8],\n",
        "       simple_regret_gp_15[slice8],\n",
        "       simple_regret_gp_16[slice8],\n",
        "       simple_regret_gp_17[slice8],\n",
        "       simple_regret_gp_18[slice8],\n",
        "       simple_regret_gp_19[slice8],\n",
        "       simple_regret_gp_20[slice8]]\n",
        "\n",
        "stp8 = [simple_regret_stp_1[slice8],\n",
        "       simple_regret_stp_2[slice8],\n",
        "       simple_regret_stp_3[slice8],\n",
        "       simple_regret_stp_4[slice8],\n",
        "       simple_regret_stp_5[slice8],\n",
        "       simple_regret_stp_6[slice8],\n",
        "       simple_regret_stp_7[slice8],\n",
        "       simple_regret_stp_8[slice8],\n",
        "       simple_regret_stp_9[slice8],\n",
        "       simple_regret_stp_10[slice8],\n",
        "       simple_regret_stp_11[slice8],\n",
        "       simple_regret_stp_12[slice8],\n",
        "       simple_regret_stp_13[slice8],\n",
        "       simple_regret_stp_14[slice8],\n",
        "       simple_regret_stp_15[slice8],\n",
        "       simple_regret_stp_16[slice8],\n",
        "       simple_regret_stp_17[slice8],\n",
        "       simple_regret_stp_18[slice8],\n",
        "       simple_regret_stp_19[slice8],\n",
        "       simple_regret_stp_20[slice8]]\n",
        "\n",
        "gp8_results = pd.DataFrame(gp8).sort_values(by=[0], ascending=False)\n",
        "stp8_results = pd.DataFrame(stp8).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - gp:\n",
        "lower_gp8 = np.asarray(gp8_results[4:5][0])[0]\n",
        "median_gp8 = np.asarray(gp8_results[9:10][0])[0]\n",
        "upper_gp8 = np.asarray(gp8_results[14:15][0])[0]\n",
        "\n",
        "lower_stp8 = np.asarray(stp8_results[4:5][0])[0]\n",
        "median_stp8 = np.asarray(stp8_results[9:10][0])[0]\n",
        "upper_stp8 = np.asarray(stp8_results[14:15][0])[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "id": "mnFJ7maJJLmU"
      },
      "outputs": [],
      "source": [
        "# Iteration18 :\n",
        "\n",
        "slice18 = 17\n",
        "\n",
        "gp18 = [simple_regret_gp_1[slice18],\n",
        "       simple_regret_gp_2[slice18],\n",
        "       simple_regret_gp_3[slice18],\n",
        "       simple_regret_gp_4[slice18],\n",
        "       simple_regret_gp_5[slice18],\n",
        "       simple_regret_gp_6[slice18],\n",
        "       simple_regret_gp_7[slice18],\n",
        "       simple_regret_gp_8[slice18],\n",
        "       simple_regret_gp_9[slice18],\n",
        "       simple_regret_gp_10[slice18],\n",
        "       simple_regret_gp_11[slice18],\n",
        "       simple_regret_gp_12[slice18],\n",
        "       simple_regret_gp_13[slice18],\n",
        "       simple_regret_gp_14[slice18],\n",
        "       simple_regret_gp_15[slice18],\n",
        "       simple_regret_gp_16[slice18],\n",
        "       simple_regret_gp_17[slice18],\n",
        "       simple_regret_gp_18[slice18],\n",
        "       simple_regret_gp_19[slice18],\n",
        "       simple_regret_gp_20[slice18]]\n",
        "\n",
        "stp18 = [simple_regret_stp_1[slice18],\n",
        "       simple_regret_stp_2[slice18],\n",
        "       simple_regret_stp_3[slice18],\n",
        "       simple_regret_stp_4[slice18],\n",
        "       simple_regret_stp_5[slice18],\n",
        "       simple_regret_stp_6[slice18],\n",
        "       simple_regret_stp_7[slice18],\n",
        "       simple_regret_stp_8[slice18],\n",
        "       simple_regret_stp_9[slice18],\n",
        "       simple_regret_stp_10[slice18],\n",
        "       simple_regret_stp_11[slice18],\n",
        "       simple_regret_stp_12[slice18],\n",
        "       simple_regret_stp_13[slice18],\n",
        "       simple_regret_stp_14[slice18],\n",
        "       simple_regret_stp_15[slice18],\n",
        "       simple_regret_stp_16[slice18],\n",
        "       simple_regret_stp_17[slice18],\n",
        "       simple_regret_stp_18[slice18],\n",
        "       simple_regret_stp_19[slice18],\n",
        "       simple_regret_stp_20[slice18]]\n",
        "\n",
        "gp18_results = pd.DataFrame(gp18).sort_values(by=[0], ascending=False)\n",
        "stp18_results = pd.DataFrame(stp18).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - gp:\n",
        "lower_gp18 = np.asarray(gp18_results[4:5][0])[0]\n",
        "median_gp18 = np.asarray(gp18_results[9:10][0])[0]\n",
        "upper_gp18 = np.asarray(gp18_results[14:15][0])[0]\n",
        "\n",
        "lower_stp18 = np.asarray(stp18_results[4:5][0])[0]\n",
        "median_stp18 = np.asarray(stp18_results[9:10][0])[0]\n",
        "upper_stp18 = np.asarray(stp18_results[14:15][0])[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "id": "LtB-6atqJLmV"
      },
      "outputs": [],
      "source": [
        "# Iteration28 :\n",
        "\n",
        "slice28 = 27\n",
        "\n",
        "gp28 = [simple_regret_gp_1[slice28],\n",
        "       simple_regret_gp_2[slice28],\n",
        "       simple_regret_gp_3[slice28],\n",
        "       simple_regret_gp_4[slice28],\n",
        "       simple_regret_gp_5[slice28],\n",
        "       simple_regret_gp_6[slice28],\n",
        "       simple_regret_gp_7[slice28],\n",
        "       simple_regret_gp_8[slice28],\n",
        "       simple_regret_gp_9[slice28],\n",
        "       simple_regret_gp_10[slice28],\n",
        "       simple_regret_gp_11[slice28],\n",
        "       simple_regret_gp_12[slice28],\n",
        "       simple_regret_gp_13[slice28],\n",
        "       simple_regret_gp_14[slice28],\n",
        "       simple_regret_gp_15[slice28],\n",
        "       simple_regret_gp_16[slice28],\n",
        "       simple_regret_gp_17[slice28],\n",
        "       simple_regret_gp_18[slice28],\n",
        "       simple_regret_gp_19[slice28],\n",
        "       simple_regret_gp_20[slice28]]\n",
        "\n",
        "stp28 = [simple_regret_stp_1[slice28],\n",
        "       simple_regret_stp_2[slice28],\n",
        "       simple_regret_stp_3[slice28],\n",
        "       simple_regret_stp_4[slice28],\n",
        "       simple_regret_stp_5[slice28],\n",
        "       simple_regret_stp_6[slice28],\n",
        "       simple_regret_stp_7[slice28],\n",
        "       simple_regret_stp_8[slice28],\n",
        "       simple_regret_stp_9[slice28],\n",
        "       simple_regret_stp_10[slice28],\n",
        "       simple_regret_stp_11[slice28],\n",
        "       simple_regret_stp_12[slice28],\n",
        "       simple_regret_stp_13[slice28],\n",
        "       simple_regret_stp_14[slice28],\n",
        "       simple_regret_stp_15[slice28],\n",
        "       simple_regret_stp_16[slice28],\n",
        "       simple_regret_stp_17[slice28],\n",
        "       simple_regret_stp_18[slice28],\n",
        "       simple_regret_stp_19[slice28],\n",
        "       simple_regret_stp_20[slice28]]\n",
        "\n",
        "gp28_results = pd.DataFrame(gp28).sort_values(by=[0], ascending=False)\n",
        "stp28_results = pd.DataFrame(stp28).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - gp:\n",
        "lower_gp28 = np.asarray(gp28_results[4:5][0])[0]\n",
        "median_gp28 = np.asarray(gp28_results[9:10][0])[0]\n",
        "upper_gp28 = np.asarray(gp28_results[14:15][0])[0]\n",
        "\n",
        "lower_stp28 = np.asarray(stp28_results[4:5][0])[0]\n",
        "median_stp28 = np.asarray(stp28_results[9:10][0])[0]\n",
        "upper_stp28 = np.asarray(stp28_results[14:15][0])[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {
        "id": "rYktS_mbJLmV"
      },
      "outputs": [],
      "source": [
        "# Iteration38 :\n",
        "\n",
        "slice38 = 37\n",
        "\n",
        "gp38 = [simple_regret_gp_1[slice38],\n",
        "       simple_regret_gp_2[slice38],\n",
        "       simple_regret_gp_3[slice38],\n",
        "       simple_regret_gp_4[slice38],\n",
        "       simple_regret_gp_5[slice38],\n",
        "       simple_regret_gp_6[slice38],\n",
        "       simple_regret_gp_7[slice38],\n",
        "       simple_regret_gp_8[slice38],\n",
        "       simple_regret_gp_9[slice38],\n",
        "       simple_regret_gp_10[slice38],\n",
        "       simple_regret_gp_11[slice38],\n",
        "       simple_regret_gp_12[slice38],\n",
        "       simple_regret_gp_13[slice38],\n",
        "       simple_regret_gp_14[slice38],\n",
        "       simple_regret_gp_15[slice38],\n",
        "       simple_regret_gp_16[slice38],\n",
        "       simple_regret_gp_17[slice38],\n",
        "       simple_regret_gp_18[slice38],\n",
        "       simple_regret_gp_19[slice38],\n",
        "       simple_regret_gp_20[slice38]]\n",
        "\n",
        "stp38 = [simple_regret_stp_1[slice38],\n",
        "       simple_regret_stp_2[slice38],\n",
        "       simple_regret_stp_3[slice38],\n",
        "       simple_regret_stp_4[slice38],\n",
        "       simple_regret_stp_5[slice38],\n",
        "       simple_regret_stp_6[slice38],\n",
        "       simple_regret_stp_7[slice38],\n",
        "       simple_regret_stp_8[slice38],\n",
        "       simple_regret_stp_9[slice38],\n",
        "       simple_regret_stp_10[slice38],\n",
        "       simple_regret_stp_11[slice38],\n",
        "       simple_regret_stp_12[slice38],\n",
        "       simple_regret_stp_13[slice38],\n",
        "       simple_regret_stp_14[slice38],\n",
        "       simple_regret_stp_15[slice38],\n",
        "       simple_regret_stp_16[slice38],\n",
        "       simple_regret_stp_17[slice38],\n",
        "       simple_regret_stp_18[slice38],\n",
        "       simple_regret_stp_19[slice38],\n",
        "       simple_regret_stp_20[slice38]]\n",
        "\n",
        "gp38_results = pd.DataFrame(gp38).sort_values(by=[0], ascending=False)\n",
        "stp38_results = pd.DataFrame(stp38).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - gp:\n",
        "lower_gp38 = np.asarray(gp38_results[4:5][0])[0]\n",
        "median_gp38 = np.asarray(gp38_results[9:10][0])[0]\n",
        "upper_gp38 = np.asarray(gp38_results[14:15][0])[0]\n",
        "\n",
        "lower_stp38 = np.asarray(stp38_results[4:5][0])[0]\n",
        "median_stp38 = np.asarray(stp38_results[9:10][0])[0]\n",
        "upper_stp38 = np.asarray(stp38_results[14:15][0])[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "id": "NhZi9O_IJLmW"
      },
      "outputs": [],
      "source": [
        "# Iteration48 :\n",
        "\n",
        "slice48 = 47\n",
        "\n",
        "gp48 = [simple_regret_gp_1[slice48],\n",
        "       simple_regret_gp_2[slice48],\n",
        "       simple_regret_gp_3[slice48],\n",
        "       simple_regret_gp_4[slice48],\n",
        "       simple_regret_gp_5[slice48],\n",
        "       simple_regret_gp_6[slice48],\n",
        "       simple_regret_gp_7[slice48],\n",
        "       simple_regret_gp_8[slice48],\n",
        "       simple_regret_gp_9[slice48],\n",
        "       simple_regret_gp_10[slice48],\n",
        "       simple_regret_gp_11[slice48],\n",
        "       simple_regret_gp_12[slice48],\n",
        "       simple_regret_gp_13[slice48],\n",
        "       simple_regret_gp_14[slice48],\n",
        "       simple_regret_gp_15[slice48],\n",
        "       simple_regret_gp_16[slice48],\n",
        "       simple_regret_gp_17[slice48],\n",
        "       simple_regret_gp_18[slice48],\n",
        "       simple_regret_gp_19[slice48],\n",
        "       simple_regret_gp_20[slice48]]\n",
        "\n",
        "stp48 = [simple_regret_stp_1[slice48],\n",
        "       simple_regret_stp_2[slice48],\n",
        "       simple_regret_stp_3[slice48],\n",
        "       simple_regret_stp_4[slice48],\n",
        "       simple_regret_stp_5[slice48],\n",
        "       simple_regret_stp_6[slice48],\n",
        "       simple_regret_stp_7[slice48],\n",
        "       simple_regret_stp_8[slice48],\n",
        "       simple_regret_stp_9[slice48],\n",
        "       simple_regret_stp_10[slice48],\n",
        "       simple_regret_stp_11[slice48],\n",
        "       simple_regret_stp_12[slice48],\n",
        "       simple_regret_stp_13[slice48],\n",
        "       simple_regret_stp_14[slice48],\n",
        "       simple_regret_stp_15[slice48],\n",
        "       simple_regret_stp_16[slice48],\n",
        "       simple_regret_stp_17[slice48],\n",
        "       simple_regret_stp_18[slice48],\n",
        "       simple_regret_stp_19[slice48],\n",
        "       simple_regret_stp_20[slice48]]\n",
        "\n",
        "gp48_results = pd.DataFrame(gp48).sort_values(by=[0], ascending=False)\n",
        "stp48_results = pd.DataFrame(stp48).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - gp:\n",
        "lower_gp48 = np.asarray(gp48_results[4:5][0])[0]\n",
        "median_gp48 = np.asarray(gp48_results[9:10][0])[0]\n",
        "upper_gp48 = np.asarray(gp48_results[14:15][0])[0]\n",
        "\n",
        "lower_stp48 = np.asarray(stp48_results[4:5][0])[0]\n",
        "median_stp48 = np.asarray(stp48_results[9:10][0])[0]\n",
        "upper_stp48 = np.asarray(stp48_results[14:15][0])[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {
        "id": "F9q09Tj7JLmX"
      },
      "outputs": [],
      "source": [
        "# Iteration58 :\n",
        "\n",
        "slice58 = 57\n",
        "\n",
        "gp58 = [simple_regret_gp_1[slice58],\n",
        "       simple_regret_gp_2[slice58],\n",
        "       simple_regret_gp_3[slice58],\n",
        "       simple_regret_gp_4[slice58],\n",
        "       simple_regret_gp_5[slice58],\n",
        "       simple_regret_gp_6[slice58],\n",
        "       simple_regret_gp_7[slice58],\n",
        "       simple_regret_gp_8[slice58],\n",
        "       simple_regret_gp_9[slice58],\n",
        "       simple_regret_gp_10[slice58],\n",
        "       simple_regret_gp_11[slice58],\n",
        "       simple_regret_gp_12[slice58],\n",
        "       simple_regret_gp_13[slice58],\n",
        "       simple_regret_gp_14[slice58],\n",
        "       simple_regret_gp_15[slice58],\n",
        "       simple_regret_gp_16[slice58],\n",
        "       simple_regret_gp_17[slice58],\n",
        "       simple_regret_gp_18[slice58],\n",
        "       simple_regret_gp_19[slice58],\n",
        "       simple_regret_gp_20[slice58]]\n",
        "\n",
        "stp58 = [simple_regret_stp_1[slice58],\n",
        "       simple_regret_stp_2[slice58],\n",
        "       simple_regret_stp_3[slice58],\n",
        "       simple_regret_stp_4[slice58],\n",
        "       simple_regret_stp_5[slice58],\n",
        "       simple_regret_stp_6[slice58],\n",
        "       simple_regret_stp_7[slice58],\n",
        "       simple_regret_stp_8[slice58],\n",
        "       simple_regret_stp_9[slice58],\n",
        "       simple_regret_stp_10[slice58],\n",
        "       simple_regret_stp_11[slice58],\n",
        "       simple_regret_stp_12[slice58],\n",
        "       simple_regret_stp_13[slice58],\n",
        "       simple_regret_stp_14[slice58],\n",
        "       simple_regret_stp_15[slice58],\n",
        "       simple_regret_stp_16[slice58],\n",
        "       simple_regret_stp_17[slice58],\n",
        "       simple_regret_stp_18[slice58],\n",
        "       simple_regret_stp_19[slice58],\n",
        "       simple_regret_stp_20[slice58]]\n",
        "\n",
        "gp58_results = pd.DataFrame(gp58).sort_values(by=[0], ascending=False)\n",
        "stp58_results = pd.DataFrame(stp58).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - gp:\n",
        "lower_gp58 = np.asarray(gp58_results[4:5][0])[0]\n",
        "median_gp58 = np.asarray(gp58_results[9:10][0])[0]\n",
        "upper_gp58 = np.asarray(gp58_results[14:15][0])[0]\n",
        "\n",
        "lower_stp58 = np.asarray(stp58_results[4:5][0])[0]\n",
        "median_stp58 = np.asarray(stp58_results[9:10][0])[0]\n",
        "upper_stp58 = np.asarray(stp58_results[14:15][0])[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {
        "id": "rfPXvzCsJLmY"
      },
      "outputs": [],
      "source": [
        "# Iteration68 :\n",
        "\n",
        "slice68 = 67\n",
        "\n",
        "gp68 = [simple_regret_gp_1[slice68],\n",
        "       simple_regret_gp_2[slice68],\n",
        "       simple_regret_gp_3[slice68],\n",
        "       simple_regret_gp_4[slice68],\n",
        "       simple_regret_gp_5[slice68],\n",
        "       simple_regret_gp_6[slice68],\n",
        "       simple_regret_gp_7[slice68],\n",
        "       simple_regret_gp_8[slice68],\n",
        "       simple_regret_gp_9[slice68],\n",
        "       simple_regret_gp_10[slice68],\n",
        "       simple_regret_gp_11[slice68],\n",
        "       simple_regret_gp_12[slice68],\n",
        "       simple_regret_gp_13[slice68],\n",
        "       simple_regret_gp_14[slice68],\n",
        "       simple_regret_gp_15[slice68],\n",
        "       simple_regret_gp_16[slice68],\n",
        "       simple_regret_gp_17[slice68],\n",
        "       simple_regret_gp_18[slice68],\n",
        "       simple_regret_gp_19[slice68],\n",
        "       simple_regret_gp_20[slice68]]\n",
        "\n",
        "stp68 = [simple_regret_stp_1[slice68],\n",
        "       simple_regret_stp_2[slice68],\n",
        "       simple_regret_stp_3[slice68],\n",
        "       simple_regret_stp_4[slice68],\n",
        "       simple_regret_stp_5[slice68],\n",
        "       simple_regret_stp_6[slice68],\n",
        "       simple_regret_stp_7[slice68],\n",
        "       simple_regret_stp_8[slice68],\n",
        "       simple_regret_stp_9[slice68],\n",
        "       simple_regret_stp_10[slice68],\n",
        "       simple_regret_stp_11[slice68],\n",
        "       simple_regret_stp_12[slice68],\n",
        "       simple_regret_stp_13[slice68],\n",
        "       simple_regret_stp_14[slice68],\n",
        "       simple_regret_stp_15[slice68],\n",
        "       simple_regret_stp_16[slice68],\n",
        "       simple_regret_stp_17[slice68],\n",
        "       simple_regret_stp_18[slice68],\n",
        "       simple_regret_stp_19[slice68],\n",
        "       simple_regret_stp_20[slice68]]\n",
        "\n",
        "gp68_results = pd.DataFrame(gp68).sort_values(by=[0], ascending=False)\n",
        "stp68_results = pd.DataFrame(stp68).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - gp:\n",
        "lower_gp68 = np.asarray(gp68_results[4:5][0])[0]\n",
        "median_gp68 = np.asarray(gp68_results[9:10][0])[0]\n",
        "upper_gp68 = np.asarray(gp68_results[14:15][0])[0]\n",
        "\n",
        "lower_stp68 = np.asarray(stp68_results[4:5][0])[0]\n",
        "median_stp68 = np.asarray(stp68_results[9:10][0])[0]\n",
        "upper_stp68 = np.asarray(stp68_results[14:15][0])[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {
        "id": "GAfYgb5ZJLmY"
      },
      "outputs": [],
      "source": [
        "# Iteration78 :\n",
        "\n",
        "slice78 = 77\n",
        "\n",
        "gp78 = [simple_regret_gp_1[slice78],\n",
        "       simple_regret_gp_2[slice78],\n",
        "       simple_regret_gp_3[slice78],\n",
        "       simple_regret_gp_4[slice78],\n",
        "       simple_regret_gp_5[slice78],\n",
        "       simple_regret_gp_6[slice78],\n",
        "       simple_regret_gp_7[slice78],\n",
        "       simple_regret_gp_8[slice78],\n",
        "       simple_regret_gp_9[slice78],\n",
        "       simple_regret_gp_10[slice78],\n",
        "       simple_regret_gp_11[slice78],\n",
        "       simple_regret_gp_12[slice78],\n",
        "       simple_regret_gp_13[slice78],\n",
        "       simple_regret_gp_14[slice78],\n",
        "       simple_regret_gp_15[slice78],\n",
        "       simple_regret_gp_16[slice78],\n",
        "       simple_regret_gp_17[slice78],\n",
        "       simple_regret_gp_18[slice78],\n",
        "       simple_regret_gp_19[slice78],\n",
        "       simple_regret_gp_20[slice78]]\n",
        "\n",
        "stp78 = [simple_regret_stp_1[slice78],\n",
        "       simple_regret_stp_2[slice78],\n",
        "       simple_regret_stp_3[slice78],\n",
        "       simple_regret_stp_4[slice78],\n",
        "       simple_regret_stp_5[slice78],\n",
        "       simple_regret_stp_6[slice78],\n",
        "       simple_regret_stp_7[slice78],\n",
        "       simple_regret_stp_8[slice78],\n",
        "       simple_regret_stp_9[slice78],\n",
        "       simple_regret_stp_10[slice78],\n",
        "       simple_regret_stp_11[slice78],\n",
        "       simple_regret_stp_12[slice78],\n",
        "       simple_regret_stp_13[slice78],\n",
        "       simple_regret_stp_14[slice78],\n",
        "       simple_regret_stp_15[slice78],\n",
        "       simple_regret_stp_16[slice78],\n",
        "       simple_regret_stp_17[slice78],\n",
        "       simple_regret_stp_18[slice78],\n",
        "       simple_regret_stp_19[slice78],\n",
        "       simple_regret_stp_20[slice78]]\n",
        "\n",
        "gp78_results = pd.DataFrame(gp78).sort_values(by=[0], ascending=False)\n",
        "stp78_results = pd.DataFrame(stp78).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - gp:\n",
        "lower_gp78 = np.asarray(gp78_results[4:5][0])[0]\n",
        "median_gp78 = np.asarray(gp78_results[9:10][0])[0]\n",
        "upper_gp78 = np.asarray(gp78_results[14:15][0])[0]\n",
        "\n",
        "lower_stp78 = np.asarray(stp78_results[4:5][0])[0]\n",
        "median_stp78 = np.asarray(stp78_results[9:10][0])[0]\n",
        "upper_stp78 = np.asarray(stp78_results[14:15][0])[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {
        "id": "zmiakdr1JLmZ"
      },
      "outputs": [],
      "source": [
        "# Iteration88 :\n",
        "\n",
        "slice88 = 87\n",
        "\n",
        "gp88 = [simple_regret_gp_1[slice88],\n",
        "       simple_regret_gp_2[slice88],\n",
        "       simple_regret_gp_3[slice88],\n",
        "       simple_regret_gp_4[slice88],\n",
        "       simple_regret_gp_5[slice88],\n",
        "       simple_regret_gp_6[slice88],\n",
        "       simple_regret_gp_7[slice88],\n",
        "       simple_regret_gp_8[slice88],\n",
        "       simple_regret_gp_9[slice88],\n",
        "       simple_regret_gp_10[slice88],\n",
        "       simple_regret_gp_11[slice88],\n",
        "       simple_regret_gp_12[slice88],\n",
        "       simple_regret_gp_13[slice88],\n",
        "       simple_regret_gp_14[slice88],\n",
        "       simple_regret_gp_15[slice88],\n",
        "       simple_regret_gp_16[slice88],\n",
        "       simple_regret_gp_17[slice88],\n",
        "       simple_regret_gp_18[slice88],\n",
        "       simple_regret_gp_19[slice88],\n",
        "       simple_regret_gp_20[slice88]]\n",
        "\n",
        "stp88 = [simple_regret_stp_1[slice88],\n",
        "       simple_regret_stp_2[slice88],\n",
        "       simple_regret_stp_3[slice88],\n",
        "       simple_regret_stp_4[slice88],\n",
        "       simple_regret_stp_5[slice88],\n",
        "       simple_regret_stp_6[slice88],\n",
        "       simple_regret_stp_7[slice88],\n",
        "       simple_regret_stp_8[slice88],\n",
        "       simple_regret_stp_9[slice88],\n",
        "       simple_regret_stp_10[slice88],\n",
        "       simple_regret_stp_11[slice88],\n",
        "       simple_regret_stp_12[slice88],\n",
        "       simple_regret_stp_13[slice88],\n",
        "       simple_regret_stp_14[slice88],\n",
        "       simple_regret_stp_15[slice88],\n",
        "       simple_regret_stp_16[slice88],\n",
        "       simple_regret_stp_17[slice88],\n",
        "       simple_regret_stp_18[slice88],\n",
        "       simple_regret_stp_19[slice88],\n",
        "       simple_regret_stp_20[slice88]]\n",
        "\n",
        "gp88_results = pd.DataFrame(gp88).sort_values(by=[0], ascending=False)\n",
        "stp88_results = pd.DataFrame(stp88).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - gp:\n",
        "lower_gp88 = np.asarray(gp88_results[4:5][0])[0]\n",
        "median_gp88 = np.asarray(gp88_results[9:10][0])[0]\n",
        "upper_gp88 = np.asarray(gp88_results[14:15][0])[0]\n",
        "\n",
        "lower_stp88 = np.asarray(stp88_results[4:5][0])[0]\n",
        "median_stp88 = np.asarray(stp88_results[9:10][0])[0]\n",
        "upper_stp88 = np.asarray(stp88_results[14:15][0])[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {
        "id": "kIZQYXeNJLma"
      },
      "outputs": [],
      "source": [
        "# Iteration98 :\n",
        "\n",
        "slice98 = 97\n",
        "\n",
        "gp98 = [simple_regret_gp_1[slice98],\n",
        "       simple_regret_gp_2[slice98],\n",
        "       simple_regret_gp_3[slice98],\n",
        "       simple_regret_gp_4[slice98],\n",
        "       simple_regret_gp_5[slice98],\n",
        "       simple_regret_gp_6[slice98],\n",
        "       simple_regret_gp_7[slice98],\n",
        "       simple_regret_gp_8[slice98],\n",
        "       simple_regret_gp_9[slice98],\n",
        "       simple_regret_gp_10[slice98],\n",
        "       simple_regret_gp_11[slice98],\n",
        "       simple_regret_gp_12[slice98],\n",
        "       simple_regret_gp_13[slice98],\n",
        "       simple_regret_gp_14[slice98],\n",
        "       simple_regret_gp_15[slice98],\n",
        "       simple_regret_gp_16[slice98],\n",
        "       simple_regret_gp_17[slice98],\n",
        "       simple_regret_gp_18[slice98],\n",
        "       simple_regret_gp_19[slice98],\n",
        "       simple_regret_gp_20[slice98]]\n",
        "\n",
        "stp98 = [simple_regret_stp_1[slice98],\n",
        "       simple_regret_stp_2[slice98],\n",
        "       simple_regret_stp_3[slice98],\n",
        "       simple_regret_stp_4[slice98],\n",
        "       simple_regret_stp_5[slice98],\n",
        "       simple_regret_stp_6[slice98],\n",
        "       simple_regret_stp_7[slice98],\n",
        "       simple_regret_stp_8[slice98],\n",
        "       simple_regret_stp_9[slice98],\n",
        "       simple_regret_stp_10[slice98],\n",
        "       simple_regret_stp_11[slice98],\n",
        "       simple_regret_stp_12[slice98],\n",
        "       simple_regret_stp_13[slice98],\n",
        "       simple_regret_stp_14[slice98],\n",
        "       simple_regret_stp_15[slice98],\n",
        "       simple_regret_stp_16[slice98],\n",
        "       simple_regret_stp_17[slice98],\n",
        "       simple_regret_stp_18[slice98],\n",
        "       simple_regret_stp_19[slice98],\n",
        "       simple_regret_stp_20[slice98]]\n",
        "\n",
        "gp98_results = pd.DataFrame(gp98).sort_values(by=[0], ascending=False)\n",
        "stp98_results = pd.DataFrame(stp98).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - gp:\n",
        "lower_gp98 = np.asarray(gp98_results[4:5][0])[0]\n",
        "median_gp98 = np.asarray(gp98_results[9:10][0])[0]\n",
        "upper_gp98 = np.asarray(gp98_results[14:15][0])[0]\n",
        "\n",
        "lower_stp98 = np.asarray(stp98_results[4:5][0])[0]\n",
        "median_stp98 = np.asarray(stp98_results[9:10][0])[0]\n",
        "upper_stp98 = np.asarray(stp98_results[14:15][0])[0]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {
        "id": "ll-p_qWUJLmb"
      },
      "outputs": [],
      "source": [
        "# Iteration9 :\n",
        "\n",
        "slice9 = 8\n",
        "\n",
        "gp9 = [simple_regret_gp_1[slice9],\n",
        "       simple_regret_gp_2[slice9],\n",
        "       simple_regret_gp_3[slice9],\n",
        "       simple_regret_gp_4[slice9],\n",
        "       simple_regret_gp_5[slice9],\n",
        "       simple_regret_gp_6[slice9],\n",
        "       simple_regret_gp_7[slice9],\n",
        "       simple_regret_gp_8[slice9],\n",
        "       simple_regret_gp_9[slice9],\n",
        "       simple_regret_gp_10[slice9],\n",
        "       simple_regret_gp_11[slice9],\n",
        "       simple_regret_gp_12[slice9],\n",
        "       simple_regret_gp_13[slice9],\n",
        "       simple_regret_gp_14[slice9],\n",
        "       simple_regret_gp_15[slice9],\n",
        "       simple_regret_gp_16[slice9],\n",
        "       simple_regret_gp_17[slice9],\n",
        "       simple_regret_gp_18[slice9],\n",
        "       simple_regret_gp_19[slice9],\n",
        "       simple_regret_gp_20[slice9]]\n",
        "\n",
        "stp9 = [simple_regret_stp_1[slice9],\n",
        "       simple_regret_stp_2[slice9],\n",
        "       simple_regret_stp_3[slice9],\n",
        "       simple_regret_stp_4[slice9],\n",
        "       simple_regret_stp_5[slice9],\n",
        "       simple_regret_stp_6[slice9],\n",
        "       simple_regret_stp_7[slice9],\n",
        "       simple_regret_stp_8[slice9],\n",
        "       simple_regret_stp_9[slice9],\n",
        "       simple_regret_stp_10[slice9],\n",
        "       simple_regret_stp_11[slice9],\n",
        "       simple_regret_stp_12[slice9],\n",
        "       simple_regret_stp_13[slice9],\n",
        "       simple_regret_stp_14[slice9],\n",
        "       simple_regret_stp_15[slice9],\n",
        "       simple_regret_stp_16[slice9],\n",
        "       simple_regret_stp_17[slice9],\n",
        "       simple_regret_stp_18[slice9],\n",
        "       simple_regret_stp_19[slice9],\n",
        "       simple_regret_stp_20[slice9]]\n",
        "\n",
        "gp9_results = pd.DataFrame(gp9).sort_values(by=[0], ascending=False)\n",
        "stp9_results = pd.DataFrame(stp9).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - gp:\n",
        "lower_gp9 = np.asarray(gp9_results[4:5][0])[0]\n",
        "median_gp9 = np.asarray(gp9_results[9:10][0])[0]\n",
        "upper_gp9 = np.asarray(gp9_results[14:15][0])[0]\n",
        "\n",
        "lower_stp9 = np.asarray(stp9_results[4:5][0])[0]\n",
        "median_stp9 = np.asarray(stp9_results[9:10][0])[0]\n",
        "upper_stp9 = np.asarray(stp9_results[14:15][0])[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {
        "id": "G3QVtLpJJLmc"
      },
      "outputs": [],
      "source": [
        "# Iteration19 :\n",
        "\n",
        "slice19 = 18\n",
        "\n",
        "gp19 = [simple_regret_gp_1[slice19],\n",
        "       simple_regret_gp_2[slice19],\n",
        "       simple_regret_gp_3[slice19],\n",
        "       simple_regret_gp_4[slice19],\n",
        "       simple_regret_gp_5[slice19],\n",
        "       simple_regret_gp_6[slice19],\n",
        "       simple_regret_gp_7[slice19],\n",
        "       simple_regret_gp_8[slice19],\n",
        "       simple_regret_gp_9[slice19],\n",
        "       simple_regret_gp_10[slice19],\n",
        "       simple_regret_gp_11[slice19],\n",
        "       simple_regret_gp_12[slice19],\n",
        "       simple_regret_gp_13[slice19],\n",
        "       simple_regret_gp_14[slice19],\n",
        "       simple_regret_gp_15[slice19],\n",
        "       simple_regret_gp_16[slice19],\n",
        "       simple_regret_gp_17[slice19],\n",
        "       simple_regret_gp_18[slice19],\n",
        "       simple_regret_gp_19[slice19],\n",
        "       simple_regret_gp_20[slice19]]\n",
        "\n",
        "stp19 = [simple_regret_stp_1[slice19],\n",
        "       simple_regret_stp_2[slice19],\n",
        "       simple_regret_stp_3[slice19],\n",
        "       simple_regret_stp_4[slice19],\n",
        "       simple_regret_stp_5[slice19],\n",
        "       simple_regret_stp_6[slice19],\n",
        "       simple_regret_stp_7[slice19],\n",
        "       simple_regret_stp_8[slice19],\n",
        "       simple_regret_stp_9[slice19],\n",
        "       simple_regret_stp_10[slice19],\n",
        "       simple_regret_stp_11[slice19],\n",
        "       simple_regret_stp_12[slice19],\n",
        "       simple_regret_stp_13[slice19],\n",
        "       simple_regret_stp_14[slice19],\n",
        "       simple_regret_stp_15[slice19],\n",
        "       simple_regret_stp_16[slice19],\n",
        "       simple_regret_stp_17[slice19],\n",
        "       simple_regret_stp_18[slice19],\n",
        "       simple_regret_stp_19[slice19],\n",
        "       simple_regret_stp_20[slice19]]\n",
        "\n",
        "gp19_results = pd.DataFrame(gp19).sort_values(by=[0], ascending=False)\n",
        "stp19_results = pd.DataFrame(stp19).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - gp:\n",
        "lower_gp19 = np.asarray(gp19_results[4:5][0])[0]\n",
        "median_gp19 = np.asarray(gp19_results[9:10][0])[0]\n",
        "upper_gp19 = np.asarray(gp19_results[14:15][0])[0]\n",
        "\n",
        "lower_stp19 = np.asarray(stp19_results[4:5][0])[0]\n",
        "median_stp19 = np.asarray(stp19_results[9:10][0])[0]\n",
        "upper_stp19 = np.asarray(stp19_results[14:15][0])[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {
        "id": "P61Tku0pJLmd"
      },
      "outputs": [],
      "source": [
        "# Iteration29 :\n",
        "\n",
        "slice29 = 28\n",
        "\n",
        "gp29 = [simple_regret_gp_1[slice29],\n",
        "       simple_regret_gp_2[slice29],\n",
        "       simple_regret_gp_3[slice29],\n",
        "       simple_regret_gp_4[slice29],\n",
        "       simple_regret_gp_5[slice29],\n",
        "       simple_regret_gp_6[slice29],\n",
        "       simple_regret_gp_7[slice29],\n",
        "       simple_regret_gp_8[slice29],\n",
        "       simple_regret_gp_9[slice29],\n",
        "       simple_regret_gp_10[slice29],\n",
        "       simple_regret_gp_11[slice29],\n",
        "       simple_regret_gp_12[slice29],\n",
        "       simple_regret_gp_13[slice29],\n",
        "       simple_regret_gp_14[slice29],\n",
        "       simple_regret_gp_15[slice29],\n",
        "       simple_regret_gp_16[slice29],\n",
        "       simple_regret_gp_17[slice29],\n",
        "       simple_regret_gp_18[slice29],\n",
        "       simple_regret_gp_19[slice29],\n",
        "       simple_regret_gp_20[slice29]]\n",
        "\n",
        "stp29 = [simple_regret_stp_1[slice29],\n",
        "       simple_regret_stp_2[slice29],\n",
        "       simple_regret_stp_3[slice29],\n",
        "       simple_regret_stp_4[slice29],\n",
        "       simple_regret_stp_5[slice29],\n",
        "       simple_regret_stp_6[slice29],\n",
        "       simple_regret_stp_7[slice29],\n",
        "       simple_regret_stp_8[slice29],\n",
        "       simple_regret_stp_9[slice29],\n",
        "       simple_regret_stp_10[slice29],\n",
        "       simple_regret_stp_11[slice29],\n",
        "       simple_regret_stp_12[slice29],\n",
        "       simple_regret_stp_13[slice29],\n",
        "       simple_regret_stp_14[slice29],\n",
        "       simple_regret_stp_15[slice29],\n",
        "       simple_regret_stp_16[slice29],\n",
        "       simple_regret_stp_17[slice29],\n",
        "       simple_regret_stp_18[slice29],\n",
        "       simple_regret_stp_19[slice29],\n",
        "       simple_regret_stp_20[slice29]]\n",
        "\n",
        "gp29_results = pd.DataFrame(gp29).sort_values(by=[0], ascending=False)\n",
        "stp29_results = pd.DataFrame(stp29).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - gp:\n",
        "lower_gp29 = np.asarray(gp29_results[4:5][0])[0]\n",
        "median_gp29 = np.asarray(gp29_results[9:10][0])[0]\n",
        "upper_gp29 = np.asarray(gp29_results[14:15][0])[0]\n",
        "\n",
        "lower_stp29 = np.asarray(stp29_results[4:5][0])[0]\n",
        "median_stp29 = np.asarray(stp29_results[9:10][0])[0]\n",
        "upper_stp29 = np.asarray(stp29_results[14:15][0])[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {
        "id": "4IlVVbohJLme"
      },
      "outputs": [],
      "source": [
        "# Iteration39 :\n",
        "\n",
        "slice39 = 38\n",
        "\n",
        "gp39 = [simple_regret_gp_1[slice39],\n",
        "       simple_regret_gp_2[slice39],\n",
        "       simple_regret_gp_3[slice39],\n",
        "       simple_regret_gp_4[slice39],\n",
        "       simple_regret_gp_5[slice39],\n",
        "       simple_regret_gp_6[slice39],\n",
        "       simple_regret_gp_7[slice39],\n",
        "       simple_regret_gp_8[slice39],\n",
        "       simple_regret_gp_9[slice39],\n",
        "       simple_regret_gp_10[slice39],\n",
        "       simple_regret_gp_11[slice39],\n",
        "       simple_regret_gp_12[slice39],\n",
        "       simple_regret_gp_13[slice39],\n",
        "       simple_regret_gp_14[slice39],\n",
        "       simple_regret_gp_15[slice39],\n",
        "       simple_regret_gp_16[slice39],\n",
        "       simple_regret_gp_17[slice39],\n",
        "       simple_regret_gp_18[slice39],\n",
        "       simple_regret_gp_19[slice39],\n",
        "       simple_regret_gp_20[slice39]]\n",
        "\n",
        "stp39 = [simple_regret_stp_1[slice39],\n",
        "       simple_regret_stp_2[slice39],\n",
        "       simple_regret_stp_3[slice39],\n",
        "       simple_regret_stp_4[slice39],\n",
        "       simple_regret_stp_5[slice39],\n",
        "       simple_regret_stp_6[slice39],\n",
        "       simple_regret_stp_7[slice39],\n",
        "       simple_regret_stp_8[slice39],\n",
        "       simple_regret_stp_9[slice39],\n",
        "       simple_regret_stp_10[slice39],\n",
        "       simple_regret_stp_11[slice39],\n",
        "       simple_regret_stp_12[slice39],\n",
        "       simple_regret_stp_13[slice39],\n",
        "       simple_regret_stp_14[slice39],\n",
        "       simple_regret_stp_15[slice39],\n",
        "       simple_regret_stp_16[slice39],\n",
        "       simple_regret_stp_17[slice39],\n",
        "       simple_regret_stp_18[slice39],\n",
        "       simple_regret_stp_19[slice39],\n",
        "       simple_regret_stp_20[slice39]]\n",
        "\n",
        "gp39_results = pd.DataFrame(gp39).sort_values(by=[0], ascending=False)\n",
        "stp39_results = pd.DataFrame(stp39).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - gp:\n",
        "lower_gp39 = np.asarray(gp39_results[4:5][0])[0]\n",
        "median_gp39 = np.asarray(gp39_results[9:10][0])[0]\n",
        "upper_gp39 = np.asarray(gp39_results[14:15][0])[0]\n",
        "\n",
        "lower_stp39 = np.asarray(stp39_results[4:5][0])[0]\n",
        "median_stp39 = np.asarray(stp39_results[9:10][0])[0]\n",
        "upper_stp39 = np.asarray(stp39_results[14:15][0])[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {
        "id": "LwNNbBX3JLmf"
      },
      "outputs": [],
      "source": [
        "# Iteration49 :\n",
        "\n",
        "slice49 = 48\n",
        "\n",
        "gp49 = [simple_regret_gp_1[slice49],\n",
        "       simple_regret_gp_2[slice49],\n",
        "       simple_regret_gp_3[slice49],\n",
        "       simple_regret_gp_4[slice49],\n",
        "       simple_regret_gp_5[slice49],\n",
        "       simple_regret_gp_6[slice49],\n",
        "       simple_regret_gp_7[slice49],\n",
        "       simple_regret_gp_8[slice49],\n",
        "       simple_regret_gp_9[slice49],\n",
        "       simple_regret_gp_10[slice49],\n",
        "       simple_regret_gp_11[slice49],\n",
        "       simple_regret_gp_12[slice49],\n",
        "       simple_regret_gp_13[slice49],\n",
        "       simple_regret_gp_14[slice49],\n",
        "       simple_regret_gp_15[slice49],\n",
        "       simple_regret_gp_16[slice49],\n",
        "       simple_regret_gp_17[slice49],\n",
        "       simple_regret_gp_18[slice49],\n",
        "       simple_regret_gp_19[slice49],\n",
        "       simple_regret_gp_20[slice49]]\n",
        "\n",
        "stp49 = [simple_regret_stp_1[slice49],\n",
        "       simple_regret_stp_2[slice49],\n",
        "       simple_regret_stp_3[slice49],\n",
        "       simple_regret_stp_4[slice49],\n",
        "       simple_regret_stp_5[slice49],\n",
        "       simple_regret_stp_6[slice49],\n",
        "       simple_regret_stp_7[slice49],\n",
        "       simple_regret_stp_8[slice49],\n",
        "       simple_regret_stp_9[slice49],\n",
        "       simple_regret_stp_10[slice49],\n",
        "       simple_regret_stp_11[slice49],\n",
        "       simple_regret_stp_12[slice49],\n",
        "       simple_regret_stp_13[slice49],\n",
        "       simple_regret_stp_14[slice49],\n",
        "       simple_regret_stp_15[slice49],\n",
        "       simple_regret_stp_16[slice49],\n",
        "       simple_regret_stp_17[slice49],\n",
        "       simple_regret_stp_18[slice49],\n",
        "       simple_regret_stp_19[slice49],\n",
        "       simple_regret_stp_20[slice49]]\n",
        "\n",
        "gp49_results = pd.DataFrame(gp49).sort_values(by=[0], ascending=False)\n",
        "stp49_results = pd.DataFrame(stp49).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - gp:\n",
        "lower_gp49 = np.asarray(gp49_results[4:5][0])[0]\n",
        "median_gp49 = np.asarray(gp49_results[9:10][0])[0]\n",
        "upper_gp49 = np.asarray(gp49_results[14:15][0])[0]\n",
        "\n",
        "lower_stp49 = np.asarray(stp49_results[4:5][0])[0]\n",
        "median_stp49 = np.asarray(stp49_results[9:10][0])[0]\n",
        "upper_stp49 = np.asarray(stp49_results[14:15][0])[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {
        "id": "29i3mfHzJLmf"
      },
      "outputs": [],
      "source": [
        "# Iteration59 :\n",
        "\n",
        "slice59 = 58\n",
        "\n",
        "gp59 = [simple_regret_gp_1[slice59],\n",
        "       simple_regret_gp_2[slice59],\n",
        "       simple_regret_gp_3[slice59],\n",
        "       simple_regret_gp_4[slice59],\n",
        "       simple_regret_gp_5[slice59],\n",
        "       simple_regret_gp_6[slice59],\n",
        "       simple_regret_gp_7[slice59],\n",
        "       simple_regret_gp_8[slice59],\n",
        "       simple_regret_gp_9[slice59],\n",
        "       simple_regret_gp_10[slice59],\n",
        "       simple_regret_gp_11[slice59],\n",
        "       simple_regret_gp_12[slice59],\n",
        "       simple_regret_gp_13[slice59],\n",
        "       simple_regret_gp_14[slice59],\n",
        "       simple_regret_gp_15[slice59],\n",
        "       simple_regret_gp_16[slice59],\n",
        "       simple_regret_gp_17[slice59],\n",
        "       simple_regret_gp_18[slice59],\n",
        "       simple_regret_gp_19[slice59],\n",
        "       simple_regret_gp_20[slice59]]\n",
        "\n",
        "stp59 = [simple_regret_stp_1[slice59],\n",
        "       simple_regret_stp_2[slice59],\n",
        "       simple_regret_stp_3[slice59],\n",
        "       simple_regret_stp_4[slice59],\n",
        "       simple_regret_stp_5[slice59],\n",
        "       simple_regret_stp_6[slice59],\n",
        "       simple_regret_stp_7[slice59],\n",
        "       simple_regret_stp_8[slice59],\n",
        "       simple_regret_stp_9[slice59],\n",
        "       simple_regret_stp_10[slice59],\n",
        "       simple_regret_stp_11[slice59],\n",
        "       simple_regret_stp_12[slice59],\n",
        "       simple_regret_stp_13[slice59],\n",
        "       simple_regret_stp_14[slice59],\n",
        "       simple_regret_stp_15[slice59],\n",
        "       simple_regret_stp_16[slice59],\n",
        "       simple_regret_stp_17[slice59],\n",
        "       simple_regret_stp_18[slice59],\n",
        "       simple_regret_stp_19[slice59],\n",
        "       simple_regret_stp_20[slice59]]\n",
        "\n",
        "gp59_results = pd.DataFrame(gp59).sort_values(by=[0], ascending=False)\n",
        "stp59_results = pd.DataFrame(stp59).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - gp:\n",
        "lower_gp59 = np.asarray(gp59_results[4:5][0])[0]\n",
        "median_gp59 = np.asarray(gp59_results[9:10][0])[0]\n",
        "upper_gp59 = np.asarray(gp59_results[14:15][0])[0]\n",
        "\n",
        "lower_stp59 = np.asarray(stp59_results[4:5][0])[0]\n",
        "median_stp59 = np.asarray(stp59_results[9:10][0])[0]\n",
        "upper_stp59 = np.asarray(stp59_results[14:15][0])[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {
        "id": "6fQoMpF5JLmg"
      },
      "outputs": [],
      "source": [
        "# Iteration69 :\n",
        "\n",
        "slice69 = 68\n",
        "\n",
        "gp69 = [simple_regret_gp_1[slice69],\n",
        "       simple_regret_gp_2[slice69],\n",
        "       simple_regret_gp_3[slice69],\n",
        "       simple_regret_gp_4[slice69],\n",
        "       simple_regret_gp_5[slice69],\n",
        "       simple_regret_gp_6[slice69],\n",
        "       simple_regret_gp_7[slice69],\n",
        "       simple_regret_gp_8[slice69],\n",
        "       simple_regret_gp_9[slice69],\n",
        "       simple_regret_gp_10[slice69],\n",
        "       simple_regret_gp_11[slice69],\n",
        "       simple_regret_gp_12[slice69],\n",
        "       simple_regret_gp_13[slice69],\n",
        "       simple_regret_gp_14[slice69],\n",
        "       simple_regret_gp_15[slice69],\n",
        "       simple_regret_gp_16[slice69],\n",
        "       simple_regret_gp_17[slice69],\n",
        "       simple_regret_gp_18[slice69],\n",
        "       simple_regret_gp_19[slice69],\n",
        "       simple_regret_gp_20[slice69]]\n",
        "\n",
        "stp69 = [simple_regret_stp_1[slice69],\n",
        "       simple_regret_stp_2[slice69],\n",
        "       simple_regret_stp_3[slice69],\n",
        "       simple_regret_stp_4[slice69],\n",
        "       simple_regret_stp_5[slice69],\n",
        "       simple_regret_stp_6[slice69],\n",
        "       simple_regret_stp_7[slice69],\n",
        "       simple_regret_stp_8[slice69],\n",
        "       simple_regret_stp_9[slice69],\n",
        "       simple_regret_stp_10[slice69],\n",
        "       simple_regret_stp_11[slice69],\n",
        "       simple_regret_stp_12[slice69],\n",
        "       simple_regret_stp_13[slice69],\n",
        "       simple_regret_stp_14[slice69],\n",
        "       simple_regret_stp_15[slice69],\n",
        "       simple_regret_stp_16[slice69],\n",
        "       simple_regret_stp_17[slice69],\n",
        "       simple_regret_stp_18[slice69],\n",
        "       simple_regret_stp_19[slice69],\n",
        "       simple_regret_stp_20[slice69]]\n",
        "\n",
        "gp69_results = pd.DataFrame(gp69).sort_values(by=[0], ascending=False)\n",
        "stp69_results = pd.DataFrame(stp69).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - gp:\n",
        "lower_gp69 = np.asarray(gp69_results[4:5][0])[0]\n",
        "median_gp69 = np.asarray(gp69_results[9:10][0])[0]\n",
        "upper_gp69 = np.asarray(gp69_results[14:15][0])[0]\n",
        "\n",
        "lower_stp69 = np.asarray(stp69_results[4:5][0])[0]\n",
        "median_stp69 = np.asarray(stp69_results[9:10][0])[0]\n",
        "upper_stp69 = np.asarray(stp69_results[14:15][0])[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {
        "id": "DbfRkjROJLmg"
      },
      "outputs": [],
      "source": [
        "# Iteration79 :\n",
        "\n",
        "slice79 = 78\n",
        "\n",
        "gp79 = [simple_regret_gp_1[slice79],\n",
        "       simple_regret_gp_2[slice79],\n",
        "       simple_regret_gp_3[slice79],\n",
        "       simple_regret_gp_4[slice79],\n",
        "       simple_regret_gp_5[slice79],\n",
        "       simple_regret_gp_6[slice79],\n",
        "       simple_regret_gp_7[slice79],\n",
        "       simple_regret_gp_8[slice79],\n",
        "       simple_regret_gp_9[slice79],\n",
        "       simple_regret_gp_10[slice79],\n",
        "       simple_regret_gp_11[slice79],\n",
        "       simple_regret_gp_12[slice79],\n",
        "       simple_regret_gp_13[slice79],\n",
        "       simple_regret_gp_14[slice79],\n",
        "       simple_regret_gp_15[slice79],\n",
        "       simple_regret_gp_16[slice79],\n",
        "       simple_regret_gp_17[slice79],\n",
        "       simple_regret_gp_18[slice79],\n",
        "       simple_regret_gp_19[slice79],\n",
        "       simple_regret_gp_20[slice79]]\n",
        "\n",
        "stp79 = [simple_regret_stp_1[slice79],\n",
        "       simple_regret_stp_2[slice79],\n",
        "       simple_regret_stp_3[slice79],\n",
        "       simple_regret_stp_4[slice79],\n",
        "       simple_regret_stp_5[slice79],\n",
        "       simple_regret_stp_6[slice79],\n",
        "       simple_regret_stp_7[slice79],\n",
        "       simple_regret_stp_8[slice79],\n",
        "       simple_regret_stp_9[slice79],\n",
        "       simple_regret_stp_10[slice79],\n",
        "       simple_regret_stp_11[slice79],\n",
        "       simple_regret_stp_12[slice79],\n",
        "       simple_regret_stp_13[slice79],\n",
        "       simple_regret_stp_14[slice79],\n",
        "       simple_regret_stp_15[slice79],\n",
        "       simple_regret_stp_16[slice79],\n",
        "       simple_regret_stp_17[slice79],\n",
        "       simple_regret_stp_18[slice79],\n",
        "       simple_regret_stp_19[slice79],\n",
        "       simple_regret_stp_20[slice79]]\n",
        "\n",
        "gp79_results = pd.DataFrame(gp79).sort_values(by=[0], ascending=False)\n",
        "stp79_results = pd.DataFrame(stp79).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - gp:\n",
        "lower_gp79 = np.asarray(gp79_results[4:5][0])[0]\n",
        "median_gp79 = np.asarray(gp79_results[9:10][0])[0]\n",
        "upper_gp79 = np.asarray(gp79_results[14:15][0])[0]\n",
        "\n",
        "lower_stp79 = np.asarray(stp79_results[4:5][0])[0]\n",
        "median_stp79 = np.asarray(stp79_results[9:10][0])[0]\n",
        "upper_stp79 = np.asarray(stp79_results[14:15][0])[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {
        "id": "vugr-aNhJLmh"
      },
      "outputs": [],
      "source": [
        "# Iteration89 :\n",
        "\n",
        "slice89 = 88\n",
        "\n",
        "gp89 = [simple_regret_gp_1[slice89],\n",
        "       simple_regret_gp_2[slice89],\n",
        "       simple_regret_gp_3[slice89],\n",
        "       simple_regret_gp_4[slice89],\n",
        "       simple_regret_gp_5[slice89],\n",
        "       simple_regret_gp_6[slice89],\n",
        "       simple_regret_gp_7[slice89],\n",
        "       simple_regret_gp_8[slice89],\n",
        "       simple_regret_gp_9[slice89],\n",
        "       simple_regret_gp_10[slice89],\n",
        "       simple_regret_gp_11[slice89],\n",
        "       simple_regret_gp_12[slice89],\n",
        "       simple_regret_gp_13[slice89],\n",
        "       simple_regret_gp_14[slice89],\n",
        "       simple_regret_gp_15[slice89],\n",
        "       simple_regret_gp_16[slice89],\n",
        "       simple_regret_gp_17[slice89],\n",
        "       simple_regret_gp_18[slice89],\n",
        "       simple_regret_gp_19[slice89],\n",
        "       simple_regret_gp_20[slice89]]\n",
        "\n",
        "stp89 = [simple_regret_stp_1[slice89],\n",
        "       simple_regret_stp_2[slice89],\n",
        "       simple_regret_stp_3[slice89],\n",
        "       simple_regret_stp_4[slice89],\n",
        "       simple_regret_stp_5[slice89],\n",
        "       simple_regret_stp_6[slice89],\n",
        "       simple_regret_stp_7[slice89],\n",
        "       simple_regret_stp_8[slice89],\n",
        "       simple_regret_stp_9[slice89],\n",
        "       simple_regret_stp_10[slice89],\n",
        "       simple_regret_stp_11[slice89],\n",
        "       simple_regret_stp_12[slice89],\n",
        "       simple_regret_stp_13[slice89],\n",
        "       simple_regret_stp_14[slice89],\n",
        "       simple_regret_stp_15[slice89],\n",
        "       simple_regret_stp_16[slice89],\n",
        "       simple_regret_stp_17[slice89],\n",
        "       simple_regret_stp_18[slice89],\n",
        "       simple_regret_stp_19[slice89],\n",
        "       simple_regret_stp_20[slice89]]\n",
        "\n",
        "gp89_results = pd.DataFrame(gp89).sort_values(by=[0], ascending=False)\n",
        "stp89_results = pd.DataFrame(stp89).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - gp:\n",
        "lower_gp89 = np.asarray(gp89_results[4:5][0])[0]\n",
        "median_gp89 = np.asarray(gp89_results[9:10][0])[0]\n",
        "upper_gp89 = np.asarray(gp89_results[14:15][0])[0]\n",
        "\n",
        "lower_stp89 = np.asarray(stp89_results[4:5][0])[0]\n",
        "median_stp89 = np.asarray(stp89_results[9:10][0])[0]\n",
        "upper_stp89 = np.asarray(stp89_results[14:15][0])[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DR4jfezYJLmi",
        "outputId": "9446fd02-46d7-4923-d580-12f0d4c6aeb3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.04261840449610358, -0.567767694400235)"
            ]
          },
          "metadata": {},
          "execution_count": 158
        }
      ],
      "source": [
        "# Iteration99 :\n",
        "\n",
        "slice99 = 98\n",
        "\n",
        "gp99 = [simple_regret_gp_1[slice99],\n",
        "       simple_regret_gp_2[slice99],\n",
        "       simple_regret_gp_3[slice99],\n",
        "       simple_regret_gp_4[slice99],\n",
        "       simple_regret_gp_5[slice99],\n",
        "       simple_regret_gp_6[slice99],\n",
        "       simple_regret_gp_7[slice99],\n",
        "       simple_regret_gp_8[slice99],\n",
        "       simple_regret_gp_9[slice99],\n",
        "       simple_regret_gp_10[slice99],\n",
        "       simple_regret_gp_11[slice99],\n",
        "       simple_regret_gp_12[slice99],\n",
        "       simple_regret_gp_13[slice99],\n",
        "       simple_regret_gp_14[slice99],\n",
        "       simple_regret_gp_15[slice99],\n",
        "       simple_regret_gp_16[slice99],\n",
        "       simple_regret_gp_17[slice99],\n",
        "       simple_regret_gp_18[slice99],\n",
        "       simple_regret_gp_19[slice99],\n",
        "       simple_regret_gp_20[slice99]]\n",
        "\n",
        "stp99 = [simple_regret_stp_1[slice99],\n",
        "       simple_regret_stp_2[slice99],\n",
        "       simple_regret_stp_3[slice99],\n",
        "       simple_regret_stp_4[slice99],\n",
        "       simple_regret_stp_5[slice99],\n",
        "       simple_regret_stp_6[slice99],\n",
        "       simple_regret_stp_7[slice99],\n",
        "       simple_regret_stp_8[slice99],\n",
        "       simple_regret_stp_9[slice99],\n",
        "       simple_regret_stp_10[slice99],\n",
        "       simple_regret_stp_11[slice99],\n",
        "       simple_regret_stp_12[slice99],\n",
        "       simple_regret_stp_13[slice99],\n",
        "       simple_regret_stp_14[slice99],\n",
        "       simple_regret_stp_15[slice99],\n",
        "       simple_regret_stp_16[slice99],\n",
        "       simple_regret_stp_17[slice99],\n",
        "       simple_regret_stp_18[slice99],\n",
        "       simple_regret_stp_19[slice99],\n",
        "       simple_regret_stp_20[slice99]]\n",
        "\n",
        "gp99_results = pd.DataFrame(gp99).sort_values(by=[0], ascending=False)\n",
        "stp99_results = pd.DataFrame(stp99).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - gp:\n",
        "lower_gp99 = np.asarray(gp99_results[4:5][0])[0]\n",
        "median_gp99 = np.asarray(gp99_results[9:10][0])[0]\n",
        "upper_gp99 = np.asarray(gp99_results[14:15][0])[0]\n",
        "\n",
        "lower_stp99 = np.asarray(stp99_results[4:5][0])[0]\n",
        "median_stp99 = np.asarray(stp99_results[9:10][0])[0]\n",
        "upper_stp99 = np.asarray(stp99_results[14:15][0])[0]\n",
        "\n",
        "lower_gp99, lower_stp99"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {
        "id": "IzQng-ULJLmj"
      },
      "outputs": [],
      "source": [
        "# Iteration10 :\n",
        "\n",
        "slice10 = 9\n",
        "\n",
        "gp10 = [simple_regret_gp_1[slice10],\n",
        "       simple_regret_gp_2[slice10],\n",
        "       simple_regret_gp_3[slice10],\n",
        "       simple_regret_gp_4[slice10],\n",
        "       simple_regret_gp_5[slice10],\n",
        "       simple_regret_gp_6[slice10],\n",
        "       simple_regret_gp_7[slice10],\n",
        "       simple_regret_gp_8[slice10],\n",
        "       simple_regret_gp_9[slice10],\n",
        "       simple_regret_gp_10[slice10],\n",
        "       simple_regret_gp_11[slice10],\n",
        "       simple_regret_gp_12[slice10],\n",
        "       simple_regret_gp_13[slice10],\n",
        "       simple_regret_gp_14[slice10],\n",
        "       simple_regret_gp_15[slice10],\n",
        "       simple_regret_gp_16[slice10],\n",
        "       simple_regret_gp_17[slice10],\n",
        "       simple_regret_gp_18[slice10],\n",
        "       simple_regret_gp_19[slice10],\n",
        "       simple_regret_gp_20[slice10]]\n",
        "\n",
        "stp10 = [simple_regret_stp_1[slice10],\n",
        "       simple_regret_stp_2[slice10],\n",
        "       simple_regret_stp_3[slice10],\n",
        "       simple_regret_stp_4[slice10],\n",
        "       simple_regret_stp_5[slice10],\n",
        "       simple_regret_stp_6[slice10],\n",
        "       simple_regret_stp_7[slice10],\n",
        "       simple_regret_stp_8[slice10],\n",
        "       simple_regret_stp_9[slice10],\n",
        "       simple_regret_stp_10[slice10],\n",
        "       simple_regret_stp_11[slice10],\n",
        "       simple_regret_stp_12[slice10],\n",
        "       simple_regret_stp_13[slice10],\n",
        "       simple_regret_stp_14[slice10],\n",
        "       simple_regret_stp_15[slice10],\n",
        "       simple_regret_stp_16[slice10],\n",
        "       simple_regret_stp_17[slice10],\n",
        "       simple_regret_stp_18[slice10],\n",
        "       simple_regret_stp_19[slice10],\n",
        "       simple_regret_stp_20[slice10]]\n",
        "\n",
        "gp10_results = pd.DataFrame(gp10).sort_values(by=[0], ascending=False)\n",
        "stp10_results = pd.DataFrame(stp10).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - gp:\n",
        "lower_gp10 = np.asarray(gp10_results[4:5][0])[0]\n",
        "median_gp10 = np.asarray(gp10_results[9:10][0])[0]\n",
        "upper_gp10 = np.asarray(gp10_results[14:15][0])[0]\n",
        "\n",
        "lower_stp10 = np.asarray(stp10_results[4:5][0])[0]\n",
        "median_stp10 = np.asarray(stp10_results[9:10][0])[0]\n",
        "upper_stp10 = np.asarray(stp10_results[14:15][0])[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "metadata": {
        "id": "DQ_Cuh-4JLmk"
      },
      "outputs": [],
      "source": [
        "# Iteration20 :\n",
        "\n",
        "slice20 = 19\n",
        "\n",
        "gp20 = [simple_regret_gp_1[slice20],\n",
        "       simple_regret_gp_2[slice20],\n",
        "       simple_regret_gp_3[slice20],\n",
        "       simple_regret_gp_4[slice20],\n",
        "       simple_regret_gp_5[slice20],\n",
        "       simple_regret_gp_6[slice20],\n",
        "       simple_regret_gp_7[slice20],\n",
        "       simple_regret_gp_8[slice20],\n",
        "       simple_regret_gp_9[slice20],\n",
        "       simple_regret_gp_10[slice20],\n",
        "       simple_regret_gp_11[slice20],\n",
        "       simple_regret_gp_12[slice20],\n",
        "       simple_regret_gp_13[slice20],\n",
        "       simple_regret_gp_14[slice20],\n",
        "       simple_regret_gp_15[slice20],\n",
        "       simple_regret_gp_16[slice20],\n",
        "       simple_regret_gp_17[slice20],\n",
        "       simple_regret_gp_18[slice20],\n",
        "       simple_regret_gp_19[slice20],\n",
        "       simple_regret_gp_20[slice20]]\n",
        "\n",
        "stp20 = [simple_regret_stp_1[slice20],\n",
        "       simple_regret_stp_2[slice20],\n",
        "       simple_regret_stp_3[slice20],\n",
        "       simple_regret_stp_4[slice20],\n",
        "       simple_regret_stp_5[slice20],\n",
        "       simple_regret_stp_6[slice20],\n",
        "       simple_regret_stp_7[slice20],\n",
        "       simple_regret_stp_8[slice20],\n",
        "       simple_regret_stp_9[slice20],\n",
        "       simple_regret_stp_10[slice20],\n",
        "       simple_regret_stp_11[slice20],\n",
        "       simple_regret_stp_12[slice20],\n",
        "       simple_regret_stp_13[slice20],\n",
        "       simple_regret_stp_14[slice20],\n",
        "       simple_regret_stp_15[slice20],\n",
        "       simple_regret_stp_16[slice20],\n",
        "       simple_regret_stp_17[slice20],\n",
        "       simple_regret_stp_18[slice20],\n",
        "       simple_regret_stp_19[slice20],\n",
        "       simple_regret_stp_20[slice20]]\n",
        "\n",
        "gp20_results = pd.DataFrame(gp20).sort_values(by=[0], ascending=False)\n",
        "stp20_results = pd.DataFrame(stp20).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - gp:\n",
        "lower_gp20 = np.asarray(gp20_results[4:5][0])[0]\n",
        "median_gp20 = np.asarray(gp20_results[9:10][0])[0]\n",
        "upper_gp20 = np.asarray(gp20_results[14:15][0])[0]\n",
        "\n",
        "lower_stp20 = np.asarray(stp20_results[4:5][0])[0]\n",
        "median_stp20 = np.asarray(stp20_results[9:10][0])[0]\n",
        "upper_stp20 = np.asarray(stp20_results[14:15][0])[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "metadata": {
        "id": "oYxGG4B6JLml"
      },
      "outputs": [],
      "source": [
        "# Iteration30 :\n",
        "\n",
        "slice30 = 29\n",
        "\n",
        "gp30 = [simple_regret_gp_1[slice30],\n",
        "       simple_regret_gp_2[slice30],\n",
        "       simple_regret_gp_3[slice30],\n",
        "       simple_regret_gp_4[slice30],\n",
        "       simple_regret_gp_5[slice30],\n",
        "       simple_regret_gp_6[slice30],\n",
        "       simple_regret_gp_7[slice30],\n",
        "       simple_regret_gp_8[slice30],\n",
        "       simple_regret_gp_9[slice30],\n",
        "       simple_regret_gp_10[slice30],\n",
        "       simple_regret_gp_11[slice30],\n",
        "       simple_regret_gp_12[slice30],\n",
        "       simple_regret_gp_13[slice30],\n",
        "       simple_regret_gp_14[slice30],\n",
        "       simple_regret_gp_15[slice30],\n",
        "       simple_regret_gp_16[slice30],\n",
        "       simple_regret_gp_17[slice30],\n",
        "       simple_regret_gp_18[slice30],\n",
        "       simple_regret_gp_19[slice30],\n",
        "       simple_regret_gp_20[slice30]]\n",
        "\n",
        "stp30 = [simple_regret_stp_1[slice30],\n",
        "       simple_regret_stp_2[slice30],\n",
        "       simple_regret_stp_3[slice30],\n",
        "       simple_regret_stp_4[slice30],\n",
        "       simple_regret_stp_5[slice30],\n",
        "       simple_regret_stp_6[slice30],\n",
        "       simple_regret_stp_7[slice30],\n",
        "       simple_regret_stp_8[slice30],\n",
        "       simple_regret_stp_9[slice30],\n",
        "       simple_regret_stp_10[slice30],\n",
        "       simple_regret_stp_11[slice30],\n",
        "       simple_regret_stp_12[slice30],\n",
        "       simple_regret_stp_13[slice30],\n",
        "       simple_regret_stp_14[slice30],\n",
        "       simple_regret_stp_15[slice30],\n",
        "       simple_regret_stp_16[slice30],\n",
        "       simple_regret_stp_17[slice30],\n",
        "       simple_regret_stp_18[slice30],\n",
        "       simple_regret_stp_19[slice30],\n",
        "       simple_regret_stp_20[slice30]]\n",
        "\n",
        "gp30_results = pd.DataFrame(gp30).sort_values(by=[0], ascending=False)\n",
        "stp30_results = pd.DataFrame(stp30).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - gp:\n",
        "lower_gp30 = np.asarray(gp30_results[4:5][0])[0]\n",
        "median_gp30 = np.asarray(gp30_results[9:10][0])[0]\n",
        "upper_gp30 = np.asarray(gp30_results[14:15][0])[0]\n",
        "\n",
        "lower_stp30 = np.asarray(stp30_results[4:5][0])[0]\n",
        "median_stp30 = np.asarray(stp30_results[9:10][0])[0]\n",
        "upper_stp30 = np.asarray(stp30_results[14:15][0])[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 162,
      "metadata": {
        "id": "0yn4pSn1JLmm"
      },
      "outputs": [],
      "source": [
        "# Iteration40 :\n",
        "\n",
        "slice40 = 39\n",
        "\n",
        "gp40 = [simple_regret_gp_1[slice40],\n",
        "       simple_regret_gp_2[slice40],\n",
        "       simple_regret_gp_3[slice40],\n",
        "       simple_regret_gp_4[slice40],\n",
        "       simple_regret_gp_5[slice40],\n",
        "       simple_regret_gp_6[slice40],\n",
        "       simple_regret_gp_7[slice40],\n",
        "       simple_regret_gp_8[slice40],\n",
        "       simple_regret_gp_9[slice40],\n",
        "       simple_regret_gp_10[slice40],\n",
        "       simple_regret_gp_11[slice40],\n",
        "       simple_regret_gp_12[slice40],\n",
        "       simple_regret_gp_13[slice40],\n",
        "       simple_regret_gp_14[slice40],\n",
        "       simple_regret_gp_15[slice40],\n",
        "       simple_regret_gp_16[slice40],\n",
        "       simple_regret_gp_17[slice40],\n",
        "       simple_regret_gp_18[slice40],\n",
        "       simple_regret_gp_19[slice40],\n",
        "       simple_regret_gp_20[slice40]]\n",
        "\n",
        "stp40 = [simple_regret_stp_1[slice40],\n",
        "       simple_regret_stp_2[slice40],\n",
        "       simple_regret_stp_3[slice40],\n",
        "       simple_regret_stp_4[slice40],\n",
        "       simple_regret_stp_5[slice40],\n",
        "       simple_regret_stp_6[slice40],\n",
        "       simple_regret_stp_7[slice40],\n",
        "       simple_regret_stp_8[slice40],\n",
        "       simple_regret_stp_9[slice40],\n",
        "       simple_regret_stp_10[slice40],\n",
        "       simple_regret_stp_11[slice40],\n",
        "       simple_regret_stp_12[slice40],\n",
        "       simple_regret_stp_13[slice40],\n",
        "       simple_regret_stp_14[slice40],\n",
        "       simple_regret_stp_15[slice40],\n",
        "       simple_regret_stp_16[slice40],\n",
        "       simple_regret_stp_17[slice40],\n",
        "       simple_regret_stp_18[slice40],\n",
        "       simple_regret_stp_19[slice40],\n",
        "       simple_regret_stp_20[slice40]]\n",
        "\n",
        "gp40_results = pd.DataFrame(gp40).sort_values(by=[0], ascending=False)\n",
        "stp40_results = pd.DataFrame(stp40).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - gp:\n",
        "lower_gp40 = np.asarray(gp40_results[4:5][0])[0]\n",
        "median_gp40 = np.asarray(gp40_results[9:10][0])[0]\n",
        "upper_gp40 = np.asarray(gp40_results[14:15][0])[0]\n",
        "\n",
        "lower_stp40 = np.asarray(stp40_results[4:5][0])[0]\n",
        "median_stp40 = np.asarray(stp40_results[9:10][0])[0]\n",
        "upper_stp40 = np.asarray(stp40_results[14:15][0])[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 163,
      "metadata": {
        "id": "QsSkJVABJLmn"
      },
      "outputs": [],
      "source": [
        "# Iteration50 :\n",
        "\n",
        "slice50 = 49\n",
        "\n",
        "gp50 = [simple_regret_gp_1[slice50],\n",
        "       simple_regret_gp_2[slice50],\n",
        "       simple_regret_gp_3[slice50],\n",
        "       simple_regret_gp_4[slice50],\n",
        "       simple_regret_gp_5[slice50],\n",
        "       simple_regret_gp_6[slice50],\n",
        "       simple_regret_gp_7[slice50],\n",
        "       simple_regret_gp_8[slice50],\n",
        "       simple_regret_gp_9[slice50],\n",
        "       simple_regret_gp_10[slice50],\n",
        "       simple_regret_gp_11[slice50],\n",
        "       simple_regret_gp_12[slice50],\n",
        "       simple_regret_gp_13[slice50],\n",
        "       simple_regret_gp_14[slice50],\n",
        "       simple_regret_gp_15[slice50],\n",
        "       simple_regret_gp_16[slice50],\n",
        "       simple_regret_gp_17[slice50],\n",
        "       simple_regret_gp_18[slice50],\n",
        "       simple_regret_gp_19[slice50],\n",
        "       simple_regret_gp_20[slice50]]\n",
        "\n",
        "stp50 = [simple_regret_stp_1[slice50],\n",
        "       simple_regret_stp_2[slice50],\n",
        "       simple_regret_stp_3[slice50],\n",
        "       simple_regret_stp_4[slice50],\n",
        "       simple_regret_stp_5[slice50],\n",
        "       simple_regret_stp_6[slice50],\n",
        "       simple_regret_stp_7[slice50],\n",
        "       simple_regret_stp_8[slice50],\n",
        "       simple_regret_stp_9[slice50],\n",
        "       simple_regret_stp_10[slice50],\n",
        "       simple_regret_stp_11[slice50],\n",
        "       simple_regret_stp_12[slice50],\n",
        "       simple_regret_stp_13[slice50],\n",
        "       simple_regret_stp_14[slice50],\n",
        "       simple_regret_stp_15[slice50],\n",
        "       simple_regret_stp_16[slice50],\n",
        "       simple_regret_stp_17[slice50],\n",
        "       simple_regret_stp_18[slice50],\n",
        "       simple_regret_stp_19[slice50],\n",
        "       simple_regret_stp_20[slice50]]\n",
        "\n",
        "gp50_results = pd.DataFrame(gp50).sort_values(by=[0], ascending=False)\n",
        "stp50_results = pd.DataFrame(stp50).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - gp:\n",
        "lower_gp50 = np.asarray(gp50_results[4:5][0])[0]\n",
        "median_gp50 = np.asarray(gp50_results[9:10][0])[0]\n",
        "upper_gp50 = np.asarray(gp50_results[14:15][0])[0]\n",
        "\n",
        "lower_stp50 = np.asarray(stp50_results[4:5][0])[0]\n",
        "median_stp50 = np.asarray(stp50_results[9:10][0])[0]\n",
        "upper_stp50 = np.asarray(stp50_results[14:15][0])[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 164,
      "metadata": {
        "id": "ST1uz8D4JLmo"
      },
      "outputs": [],
      "source": [
        "# Iteration60 :\n",
        "\n",
        "slice60 = 59\n",
        "\n",
        "gp60 = [simple_regret_gp_1[slice60],\n",
        "       simple_regret_gp_2[slice60],\n",
        "       simple_regret_gp_3[slice60],\n",
        "       simple_regret_gp_4[slice60],\n",
        "       simple_regret_gp_5[slice60],\n",
        "       simple_regret_gp_6[slice60],\n",
        "       simple_regret_gp_7[slice60],\n",
        "       simple_regret_gp_8[slice60],\n",
        "       simple_regret_gp_9[slice60],\n",
        "       simple_regret_gp_10[slice60],\n",
        "       simple_regret_gp_11[slice60],\n",
        "       simple_regret_gp_12[slice60],\n",
        "       simple_regret_gp_13[slice60],\n",
        "       simple_regret_gp_14[slice60],\n",
        "       simple_regret_gp_15[slice60],\n",
        "       simple_regret_gp_16[slice60],\n",
        "       simple_regret_gp_17[slice60],\n",
        "       simple_regret_gp_18[slice60],\n",
        "       simple_regret_gp_19[slice60],\n",
        "       simple_regret_gp_20[slice60]]\n",
        "\n",
        "stp60 = [simple_regret_stp_1[slice60],\n",
        "       simple_regret_stp_2[slice60],\n",
        "       simple_regret_stp_3[slice60],\n",
        "       simple_regret_stp_4[slice60],\n",
        "       simple_regret_stp_5[slice60],\n",
        "       simple_regret_stp_6[slice60],\n",
        "       simple_regret_stp_7[slice60],\n",
        "       simple_regret_stp_8[slice60],\n",
        "       simple_regret_stp_9[slice60],\n",
        "       simple_regret_stp_10[slice60],\n",
        "       simple_regret_stp_11[slice60],\n",
        "       simple_regret_stp_12[slice60],\n",
        "       simple_regret_stp_13[slice60],\n",
        "       simple_regret_stp_14[slice60],\n",
        "       simple_regret_stp_15[slice60],\n",
        "       simple_regret_stp_16[slice60],\n",
        "       simple_regret_stp_17[slice60],\n",
        "       simple_regret_stp_18[slice60],\n",
        "       simple_regret_stp_19[slice60],\n",
        "       simple_regret_stp_20[slice60]]\n",
        "\n",
        "gp60_results = pd.DataFrame(gp60).sort_values(by=[0], ascending=False)\n",
        "stp60_results = pd.DataFrame(stp60).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - gp:\n",
        "lower_gp60 = np.asarray(gp60_results[4:5][0])[0]\n",
        "median_gp60 = np.asarray(gp60_results[9:10][0])[0]\n",
        "upper_gp60 = np.asarray(gp60_results[14:15][0])[0]\n",
        "\n",
        "lower_stp60 = np.asarray(stp60_results[4:5][0])[0]\n",
        "median_stp60 = np.asarray(stp60_results[9:10][0])[0]\n",
        "upper_stp60 = np.asarray(stp60_results[14:15][0])[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 165,
      "metadata": {
        "id": "blv1ODfsJLmo"
      },
      "outputs": [],
      "source": [
        "# Iteration70 :\n",
        "\n",
        "slice70 = 69\n",
        "\n",
        "gp70 = [simple_regret_gp_1[slice70],\n",
        "       simple_regret_gp_2[slice70],\n",
        "       simple_regret_gp_3[slice70],\n",
        "       simple_regret_gp_4[slice70],\n",
        "       simple_regret_gp_5[slice70],\n",
        "       simple_regret_gp_6[slice70],\n",
        "       simple_regret_gp_7[slice70],\n",
        "       simple_regret_gp_8[slice70],\n",
        "       simple_regret_gp_9[slice70],\n",
        "       simple_regret_gp_10[slice70],\n",
        "       simple_regret_gp_11[slice70],\n",
        "       simple_regret_gp_12[slice70],\n",
        "       simple_regret_gp_13[slice70],\n",
        "       simple_regret_gp_14[slice70],\n",
        "       simple_regret_gp_15[slice70],\n",
        "       simple_regret_gp_16[slice70],\n",
        "       simple_regret_gp_17[slice70],\n",
        "       simple_regret_gp_18[slice70],\n",
        "       simple_regret_gp_19[slice70],\n",
        "       simple_regret_gp_20[slice70]]\n",
        "\n",
        "stp70 = [simple_regret_stp_1[slice70],\n",
        "       simple_regret_stp_2[slice70],\n",
        "       simple_regret_stp_3[slice70],\n",
        "       simple_regret_stp_4[slice70],\n",
        "       simple_regret_stp_5[slice70],\n",
        "       simple_regret_stp_6[slice70],\n",
        "       simple_regret_stp_7[slice70],\n",
        "       simple_regret_stp_8[slice70],\n",
        "       simple_regret_stp_9[slice70],\n",
        "       simple_regret_stp_10[slice70],\n",
        "       simple_regret_stp_11[slice70],\n",
        "       simple_regret_stp_12[slice70],\n",
        "       simple_regret_stp_13[slice70],\n",
        "       simple_regret_stp_14[slice70],\n",
        "       simple_regret_stp_15[slice70],\n",
        "       simple_regret_stp_16[slice70],\n",
        "       simple_regret_stp_17[slice70],\n",
        "       simple_regret_stp_18[slice70],\n",
        "       simple_regret_stp_19[slice70],\n",
        "       simple_regret_stp_20[slice70]]\n",
        "\n",
        "gp70_results = pd.DataFrame(gp70).sort_values(by=[0], ascending=False)\n",
        "stp70_results = pd.DataFrame(stp70).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - gp:\n",
        "lower_gp70 = np.asarray(gp70_results[4:5][0])[0]\n",
        "median_gp70 = np.asarray(gp70_results[9:10][0])[0]\n",
        "upper_gp70 = np.asarray(gp70_results[14:15][0])[0]\n",
        "\n",
        "lower_stp70 = np.asarray(stp70_results[4:5][0])[0]\n",
        "median_stp70 = np.asarray(stp70_results[9:10][0])[0]\n",
        "upper_stp70 = np.asarray(stp70_results[14:15][0])[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 166,
      "metadata": {
        "id": "p6CI5KuzJLmp"
      },
      "outputs": [],
      "source": [
        "# Iteration80 :\n",
        "\n",
        "slice80 = 79\n",
        "\n",
        "gp80 = [simple_regret_gp_1[slice80],\n",
        "       simple_regret_gp_2[slice80],\n",
        "       simple_regret_gp_3[slice80],\n",
        "       simple_regret_gp_4[slice80],\n",
        "       simple_regret_gp_5[slice80],\n",
        "       simple_regret_gp_6[slice80],\n",
        "       simple_regret_gp_7[slice80],\n",
        "       simple_regret_gp_8[slice80],\n",
        "       simple_regret_gp_9[slice80],\n",
        "       simple_regret_gp_10[slice80],\n",
        "       simple_regret_gp_11[slice80],\n",
        "       simple_regret_gp_12[slice80],\n",
        "       simple_regret_gp_13[slice80],\n",
        "       simple_regret_gp_14[slice80],\n",
        "       simple_regret_gp_15[slice80],\n",
        "       simple_regret_gp_16[slice80],\n",
        "       simple_regret_gp_17[slice80],\n",
        "       simple_regret_gp_18[slice80],\n",
        "       simple_regret_gp_19[slice80],\n",
        "       simple_regret_gp_20[slice80]]\n",
        "\n",
        "stp80 = [simple_regret_stp_1[slice80],\n",
        "       simple_regret_stp_2[slice80],\n",
        "       simple_regret_stp_3[slice80],\n",
        "       simple_regret_stp_4[slice80],\n",
        "       simple_regret_stp_5[slice80],\n",
        "       simple_regret_stp_6[slice80],\n",
        "       simple_regret_stp_7[slice80],\n",
        "       simple_regret_stp_8[slice80],\n",
        "       simple_regret_stp_9[slice80],\n",
        "       simple_regret_stp_10[slice80],\n",
        "       simple_regret_stp_11[slice80],\n",
        "       simple_regret_stp_12[slice80],\n",
        "       simple_regret_stp_13[slice80],\n",
        "       simple_regret_stp_14[slice80],\n",
        "       simple_regret_stp_15[slice80],\n",
        "       simple_regret_stp_16[slice80],\n",
        "       simple_regret_stp_17[slice80],\n",
        "       simple_regret_stp_18[slice80],\n",
        "       simple_regret_stp_19[slice80],\n",
        "       simple_regret_stp_20[slice80]]\n",
        "\n",
        "gp80_results = pd.DataFrame(gp80).sort_values(by=[0], ascending=False)\n",
        "stp80_results = pd.DataFrame(stp80).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - gp:\n",
        "lower_gp80 = np.asarray(gp80_results[4:5][0])[0]\n",
        "median_gp80 = np.asarray(gp80_results[9:10][0])[0]\n",
        "upper_gp80 = np.asarray(gp80_results[14:15][0])[0]\n",
        "\n",
        "lower_stp80 = np.asarray(stp80_results[4:5][0])[0]\n",
        "median_stp80 = np.asarray(stp80_results[9:10][0])[0]\n",
        "upper_stp80 = np.asarray(stp80_results[14:15][0])[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "metadata": {
        "id": "d0O1SFsmJLmq"
      },
      "outputs": [],
      "source": [
        "# Iteration90 :\n",
        "\n",
        "slice90 = 89\n",
        "\n",
        "gp90 = [simple_regret_gp_1[slice90],\n",
        "       simple_regret_gp_2[slice90],\n",
        "       simple_regret_gp_3[slice90],\n",
        "       simple_regret_gp_4[slice90],\n",
        "       simple_regret_gp_5[slice90],\n",
        "       simple_regret_gp_6[slice90],\n",
        "       simple_regret_gp_7[slice90],\n",
        "       simple_regret_gp_8[slice90],\n",
        "       simple_regret_gp_9[slice90],\n",
        "       simple_regret_gp_10[slice90],\n",
        "       simple_regret_gp_11[slice90],\n",
        "       simple_regret_gp_12[slice90],\n",
        "       simple_regret_gp_13[slice90],\n",
        "       simple_regret_gp_14[slice90],\n",
        "       simple_regret_gp_15[slice90],\n",
        "       simple_regret_gp_16[slice90],\n",
        "       simple_regret_gp_17[slice90],\n",
        "       simple_regret_gp_18[slice90],\n",
        "       simple_regret_gp_19[slice90],\n",
        "       simple_regret_gp_20[slice90]]\n",
        "\n",
        "stp90 = [simple_regret_stp_1[slice90],\n",
        "       simple_regret_stp_2[slice90],\n",
        "       simple_regret_stp_3[slice90],\n",
        "       simple_regret_stp_4[slice90],\n",
        "       simple_regret_stp_5[slice90],\n",
        "       simple_regret_stp_6[slice90],\n",
        "       simple_regret_stp_7[slice90],\n",
        "       simple_regret_stp_8[slice90],\n",
        "       simple_regret_stp_9[slice90],\n",
        "       simple_regret_stp_10[slice90],\n",
        "       simple_regret_stp_11[slice90],\n",
        "       simple_regret_stp_12[slice90],\n",
        "       simple_regret_stp_13[slice90],\n",
        "       simple_regret_stp_14[slice90],\n",
        "       simple_regret_stp_15[slice90],\n",
        "       simple_regret_stp_16[slice90],\n",
        "       simple_regret_stp_17[slice90],\n",
        "       simple_regret_stp_18[slice90],\n",
        "       simple_regret_stp_19[slice90],\n",
        "       simple_regret_stp_20[slice90]]\n",
        "\n",
        "gp90_results = pd.DataFrame(gp90).sort_values(by=[0], ascending=False)\n",
        "stp90_results = pd.DataFrame(stp90).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - gp:\n",
        "lower_gp90 = np.asarray(gp90_results[4:5][0])[0]\n",
        "median_gp90 = np.asarray(gp90_results[9:10][0])[0]\n",
        "upper_gp90 = np.asarray(gp90_results[14:15][0])[0]\n",
        "\n",
        "lower_stp90 = np.asarray(stp90_results[4:5][0])[0]\n",
        "median_stp90 = np.asarray(stp90_results[9:10][0])[0]\n",
        "upper_stp90 = np.asarray(stp90_results[14:15][0])[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 168,
      "metadata": {
        "id": "jc9A3bPwJLmr"
      },
      "outputs": [],
      "source": [
        "# Iteration100 :\n",
        "\n",
        "slice100 = 99\n",
        "\n",
        "gp100 = [simple_regret_gp_1[slice100],\n",
        "       simple_regret_gp_2[slice100],\n",
        "       simple_regret_gp_3[slice100],\n",
        "       simple_regret_gp_4[slice100],\n",
        "       simple_regret_gp_5[slice100],\n",
        "       simple_regret_gp_6[slice100],\n",
        "       simple_regret_gp_7[slice100],\n",
        "       simple_regret_gp_8[slice100],\n",
        "       simple_regret_gp_9[slice100],\n",
        "       simple_regret_gp_10[slice100],\n",
        "       simple_regret_gp_11[slice100],\n",
        "       simple_regret_gp_12[slice100],\n",
        "       simple_regret_gp_13[slice100],\n",
        "       simple_regret_gp_14[slice100],\n",
        "       simple_regret_gp_15[slice100],\n",
        "       simple_regret_gp_16[slice100],\n",
        "       simple_regret_gp_17[slice100],\n",
        "       simple_regret_gp_18[slice100],\n",
        "       simple_regret_gp_19[slice100],\n",
        "       simple_regret_gp_20[slice100]]\n",
        "\n",
        "stp100 = [simple_regret_stp_1[slice100],\n",
        "       simple_regret_stp_2[slice100],\n",
        "       simple_regret_stp_3[slice100],\n",
        "       simple_regret_stp_4[slice100],\n",
        "       simple_regret_stp_5[slice100],\n",
        "       simple_regret_stp_6[slice100],\n",
        "       simple_regret_stp_7[slice100],\n",
        "       simple_regret_stp_8[slice100],\n",
        "       simple_regret_stp_9[slice100],\n",
        "       simple_regret_stp_10[slice100],\n",
        "       simple_regret_stp_11[slice100],\n",
        "       simple_regret_stp_12[slice100],\n",
        "       simple_regret_stp_13[slice100],\n",
        "       simple_regret_stp_14[slice100],\n",
        "       simple_regret_stp_15[slice100],\n",
        "       simple_regret_stp_16[slice100],\n",
        "       simple_regret_stp_17[slice100],\n",
        "       simple_regret_stp_18[slice100],\n",
        "       simple_regret_stp_19[slice100],\n",
        "       simple_regret_stp_20[slice100]]\n",
        "\n",
        "gp100_results = pd.DataFrame(gp100).sort_values(by=[0], ascending=False)\n",
        "stp100_results = pd.DataFrame(stp100).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - gp:\n",
        "lower_gp100 = np.asarray(gp100_results[4:5][0])[0]\n",
        "median_gp100 = np.asarray(gp100_results[9:10][0])[0]\n",
        "upper_gp100 = np.asarray(gp100_results[14:15][0])[0]\n",
        "\n",
        "lower_stp100 = np.asarray(stp100_results[4:5][0])[0]\n",
        "median_stp100 = np.asarray(stp100_results[9:10][0])[0]\n",
        "upper_stp100 = np.asarray(stp100_results[14:15][0])[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 169,
      "metadata": {
        "id": "R1gk3HGTJLms"
      },
      "outputs": [],
      "source": [
        "### Summarise arrays: 'GP'\n",
        "\n",
        "lower_gp = [lower_gp1,\n",
        "            lower_gp2,\n",
        "            lower_gp3,\n",
        "            lower_gp4,\n",
        "            lower_gp5,\n",
        "            lower_gp6,\n",
        "            lower_gp7,\n",
        "            lower_gp8,\n",
        "            lower_gp9,\n",
        "            lower_gp10,\n",
        "            lower_gp11,\n",
        "            lower_gp12,\n",
        "            lower_gp13,\n",
        "            lower_gp14,\n",
        "            lower_gp15,\n",
        "            lower_gp16,\n",
        "            lower_gp17,\n",
        "            lower_gp18,\n",
        "            lower_gp19,\n",
        "            lower_gp20,\n",
        "            lower_gp21,\n",
        "            lower_gp22,\n",
        "            lower_gp23,\n",
        "            lower_gp24,\n",
        "            lower_gp25,\n",
        "            lower_gp26,\n",
        "            lower_gp27,\n",
        "            lower_gp28,\n",
        "            lower_gp29,\n",
        "            lower_gp30,\n",
        "            lower_gp31,\n",
        "            lower_gp32,\n",
        "            lower_gp33,\n",
        "            lower_gp34,\n",
        "            lower_gp35,\n",
        "            lower_gp36,\n",
        "            lower_gp37,\n",
        "            lower_gp38,\n",
        "            lower_gp39,\n",
        "            lower_gp40,\n",
        "            lower_gp41,\n",
        "            lower_gp42,\n",
        "            lower_gp43,\n",
        "            lower_gp44,\n",
        "            lower_gp45,\n",
        "            lower_gp46,\n",
        "            lower_gp47,\n",
        "            lower_gp48,\n",
        "            lower_gp49,\n",
        "            lower_gp50,\n",
        "            lower_gp51,\n",
        "            lower_gp52,\n",
        "            lower_gp53,\n",
        "            lower_gp54,\n",
        "            lower_gp55,\n",
        "            lower_gp56,\n",
        "            lower_gp57,\n",
        "            lower_gp58,\n",
        "            lower_gp59,\n",
        "            lower_gp60,\n",
        "            lower_gp61,\n",
        "            lower_gp62,\n",
        "            lower_gp63,\n",
        "            lower_gp64,\n",
        "            lower_gp65,\n",
        "            lower_gp66,\n",
        "            lower_gp67,\n",
        "            lower_gp68,\n",
        "            lower_gp69,\n",
        "            lower_gp70,\n",
        "            lower_gp71,\n",
        "            lower_gp72,\n",
        "            lower_gp73,\n",
        "            lower_gp74,\n",
        "            lower_gp75,\n",
        "            lower_gp76,\n",
        "            lower_gp77,\n",
        "            lower_gp78,\n",
        "            lower_gp79,\n",
        "            lower_gp80,\n",
        "            lower_gp81,\n",
        "            lower_gp82,\n",
        "            lower_gp83,\n",
        "            lower_gp84,\n",
        "            lower_gp85,\n",
        "            lower_gp86,\n",
        "            lower_gp87,\n",
        "            lower_gp88,\n",
        "            lower_gp89,\n",
        "            lower_gp90,\n",
        "            lower_gp91,\n",
        "            lower_gp92,\n",
        "            lower_gp93,\n",
        "            lower_gp94,\n",
        "            lower_gp95,\n",
        "            lower_gp96,\n",
        "            lower_gp97,\n",
        "            lower_gp98,\n",
        "            lower_gp99,\n",
        "            lower_gp100,\n",
        "            lower_gp101]\n",
        "\n",
        "median_gp = [median_gp1,\n",
        "            median_gp2,\n",
        "            median_gp3,\n",
        "            median_gp4,\n",
        "            median_gp5,\n",
        "            median_gp6,\n",
        "            median_gp7,\n",
        "            median_gp8,\n",
        "            median_gp9,\n",
        "            median_gp10,\n",
        "            median_gp11,\n",
        "            median_gp12,\n",
        "            median_gp13,\n",
        "            median_gp14,\n",
        "            median_gp15,\n",
        "            median_gp16,\n",
        "            median_gp17,\n",
        "            median_gp18,\n",
        "            median_gp19,\n",
        "            median_gp20,\n",
        "            median_gp21,\n",
        "            median_gp22,\n",
        "            median_gp23,\n",
        "            median_gp24,\n",
        "            median_gp25,\n",
        "            median_gp26,\n",
        "            median_gp27,\n",
        "            median_gp28,\n",
        "            median_gp29,\n",
        "            median_gp30,\n",
        "            median_gp31,\n",
        "            median_gp32,\n",
        "            median_gp33,\n",
        "            median_gp34,\n",
        "            median_gp35,\n",
        "            median_gp36,\n",
        "            median_gp37,\n",
        "            median_gp38,\n",
        "            median_gp39,\n",
        "            median_gp40,\n",
        "            median_gp41,\n",
        "            median_gp42,\n",
        "            median_gp43,\n",
        "            median_gp44,\n",
        "            median_gp45,\n",
        "            median_gp46,\n",
        "            median_gp47,\n",
        "            median_gp48,\n",
        "            median_gp49,\n",
        "            median_gp50,\n",
        "            median_gp51,\n",
        "            median_gp52,\n",
        "            median_gp53,\n",
        "            median_gp54,\n",
        "            median_gp55,\n",
        "            median_gp56,\n",
        "            median_gp57,\n",
        "            median_gp58,\n",
        "            median_gp59,\n",
        "            median_gp60,\n",
        "            median_gp61,\n",
        "            median_gp62,\n",
        "            median_gp63,\n",
        "            median_gp64,\n",
        "            median_gp65,\n",
        "            median_gp66,\n",
        "            median_gp67,\n",
        "            median_gp68,\n",
        "            median_gp69,\n",
        "            median_gp70,\n",
        "            median_gp71,\n",
        "            median_gp72,\n",
        "            median_gp73,\n",
        "            median_gp74,\n",
        "            median_gp75,\n",
        "            median_gp76,\n",
        "            median_gp77,\n",
        "            median_gp78,\n",
        "            median_gp79,\n",
        "            median_gp80,\n",
        "            median_gp81,\n",
        "            median_gp82,\n",
        "            median_gp83,\n",
        "            median_gp84,\n",
        "            median_gp85,\n",
        "            median_gp86,\n",
        "            median_gp87,\n",
        "            median_gp88,\n",
        "            median_gp89,\n",
        "            median_gp90,\n",
        "            median_gp91,\n",
        "            median_gp92,\n",
        "            median_gp93,\n",
        "            median_gp94,\n",
        "            median_gp95,\n",
        "            median_gp96,\n",
        "            median_gp97,\n",
        "            median_gp98,\n",
        "            median_gp99,\n",
        "            median_gp100,\n",
        "            median_gp101]\n",
        "\n",
        "upper_gp = [upper_gp1,\n",
        "            upper_gp2,\n",
        "            upper_gp3,\n",
        "            upper_gp4,\n",
        "            upper_gp5,\n",
        "            upper_gp6,\n",
        "            upper_gp7,\n",
        "            upper_gp8,\n",
        "            upper_gp9,\n",
        "            upper_gp10,\n",
        "            upper_gp11,\n",
        "            upper_gp12,\n",
        "            upper_gp13,\n",
        "            upper_gp14,\n",
        "            upper_gp15,\n",
        "            upper_gp16,\n",
        "            upper_gp17,\n",
        "            upper_gp18,\n",
        "            upper_gp19,\n",
        "            upper_gp20,\n",
        "            upper_gp21,\n",
        "            upper_gp22,\n",
        "            upper_gp23,\n",
        "            upper_gp24,\n",
        "            upper_gp25,\n",
        "            upper_gp26,\n",
        "            upper_gp27,\n",
        "            upper_gp28,\n",
        "            upper_gp29,\n",
        "            upper_gp30,\n",
        "            upper_gp31,\n",
        "            upper_gp32,\n",
        "            upper_gp33,\n",
        "            upper_gp34,\n",
        "            upper_gp35,\n",
        "            upper_gp36,\n",
        "            upper_gp37,\n",
        "            upper_gp38,\n",
        "            upper_gp39,\n",
        "            upper_gp40,\n",
        "            upper_gp41,\n",
        "            upper_gp42,\n",
        "            upper_gp43,\n",
        "            upper_gp44,\n",
        "            upper_gp45,\n",
        "            upper_gp46,\n",
        "            upper_gp47,\n",
        "            upper_gp48,\n",
        "            upper_gp49,\n",
        "            upper_gp50,\n",
        "            upper_gp51,\n",
        "            upper_gp52,\n",
        "            upper_gp53,\n",
        "            upper_gp54,\n",
        "            upper_gp55,\n",
        "            upper_gp56,\n",
        "            upper_gp57,\n",
        "            upper_gp58,\n",
        "            upper_gp59,\n",
        "            upper_gp60,\n",
        "            upper_gp61,\n",
        "            upper_gp62,\n",
        "            upper_gp63,\n",
        "            upper_gp64,\n",
        "            upper_gp65,\n",
        "            upper_gp66,\n",
        "            upper_gp67,\n",
        "            upper_gp68,\n",
        "            upper_gp69,\n",
        "            upper_gp70,\n",
        "            upper_gp71,\n",
        "            upper_gp72,\n",
        "            upper_gp73,\n",
        "            upper_gp74,\n",
        "            upper_gp75,\n",
        "            upper_gp76,\n",
        "            upper_gp77,\n",
        "            upper_gp78,\n",
        "            upper_gp79,\n",
        "            upper_gp80,\n",
        "            upper_gp81,\n",
        "            upper_gp82,\n",
        "            upper_gp83,\n",
        "            upper_gp84,\n",
        "            upper_gp85,\n",
        "            upper_gp86,\n",
        "            upper_gp87,\n",
        "            upper_gp88,\n",
        "            upper_gp89,\n",
        "            upper_gp90,\n",
        "            upper_gp91,\n",
        "            upper_gp92,\n",
        "            upper_gp93,\n",
        "            upper_gp94,\n",
        "            upper_gp95,\n",
        "            upper_gp96,\n",
        "            upper_gp97,\n",
        "            upper_gp98,\n",
        "            upper_gp99,\n",
        "            upper_gp100,\n",
        "            upper_gp101]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 170,
      "metadata": {
        "id": "jox8uqaeJLmu"
      },
      "outputs": [],
      "source": [
        "### Summarise arrays: 'STP'\n",
        "\n",
        "lower_stp = [lower_stp1,\n",
        "            lower_stp2,\n",
        "            lower_stp3,\n",
        "            lower_stp4,\n",
        "            lower_stp5,\n",
        "            lower_stp6,\n",
        "            lower_stp7,\n",
        "            lower_stp8,\n",
        "            lower_stp9,\n",
        "            lower_stp10,\n",
        "            lower_stp11,\n",
        "            lower_stp12,\n",
        "            lower_stp13,\n",
        "            lower_stp14,\n",
        "            lower_stp15,\n",
        "            lower_stp16,\n",
        "            lower_stp17,\n",
        "            lower_stp18,\n",
        "            lower_stp19,\n",
        "            lower_stp20,\n",
        "            lower_stp21,\n",
        "            lower_stp22,\n",
        "            lower_stp23,\n",
        "            lower_stp24,\n",
        "            lower_stp25,\n",
        "            lower_stp26,\n",
        "            lower_stp27,\n",
        "            lower_stp28,\n",
        "            lower_stp29,\n",
        "            lower_stp30,\n",
        "            lower_stp31,\n",
        "            lower_stp32,\n",
        "            lower_stp33,\n",
        "            lower_stp34,\n",
        "            lower_stp35,\n",
        "            lower_stp36,\n",
        "            lower_stp37,\n",
        "            lower_stp38,\n",
        "            lower_stp39,\n",
        "            lower_stp40,\n",
        "            lower_stp41,\n",
        "            lower_stp42,\n",
        "            lower_stp43,\n",
        "            lower_stp44,\n",
        "            lower_stp45,\n",
        "            lower_stp46,\n",
        "            lower_stp47,\n",
        "            lower_stp48,\n",
        "            lower_stp49,\n",
        "            lower_stp50,\n",
        "            lower_stp51,\n",
        "            lower_stp52,\n",
        "            lower_stp53,\n",
        "            lower_stp54,\n",
        "            lower_stp55,\n",
        "            lower_stp56,\n",
        "            lower_stp57,\n",
        "            lower_stp58,\n",
        "            lower_stp59,\n",
        "            lower_stp60,\n",
        "            lower_stp61,\n",
        "            lower_stp62,\n",
        "            lower_stp63,\n",
        "            lower_stp64,\n",
        "            lower_stp65,\n",
        "            lower_stp66,\n",
        "            lower_stp67,\n",
        "            lower_stp68,\n",
        "            lower_stp69,\n",
        "            lower_stp70,\n",
        "            lower_stp71,\n",
        "            lower_stp72,\n",
        "            lower_stp73,\n",
        "            lower_stp74,\n",
        "            lower_stp75,\n",
        "            lower_stp76,\n",
        "            lower_stp77,\n",
        "            lower_stp78,\n",
        "            lower_stp79,\n",
        "            lower_stp80,\n",
        "            lower_stp81,\n",
        "            lower_stp82,\n",
        "            lower_stp83,\n",
        "            lower_stp84,\n",
        "            lower_stp85,\n",
        "            lower_stp86,\n",
        "            lower_stp87,\n",
        "            lower_stp88,\n",
        "            lower_stp89,\n",
        "            lower_stp90,\n",
        "            lower_stp91,\n",
        "            lower_stp92,\n",
        "            lower_stp93,\n",
        "            lower_stp94,\n",
        "            lower_stp95,\n",
        "            lower_stp96,\n",
        "            lower_stp97,\n",
        "            lower_stp98,\n",
        "            lower_stp99,\n",
        "            lower_stp100,\n",
        "            lower_stp101]\n",
        "\n",
        "median_stp = [median_stp1,\n",
        "            median_stp2,\n",
        "            median_stp3,\n",
        "            median_stp4,\n",
        "            median_stp5,\n",
        "            median_stp6,\n",
        "            median_stp7,\n",
        "            median_stp8,\n",
        "            median_stp9,\n",
        "            median_stp10,\n",
        "            median_stp11,\n",
        "            median_stp12,\n",
        "            median_stp13,\n",
        "            median_stp14,\n",
        "            median_stp15,\n",
        "            median_stp16,\n",
        "            median_stp17,\n",
        "            median_stp18,\n",
        "            median_stp19,\n",
        "            median_stp20,\n",
        "            median_stp21,\n",
        "            median_stp22,\n",
        "            median_stp23,\n",
        "            median_stp24,\n",
        "            median_stp25,\n",
        "            median_stp26,\n",
        "            median_stp27,\n",
        "            median_stp28,\n",
        "            median_stp29,\n",
        "            median_stp30,\n",
        "            median_stp31,\n",
        "            median_stp32,\n",
        "            median_stp33,\n",
        "            median_stp34,\n",
        "            median_stp35,\n",
        "            median_stp36,\n",
        "            median_stp37,\n",
        "            median_stp38,\n",
        "            median_stp39,\n",
        "            median_stp40,\n",
        "            median_stp41,\n",
        "            median_stp42,\n",
        "            median_stp43,\n",
        "            median_stp44,\n",
        "            median_stp45,\n",
        "            median_stp46,\n",
        "            median_stp47,\n",
        "            median_stp48,\n",
        "            median_stp49,\n",
        "            median_stp50,\n",
        "            median_stp51,\n",
        "            median_stp52,\n",
        "            median_stp53,\n",
        "            median_stp54,\n",
        "            median_stp55,\n",
        "            median_stp56,\n",
        "            median_stp57,\n",
        "            median_stp58,\n",
        "            median_stp59,\n",
        "            median_stp60,\n",
        "            median_stp61,\n",
        "            median_stp62,\n",
        "            median_stp63,\n",
        "            median_stp64,\n",
        "            median_stp65,\n",
        "            median_stp66,\n",
        "            median_stp67,\n",
        "            median_stp68,\n",
        "            median_stp69,\n",
        "            median_stp70,\n",
        "            median_stp71,\n",
        "            median_stp72,\n",
        "            median_stp73,\n",
        "            median_stp74,\n",
        "            median_stp75,\n",
        "            median_stp76,\n",
        "            median_stp77,\n",
        "            median_stp78,\n",
        "            median_stp79,\n",
        "            median_stp80,\n",
        "            median_stp81,\n",
        "            median_stp82,\n",
        "            median_stp83,\n",
        "            median_stp84,\n",
        "            median_stp85,\n",
        "            median_stp86,\n",
        "            median_stp87,\n",
        "            median_stp88,\n",
        "            median_stp89,\n",
        "            median_stp90,\n",
        "            median_stp91,\n",
        "            median_stp92,\n",
        "            median_stp93,\n",
        "            median_stp94,\n",
        "            median_stp95,\n",
        "            median_stp96,\n",
        "            median_stp97,\n",
        "            median_stp98,\n",
        "            median_stp99,\n",
        "            median_stp100,\n",
        "            median_stp101]\n",
        "\n",
        "upper_stp = [upper_stp1,\n",
        "            upper_stp2,\n",
        "            upper_stp3,\n",
        "            upper_stp4,\n",
        "            upper_stp5,\n",
        "            upper_stp6,\n",
        "            upper_stp7,\n",
        "            upper_stp8,\n",
        "            upper_stp9,\n",
        "            upper_stp10,\n",
        "            upper_stp11,\n",
        "            upper_stp12,\n",
        "            upper_stp13,\n",
        "            upper_stp14,\n",
        "            upper_stp15,\n",
        "            upper_stp16,\n",
        "            upper_stp17,\n",
        "            upper_stp18,\n",
        "            upper_stp19,\n",
        "            upper_stp20,\n",
        "            upper_stp21,\n",
        "            upper_stp22,\n",
        "            upper_stp23,\n",
        "            upper_stp24,\n",
        "            upper_stp25,\n",
        "            upper_stp26,\n",
        "            upper_stp27,\n",
        "            upper_stp28,\n",
        "            upper_stp29,\n",
        "            upper_stp30,\n",
        "            upper_stp31,\n",
        "            upper_stp32,\n",
        "            upper_stp33,\n",
        "            upper_stp34,\n",
        "            upper_stp35,\n",
        "            upper_stp36,\n",
        "            upper_stp37,\n",
        "            upper_stp38,\n",
        "            upper_stp39,\n",
        "            upper_stp40,\n",
        "            upper_stp41,\n",
        "            upper_stp42,\n",
        "            upper_stp43,\n",
        "            upper_stp44,\n",
        "            upper_stp45,\n",
        "            upper_stp46,\n",
        "            upper_stp47,\n",
        "            upper_stp48,\n",
        "            upper_stp49,\n",
        "            upper_stp50,\n",
        "            upper_stp51,\n",
        "            upper_stp52,\n",
        "            upper_stp53,\n",
        "            upper_stp54,\n",
        "            upper_stp55,\n",
        "            upper_stp56,\n",
        "            upper_stp57,\n",
        "            upper_stp58,\n",
        "            upper_stp59,\n",
        "            upper_stp60,\n",
        "            upper_stp61,\n",
        "            upper_stp62,\n",
        "            upper_stp63,\n",
        "            upper_stp64,\n",
        "            upper_stp65,\n",
        "            upper_stp66,\n",
        "            upper_stp67,\n",
        "            upper_stp68,\n",
        "            upper_stp69,\n",
        "            upper_stp70,\n",
        "            upper_stp71,\n",
        "            upper_stp72,\n",
        "            upper_stp73,\n",
        "            upper_stp74,\n",
        "            upper_stp75,\n",
        "            upper_stp76,\n",
        "            upper_stp77,\n",
        "            upper_stp78,\n",
        "            upper_stp79,\n",
        "            upper_stp80,\n",
        "            upper_stp81,\n",
        "            upper_stp82,\n",
        "            upper_stp83,\n",
        "            upper_stp84,\n",
        "            upper_stp85,\n",
        "            upper_stp86,\n",
        "            upper_stp87,\n",
        "            upper_stp88,\n",
        "            upper_stp89,\n",
        "            upper_stp90,\n",
        "            upper_stp91,\n",
        "            upper_stp92,\n",
        "            upper_stp93,\n",
        "            upper_stp94,\n",
        "            upper_stp95,\n",
        "            upper_stp96,\n",
        "            upper_stp97,\n",
        "            upper_stp98,\n",
        "            upper_stp99,\n",
        "            upper_stp100,\n",
        "            upper_stp101]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 172,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "W4hkYeeMJLmw",
        "outputId": "8391b9c2-d8e2-4be1-c042-9b71b24a234c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "### Visualise!\n",
        "\n",
        "title = obj_func\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(median_gp, color = 'Red')\n",
        "plt.plot(median_stp, color = 'Blue')\n",
        "\n",
        "xstar = np.arange(0, max_iter+1, step=1)\n",
        "plt.fill_between(xstar, lower_gp, upper_gp, facecolor = 'Red', alpha=0.4, label='GP ERM Regret: IQR')\n",
        "plt.fill_between(xstar, lower_stp, upper_stp, facecolor = 'Blue', alpha=0.4, label='STP ERM Regret: IQR ' r'($\\nu$' ' = {})'.format(df))\n",
        "\n",
        "plt.title(title, weight = 'bold', family = 'Arial')\n",
        "plt.xlabel('(Post-initialisation) iteration $\\it{k}$', weight = 'bold') # x-axis label\n",
        "plt.ylabel('ln(Regret)', weight = 'bold', family = 'Arial') # y-axis label\n",
        "plt.legend(loc=0) # add plot legend\n",
        "\n",
        "plt.show() #visualise\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 171,
      "metadata": {
        "id": "5TOZMC49JLmw"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}